<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Карманная книга по WebRTC on Roman Kurnovskii</title><link>https://romankurnovskii.com/ru/tracks/webrtc/</link><description>Recent content in Карманная книга по WebRTC on Roman Kurnovskii</description><generator>Hugo -- gohugo.io</generator><language>ru</language><copyright>&amp;copy; 2023 &lt;a href="https://romankurnovskii.com">Roman Kurnovskii&lt;/a> personal page</copyright><lastBuildDate>Sat, 02 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://romankurnovskii.com/ru/tracks/webrtc/index.xml" rel="self" type="application/rss+xml"/><item><title>Мультимедиа-устройства</title><link>https://romankurnovskii.com/ru/tracks/webrtc/media-devices/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/media-devices/</guid><description>Мультимедиа-устройства Начало работы с мультимедийными устройствами При web-разработке WebRTC-стандарт предоставляет API для доступа к камерам и микрофонам, подключенным к компьютеру или смартфону. Эти устройства обычно называются мультимедийными устройствами, и к ним можно получить доступ с помощью Java-скрипта через объект navigator.mediaDevices, который реализует интерфейс MediaDevices. С помощью этого объекта мы можем просмотреть все подключенные устройства, отслеживать изменения статуса устройства (когда устройство подключается или отключается) и открывать устройство для извлечения мультимедийного потока (см. ниже). Чаще всего для этого используют функцию getUserMedia(), которая возвращает промис, который будет преобразован в MediaStream для соответствующих мультимедийных устройств.</description></item><item><title>Захват мультимедиа и ограничения</title><link>https://romankurnovskii.com/ru/tracks/webrtc/media-capture-and-constraints/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/media-capture-and-constraints/</guid><description>Захват мультимедиа и ограничения Мультимедиа-часть WebRTC показывает, как получить доступ к оборудованию, способному записывать видео и аудио (например, камеры и микрофоны), а также как работают медиа-потоки. И помимо этого – средства отображения, которые позволяют делать захват экрана.
Мультимедиа-устройства Все камеры и микрофоны, поддерживаемые браузером, доступны и управляются через объект navigator.mediaDevices. Приложения могут получать текущий список подсоединенных устройств и отслеживать изменения, т.к. многие камеры и микрофоны подсоединены через USB, и могут подключаться/отключаться в течение работы приложения. Поскольку статус мультимедиа-устройства может меняться в любой момент времени, рекомендуем, чтоб приложения регистрировали все изменения в статусе устройства для правильной обработки статусов изменений.</description></item><item><title>Одноранговые соединения</title><link>https://romankurnovskii.com/ru/tracks/webrtc/peer-connections/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/peer-connections/</guid><description>Начало работы с одноранговыми соединениями Одноранговые соединения – часть спецификации WebRTC, которая занимается связью двух приложений на различных компьютерах для коммуникации через P2P-протокол. Коммуникация между узлами может быть видео-, аудио- или произвольными двоичными данными (для клиентов, поддерживающих RTCDataChannel API). Чтобы выяснить, как два узла могут быть соединены, оба клиента должны предоставить конфигурацию ICE-Server. Это или STUN, или TURN-сервер, и их роль – обеспечить ICE-кандидатов для каждого клиента, который затем передается на удаленный узел. Эта «передача» ICE-кандидатов обычно называется «сигналинг».</description></item><item><title>Удаленные потоки</title><link>https://romankurnovskii.com/ru/tracks/webrtc/remote-streams/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/remote-streams/</guid><description>Начало работы с удаленными потоками Как только RTCPeerConnection подключился к удаленному узлу, между ними можно передавать аудио- и видео-потоки. Это точка, в которой мы подключаем поток, полученный от getUserMedia(), к RTCPeerConnection. Медиаопоток состоит как минимум из одной дорожки мультимедиа, и они по отдельности добавляются в RTCPeerConnection, когда мы хотим передать данные удаленному узлу.
1const localStream = await getUserMedia({vide: true, audio: true}); 2const peerConnection = new RTCPeerConnection(iceConfig); 3localStream.getTracks().forEach(track =&amp;gt; { 4 peerConnection.addTrack(track, localStream); 5}); Дорожки можно добавлять в RTCPeerConnection до подключения к удаленному узлу, поэтому имеет смысл выполнить эту настройку как можно раньше, а не ждать завершения соединения.</description></item><item><title>Каналы данных</title><link>https://romankurnovskii.com/ru/tracks/webrtc/data-channels/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/data-channels/</guid><description>Стандарт WebRTC также охватывает API для отправки произвольных данных через RTCPeerConnection. Это происходит через запрос createDataChannel() для объекта RTCPeerConnection, который возвращает объект RTCDataChannel.
const peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel();
Удаленный узел может получать каналы данных через отслеживание события datachannel в объекте RTCPeerConnection. Полученное событие имеет тип RTCDataChannelEvent и содержит свойство channel, которое представляет RTCDataChannel между двумя узлами.
1const peerConnection = new RTCPeerConnection(configuration); 2peerConnection.addEventListener(&amp;#39;datachannel&amp;#39;, event =&amp;gt; { 3 const dataChannel = event.channel; 4}); События Open и Close Прежде чем канал данных можно будет использовать для отправки данных, клиент должен дождаться его открытия.</description></item><item><title>TURN сервер</title><link>https://romankurnovskii.com/ru/tracks/webrtc/turn-server/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/turn-server/</guid><description>Для работы большинства приложений WebRTC необходим сервер для ретрансляции трафика между узлами, поскольку прямой сокет часто невозможен между клиентами (если только они не находятся в одной локальной сети). Обычный способ решить эту проблему — использовать TURN-сервер (Traversal Using Relay NAT), который представляет собой протокол ретрансляции сетевого трафика.
В настоящее время существует несколько вариантов TURN-серверов, доступных в Интернете, как в виде самостоятельных приложений (например, проект COTURN с открытым исходным кодом), так и в виде облачных сервисов.</description></item><item><title>Тестирование приложений WebRTC</title><link>https://romankurnovskii.com/ru/tracks/webrtc/testing/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/testing/</guid><description>При написании автоматических тестов для приложений WebRTC, существуют полезные конфигурации, которые можно включить для браузеров, и которые упростят разработку и тестирование.
Chrome При запуске автоматических тестов в Chrome полезны следующие функции:
&amp;ndash;allow-file-access-from-files — дает API-доступ для file://URLs &amp;ndash;disable-translate — отключает всплывающие окна &amp;ndash;use-fake-ui-for-media-stream — Представляет поддельные медиапотоки. Полезно при работе на CI-серверах. &amp;ndash;use-file-for-fake-audio-capture= — дает возможность использовать файл при захвате звука. &amp;ndash;use-file-for-fake-video-capture= — дает возможность использовать файл при захвате видео. &amp;ndash;headless - Запустить в автономном режиме.</description></item><item><title>Формат SDP унифицированного плана – план перехода</title><link>https://romankurnovskii.com/ru/tracks/webrtc/unified-plan-transition-guide/</link><pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate><guid>https://romankurnovskii.com/ru/tracks/webrtc/unified-plan-transition-guide/</guid><description>Google планирует перевести реализацию WebRTC в Chrome с текущего SDP-формата (называемого «Plan B») на формат соответствующих стандартов («Unified Plan», draft-ietf-rtcweb-jsep) в течение следующих нескольких кварталов. План включает 5 этапов и одну временную функцию API.
Кто будет затронут? Людям, которые используют несколько аудиодорожек или несколько видеодорожек в одном PeerConnection, придется протестировать свой продукт в рамках Унифицированного Плана и, соответственно, адаптироваться. В случае, когда вызов инициируется с конечной точки не из Chrome, и на него отвечают в Chrome, форма запросов может измениться.</description></item></channel></rss>