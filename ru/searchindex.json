[{"content":"Введение - День 1 Первый день из 90, чтобы получить хорошее базовое понимание DevOps и инструментов.\nЭтот путь обучения начался для меня несколько лет назад, но тогда я сосредоточился на платформах виртуализации и облачных технологиях. В основном я изучал инфраструктуру как код и управление конфигурацией приложений с помощью Terraform и Chef.\nПеренесемся в март 2021 года. Мне представилась прекрасная возможность сосредоточить свои усилия на стратегии Cloud Native в Kasten by Veeam. Это должно было стать огромным фокусом на Kubernetes и DevOps, а также на сообществе, окружающем эти технологии. Я начал свое обучение и быстро понял, что помимо изучения основ Kubernetes и контейнеризации существует очень широкий мир, и именно тогда я начал общаться с сообществом и узнавать все больше и больше о культуре, инструментах и ​​​​процессах DevOps, поэтому я начал публично документировать некоторые области, которые я хотел изучить.\nНачнем наше путешествие Если вы прочитаете приведенный выше блог, вы увидите, что это содержание высокого уровня для моего учебного пути, и я скажу, что на данный момент я не являюсь экспертом ни в одном из этих разделов, но я хотел поделиться некоторыми БЕСПЛАТНЫМИ ресурсами. а некоторые платные, но вариант для обоих, так как у всех разные обстоятельства.\nВ течение следующих 90 дней я хочу задокументировать эти ресурсы и охватить эти основополагающие области. Я бы хотел, чтобы сообщество также приняло участие, поделилось своим путешествием и ресурсами, чтобы мы могли учиться публично и помогать друг другу.\nИз начального файла readme в репозитории проекта вы увидите, что я разделил все на разделы, и в основном это 12 недель плюс 6 дней. Первые 6 дней мы будем изучать основы DevOps в целом, прежде чем погрузиться в некоторые конкретные области, этот список ни в коем случае не является исчерпывающим, и мы снова будем рады, если сообщество поможет сделать этот ресурс полезным.\nЕще один ресурс, которым я поделюсь на этом этапе, который, я думаю, каждый должен внимательно изучить и, возможно, создать свою собственную карту ума для себя, своих интересов и позиции:\nDevOps Roadmap\nЯ нашел это отличным ресурсом, когда создавал свой первоначальный список и сообщение в блоге по этой теме. Вы также можете заметить, что помимо 12 тем, которые я перечислил здесь, в этом репозитории, есть и другие разделы, требующие более подробного рассмотрения.\nПервые шаги - или что такое DevOps? Есть так много статей в блогах и видео на YouTube, которые можно перечислить здесь, но поскольку мы начинаем 90-дневное испытание и сосредоточиваемся на том, чтобы тратить около часа в день на изучение чего-то нового или о DevOps, я подумал, что было бы хорошо получить некоторые из высокого уровня «что такое DevOps» для начала.\nВо-первых, DevOps — это не инструмент. Вы не можете купить его, это не номер программного обеспечения или репозиторий GitHub с открытым исходным кодом, который вы можете скачать. Это также не язык программирования, это также не какая-то магия темного искусства.\nDevOps — это способ делать более разумные вещи в разработке программного обеспечения. - Подождите… Но если вы не разработчик программного обеспечения, вы должны отвернуться прямо сейчас и не погрузиться в этот проект??? Нет, совсем нет, оставайтесь… Потому что DevOps объединяет разработку программного обеспечения и эксплуатацию. Ранее я упоминал, что больше занимаюсь виртуальными машинами, и это, как правило, относится к сфере эксплуатации, но в сообществе есть люди с самым разным опытом, и DevOps на 100 % принесет пользу отдельным лицам, разработчикам, специалистам по эксплуатации и Все инженеры по контролю качества могут в равной степени изучить эти передовые методы, лучше разбираясь в DevOps.\nDevOps — это набор практик, которые помогают достичь цели этого движения: сократить время между фазой создания идеи продукта и его выпуском в производство для конечного пользователя или кого бы то ни было, внутренней команды или клиента.\nЕще одна область, в которую мы углубимся в первую неделю, касается Методологии Agile. DevOps и Agile широко применяются вместе для обеспечения непрерывной доставки вашего Приложения.\nГлавный вывод заключается в том, что образ мышления или культура DevOps позволяют сократить затянувшийся процесс выпуска программного обеспечения с потенциально многих лет до возможности более частого выпуска небольших выпусков. Другой ключевой принцип, который следует здесь усвоить, заключается в том, что речь идет о разрушении разрозненности между командами, о которых я упоминал ранее, разработчиками, эксплуатацией и контролем качества.\nС точки зрения DevOps, разработка, тестирование и развертывание выполняются командой DevOps.\nПоследнее, что я хотел бы сделать, чтобы сделать это максимально эффективным и действенным, мы должны использовать автоматизацию\nИсточники Я всегда открыт для добавления дополнительных ресурсов в эти файлы readme, поскольку они здесь в качестве учебного пособия.\nМой совет — посмотрите все ссылки ниже, и, надеюсь, вы тоже что-то почерпнули из текста и объяснений выше.\nDevOps in 5 Minutes What is DevOps? Easy Way DevOps roadmap 2022 | Success Roadmap 2022 ","description":"DevOps - общее представление","title":"1. DevOps - общее представление","uri":"/ru/tracks/90daysofdevops/day01/"},{"content":"Окружение Go В 8-м дне мы кратко рассмотрели рабочее пространство Go, чтобы запустить его и перейти к демонстрации «Hello #90DaysOfDevOps». Но мы должны немного рассказать о рабочем пространстве Go.\nПомните, что мы выбрали значения по умолчанию, а затем прошли и создали нашу папку Go в GOPATH, который уже был определен, но на самом деле этот GOPATH можно изменить, чтобы он находился там, где вы хотите.\nЕсли вы запустите\necho $GOPATH Вывод должен быть похож на мой (может быть с другим именем пользователя), а именно:\n/home/michael/projects/go Затем здесь мы создали 3 директории. src, pkg и bin\nsrc is where all of your Go programs and projects are stored. This handles namespacing package management for all your Go repositories. This is where you will see on our workstation we have our Hello folder for the Hello #90DaysOfDevOps project.\npkg — это место, где хранятся ваши заархивированные файлы пакетов, которые установлены или были установлены в программах. Это помогает ускорить процесс компиляции в зависимости от того, были ли изменены используемые пакеты. bin — это место, где хранятся все ваши скомпилированные двоичные файлы.\nНаш Hello #90DaysOfDevOps не является сложной программой, поэтому вот пример более сложной программы Go, взятой из другого замечательного ресурса, на который стоит обратить внимание GoChronicles Компиляция и запуск кода На 9-й день мы также рассмотрели краткое введение в компиляцию кода, но здесь мы можем пойти немного глубже.\nЧтобы запустить наш код, мы сначала должны его скомпилировать. В Go это можно сделать тремя способами.\ngo build go install go run Прежде чем мы перейдем к описанному выше этапу компиляции, нам нужно взглянуть на то, что мы получаем при установке Go.\nКогда мы установили Go на 8-й день, мы установили что-то, известное как инструменты Go, которые состоят из нескольких программ, которые позволяют нам создавать и обрабатывать наши исходные файлы Go. Одним из инструментов является «Go».\nСтоит отметить, что вы можете установить дополнительные инструменты, которых нет в стандартной установке Go.\nЕсли вы откроете командную строку и наберете «go», вы должны увидеть что-то вроде изображения ниже, а затем вы увидите «Дополнительные разделы справки» ниже, и пока нам не нужно беспокоиться об этом.\nВозможно, вы также помните, что мы уже использовали как минимум два из этих инструментов в День 8. Мы хотим узнать больше о сборке, установке и запуске.\ngo run - Эта команда компилирует и запускает основной пакет, состоящий из файлов .go, указанных в командной строке. Команда компилируется во временную папку. go build - чтобы скомпилировать пакеты и зависимости, скомпилируйте пакет в текущем каталоге. Если пакет «main», поместит исполняемый файл в текущий каталог, если нет, то он поместит исполняемый файл в папку «pkg». go build также позволяет вам создать исполняемый файл для любой платформы ОС, поддерживаемой Go. go install - то же самое, что и go build, но помещает исполняемый файл в папку bin Мы прошли через go build и go run, но не стесняйтесь запускать их снова здесь, если хотите, go install, как указано выше, помещает исполняемый файл в нашу папку bin. Надеюсь, что вы следите за мной и смотрите один из плейлистов или видеороликов ниже. Я беру их по кусочкам и перевожу в свои заметки, чтобы понять основы языка Голанг. Приведенные ниже ресурсы, вероятно, дадут вам гораздо лучшее понимание многих областей, которые вам нужны в целом, но я пытаюсь задокументировать 7 дней или 7 часов путешествия с интересными вещами, которые я нашел.\nИсточники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 11-й день\n","description":"Окружение Go","title":"10. Окружение Go","uri":"/ru/tracks/90daysofdevops/day10/"},{"content":"Прежде чем мы перейдем к темам сегодняшнего дня, я хочу выразить огромную благодарность Techworld with Nana и этому фантастическому краткому путешествию по основам Go.\nВ 8-м дне мы настроили нашу среду, в 9-м дне мы разобрали код Hello #90DaysOfDevOps, а в 10-м дне) мы поработали с нашей рабочей средой Go и немного углубились в компиляцию и запуск кода.\nСегодня мы рассмотрим переменные, константы и типы данных при написании новой программы.\nПеременные и константы в Go Давайте начнем с планирования нашего приложения, я думаю, было бы неплохо поработать над программой, которая сообщает нам, сколько дней осталось в нашем испытании #90DaysOfDevOps.\nПервое, что нужно учитывать, это то, что, поскольку мы создаем наше приложение, мы приветствуем наших посетителей и даем пользователям отзывы о количестве дней, которые они выполнили, мы можем использовать термин #90DaysOfDevOps много раз на протяжении всей программы. Это отличный вариант использования переменной #90DaysOfDevOps в нашей программе.\nПеременные используются для хранения значений. Как маленькая коробка с нашей сохраненной информацией или ценностями. Затем мы можем использовать эту переменную во всей программе, что также выгодно тем, что если эта задача или переменная изменится, нам нужно будет изменить это только в одном месте. Это означает, что мы могли бы перенести это на другие проблемы, с которыми мы сталкиваемся в сообществе, просто изменив значение этой переменной. Чтобы объявить это в нашей программе Go, мы определяем значение, используя ключевое слово для переменных. Это будет жить в нашем блоке кода func main, который вы увидите позже. Подробнее о Ключевых словах можно узнать здесь.\nНе забудьте убедиться, что ваши имена переменных являются понятными. Если вы объявляете переменную, вы должны использовать ее, иначе вы получите ошибку. Это делается для того, чтобы избежать возможного неиспользованного кода. То же самое для неиспользуемых пакетов.\nvar challenge = \"#90DaysOfDevOps\" С приведенным выше набором и использованием, как мы увидим в следующем фрагменте кода, вы можете видеть из вывода ниже, что мы использовали переменную.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" fmt.Println(\"Welcome to\", challenge \"\") } Затем вы увидите ниже, что мы построили наш код с помощью приведенного выше примера и получили вывод, показанный ниже. Мы также знаем, что наш челендж длится как минимум 90 дней для этой задачи, но в следующей, может быть, будет 100, поэтому мы хотим определить переменную, которая поможет нам. Однако для нашей программы мы хотим определить это как константу. Константы похожи на переменные, за исключением того, что их значение не может быть изменено в коде (мы все еще можем создать новое приложение позже с этим кодом и изменить эту константу, но это 90 не изменится, пока мы запускаем наше приложение)\nДобавим const в наш код и добавим еще одну строку кода, чтобы напечатать результат.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 fmt.Println(\"Welcome to\", challenge) fmt.Println(\"This is a\", daystotal, \"challenge\") } Если мы затем снова пройдем этот процесс go build и запустим, вы увидите результат.\nНо это не будет концом нашей программы, мы вернемся к ней в 12-м дне, чтобы добавить больше функциональности. Теперь мы хотим добавить еще одну переменную для количества дней, в течение которых мы выполнили задание.\nНиже я добавил переменную dayscomplete с количеством завершенных дней.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 var dayscomplete = 11 fmt.Println(\"Welcome to\", challenge, \"\") fmt.Println(\"This is a\", daystotal, \"challenge and you have completed\", dayscomplete, \"days\") fmt.Println(\"Great work\") } Давайте снова запустим go build, или вы можете просто использовать go run\nВот несколько других примеров, которые я использовал, чтобы упростить чтение и редактирование кода. До сих пор мы использовали Println, но мы можем упростить это, используя Printf, используя %v, что означает, что мы определяем наши переменные по порядку в конце строки кода. мы также используем \\n для разрыва строки.\nЯ использую %v, поскольку здесь используется значение по умолчанию, но есть и другие параметры, которые можно найти документации пакета fmt.\nПеременные также могут быть определены в вашем коде в более простом формате. Вместо того, чтобы определять, что это var и type, вы можете закодировать это следующим образом, чтобы получить ту же функциональность, но более чистый и простой вид вашего кода. Это будет работать только для переменных, а не для констант.\nfunc main() { challenge := \"#90DaysOfDevOps\" const daystotal = 90 Типы в Go В приведенных выше примерах мы не определили тип переменных, это потому, что мы можем задать им значение, Go достаточно умен, чтобы знать, что это за тип, или, по крайней мере, может сделать вывод, что это на основе значения, которое вы сохранили. . Однако, если мы хотим, чтобы пользователь ввел данные, для этого потребуется определенный тип.\nДо сих пор в нашем коде использовались строки и целые числа. Целые числа для количества дней и строки для названия задачи.\nТакже важно отметить, что каждый тип данных может выполнять разные действия и вести себя по-разному. Например, целые числа могут умножаться там, где нет строк.\nЕсть четыре категории\nBasic type: в эту категорию попадают числа, строки и логические значения. Aggregate type: к этой категории относятся массивы и структуры. Reference type: в эту категорию попадают указатели, срезы, карты, функции и каналы. Interface type Тип данных — важная концепция в программировании. Тип данных определяет размер и тип значений переменных.\nGo статически типизирован, а это означает, что после определения типа переменной он может хранить данные только этого типа.\nВ Go есть три основных типа данных:\nbool: представляет логическое значение и может быть либо истинным, либо ложным. Numeric: представляет целые типы, значения с плавающей запятой и сложные типы. string: представляет строковое значение. Я нашел этот ресурс очень подробным о типах данных Golang by example\nЯ бы также посоветовал Techworld with Nana на этом этапе довольно подробно рассказать о типах данных в Go.\nЕсли нам нужно определить тип в нашей переменной, мы можем сделать это так:\nvar TwitterHandle string var DaysCompleted uint Поскольку Go принимает переменные, которым задано значение, мы можем распечатать эти значения следующим образом:\nfmt.Printf(\"challenge is %T, daystotal is %T, dayscomplete is %T\\n\", conference, daystotal, dayscomplete) Существует много различных типов целых чисел и типов с плавающей запятой, ссылки выше подробно описывают их.\nint = целые числа unint = беззнаковые целые числа floating point types = числа с плавающей запятой Источники Введение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Далее мы начнем добавлять в нашу программу некоторые функции пользовательского ввода, чтобы программа спрашивала, сколько дней было завершено.\nУвидимся завтра.\n","description":"Переменные и константы в Go","title":"11. Переменные и константы в Go","uri":"/ru/tracks/90daysofdevops/day11/"},{"content":"Получение данных с клавиуатуры Вчера (Днем 11-м) мы создали нашу первую программу Go, и данные, которые мы хотели получить от пользователя, были созданы как переменные в нашем коде. Теперь мы хотим спросить пользователя данные для ввода, чтобы дать переменной значение для конечного сообщения.\nПолучение пользовательских данных Прежде чем мы это сделаем, давайте еще раз взглянем на наше приложение и пройдемся по переменным, которые нам нужны в качестве теста, прежде чем получить этот пользовательский ввод.\nДавайте теперь добавим новую переменную с именем TwitterName, вы можете найти этот новый код ниже, и если мы запустим этот код, это будет наш вывод.\npackage main import \"fmt\" func main() { challenge := \"#90DaysOfDevOps\" const daystotal = 90 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge\\n\", daystotal) var TwitterName string var DaysComplete int // ask user for their twitter handle TwitterName = \"@MichaelCade1\" DaysComplete = 12 fmt.Printf(\"%v has completed %v days of the challenge\\n\", TwitterName, DaysComplete) fmt.Println(\"Great work\") } Прежде чем мы это сделаем, давайте еще раз взглянем на наше приложение и пройдемся по переменным, которые нам нужны в качестве теста, прежде чем получить этот пользовательский ввод.\nВчера мы закончили с нашим кодом, выглядящим так:\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 var dayscomplete = 11 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge and you have completed %v days\\n\", daystotal, dayscomplete) fmt.Println(\"Great work\") } Мы вручную определили в коде наши переменные и константы challenge, daystotal, dayscomplete.\nДавайте теперь добавим новую переменную с именем TwitterName\nУ нас 12-й день, и нам нужно было бы менять dayscomplete каждый день и компилировать наш код каждый день, если бы он был жестко запрограммирован, что звучит не так уж здорово.\nПолучая пользовательский ввод, мы хотим получить значение, возможно, имя и количество завершенных дней. Для этого мы можем использовать другую функцию из пакета fmt.\nКратко о пакете fmt, различные функции для: форматированного ввода и вывода (I/O) (input and output)\nПечать сообщений Собирать пользовательский ввод Записать в файл Это вместо того, чтобы присваивать значение переменной, мы хотим попросить пользователя ввести его.\nfmt.Scan(\u0026TwitterName) Обратите внимание, что мы также используем \u0026 перед переменной. Этот символ известен как указатель, который мы рассмотрим в следующем разделе.\nВ нашем коде вы можете видеть, что мы просим пользователя ввести две переменные, TwitterName и DaysCompleted\npackage main import \"fmt\" func main() { const DaysTotal int = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Println(\"Good luck\") } Давайте теперь запустим нашу программу, и вы увидите, что у нас есть входные данные для обоих вышеперечисленных.\nХорошо, мы получили некоторый пользовательский ввод и напечатали сообщение, но как насчет того, чтобы заставить нашу программу сообщать нам, сколько дней у нас осталось в нашей задаче.\nДля этого мы создали переменную с именем remainingDays, и мы жестко оценили ее в нашем коде как 90. Затем нам нужно изменить значение этого значения, чтобы распечатать remainingDays, когда мы получим пользовательский ввод DaysCompleted мы можем сделать это с помощью этого простого изменения переменной.\nremainingDays = remainingDays - DaysCompleted Наша программа теперь выглядит вот так:\npackage main import \"fmt\" func main() { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } Если мы теперь запустим эту программу, вы увидите, что простой расчет выполняется на основе пользовательского ввода и значения remainingDays\nЧто такое указатель? (Специальные переменные) Указатель — это (специальная) переменная, которая указывает на адрес памяти другой переменной.\nОтличное объяснение этого можно найти здесь geeksforgeeks\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" fmt.Println(challenge) fmt.Println(\u0026challenge) } Ниже выполняется этот код.\nРесурсы Введение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся завтра.\n","description":"Получение пользовательского ввода с помощью указателей и готовой программы","title":"12. Golang - чтение данных и указатели","uri":"/ru/tracks/90daysofdevops/day12/"},{"content":"Твитните о своем прогрессе с нашим новым приложением В последний день изучения этого языка программирования мы только коснулись его основ, но я думаю, что это начало.\nЗа последние несколько дней мы взяли небольшую идею для приложения и добавили функциональность, в этой статье я хочу воспользоваться преимуществами тех пакетов, которые мы упомянули, и создать функциональность для нашего приложения, чтобы не только дать вам обновление вашего прогресса на экране, но также отправьте твит с подробностями задачи и вашим статусом.\nДобавление возможности твитить свой прогресс Первое, что нам нужно сделать, это настроить доступ API разработчика к Twitter, чтобы это работало.\nПерейдите на Платформу разработчиков Twitter и войдите в систему, используя свой идентификатор Twitter и данные. Оказавшись внутри, вы должны увидеть что-то вроде приведенного ниже без приложения, которое я уже создал.\nЗдесь вы также можете запросить дополнительный доступ. Это может занять некоторое время, но для меня это было очень быстро.\nЗатем мы должны выбрать «Projects \u0026 Apps» и создать наше приложение. Ограничения зависят от доступа к вашей учетной записи, при этом у вас должно быть только одно приложение и один проект, а с повышенными правами у вас может быть 3 приложения.\nДайте вашему приложению имя\nЗатем вам будут предоставлены эти токены API, важно сохранить их в безопасном месте. (С тех пор я удалил это приложение) Они понадобятся нам позже с нашим приложением Go.\nТеперь у нас создано наше приложение (мне пришлось изменить имя моего приложения, так как то, что на скриншоте выше, уже было сделано, эти имена должны быть уникальными)\nКлючи, которые мы собрали ранее, известны как наши потребительские ключи, и нам также понадобятся наш токен доступа и секреты. Мы можем собрать эту информацию, используя вкладку «Ключи и токены».\nХорошо, на данный момент мы закончили работу с порталом для разработчиков Twitter. Убедитесь, что вы сохранили свои ключи, потому что они понадобятся нам позже.\nПерейти Twitter бот Помните код, который мы запускаем в нашем приложении?\npackage main import \"fmt\" func main() { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } Теперь нам нужно подумать о коде для отправки нашего вывода или сообщения в Twitter в виде твита. Мы будем использовать go-twitter. Это клиентская библиотека Go для Twitter API.\nЧтобы проверить это, прежде чем помещать это в наше основное приложение, я создал новый каталог в нашей папке src с именем go-twitter-bot, запустил go mod init github.com/michaelcade/go-twitter-bot в папке который затем создал файл go.mod, а затем мы можем начать писать наш новый main.go и протестировать его.\nТеперь нам нужны те ключи, токены и секреты, которые мы собрали на портале разработчиков Twitter. Мы собираемся установить их в наших переменных среды. Это будет зависеть от ОС, которую вы используете:\nWindows\nset CONSUMER_KEY set CONSUMER_SECRET set ACCESS_TOKEN set ACCESS_TOKEN_SECRET Linux / macOS\nexport CONSUMER_KEY export CONSUMER_SECRET export ACCESS_TOKEN export ACCESS_TOKEN_SECRET At this stage, you can take a look at day13_example2 at the code but you will see here that we are using a struct to define our keys, secrets and tokens.\nWe then have a func to parse those credentials and make that connection to the Twitter API\nThen based on the success we will then send a tweet.\nНа этом этапе вы можете взглянуть на следующий код\npackage main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := \u0026twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { fmt.Println(\"Go-Twitter Bot v0.01\") creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } client, err := getClient(\u0026creds) if err != nil { log.Println(\"Error getting Twitter Client\") log.Println(err) } tweet, resp, err := client.Statuses.Update(\"A Test Tweet from the future, testing a #90DaysOfDevOps Program that tweets, tweet tweet\", nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } Здесь вы увидите, что мы используем структуру для определения наших ключей, секретов и токенов.\nЗатем у нас есть func, чтобы проанализировать эти учетные данные и установить это соединение с API Twitter.\nЗатем, в зависимости от успеха, мы отправим твит.\nКод выше либо выдаст вам ошибку в зависимости от того, что происходит, либо будет выполнен успешно, и вам будет отправлен твит с сообщением, указанным в коде.\nСоединение двух вместе - Go-Twitter-Bot + наше приложение Теперь нам нужно объединить эти два файла в наш main.go. Я уверен, что кто-то кричит, что есть лучший способ сделать это, и, пожалуйста, прокомментируйте это, поскольку вы можете иметь более одного файла .go в одном файле. project это может иметь смысл, но это работает.\nТак выглядит итоговый рзультат:\npackage main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := \u0026twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted //fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) //fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) // fmt.Println(\"Good luck\") client, err := getClient(\u0026creds) if err != nil { log.Println(\"Error getting Twitter Client, this is expected if you did not supply your Twitter API tokens\") log.Println(err) } message := fmt.Sprintf(\"Hey I am %v I have been doing the %v for %v days and I have %v Days left\", TwitterName, challenge, DaysCompleted, remainingDays) tweet, resp, err := client.Statuses.Update(message, nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } } Результатом этого должен быть твит, но если вы не указали свои переменные среды, вы должны получить сообщение об ошибке, подобное приведенному ниже.\nПосле того, как вы исправите это или решите не проходить аутентификацию в Twitter, вы можете использовать код, с которым мы закончили вчера. Вывод терминала в случае успеха будет выглядеть примерно так:\nПолученный твит должен выглядеть примерно так:\nКак скомпилировать для нескольких ОС Далее я хочу затронуть вопрос: «Как компилировать для нескольких операционных систем?» Отличительной особенностью Go является то, что он может легко компилироваться для многих различных операционных систем. Вы можете получить полный список, выполнив следующую команду:\ngo tool dist list Использование наших команд go build до сих пор было замечательным, и оно будет использовать переменные среды GOOS и GOARCH, чтобы определить хост-компьютер и то, для чего должна быть собрана сборка. Но мы также можем создавать другие двоичные файлы, используя приведенный ниже код в качестве примера.\nGOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.1_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin_arm64 main.go Это даст вам двоичные файлы в вашем каталоге для всех вышеперечисленных платформ. Затем вы можете взять это и создать make-файл для создания этих двоичных файлов всякий раз, когда вы добавляете новые функции и функции в свой код.\nФайл: makefile\nBINARY_NAME=90DaysOfDevOps build: GOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.2_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.2_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.2_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.2_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.2_darwin_arm64 main.go run: ./${BINARY_NAME} build_and_run: build run clean: go clean rm ${BINARY_NAME}-darwin rm ${BINARY_NAME}-linux rm ${BINARY_NAME}-windows Источники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist A great repo full of all things DevOps \u0026 exercises GoByExample - Example based learning go.dev/tour/list go.dev/learn На этом блок “язык программирования”. Так много всего, что можно охватить, и я надеюсь, что вы смогли продолжить изучение вышеизложенного и понять некоторые другие аспекты языка программирования Go.\nЗатем мы сосредоточимся на Linux и некоторых основах, которые мы все должны знать.\n","description":"Go - подключение Twitter API","title":"13. Go - подключение Twitter API","uri":"/ru/tracks/90daysofdevops/day13/"},{"content":"Общая картина: DevOps и Linux Linux и DevOps имеют очень схожие культуры и взгляды; оба ориентированы на настройку и масштабируемость. Оба эти аспекта Linux имеют особое значение для DevOps.\nМногие технологии начинаются с Linux, особенно если они связаны с разработкой программного обеспечения или управлением инфраструктурой.\nКроме того, многие проекты с открытым исходным кодом, особенно инструменты DevOps, с самого начала разрабатывались для работы в Linux.\nС точки зрения DevOps или фактически с точки зрения какой-либо операционной роли вы столкнетесь с Linux, я бы сказал, в основном. Есть место для WinOps, но большую часть времени вы будете администрировать и развертывать серверы Linux.\nЯ использую Linux ежедневно в течение нескольких лет, но мой настольный компьютер всегда был либо macOS, либо Windows. Однако, когда я перешел на роль Cloud Native, в которой я сейчас нахожусь, я сделал решительный шаг, чтобы убедиться, что мой ноутбук полностью основан на Linux и является моим ежедневным драйвером, в то время как мне по-прежнему нужна была Windows для рабочих приложений и многих моих аудио и видеоаппаратура не работает в Linux Я заставлял себя постоянно работать на рабочем столе Linux, чтобы лучше понять многие вещи, которые мы собираемся затронуть в течение следующих 7 дней.\nНачало Я не предлагаю вам делать то же самое, что и я, в любом случае, поскольку есть более простые варианты и менее разрушительные, но я скажу, что этот полный рабочий день заставит вас быстрее научиться тому, как заставить все работать в Linux.\nВ течение большей части этих 7 дней я фактически собираюсь развернуть виртуальную машину в Virtual Box на моей машине с Windows. Я также собираюсь развернуть настольную версию дистрибутива Linux, в то время как многие серверы Linux, которыми вы будете администрировать, скорее всего, будут серверами без графического интерфейса и полностью основанными на оболочке. Однако, как я сказал в начале, многие инструменты, которые мы рассмотрели в течение всех этих 90 дней, начинались с Linux, я также настоятельно рекомендую вам погрузиться в работу этого рабочего стола Linux для этого обучения.\nВ оставшейся части этого поста мы сосредоточимся на настройке и запуске виртуальной машины Ubuntu Desktop в нашей среде Virtual Box. Теперь мы можем просто загрузить Virtual Box и получить последний Ubuntu ISO с сайтов, на которые даны ссылки, и продолжить сборку. нашу среду рабочего стола, но это не было бы очень DevOps с нашей стороны, не так ли?\nЕще одна веская причина использовать большинство дистрибутивов Linux заключается в том, что они бесплатны и имеют открытый исходный код. Мы также выбираем Ubuntu, поскольку это, вероятно, наиболее широко используемый дистрибутив, не думая о мобильных устройствах и корпоративных серверах RedHat Enterprise. Я могу ошибаться, но с CentOS и ее историей я уверен, что Ubuntu занимает первое место в списке, и это очень просто.\nHashiCorp Vagrant Vagrant — это утилита CLI, которая управляет жизненным циклом ваших виртуальных машин. Мы можем использовать vagrant для запуска и отключения виртуальных машин на разных платформах, включая vSphere, Hyper-v, Virtual Box, а также Docker. У него есть другие провайдеры, но мы будем придерживаться того, что здесь мы используем Virtual Box, так что все готово.\nVagrant — свободное и открытое программное обеспечение для создания и конфигурирования виртуальной среды разработки. Является обёрткой для программного обеспечения виртуализации, например VirtualBox, и средств управления конфигурациями, таких как Chef, Salt и Puppet.\nПервое, что нам нужно сделать, это установить Vagrant на нашу машину, когда вы перейдете на страницу загрузок, вы увидите все операционные системы, перечисленные на ваш выбор. HashiCorp Vagrant Я использую Windows, поэтому я взял двоичный файл для своей системы и установил его в свою систему.\nДалее нам также нужно установить Virtual Box. Опять же, это также может быть установлено на многих разных операционных системах.\nФайл VAGRANTFILE VAGRANTFILE описывает тип машины, которую мы хотим развернуть. Он также определяет, как мы хотим, чтобы конфигурация и подготовка этой машины выглядели.\nКогда дело доходит до их сохранения и организации ваших VAGRANTFILE, я стараюсь помещать их в отдельные папки в своем рабочем пространстве. Ниже вы можете увидеть, как это выглядит в моей системе. Надеюсь, после этого вы поиграете с Vagrant и увидите легкость запуска разных систем, это также отлично подходит для этой кроличьей норы, известной как скачок дистрибутива для Linux Desktops.\nДавайте взглянем на этот VAGRANTFILE и посмотрим, что мы строим.\nVagrant.configure(\"2\") do |config| config.vm.box = \"chenhan/ubuntu-desktop-20.04\" config.vm.provider :virtualbox do |v| v.memory = 8096 v.cpus = 4 v.customize [\"modifyvm\", :id, \"--vram\", \"128mb\"] end end Это очень простой VAGRANTFILE. В целом, мы говорим, что нам нужна конкретная «сборка». Сборка, возможно, является либо общедоступным образом, либо частной сборкой системы, которую вы ищете. Вы можете найти длинный список здесь, в общедоступном каталоге Vagrant\nДалее мы говорим, что хотим использовать определенного провайдера, в данном случае это «VirtualBox», а затем мы хотим определить память нашей машины как «8 ГБ, а количество процессоров — как «4». Мой опыт также говорит мне, что вы можете также добавить следующую строку, если у вас возникли проблемы с отображением. Это установит видеопамять на то, что вы хотите, я бы увеличил ее до 128 МБ, но зависит от вашей системы.\nv.customize [\"modifyvm\", :id, \"--vram\", \"\"] Инициализация нашего рабочего стола Linux Теперь мы готовы запустить нашу первую машину в терминале нашего ПК. В моем случае я использую PowerShell на своем компьютере с Windows, перейдите в папку своих проектов и там, где вы найдете свой VAGRANTFILE. Оказавшись там, вы можете ввести команду vagrant up, и если все правильно, вы увидите что-то вроде того, что показано ниже.\nЕще одна вещь, которую следует добавить, это то, что сеть будет настроена на NAT на вашей виртуальной машине, на данном этапе нам действительно не нужно знать о NAT, и я планирую провести целую сессию в следующем разделе о сети. Но знайте, что это просто кнопка, когда дело доходит до включения машины в вашу домашнюю сеть, это также сетевой режим по умолчанию в Virtual Box. Вы можете узнать больше в документации Virtual Box\nКак только vagrant up завершен, мы можем использовать vagrant ssh, чтобы перейти прямо в терминал нашей новой виртуальной машины.\nИменно здесь мы будем проводить большую часть наших исследований в течение следующих нескольких дней, но я также хочу погрузиться в некоторые настройки для вашей рабочей станции разработчика, которые я сделал, и это значительно упрощает вашу жизнь при использовании этого в качестве ежедневного драйвера, и, конечно же, а ты реально в DevOps разве что у тебя крутой нестандартный терминал?\nНо просто для подтверждения в Virtual Box вы должны увидеть приглашение для входа в систему при выборе виртуальной машины.\nО, и если вы зашли так далеко и спрашивали: «ЧТО ТАКОЕ ИМЯ ПОЛЬЗОВАТЕЛЯ И ПАРОЛЬ?»\nUsername = vagrant Password = vagrant Завтра мы рассмотрим некоторые команды и то, что они делают. Терминал станет местом, где все произойдет.\nРесурсы Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need be a hacker!) Vargant tutorial Как я уже упоминал, далее мы рассмотрим команды, которые мы можем использовать ежедневно в наших средах Linux.\n","description":"DevOps и Linux","title":"14. DevOps и Linux","uri":"/ru/tracks/90daysofdevops/day14/"},{"content":"Команды Linux для DevOps Я упомянул вчера, что мы собираемся провести много времени в терминале с некоторыми командами, чтобы что-то сделать.\nЯ также упомянул, что с нашей виртуальной машиной, подготовленной с помощью vagrant, мы можем использовать vagrant ssh и получить доступ к нашей машине. Вам нужно будет находиться в том же каталоге, из которого мы его предоставили.\nДля SSH нам не понадобятся имя пользователя и пароль, они понадобятся нам только в том случае, если решим войти в консоль Virtual Box.\nВот где мы хотим быть, как показано ниже:\nКоманды Очевидно, что я не могу охватить здесь все команды. Есть тонны документации, которые охватывают их, но также, если вы находитесь в своем терминале, и вам просто нужно понять параметры конкретной команды, у нас есть команда man, сокращенная от manual. Мы можем использовать это, чтобы просмотреть каждую из команд, которые мы коснемся в этом посте, чтобы узнать больше вариантов для каждой из них. Мы можем запустить man man, который поможет вам со страницами руководства. Чтобы выйти из справочных страниц, вы должны нажать q для выхода.\nПримеры:\nman ls man whoami ... sudo Если вы знакомы с Windows и щелкаете правой кнопкой мыши по запустить от имени администратора, мы можем думать о sudo как об этом. Когда вы запускаете команду с помощью этой команды, вы будете запускать ее как «root», она запросит у вас пароль перед запуском команды.\nДля разовых работ, таких как установка приложений или служб, вам может понадобиться эта команда sudo, но что, если у вас есть несколько задач, и вы хотите какое-то время пожить как sudo? Здесь вы можете снова использовать sudo su так же, как sudo, после ввода вам будет предложено ввести пароль root. В тестовой виртуальной машине, такой как наша, это нормально, но мне было бы очень сложно работать как «root» в течение длительного времени, могут произойти плохие вещи. Чтобы выйти из этого возвышенного положения, вы просто набираете «exit».\nЯ ловлю себя на том, что все время использую clear. Команда clear делает именно то, о чем говорит: она очищает экран от всех предыдущих команд, помещая курсор наверх и предоставляя вам красивое чистое рабочее пространство. Windows, это «cls» в .mdprompt.\nДавайте теперь посмотрим на некоторые команды, с помощью которых мы можем создавать вещи в нашей системе, а затем визуализировать их в нашем терминале. Прежде всего, у нас есть mkdir, это позволит нам создать папку в нашей системе. С помощью следующей команды мы можем создать папку в нашем домашнем каталоге с именем Day15 mkdir Day15\nС помощью cd это позволяет нам изменить каталог, поэтому для перехода в наш вновь созданный каталог мы можем сделать это с помощью вкладки cd Day15, которая также может использоваться для автозаполнения доступного каталога. Если мы хотим вернуться к тому, с чего начали, мы можем использовать cd ..\nrmdir позволяет нам удалить каталог, если мы запустим rmdir Day15, тогда папка будет удалена (обратите внимание, что это будет работать, только если у вас ничего нет в папке)\nЯ уверен, что все мы делали это, когда мы переходили в глубины нашей файловой системы в каталог и не знали, где мы находимся. pwd дает нам распечатку рабочего каталога, pwd, насколько это похоже на пароль, означает печать рабочего каталога.\nМы знаем, как создавать папки и каталоги, но как мы создаем файлы? Мы можем создавать файлы с помощью команды «touch», если бы мы запускали «touch Day15», это создало бы файл. Игнорируйте mkdir, мы еще увидим это позже.\nls Я могу поставить на это свой дом, вы будете использовать эту команду так много раз, что она выведет список всех файлов и папок в текущем каталоге. Давайте посмотрим, сможем ли мы увидеть тот файл, который мы только что создали.\nКак мы можем найти файлы в нашей системе Linux? locate позволит нам искать в нашей файловой системе. Если мы используем locate Day15, он сообщит о местонахождении файла. Бонусом является то, что если вы знаете, что файл существует, но вы получаете пустой результат, запустите sudo updatedb, который проиндексирует все файлы в файловой системе, а затем снова запустите locate. Если у вас нет locate, вы можете установить его с помощью этой команды sudo apt install mlocate\nКак насчет перемещения файлов из одного места в другое? mv позволит вам перемещать ваши файлы. Пример mv Day15 90DaysOfDevOps переместит ваш файл в папку 90DaysOfDevOps.\nМы переместили наш файл, но что, если мы хотим переименовать его сейчас во что-то другое? Мы можем сделать это снова с помощью команды mv. Мы можем просто использовать mv Day15 day15, чтобы перейти к верхнему регистру, или мы могли бы использовать mv day15 AnotherDay, чтобы полностью изменить его, теперь используйте ls для проверки файла.\nХватит, теперь давайте избавимся (удалим) от нашего файла и, возможно, даже от нашего каталога, если он у нас есть. rm просто rm AnotherDay удалит наш файл. Мы также будем использовать rm -R, который будет рекурсивно работать через папку или местоположение. Мы также можем использовать rm -R -f, чтобы принудительно удалить все эти файлы. Спойлер, если вы запустите rm -R -f /, добавьте к нему sudo, и вы можете попрощаться со своей системой ….!\nМы рассмотрели перемещение файлов, но что, если я просто хочу скопировать файлы из одной папки в другую, просто скажу, что это очень похоже на команду mv, но мы используем cp, чтобы теперь мы могли сказать cp Day15 Desktop\nМы создали папки и файлы, но на самом деле мы не поместили никакого содержимого в нашу папку, мы можем добавить содержимое несколькими способами, но самый простой способ - это echo, мы также можем использовать echo, чтобы распечатать много вещей в нашей папке. терминал, я лично часто использую эхо для вывода системных переменных, чтобы узнать, установлены они или нет. мы можем использовать echo \"Hello #90DaysOfDevOps\" \u003e Day15, и это добавит это в наш файл. Мы также можем добавить к нашему файлу, используя echo \"Commands are fun!\" \u003e\u003e День15\nЕще одна из тех команд, которые вы будете часто использовать! кошка сокращение от конкатенации. Мы можем использовать cat Day15, чтобы увидеть содержимое внутри файла. Отлично подходит для быстрого чтения этих файлов конфигурации.\nЕсли у вас есть длинный сложный файл конфигурации, и вы хотите или вам нужно найти что-то быстрое в этом файле, а не читать каждую строку, тогда grep вам в помощь, это позволит нам искать в вашем файле определенное слово, используя cat Day15 | grep \"#90DaysOfDevOps\"\nЕсли вы похожи на меня и часто используете эту команду clear, то вы можете пропустить некоторые из ранее запущенных команд, мы можем использовать «историю», чтобы узнать все те команды, которые мы запускали ранее. history -c удалит историю.\nКогда вы запускаете history и хотите выбрать конкретную команду, вы можете использовать !3, чтобы выбрать 3-ю команду в списке.\nВы также можете использовать history | grep \"Команда\" для поиска чего-то определенного.\nНа серверах для отслеживания времени выполнения команды может быть полезно добавлять дату и время к каждой команде в файле истории.\nСледующая системная переменная управляет этим поведением:\nHISTTIMEFORMAT=\"%d-%m-%Y %T \" Вы можете легко добавить ее в свой bash_profile:\necho 'export HISTTIMEFORMAT=\"%d-%m-%Y %T \"' \u003e\u003e ~/.bash_profile Можем увеличить размер файла для хранения истории:\necho 'export HISTSIZE=100000' \u003e\u003e ~/.bash_profile echo 'export HISTFILESIZE=10000000' \u003e\u003e ~/.bash_profile Нужно сменить пароль? passwd позволит нам изменить наш пароль. Обратите внимание, что когда вы добавляете свой пароль таким образом, когда он скрыт, он не будет отображаться в history, однако, если ваша команда имеет -p ПАРОЛЬ, тогда он будет виден в вашей history.\nМы также можем добавить новых пользователей в нашу систему, мы можем сделать это с помощью useradd, мы должны добавить пользователя с помощью нашей команды sudo, мы можем добавить нового пользователя с помощью sudo useradd NewUser\nДля повторного создания группы требуется sudo, и мы можем использовать sudo groupadd DevOps, тогда, если мы хотим добавить нашего нового пользователя в эту группу, мы можем сделать это, запустив sudo usermod -a -G DevOps -a is add а -G это имя группы.\nКак добавить пользователей в группу sudo? Это было бы очень редким случаем но для того, чтобы сделать это, выполним: usermod -a -G sudo NewUser\nПрава / Permissions read, write and execute - — это права доступа ко всем нашим файлам и папкам в нашей системе Linux.\nПолный список:\n0 = None --- 1 = Execute only --X 2 = Write only -W- 3 = Write \u0026 Exectute -WX 4 = Read Only R-- 5 = Read \u0026 Execute R-X 6 = Read \u0026 Write RW- 7 = Read, Write \u0026 Execute RWX Вы также увидите «777» или «775», и они представляют те же числа, что и в приведенном выше списке, но каждый из них представляет User - Group - Everyone*\nДавайте посмотрим на наш файл. ls -al Day15 вы можете увидеть 3 группы, упомянутые выше, пользователь и группа могут читать и изменять (write), но все остальыне только читать (read).\nМы можем изменить это с помощью chmod, вы можете сделать это, если вы также создаете двоичные файлы в своих системах, и вам нужно дать возможность запускать эти двоичные файлы. chmod 750 Day15 теперь запустите ls -la Day15, если вы хотите запустить это для всей папки, вы можете использовать -R, чтобы сделать это рекурсивно.\nКак насчет смены владельца файла? Мы можем использовать «chown» для этой операции, если мы хотим изменить владельца нашего «Day15» с пользователя «vagrant» на «NewUser», мы можем запустить «sudo chown NewUser Day15» снова, можно использовать «-R».\nКоманда, с которой вы столкнетесь, это awk, где она реально используется, когда у вас есть выходные данные, из которых вам нужны только определенные данные. например, запуская who, мы получаем строки с информацией, но, возможно, нам нужны только имена. Мы можем запустить кто | awk '{print $1}', чтобы получить только список этого первого столбца.\nЕсли вы хотите читать потоки данных из стандартного ввода, то генерирует и выполняет командные строки; это означает, что он может принимать вывод команды и передавать его в качестве аргумента другой команды. xargs — полезный инструмент для этого случая использования. Если, например, мне нужен список всех учетных записей пользователей Linux в системе, которую я могу запустить. cut -d: -f1 \u003c /etc/passwd и получите длинный список, который мы видим ниже.\nЕсли я хочу заархивировать этот список, я могу сделать это, используя xargs в команде вроде этой cut -d: -f1 \u003c /etc/passwd | sort | xargs\nЯ также не упомянул команду cut, которая позволяет нам удалять разделы из каждой строки файла. Его можно использовать для вырезания частей строки по положению байта, символу и полю. Команда cut -d \" \" -f 2 list.txt позволяет нам удалить первую букву, которая у нас есть, и просто отобразить наши числа. Есть так много комбинаций, которые можно использовать здесь с этой командой, я уверен, что потратил слишком много времени, пытаясь использовать эту команду, когда я мог бы быстрее извлечь данные вручную.\nТакже обратите внимание, если вы вводите команду, и вы больше не довольны ею, и вы хотите начать снова, просто нажмите Ctrl + c, и это отменит эту строку и начнет все заново.\nРесурсы Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need be a hacker!) Это уже довольно большой список, но я могу с уверенностью сказать, что я использую все эти команды в своей повседневной жизни, будь то администрирование серверов Linux или мой рабочий стол Linux, это очень легко, когда вы находитесь в Windows или macOS для навигации по пользовательскому интерфейсу, но в Linux Servers их нет, все делается через терминал.\n","description":"Команды Linux в DevOps","title":"15. Команды Linux в DevOps","uri":"/ru/tracks/90daysofdevops/day15/"},{"content":"Управление системой, файловой системой и хранилищем в Linux К этому времени мы кратко рассмотрели Linux и DevOps, а затем мы настроили нашу лабораторную среду с помощью vagant 14-й день), а затем коснулись небольшой части команд, которые будут в вашем ежедневном набор инструментов во время использования терминала - (День 15).\nСегодня мы рассмотрим три ключевые области обслуживания систем Linux с помощью обновлений, установки программного обеспечения. Поймем для чего используются системные папки, а также рассмотрим хранилище.\nУправление Ubuntu и программным обеспечением Первое, что мы собираемся рассмотреть, это то, как мы обновляем нашу операционную систему. Большинству из вас этот процесс знаком в ОС Windows и macOS, он немного отличается на рабочем столе и сервере Linux.\nМы рассмотрим диспетчер пакетов apt - утилита, которую мы собираемся использовать на нашей виртуальной машине Ubuntu для обновлений и установки программного обеспечения.\nКак правило, по крайней мере на рабочих станциях разработчиков, мы запускаем эту команду, чтобы убедиться, что у нас есть последние доступные обновления из центральных репозиториев перед установкой любого программного обеспечения.\nsudo apt-get update\nТеперь у нас есть обновленная виртуальная машина Ubuntu с установленными последними обновлениями ОС. Теперь мы хотим установить здесь некоторое программное обеспечение. Давайте выберем figlet — программу, генерирующую текстовые баннеры. Если мы введем «figlet» в наш терминал, вы увидите, что приложение не установлен в нашей системе.\nОднако из вышеизложенного вы увидите, что утилита apt предлагает нам некотоыре опции установки apt install ... , которые мы можем попробовать. Это потому, что в репозиториях по умолчанию есть программа figlet. Давайте попробуем sudo apt install figlet Теперь мы можем использовать наше приложение figlet Если мы хотим удалить эту или любую из наших установок программного обеспечения, мы также можем сделать это с помощью менеджера пакетов «apt». sudo apt remove figlet\nСуществуют сторонние репозитории, которые мы также можем добавить в нашу систему, те, к которым у нас есть доступ из коробки, являются репозиториями Ubuntu по умолчанию.\nЕсли бы, например, мы хотели установить vagrant на нашу виртуальную машину Ubuntu, мы не смогли бы сделать это прямо сейчас, и вы можете увидеть это ниже в первой введенной команде. Затем мы добавляем ключ к репозиторию HashiCorp, а затем добавляем репозиторий в нашу систему.\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" Как только мы добавим репозиторий HashiCorp, мы можем запустить sudo apt install vagrant и установить vagrant в нашей системе.\nСуществует много вариантов, когда дело доходит до установки программного обеспечения, различных вариантов менеджеров пакетов, встроенных в Ubuntu, мы также могли бы использовать сохраненные темплейты (snapshots) для установки нашего программного обеспечения.\nНадеюсь, это даст вам представление о том, как управлять установками ОС и программного обеспечения в Linux.\nФайловая система Linux состоит из файлов конфигурации, и если вы хотите что-то изменить, вы меняете эти файлы конфигурации.\nВ Windows у вас есть диск C:, и это то, что мы считаем корнем. В Linux у нас есть /, где мы собираемся найти важные папки в нашей системе Linux.\n/bin - Сокращенно от binary, папка bin — это место, где в основном находятся наши двоичные файлы, которые нужны вашей системе, исполняемые файлы и инструменты. /boot - Все файлы, необходимые вашей системе для загрузки. Как загрузиться и с какого диска загрузиться. /dev - Вы можете найти информацию об устройстве здесь, здесь вы найдете указатели на ваши диски sda, которые будут вашим основным диском ОС. /etc - Вероятно, это самая важная папка в вашей системе Linux, где находится большинство ваших файлов конфигурации. /home - здесь вы найдете свои пользовательские папки и файлы. У нас есть пользовательская папка vagrant. В ней вы найдете папки “Documents” и «Desktop», с которыми мы работали для раздела команд. /lib - Мы упомянули, что /bin — это место, где находятся наши бинарные и исполняемые файлы, а /lib — это место, где вы найдете разделяемые библиотеки для них. /media - Съемные носители. Флешки, диски и тд). /mnt - Mount. Это временная точка монтирования. Подробнее мы расскажем в следующем разделе о хранении данных. /opt - Дополнительные пакеты программного обеспечения. Вы заметите, что здесь хранится некоторое программное обеспечение для vagrant и virtual box. /proc - Информация о ядре (kernel) и процессе (process), аналогичная /dev /root - Домашняя папка для root. Чтобы получить доступ, вам нужно войти в эту папку с помощью sudo. /run - Каталог, содержащий PID файлы процессов, похожий на /var/run, но в отличие от него, он размещен в TMPFS, а поэтому после перезагрузки все файлы теряются. Сохраняет состояния текущих процессов /sbin - System binaries. Так же как и /bin, содержит двоичные исполняемые файлы, которые доступны на ранних этапах загрузки, когда не примонтирован каталог /usr. Но здесь находятся программы, которые можно выполнять только с правами суперпользователя. Это разные утилиты для обслуживания системы. Например, iptables, reboot, fdisk, ifconfig,swapon и т д. /tmp - Содержит временные файлы, созданные системой, любыми программами или пользователями /usr - User Aplications. Если бы мы, как обычный пользователь, установили пакеты программного обеспечения, они обычно устанавливались бы в папку /usr/bin. Здесь находятся исполняемые файлы, исходники программ, различные ресурсы приложений, картинки, музыка и документация\n/usr/bin - Содержит исполняемые файлы различных программ, которые не нужны на первых этапах загрузки системы, например, музыкальные плееры, графические редакторы, браузеры и т.д.\n/var - Variable. Переменные файлы. Наши приложения устанавливаются в папку bin. Нам нужно где-то хранить все файлы журналов, это /var. Здесь содержатся файлы системных журналов, различные кеши, базы данных и так далее /var/log - Logs. Здесь содержатся большинство файлов логов всех программ, установленных в операционной системе. У многих программ есть свои подкаталоги в этой папке, например, /var/log/apache - логи веб-сервера, /var/log/squid - файлы журналов кеширующего сервера squid. Если в системе что-либо сломалось, скорее всего, ответы вы найдете здесь.\n/var/run - Содержит файлы с PID процессов, которые могут быть использованы, для взаимодействия между программами. В отличие от каталога /run данные сохраняются после перезагрузки.\n/sys - System. Информация о системе. Назначение каталогов Linux из этой папки - получение информации о системе непосредственно от ядра. Это еще одна файловая система организуемая ядром и позволяющая просматривать и изменить многие параметры работы системы, например, работу swap, контролировать вентиляторы и многое другое.\nХранение Когда мы подходим к системе Linux или любой другой системе, мы можем захотеть узнать о доступных дисках и о том, сколько свободного места у нас есть на этих дисках. Следующие несколько команд помогут нам идентифицировать, использовать и управлять хранилищем.\nlsblk Список заблокированных устройств. «sda» — это наш физический диск, а затем «sda1, sda2, sda3» — наши разделы на этом диске. df дает нам немного больше информации об этих разделах, сколько всего, используется и доступно. Здесь вы можете использовать и другие флаги. Я обычно использую df -h, чтобы дать нам “человеческий (понятный” (human) вывод данных. Если вы добавляли новый диск в свою систему, и это то же самое в Windows, вам нужно было бы отформатировать диск в управлении дисками, в терминале Linux вы можете сделать это с помощью sudo mkfs -t ext4 /dev/sdb с sdb, относящимся к нашему недавно добавленному диску.\nЗатем нам нужно будет смонтировать наш недавно отформатированный диск, чтобы его можно было использовать. Мы сделали бы это в нашей ранее упомянутой папке /mnt и создали бы там каталог с sudo mkdir NewDisk, а затем использовали бы sudo mount /dev/sdb newdisk для монтирования диска в это место.\nТакже возможно, что вам нужно будет безопасно отключить хранилище из вашей системы, а не просто вытащить его из конфигурации. Мы можем сделать это с помощью sudo umount /dev/sdb.\nЕсли вы не хотите размонтировать этот диск и собираетесь использовать этот диск для базы данных или какого-либо другого варианта постоянного использования, тогда вы хотите, чтобы он был там при перезагрузке системы. Чтобы это произошло, нам нужно добавить этот диск в наш файл конфигурации /etc/fstab, чтобы он сохранялся, если вы этого не сделаете, его нельзя будет использовать при перезагрузке машины, и вам придется вручную выполнить описанное выше. процесс. Данные по-прежнему будут на диске, но они не будут автоматически монтироваться, пока вы не добавите конфигурацию в этот файл.\nПосле того, как вы отредактировали файл конфигурации fstab, вы можете проверить свою работу с помощью sudo mount -a, если ошибок нет, тогда ваши изменения теперь будут сохраняться при перезапусках.\nМы расскажем, как вы будете редактировать файл с помощью текстового редактора в будущем сеансе.\nРесурсы Структура файловой системы Linux Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Управление системой, файловой системой и хранилищем в Linux","title":"16. Управление системой, файловой системой и хранилищем в Linux","uri":"/ru/tracks/90daysofdevops/day16/"},{"content":"Текстовые редакторы nano и vim Большинство систем Linux - сервера, и у них не будет графического интерфейса. Я также упомянул в прошлой статье, что Linux в основном состоит из файлов конфигурации, и для внесения изменений вам потребуется иметь возможность редактировать эти файлы конфигурации, чтобы изменить что-либо в системе.\nСуществует множество вариантов, но я думаю, что мы должны рассмотреть, вероятно, два наиболее распространенных текстовых редактора терминала. Я использовал оба этих редактора, и для меня «nano» — это удобная кнопка, когда дело доходит до быстрых изменений, но у «vim» такой широкий набор возможностей.\nnano Доступна не во всех системах. Отлично для начала. Если вы запустите nano 90DaysOfDevOps.txt, мы создадим новый файл, в котором ничего не будет, здесь мы можем добавить наш текст, и в окне внизу есть инструкции о том, что мы хотим сделать с этим файлом.\nМы можем нажать control x + enter, а затем запустить ls, теперь вы можете увидеть наш новый текстовый файл.\nМожно запустить cat для этого файла, чтобы прочитать наш файл. Затем мы можем использовать тот же nano 90DaysOfDevOps.txt, чтобы добавить дополнительный текст или изменить ваш файл.\nДля меня nano очень удобен, когда дело доходит до внесения небольших изменений в файлы конфигурации.\nvim Возможно, самый распространенный текстовый редактор.\nВ значительной степени поддерживается в каждом дистрибутиве Linux. Невероятно мощный! Скорее всего, вы найдете полный 7-часовой курс, посвященный только vim. Мы можем перейти в vim с помощью команды vim или, если мы хотим отредактировать наш новый текстовый файл, мы могли бы запустить vim 90DaysOfDevOps.txt, но сначала вы увидите отсутствие меню справки внизу.\nПервый вопрос может быть «Как мне выйти из vim?» это будет escape, и если мы не внесли никаких изменений, то это будет :q\nВы начинаете в обычном «normal» режиме, есть и другие режимы «command, normal, visual, insert», если мы хотим добавить текст, нам нужно будет переключиться с «normal» на «insert», нам нужно нажать «i», если вы добавили какой-то текст и хотели бы сохранить эти изменения, тогда вы нажмете escape, а затем :wq\nВы можете подтвердить это с помощью команды cat, чтобы убедиться, что вы сохранили эти изменения.\nВ vim есть несколько крутых быстрых функций, которые позволяют очень быстро выполнять простые задачи, если вы знаете ярлыки, что само по себе является лекцией. Допустим, мы добавили список повторяющихся слов, и теперь нам нужно его изменить, может быть, это файл конфигурации, и мы повторяем сетевое имя, и теперь это изменилось, и мы хотим быстро изменить это. Я использую слово “Day” в этом примере.\nТеперь мы хотим заменить это слово на 90DaysOfDevOps, мы можем сделать это, нажав «esc» и набрав «:%s/Day/90DaysOfDevOps». В результате, когда вы нажимаете Enter, слово day заменяется на 90DaysOfDevOps.\nКопировать и вставить стало для меня большим открытием. Копия не копия, а дерьмо. мы можем скопировать, используя yy на клавиатуре в обычном режиме. p вставьте в ту же строку, P вставьте в новую строку.\nВы также можете удалить эти строки, выбрав количество строк, которые вы хотите удалить, а затем dd\nТакже, вероятно, вам понадобится время для поиска файла, теперь мы можем использовать grep, как упоминалось в предыдущем сеансе, но мы также можем использовать vim. мы можем использовать /word, и это найдет первое совпадение, для перехода к следующему вы будете использовать клавишу n и так далее.\nДля vim это даже не касается поверхности, самый большой совет, который я могу дать, — взяться за руки и использовать vim везде, где это возможно.\nОбычный вопрос на собеседовании: какой ваш любимый текстовый редактор в Linux, и я хотел бы убедиться, что у вас есть хотя бы эти знания об обоих, чтобы вы могли ответить: «Нано» — это нормально, потому что это просто. По крайней мере, вы показываете компетентность в понимании того, что такое текстовый редактор. Но потренируйтесь с ними, чтобы стать более опытным.\nЕще один указатель для навигации в vim, мы можем использовать «H, J, K, L», а также наши клавиши со стрелками.\nРесурсы Vim Cheat Sheet Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Текстовые редакторы nano и vim","title":"17. Текстовые редакторы Nano/Vim","uri":"/ru/tracks/90daysofdevops/day17/"},{"content":"SSH Как мы уже упоминали, вы, скорее всего, будете управлять множеством удаленных серверов Linux, поэтому вам необходимо убедиться, что ваше подключение к этим удаленным серверам безопасно. В этом разделе мы хотим рассказать о некоторых основах SSH (Secure Shell), которые должен знать каждый, и которые помогут вам с этим безопасным туннелем к вашим удаленным системам.\nНастройка соединения по SSH Передача файлов Создайте свой закрытый ключ Введение в SSH Безопасная оболочка (Secure Shell) Сетевой протокол (Networking Protocol) Обеспечивает безопасную связь Может защитить любой сетевой сервис Обычно используется для удаленного доступа из командной строки В нашей среде, если вы следили за нами, мы уже использовали SSH, но все это было настроено и автоматизировано с помощью нашей конфигурации vagrant, поэтому нам нужно было только запустить vagrant ssh, и мы получили доступ к нашей удаленной виртуальной машине.\nЕсли бы наша удаленная машина не находилась в той же системе, что и наша рабочая станция, и находилась бы в удаленном месте, возможно, в облачной системе или в центре обработки данных, к которому мы могли бы получить доступ только через Интернет, нам потребовался бы безопасный способ, чтобы получить доступ к системе для управления ею.\nSSH обеспечивает безопасный туннель между клиентом и сервером, поэтому злоумышленники ничего не могут перехватить.\nНа сервере есть служба SSH на стороне сервера, которая всегда работает и прослушивает определенный TCP-порт (22).\nЕсли мы используем наш клиент для подключения с правильными учетными данными или ключом SSH, мы получаем доступ к этому серверу.\nДобавление bridged network adapter в нашу систему Чтобы мы могли использовать SSH с нашей виртуальной машиной, нам нужно добавить сетевой адаптер на нашу машину.\nВыключите виртуальную машину, щелкните ее правой кнопкой мыши в Virtual Box и выберите настройки. В новом окне выберите сеть.\nТеперь снова включите вашу машину, и теперь у вас будет IP-адрес на вашей локальной машине. Вы можете подтвердить это с помощью команды ip addr.\nПроверка работы SSH-сервера Мы знаем, что SSH уже настроен на нашей машине, поскольку мы использовали его с vagrant, но мы можем удостовериться, что сервер бежит, запустив\nsudo systemctl status ssh\nЕсли в вашей системе нет SSH-сервера, вы можете установить его, введя эту команду sudo apt install openssh-server\nЗатем вы хотите убедиться, что наш SSH разрешен и брандмауэр работает. Мы можем сделать это с помощью sudo ufw allow ssh. Это не требуется в нашей конфигурации, поскольку мы автоматизировали это с помощью нашего vagrant.\nУдаленный доступ — пароль SSH Теперь, когда наш SSH-сервер прослушивает порт 22 для любых входящих запросов на подключение, и мы добавили “мост” (bridged networking), мы можем использовать putty или SSH-клиент на нашей локальной машине для подключения к нашей системе с помощью SSH.\nЗатем нажмите «Открыть», если вы впервые подключаетесь к этой системе через этот IP-адрес, вы получите это предупреждение. Мы знаем, что это наша система, поэтому вы можете выбрать «yes».\nЗатем нам будет предложено ввести имя пользователя (vagrant) и пароль (пароль по умолчанию — vagrant). Ниже вы увидите, что теперь мы используем наш SSH-клиент (Putty) для подключения к нашей машине с использованием имени пользователя и пароля.\nНа этом этапе мы подключаемся к нашей виртуальной машине с нашего удаленного клиента и можем выполнять наши команды в нашей системе.\nУдаленный доступ — ключ SSH Вышеупомянутый простой способ получить доступ к вашим системам, однако, по-прежнему зависит от имени пользователя и пароля, и если какой-либо злоумышленник получит доступ к этой информации, а также к общедоступному адресу или IP-адресу вашей системы, это может быть легко скомпрометировано. Здесь предпочтительны SSH-ключи.\nКлючи SSH означают, что мы предоставляем пару ключей, чтобы и клиент, и сервер знали, что это доверенное устройство.\nСоздать ключ несложно. На нашем локальном компьютере (Windows) мы можем выполнить следующую команду: если у вас установлен ssh-клиент в любой системе, я полагаю, что эта же команда будет работать?\nssh-keygen -t ed25519\nЯ не буду вдаваться в подробности того, что такое ed25519 и что означает здесь, но вы можете воспользоваться поиском, если хотите узнать больше о криптографии\nНа данный момент у нас есть созданный ключ SSH, хранящийся в C:\\Users\\micha/.ssh/\nНо чтобы связать это с нашей виртуальной машиной Linux, нам нужно скопировать ключ. Мы можем сделать это, используя ssh-copy-id vagrant@192.168.169.135.\nЯ использовал PowerShell для создания своих ключей на моем клиенте Windows, но здесь нет доступного ssh-copy-id. Есть способы, которыми вы можете сделать это в Windows, и небольшой поиск в Интернете найдет вам альтернативу, но я просто использую git bash на своем компьютере с Windows, чтобы сделать копию.\nТеперь мы можем вернуться к Powershell, чтобы проверить, что наше соединение теперь работает с нашими ключами SSH, и пароль не требуется.\nssh vagrant@192.168.169.135\nПри необходимости мы могли бы защититься, используя кодовую фразу. Мы также могли бы сделать еще один шаг, заявив, что пароли вообще не нужны, что означает, что будут разрешены только пары ключей через SSH. Вы можете сделать это в следующем файле конфигурации.\nsudo nano /etc/ssh/sshd_config\nздесь есть строка с PasswordAuthentication yes, она будет закомментирована #, вы должны раскомментировать и изменить yes на no. Затем вам нужно будет перезагрузить службу SSH с помощью «sudo systemctl reload sshd».\nНастройка веб-сервера Не имеет прямого отношения к тому, что мы только что сделали с SSH выше, но я хотел рассмотрть, поскольку это снова еще одна задача, которая может показаться вам немного сложной, но на самом деле этого не должно быть.\nУ нас есть виртуальная машина с Linux, и на данном этапе мы хотим добавить веб-сервер apache к нашей виртуальной машине, чтобы мы могли разместить на нем простой веб-сайт, который обслуживает мою домашнюю сеть. Обратите внимание, что эта веб-страница не будет доступна из Интернета, это можно сделать, но здесь это не рассматривается.\nВы также можете увидеть, что это называется стеком LAMP.\nLinux Operating System Apache Web Server mySQL database PHP Apache2 Apache2 — это HTTP-сервер с открытым исходным кодом. Мы можем установить apache2 с помощью следующей команды.\nsudo apt-get install apache2\nЧтобы убедиться, что apache2 установлен правильно, мы можем запустить sudo service apache2 restart.\nЗатем, используя сетевой адрес моста из пошагового руководства по SSH, откройте браузер и перейдите по этому адресу. Мой http://192.168.169.135/\nmySQL MySQL — это база данных, в которой мы будем хранить данные для нашего простого веб-сайта. Чтобы установить MySQL, мы должны использовать следующую команду sudo apt-get install mysql-server\nPHP PHP — это серверный язык (server-side scripting language), мы будем использовать его для взаимодействия с базой данных MySQL. Окончательная установка заключается в установке PHP и зависимостей с помощью sudo apt-get install php libapache2-mod-php php-mysql.\nПервое изменение конфигурации, которое мы хотим внести в apache из коробки, — это использование index.html, и вместо этого мы хотим использовать index.php.\nМы будем использовать sudo nano /etc/apache2/mods-enabled/dir.conf и переместим index.php в первый элемент списка.\nПерезапустите службу apache2 sudo systemctl restart apache2\nТеперь давайте подтвердим, что наша система правильно настроена для PHP. Создайте следующий файл с помощью этой команды, это откроет пустой файл в nano.\nsudo nano /var/www/html/90Days.php\nзатем скопируйте следующее и используйте Ctrl + x, чтобы выйти и сохранить файл.\n\u003c?php phpinfo(); ?\u003e Теперь снова перейдите к IP-адресу виртуальной машины Linux с дополнительным 90Days.php в конце URL-адреса. http://192.168.169.135/90Days.php вы должны увидеть что-то похожее на показанное ниже, если PHP настроен правильно.\nУстановка WordPress Я просмотрел тьюториал, чтобы установить WordPress в наш стек LAMP, некоторые команды показаны ниже, если они не показаны правильно в пошаговом руководстве [How to install wordpress on Ubuntu with LAMP](https://blog.ssdnodes.com/blog/ как установить-wordpress-на-ubuntu-18-04-с-лампой-учебник/)\nsudo mysql -u root -p\nCREATE DATABASE wordpressdb;\nCREATE USER 'admin-user'@'localhost' IDENTIFIED BY 'password';\nGRANT ALL PRIVILEGES ON wordpressdb.* TO 'admin-user'@'localhost';\nFLUSH PRIVILEGES;\nEXIT;\nsudo apt install php-curl php-gd php-mbstring php-xml php-xmlrpc php-soap php-intl php-zip\nsudo systemctl restart apache2\ncd /var/www\nsudo curl -O https://wordpress.org/latest.tar.gz\nsudo tar -xvf latest.tar.gz\nsudo rm latest.tar.gz\nНа данный момент вы находитесь на шаге 4 в связанной статье, вам нужно будет выполнить шаги, чтобы убедиться, что для каталога WordPress установлены все правильные разрешения.\nПоскольку это только внутреннее действие, вам не нужно «генерировать ключи безопасности» на этом шаге. Перейдите к шагу 5, который меняет конфигурацию Apache на WordPress.\nЗатем, если все настроено правильно, вы сможете получить доступ через свой внутренний сетевой адрес и запустить установку WordPress.\nРесурсы Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Web Сервер и SSH","title":"18. Web Сервер и SSH","uri":"/ru/tracks/90daysofdevops/day18/"},{"content":"Автоматизация задачи с помощью bash-скриптов Оболочка, которую мы собираемся использовать сегодня, — это bash, но мы рассмотрим другую оболочку завтра, когда будем углубляться в ZSH.\nBASH - Bourne Again Shell («возрождённый» shell)\nМы могли бы почти посвятить целую секцию из 7 дней написанию сценариев оболочки, как и языкам программирования. Bash дает нам возможность работать вместе с другими инструментами автоматизации для достижения цели.\nЯ до сих пор разговариваю со многими людьми, которые настроили несколько сложных сценариев оболочки, чтобы что-то произошло, и они полагаются на этот сценарий для некоторых из наиболее важных вещей в бизнесе, я не говорю, что нам нужно понимать сценарии оболочки/bash. для этой цели это не путь. Но мы должны изучить сценарии оболочки/bash, чтобы работать вместе с нашими инструментами автоматизации и для специальных задач.\nОдним из примеров, который мы использовали, может быть VAGRANTFILE, который мы использовали для создания нашей виртуальной машины, мы могли бы обернуть его в простой сценарий bash, который удалял и обновлял его каждый понедельник утром, чтобы у нас была свежая копия нашей виртуальной машины Linux. каждую неделю мы могли бы также добавлять весь программный стек, который нам нужен, на указанную машину с Linux и так далее с помощью одного сценария bash.\nЯ думаю, что еще одна вещь, которую я, по крайней мере, слышу, это то, что практические вопросы по скриптам становятся все более и более очевидными во всех интервью.\nНачало Как и в случае со многим, что мы рассмотрим за все эти 90 дней, единственный реальный способ научиться — это делать. Практический опыт поможет впитать все это в вашу мышечную память.\nПрежде всего, нам понадобится текстовый редактор. В День 17 мы рассказали, наверное, о двух самых распространенных текстовых редакторах и немного о том, как их использовать.\nДавайте приступим прямо к делу и создадим наш первый сценарий оболочки.\ntouch 90DaysOfDevOps.sh - создает файл 90DaysOfDevOps.sh\nЗа ним следует nano 90DaysOfDevOps.sh, это откроет наш новый пустой сценарий оболочки в nano. Опять же, вы можете выбрать другой текстовый редактор.\nПервая строка всех скриптов bash должна выглядеть примерно так: #!/usr/bin/bash, это путь к вашему двоичному файлу bash.\nОднако вы должны проверить это в терминале, запустив which bash, если вы не используете Ubuntu, вы также можете попробовать whereis bash из терминала.\nОднако вы можете увидеть другие пути, перечисленные в уже созданных сценариях оболочки, которые могут включать:\n#!/bin/bash #!/usr/bin/env bash В следующей строке нашего скрипта я хотел бы добавить комментарий и добавить цель скрипта или хотя бы какую-то информацию обо мне. Вы можете сделать это, используя #. Это позволяет нам комментировать определенные строки в нашем коде и предоставлять описания того, что будут делать следующие команды. Я считаю, что чем больше заметок, тем лучше для пользователя, особенно если вы делитесь этим.\nИногда я использую figlet, программу, которую мы установили ранее в разделе Linux, для создания аски-арта, чтобы начать что-то в наших скриптах.\nВсе команды, которые мы использовали ранее в этом разделе Linux (День 15) можно использовать здесь как простую команду для тестирования нашего скрипта.\nДавайте добавим в наш скрипт простой блок кода.\nmkdir 90DaysOfDevOps cd 90DaysOfDevOps touch Day19 ls Затем вы можете сохранить это и выйти из текстового редактора. Если мы запустим наш скрипт с ./90DaysOfDevOps.sh, вы должны получить сообщение об отказе в разрешении. Вы можете проверить права доступа к этому файлу с помощью команды ls -la, и вы увидите, что у нас нет прав на выполнение этого файла.\nМы можем изменить это, используя chmod +x 90DaysOfDevOps.sh, и тогда вы увидите x, означающий, что теперь мы можем запустить (execute) наш скрипт.\nТеперь мы можем снова запустить наш скрипт, используя ./90DaysOfDevOps.sh после того, как запуск скрипта создал новый каталог, перешел в этот каталог, а затем создал новый файл.\nДовольно простые вещи, но вы можете начать понимать, как это можно использовать для вызова других инструментов, как часть способов сделать вашу жизнь проще и автоматизировать вещи.\nПеременные, условные операторы Большая часть этого раздела на самом деле является повторением того, что мы рассмотрели, когда изучали Golang, но я думаю, что нам стоит углубиться в это снова.\nПеременные Переменные позволяют нам один раз определить конкретный повторяющийся термин, который используется в потенциально сложном сценарии.\nЧтобы добавить переменную, вы просто добавляете ее вот так на чистую строку в вашем скрипте.\nchallenge=\"90DaysOfDevOps\"\nТаким образом, когда и где мы используем $challenge в нашем коде, если мы изменим переменную, это будет отражено повсюду.\nЕсли мы сейчас запустим наш скрипт sh, вы увидите распечатку, которая была добавлена к нашему скрипту.\nМы также можем запросить пользовательский ввод, который может установить наши переменные, используя следующее:\necho \"Enter your name\" read name Затем это определило бы ввод как переменную $name. Затем мы могли бы использовать это позже.\nУсловные операторы Может быть, мы хотим узнать, кто участвует в нашем марафоне “90 дней” и сколько дней они прошли, мы можем определить это, используя условные выражения if if-else else-if, это то, что мы определили ниже в нашем скрипте. .\n#!/bin/bash # ___ ___ ____ ___ __ ____ ___ # / _ \\ / _ \\| _ \\ __ _ _ _ ___ / _ \\ / _| _ \\ _____ __/ _ \\ _ __ ___ #| (_) | | | | | | |/ _` | | | / __| | | | |_| | | |/ _ \\ \\ / / | | | '_ \\/ __| # \\__, | |_| | |_| | (_| | |_| \\__ \\ |_| | _| |_| | __/\\ V /| |_| | |_) \\__ \\ # /_/ \\___/|____/ \\__,_|\\__, |___/\\___/|_| |____/ \\___| \\_/ \\___/| .__/|___/ # |___/ |_| # # This script is to demonstrate bash scripting! # Variables to be defined ChallengeName=#90DaysOfDevOps TotalDays=90 # User Input echo \"Enter Your Name\" read name echo \"Welcome $name to $ChallengeName\" echo \"How Many Days of the $ChallengeName challenge have you completed?\" read DaysCompleted if [ $DaysCompleted -eq 90 ] then echo \"You have finished, well done\" elif [ $DaysCompleted -lt 90 ] then echo \"Keep going you are doing great\" else echo \"You have entered the wrong amount of days\" fi Вы также можете видеть из вышеприведенного, что мы проводим некоторые сравнения или сверяем значения друг с другом, чтобы перейти к следующему этапу. У нас есть разные варианты, которые стоит отметить.\neq - if the two values are equal will return TRUE ne - if the two values are not equal will return TRUE gt - if the first value is greater than the second value will return TRUE ge - if the first value is greater than or equal to the second value will return TRUE lt - if the first value is less than the second value will return TRUE le - if the first value is less than or equal to the second value will return TRUE Мы также можем использовать сценарии bash для получения информации о файлах и папках, это называется условиями файлов.\n-d file True if the file is a directory -e file True if the file exists -f file True if the provided string is a file g file True if the group id is set on a file -r file True if the file is readable -s file True if the file has a non-zero size FILE=\"90DaysOfDevOps.txt\" if [ -f \"$FILE\" ] then echo \"$FILE is a file\" else echo \"$FILE is not a file\" fi При условии, что этот файл все еще находится в нашем каталоге, мы должны вернуть первую команду echo. Но если мы удалим этот файл, мы должны получить вторую команду echo.\nНадеюсь, вы увидите, как это можно использовать для экономии времени при поиске в системе определенных элементов.\nЯ нашел этот удивительный репозиторий на GitHub, в котором, кажется, бесконечное количество скриптов DevOps Bash Tools\nПример Scenario: У нас есть наша компания под названием «90DaysOfDevOps», и мы работаем некоторое время, и теперь пришло время расширить команду с 1 человека до гораздо большего в ближайшие недели. Я пока единственный, кто знает процесс адаптации, поэтому мы хотим чтобы уменьшить это узкое место, автоматизировав некоторые из этих задач.\nRequirements:\nПользователь может быть передан в качестве аргумента командной строки. Пользователь создается с именем аргумента командной строки. Пароль может быть проанализирован как аргумент командной строки. Пароль установлен для пользователя Отображается сообщение об успешном создании учетной записи. Давайте начнем с создания нашего сценария оболочки с помощью touch create_user.sh.\nПрежде чем мы двинемся дальше, давайте также создадим этот исполняемый файл, используя chmod +x create_user.sh\nзатем мы можем использовать nano create_user.sh, чтобы начать редактирование нашего скрипта для сценария, который мы установили.\nМы можем взглянуть на первое требование «Пользователь может быть передан в качестве аргумента командной строки», мы можем использовать следующее\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1\" Идем далее и запускаем ./create_user.sh Michael, замените Michael своим именем при запуске скрипта. Далее мы можем выполнить второе требование: «Пользователь создается с именем аргумента командной строки», это можно сделать с помощью команды useradd. Опция -m предназначена для создания домашнего каталога пользователя как /home/username.\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1 user account being created.\" #A user is created with the name of command line argument sudo useradd -m \"$1\" Предупреждение: если вы не укажете имя учетной записи пользователя, произойдет ошибка, поскольку мы не заполнили переменную $1\nЗатем мы можем проверить, была ли создана эта учетная запись с помощью команды awk -F: '{print $1}' /etc/passwd.\nMore about awk linux command\nНаше следующее требование: «Пароль может быть проанализирован как аргумент командной строки». Во-первых, мы никогда не собираемся делать это в продакшене, нам нужно проработать список требований в лаборатории, чтобы понять.\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1 user account being created.\" #A user is created with the name of command line argument sudo useradd -m \"$1\" #A password can be parsed in as a command line argument. sudo chpasswd \u003c\u003c\u003c \"$1\":\"$2\" Если мы затем запустим этот скрипт с двумя параметрами ./create_user.sh пароль 90DaysOfDevOps\nНа изображении ниже вы можете видеть, что мы выполнили наш скрипт, он создал нашего пользователя и пароль, а затем мы вручную перешли к этому пользователю и подтвердили это с помощью команды whoami.\nПоследнее требование: «Отображается сообщение об успешном создании учетной записи». На самом деле у нас уже есть это в верхней строке нашего кода, и мы можем видеть на снимке экрана выше, что у нас есть «созданная учетная запись пользователя 90DaysOfDevOps». Это осталось от нашего тестирования с параметром $1.\nТеперь этот сценарий можно использовать для быстрого подключения и настройки новых пользователей в наших системах Linux. Но, может быть, вместо того, чтобы некоторым историческим людям приходилось работать с этим, а затем получать новые имена пользователей или пароли для других людей, мы могли бы добавить некоторый пользовательский ввод, который мы ранее рассмотрели ранее, для захвата наших переменных.\n#! /usr/bin/bash echo \"What is your intended username?\" read username echo \"What is your password\" read password #A user can be passed in as a command line argument echo \"$username user account being created.\" #A user is created with the name of command line argument sudo useradd -m $username #A password can be parsed in as a command line argument. sudo chpasswd \u003c\u003c\u003c $username:$password Шаги стали более интерактивными,\nПросто чтобы закончить это, возможно, мы хотим вывести успешный вывод, чтобы сказать, что наша новая учетная запись пользователя завершена.\nОдна вещь, которую я заметил, это то, что мы отображаем пароль на нашем входе, мы можем скрыть это, используя флаг -s в строке кода read -s password\nЕсли вы хотите удалить пользователя, которого вы создали для лабораторных целей, вы можете сделать это с помощью sudo userdel test_user\nЕще раз, я не говорю, что это будет то, что вы будете создавать в своей повседневной жизни, но я думал, что это то, что подчеркнет гибкость того, для чего вы можете использовать сценарии оболочки.\nПодумайте о любых повторяющихся задачах, которые вы выполняете каждый день, неделю или месяц, и о том, как вы могли бы лучше автоматизировать это. Первым вариантом, вероятно, будет использование сценария bash, прежде чем переходить к более сложной территории.\nЯ создал очень простой bash-файл, который помогает мне развернуть кластер Kubernetes с помощью minikube на моем локальном компьютере вместе со службами данных и Kasten K10, чтобы продемонстрировать требования и нужды, связанные с управлением данными. Project Pace. Но я не счел уместным поднимать вопрос здесь, поскольку мы еще не рассмотрели Kubernetes.\nРесурсы Bash in 100 seconds Bash script with practical examples - Full Course Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Автоматизация задачи с помощью bash-скриптов","title":"19. Автоматизация задачи с помощью bash-скриптов","uri":"/ru/tracks/90daysofdevops/day19/"},{"content":"Обязанности DevOps специалиста Надеюсь, вы приступили к этому после просмотра ресурсов и публикации в День 1 из #90DaysOfDevOps\nВ первом посте был краткий обзор, но теперь мы должны углубиться в концепцию DevOps и понять, что при создании приложения есть две основные части. У нас есть часть Разработка, где разработчики программного обеспечения программируют приложение и тестируют его. Затем у нас есть часть Операции, где приложение развертывается и поддерживается на сервере.\nDevOps — это связующее звено между двумя Чтобы разобраться с DevOps или задачами, которые будет выполнять инженер DevOps, нам нужно понять инструменты или процесс, а также разобраться как они вместе они вместе взаимодейтвуют.\nВсе начинается с приложения! Вы увидите так много всего, что все дело в приложении, когда речь идет о DevOps.\nРазработчики создадуют приложение, это можно сделать с помощью множества различных технологических стеков, и давайте пока оставим это воображению, поскольку мы вернемся к этому позже. Это также может включать множество различных языков программирования, инструменты сборки, репозиторий кода и т. д.\nБудучи инженером DevOps, вы не будете программировать приложение, но хорошее понимание концепций работы разработчика и используемых им систем, инструментов и процессов является ключом к успеху.\nНа очень высоком уровне вам нужно будет знать, как приложение настроено для взаимодействия со всеми необходимыми службами или службами данных, а затем также добавить требования о том, как это можно или нужно протестировать.\nПриложение нужно будет где-то развернуть, давайте сделаем его в целом простым и сделаем это сервером, неважно где, но сервером. Затем ожидается, что к нему будет обращаться клиент или конечный пользователь в зависимости от созданного приложения.\nЭтот сервер должен работать где-то локально, в общедоступном облаке, без сервера (Хорошо, я зашел слишком далеко, мы не будем рассматривать бессерверный вариант, но это вариант, и все больше и больше предприятий идут по этому пути). Кто-то должен создать настройте эти серверы и подготовьте их к запуску приложения. Теперь этот элемент может пригодиться вам как инженеру DevOps для развертывания и настройки этих серверов.\nЭти серверы должны будут работать под управлением операционной системы, и, вообще говоря, это будет Linux, но у нас есть целый раздел или потратим неделю, где мы рассмотрим некоторые фундаментальные знания, которые вы должны получить.\nТакже вероятно, что нам нужно взаимодействовать с другими службами в нашей сети или среде, поэтому нам также необходимо иметь такой уровень знаний о сети и настройке, что в некоторой степени также может оказаться в руках инженера DevOps. Опять же, мы рассмотрим это более подробно в специальном разделе, посвященном DNS, DHCP, балансировщикам нагрузки (Load Balancing) и т. д.\nМастер на все руки Однако на этом этапе я скажу, что вам не нужно быть специалистом по сетям или инфраструктуре, вам нужны базовые знания о том, как наладить работу и общаться друг с другом, во многом так же, как, возможно, иметь базовые знания язык программирования, но вам не нужно быть разработчиком. Однако вы можете прийти к этому как специалист в какой-то области, и это отличная основа для адаптации к другим областям.\nВы также, скорее всего, не будете ежедневно управлять этими серверами или приложением.\nМы говорили о серверах, но есть вероятность, что ваше приложение будет разработано для работы в виде контейнеров, которые по-прежнему работают на сервере по большей части, но вам также потребуется понимание не только виртуализации, облачной инфраструктуры как услуги (IaaS). ), но также и контейнеризация. В эти 90 дней основное внимание будет уделяться контейнерам.\nОбщий обзор С одной стороны, наши разработчики создают новые функции и функции (а также исправления ошибок) для приложения.\nС другой стороны, у нас есть какая-то среда, инфраструктура или серверы, которые настроены и управляются для запуска этого приложения и связи со всеми необходимыми службами.\nБольшой вопрос заключается в том, как нам внедрить эти функции и исправления ошибок в нашу продукцию и сделать их доступными для этих конечных пользователей?\nКак мы выпускаем новую версию приложения? Это одна из основных задач для DevOps-инженера, и здесь важно не просто понять, как это сделать один раз, а нам нужно делать это непрерывно и автоматизированным, эффективным способом, который также должен включать тестирование!\nНа этом мы собираемся закончить этот день обучения, надеюсь, это было полезно. В течение следующих нескольких дней мы собираемся немного глубже погрузиться в некоторые другие области DevOps, а затем мы перейдем к разделам, в которых более подробно рассматриваются инструменты и процессы, а также их преимущества.\nРесурсы Я всегда открыт для добавления дополнительных ресурсов в эти файлы Readme, поскольку они здесь в качестве учебного пособия.\nМой совет - просмотреть все ссылки из списка ниже, и, надеюсь, вы также что-то почерпнули из текста и объяснений выше.\nWhat is DevOps? - TechWorld with Nana What is DevOps? - GitHub YouTube What is DevOps? - IBM YouTube What is DevOps? - AWS What is DevOps? - Microsoft Если вы зашли так далеко, то поймете, хотите ли вы быть здесь или нет. До встречи в День 3\n","description":"Задачи DevOps-инженера","title":"2. Задачи DevOps-инженера","uri":"/ru/tracks/90daysofdevops/day02/"},{"content":"Настройка рабочей среды Не путать с тем, как мы настраиваем серверы Linux таким образом. Я хочу продемонстрировать возможности выбора и гибкость, которые у нас есть при настройке настольного компьютера Linux.\nЯ использую рабочий стол Linux уже почти год, и я настроил его именно так, как я хочу с точки зрения внешнего вида. Используя нашу виртуальную машину Ubuntu в Virtual Box, мы можем выполнить некоторые настройки, которые я сделал для своего ежедневного драйвера.\nЯ собрал видео на YouTube, показывающее остальные, так как некоторые люди могли бы лучше следовать за ним:\nИз коробки наша система будет выглядеть примерно так:\nМы также можем увидеть нашу оболочку bash по умолчанию: Многое из этого сводится к точечным файлам, которые мы рассмотрим в этой заключительной статье Linux из этой серии.\ndotfiles Сначала я хочу покопаться в dotfiles, я сказал в предыдущий день, что Linux состоит из файлов конфигурации. Эти файлы представляют собой файлы конфигурации для вашей системы Linux и приложений.\nЯ также добавлю, что dotfiles используются не только для настройки и придания красивого вида вашему рабочему столу, но и для изменения и конфигурации dotfile, которые помогут вам повысить производительность.\nКак я уже упоминал, многие программы хранят свои конфигурации в этих точечных файлах. Эти файлы помогают управлять функциональностью.\nКаждый файл начинается с . Вы, наверное, догадались, откуда взялось название?\nДо сих пор мы использовали bash в качестве нашей оболочки, что означает, что у вас будут .bashrc и .bash_profile в нашей домашней папке. Ниже вы можете увидеть несколько точечных файлов, которые есть в нашей системе.\nМы собираемся изменить нашу оболочку, поэтому позже мы увидим новый точечный файл конфигурации .zshrc.\nНо теперь вы знаете, если мы ссылаемся на точечные файлы, вы знаете, что это файлы конфигурации. Мы можем использовать их для добавления псевдонимов в нашу командную строку, а также путей к различным местоположениям. Некоторые люди публикуют свои точечные файлы, чтобы они были общедоступными. Вы найдете мой здесь, на моем GitHub MichaelCade/dotfiles, здесь вы найдете мой пользовательский файл .zshrc, мой предпочтительный терминал - терминатор, который также имеет некоторые файлы конфигурации в папке, а затем также некоторые параметры фона.\nZSH Как я упоминал во время наших взаимодействий, до сих пор мы использовали оболочку bash по умолчанию с Ubuntu. ZSH очень похож, но имеет некоторые преимущества перед bash.\nZsh имеет такие функции, как интерактивное завершение с помощью табуляции, автоматический поиск файлов, интеграция с регулярными выражениями, расширенное сокращение для определения области действия команды и богатый движок тем.\nМы можем использовать наш менеджер пакетов «apt», чтобы установить zsh в нашей системе. Давайте продолжим и запустим sudo apt install zsh с нашего терминала bash. Я собираюсь сделать это из консоли виртуальной машины, а не через SSH.\nКогда команда установки завершена, вы можете запустить zsh внутри вашего терминала, это запустит сценарий настройки оболочки.\nЯ выбрал «1» на вопрос выше, и теперь у нас есть еще несколько вариантов. Из этого меню видно, что мы можем внести некоторые готовые изменения, чтобы настроить ZSH в соответствии с нашими потребностями.\nЕсли вы выходите из мастера с 0, а затем используете ls -la | grep .zshrc вы должны увидеть, что у нас есть новый файл конфигурации.\nТеперь мы хотим сделать zsh нашей оболочкой по умолчанию каждый раз, когда мы открываем наш терминал, мы можем сделать это, выполнив следующую команду, чтобы изменить нашу оболочку chsh -s $(which zsh), нам затем нужно выйти из системы и снова войти в нее для грядут изменения.\nКогда вы снова войдете в систему и откроете терминал, он должен выглядеть примерно так. Мы также можем подтвердить, что наша оболочка теперь изменена, запустив which $SHELL\nОбычно я выполняю этот шаг на каждом рабочем столе Ubuntu, который я запускаю, и в целом, не заходя дальше, обнаруживаю, что оболочка zsh немного быстрее, чем bash.\nOhMyZSH Далее мы хотим немного улучшить внешний вид, а также добавить некоторые функции, которые помогут нам перемещаться по терминалу.\nOhMyZSH — это бесплатная платформа с открытым исходным кодом для управления вашей конфигурацией zsh. Существует множество плагинов, тем и других вещей, которые просто делают взаимодействие с оболочкой zsh намного приятнее.\nВы можете узнать больше о ohmyzsh\nДавайте установим Oh My ZSH, у нас есть несколько вариантов с curl, wget или fetch, у нас есть первые два, доступные в нашей системе, но я начну с curl.\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nКогда вы запустите приведенную выше команду, вы должны увидеть вывод, как показано ниже. Теперь мы можем перейти к добавлению темы для нашего опыта, в комплекте с Oh My ZSH более 100, но я выбираю для всех своих приложений, и все это тема Дракулы.\nЯ также хочу добавить, что эти два плагина являются обязательными при использовании Oh My ZSH.\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestions\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM/plugins/zsh-syntax-highlighting\nnano ~/.zshrc\nотредактируйте plugins, чтобы включить plugins=(git zsh-autosuggestions zsh-syntax-highlighting)\nРасширения Gnome Я также использую расширения Gnome, и в частности список ниже\nGnome extensions\n- Caffeine - CPU Power Manager - Dash to Dock - Desktop Icons - User Themes Установка программ Краткий список программ, которые я устанавливаю на машину с помощью apt\n- VSCode - azure-cli - containerd.io - docker - docker-ce - google-cloud-sdk - insomnia - packer - terminator - terraform - vagrant тема Dracula Этот сайт - единственная тема, которую я использую в данный момент. Выглядит четким, чистым и все выглядит отлично. Dracula Theme\nПо ссылке выше можем поискать zsh на сайте и найдем как минимум два варианта.\nСледуйте приведенным инструкциям, чтобы выполнить установку вручную или с помощью git. Затем вам нужно будет, наконец, отредактировать файл конфигурации .zshrc, как показано ниже.\nДалее нам понадобится тема Gnome Terminal Dracula со всеми инструкциями\nНа самом деле мне потребовалось бы много времени, чтобы задокументировать каждый шаг, поэтому я создал пошаговое видео процесса. (Нажмите на изображение ниже)\nЕсли вы дочитали до этого момента, значит, мы закончили наш раздел Linux в #90DaysOfDevOps. Я снова открыт для отзывов и дополнений к ресурсам здесь.\nЯ также подумал, что было проще показать вам многие шаги с помощью видео, чем записывать их здесь, что вы думаете об этом? У меня есть цель вернуться к этим дням и, где это возможно, создать видео-пошаговые руководства, чтобы добавить и, возможно, лучше объяснить и показать некоторые вещи, которые мы рассмотрели. Что вы думаете?\nРесурсы Bash in 100 seconds Bash script with practical examples - Full Course Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) Завтра мы начинаем наши 7 дней погружения в сетевое взаимодействие, мы будем стараться получить базовые знания и понимание сетевого взаимодействия (Networking) в DevOps.\n","description":"Настройка рабочей среды","title":"20. Настройка рабочей среды DevOps","uri":"/ru/tracks/90daysofdevops/day20/"},{"content":"Общая картина: DevOps и Сеть Добро пожаловать в День 21! Мы собираемся заняться сетевыми технологиями в течение следующих 7 дней. Сеть и DevOps являются всеобъемлющей темой, но нам также необходимо изучить некоторые основы сетевых технологий.\nВ конечном счете, как мы уже говорили ранее, DevOps — это культура и изменение процессов в ваших организациях. Как мы уже говорили, это могут быть виртуальные машины, контейнеры, Kubernetes, но это также может быть и сеть. Если мы используем эти принципы DevOps для нашей инфраструктуры, которая чтобы включить сеть более точно с точки зрения DevOps, вам также необходимо знать о сети, а также о различных топологиях, сетевых инструментах и ​​стеках, которые у нас есть.\nЯ бы сказал, что наши сетевые устройства должны быть настроены с использованием инфраструктуры как кода, и все должно быть автоматизировано, как и наши виртуальные машины, но для этого мы должны хорошо понимать, что мы автоматизируем.\nЧто такое NetDevOps | Сетевой DevOps? Вы также можете услышать термины Network DevOps или NetDevOps. Возможно, вы уже являетесь сетевым инженером (network engineer) и хорошо разбираетесь в сетевых компонентах в инфраструктуре, вы понимаете элементы, используемые в сети, такие как DHCP, DNS, NAT и т. д. и т. д. У вас также будет хорошее понимание аппаратных или программно-определяемых сетей. опции, коммутаторы, маршрутизаторы и т.д. и т.п.\nНо если вы не сетевой инженер, то нам, вероятно, необходимо получить базовые знания по всем направлениям в некоторых из этих областей, чтобы мы могли понять конечную цель Network DevOps.\nНо в отношении этих терминов мы можем думать о NetDevOps или Network DevOps как о применении принципов и практик DevOps к сети, применении инструментов управления версиями и автоматизации к созданию, тестированию, мониторингу и развертыванию сети.\nЕсли мы думаем о сетевой DevOps как о необходимости автоматизации, мы упоминали ранее о том, что DevOps разрушает разрозненность между командами. Если сетевые команды не перейдут на аналогичную модель и процесс, они станут узким местом или даже полным провалом.\nИспользование принципов автоматизации подготовки, настройки, тестирования, контроля версий и развертывания — отличное начало. Автоматизация в целом обеспечит скорость развертывания, стабильность сетевой инфраструктуры и последовательное улучшение, а также процесс, который будет совместно использоваться в нескольких средах после их тестирования. Например, полностью протестированная сетевая политика, которая была полностью протестирована в одной среде, может быть быстро использована в другом месте из-за характера этого в коде, а не в процессе, созданном вручную, как это могло быть раньше. Действительно хорошую точку зрения и схему этого мышления можно найти здесь. Сетевой DevOps\nNetworking - основы Давайте для начала забудем о стороне DevOps, и теперь нам нужно очень кратко взглянуть на некоторые основы работы в сети.\nСетевые устройства Host — это любые устройства, которые отправляют или получают трафик. IP Address “определение” каждого хоста. (адрес)\nNetwork — (Сеть) это то, что транспортирует трафик между хостами. Если бы у нас не было сетей, было бы много ручного перемещения данных! Логическая группа хостов, для которых требуется аналогичное подключение. Switches (Коммутаторы) облегчают связь внутри сети. Коммутатор пересылает пакеты данных между хостами. Коммутатор отправляет пакеты напрямую хостам.\nСеть: группа хостов, которым требуется одинаковое подключение. Хосты в сети используют одно и то же пространство IP-адресов. Маршрутизатор (Router) облегчает связь между сетями. Если мы сказали ранее, что коммутатор следит за связью внутри сети, маршрутизатор позволяет нам объединить эти сети или, по крайней мере, предоставить им доступ друг к другу, если это разрешено. Маршрутизатор может обеспечить точку контроля трафика (безопасность, фильтрация, перенаправление). Все больше и больше коммутаторов теперь также предоставляют некоторые из этих функций.\nМаршрутизаторы узнают, к каким сетям они подключены. Это известно как маршруты, таблица маршрутизации — это все сети, о которых знает маршрутизатор.\nМаршрутизатор имеет IP-адрес в сетях, к которым он подключен. Этот IP-адрес также будет использоваться каждым хостом за пределами их локальной сети, также известной как шлюз.\nМаршрутизаторы также создают иерархию в сетях, о которой я упоминал ранее.\nКоммутаторы и маршрутизаторы (Switches vs Routers ) Маршрутизация – это процесс перемещения данных между сетями.\nМаршрутизатор — это устройство, основной задачей которого является маршрутизация. Коммутация — это процесс перемещения данных в сети.\nКоммутатор — это устройство, основное назначение которого — коммутация. Это во многом базовый обзор устройств, поскольку мы знаем, что существует множество различных сетевых устройств, таких как:\nAccess Points Firewalls Load Balancers Layer 3 Switches IDS / IPS Proxies Virtual Switches Virtual Routers Хотя все эти устройства будут выполнять маршрутизацию и/или коммутацию.\nВ течение следующих нескольких дней мы собираемся узнать немного больше об этом списке.\nOSI Model Network Protocols DNS (Domain Name System) NAT DHCP Subnets Ресурсы Computer Networking full course\n","description":"Общая картина - DevOps и Сеть","title":"21. DevOps настройка сети","uri":"/ru/tracks/90daysofdevops/day21/"},{"content":"Модель OSI — 7 уровней Общая цель сети как отрасли состоит в том, чтобы позволить двум хостам обмениваться данными. Если я хочу передать данные от одного хоста к другому хосту, мне нужно будет что-то подключить к этому хосту, перейти к другому хосту, подключить его к первому хосту.\nСеть позволяет нам автоматизировать это, позволяя хосту автоматически обмениваться данными по сети, и для этого эти хосты должны следовать набору правил.\nЭто ничем не отличается от любого другого языка. У английского есть набор правил, которым должны следовать два носителя английского языка. У испанского есть свой собственный набор правил.\nПравила организации сети разделены на семь разных уровней, и эти уровни известны как модель OSI.\nВведение в модель OSI Модель OSI (модель взаимодействия открытых систем)/(Open Systems Interconnection Model) — это структура, используемая для описания функций сетевой системы. Модель OSI характеризует вычислительные функции в виде универсального набора правил и требований для обеспечения функциональной совместимости между различными продуктами и программным обеспечением. В эталонной модели OSI обмен данными между вычислительной системой разделен на семь различных уровней абстракции: физический, канальный, сетевой, транспортный, сеансовый, презентационный и прикладной (Physical, Data Link, Network, Transport, Session, Presentation, Application). Физический Уровень 1 в модели OSI, известный как физический, предполагает возможность передачи данных с одного хоста на другой с помощью средств, будь то физический кабель или мы также можем рассмотреть Wi-Fi на этом уровне. Мы также можем увидеть здесь более устаревшее оборудование вокруг концентраторов и повторителей для передачи данных с одного хоста на другой. Канал передачи данных Уровень 2, канал передачи данных обеспечивает передачу данных от узла к узлу, где данные упакованы в кадры. Существует также уровень исправления ошибок, которые могли возникнуть на физическом уровне. Здесь мы также вводим или впервые видим MAC-адреса.\nЗдесь мы видим первое упоминание о коммутаторах, о которых мы рассказали в первый день нашей работы с сетью День 21 Сеть Вы, вероятно, слышали термин «коммутаторы уровня 3» или «коммутаторы уровня 2». В нашей модели OSI уровень 3. Цель сети — прямая(end to end) доставка, именно здесь мы видим наши IP-адреса, также упомянутые в обзоре первого дня.\nМаршрутизаторы и хосты существуют на уровне 3, помните, что маршрутизатор — это возможность маршрутизации между несколькими сетями. Все, что имеет IP, может считаться уровнем 3. Так зачем же нам нужны схемы адресации как на уровне 2, так и на уровне 3? (MAC-адреса и IP-адреса)\nЕсли мы подумаем о передаче данных с одного хоста на другой, каждый хост имеет IP-адрес, но между ними есть несколько коммутаторов и маршрутизаторов. Каждое из устройств имеет этот MAC-адрес уровня 2.\nMAC-адрес уровня 2 будет передаваться только от хоста к коммутатору/маршрутизатору, он ориентирован на переходы, где IP-адреса уровня 3 будут оставаться с этим пакетом данных, пока он не достигнет своего конечного хоста. (Концы с концами)\nIP-адреса — уровень 3 = сквозная доставка\nMAC-адреса — уровень 2 = доставка между переходами\nТеперь есть сетевой протокол, который мы рассмотрим, но не сегодня, называемый ARP (протокол разрешения адресов), который связывает наши адреса Layer3 и Layer2.\nТранспорт Предоставление услуг между услугами, уровень 4 предназначен для различения потоков данных. Точно так же, как уровни 3 и 2 имели свои схемы адресации, на уровне 4 у нас есть порты.\nСессия, Презентация, Приложение Различие между слоями 5, 6, 7 немного расплывчато\nСтоит взглянуть на IP-модель TCP, чтобы получить более свежее представление.\nДавайте теперь попробуем объяснить, что на самом деле происходит, когда хосты общаются друг с другом, используя этот сетевой стек. На одном хосте есть приложение, которое будет генерировать данные, предназначенные для отправки на другой хост.\nИсходный хост будет проходить так называемый процесс инкапсуляции. Эти данные будут сначала отправлены на уровень 4.\nУровень 4 добавит заголовок к этим данным, что может облегчить задачу уровня 4, которая заключается в доставке услуг. Это будет порт, использующий либо TCP, либо UDP. Он также будет включать исходный порт и порт назначения.\nЭто также может быть известно как сегмент (данные и порт).\nЭтот сегмент будет передан по стеку osi на уровень 3, сетевой уровень, сетевой уровень добавит к этим данным еще один заголовок. Этот заголовок будет способствовать цели уровня 3, который является сквозной доставкой, что означает, что в этом заголовке у вас будет IP-адрес источника и IP-адрес назначения, заголовок плюс данные также могут называться пакетом.\nЗатем уровень 3 возьмет этот пакет и передаст его уровню 2, уровень 2 еще раз добавит еще один заголовок к этим данным для достижения цели уровня 2 по доставке переходов, что означает, что этот заголовок будет включать в себя MAC-адреса источника и получателя. Это называется кадром, когда у вас есть заголовок и данные уровня 2.\nЗатем этот кадр преобразуется в единицы и нули и отправляется по физическому кабелю уровня 1 или Wi-Fi.\nВыше я упомянул названия для каждого уровня заголовка и данных, но решил нарисовать и это.\nОчевидно, что приложение, отправляющее данные, отправляется куда-то, поэтому получение происходит в обратном порядке, чтобы получить эту резервную копию в стеке и на принимающем хосте. Ресурсы Computer Networking full course Practical Networking ","description":"7 уровней модели OSI","title":"22. Открытая сетевая модель OSI","uri":"/ru/tracks/90daysofdevops/day22/"},{"content":"Протоколы сети Набор правил и сообщений, образующих стандарт.\nARP - Address Resolution Protocol - протокол разрешения адресов Если вы хотите по-настоящему разобраться в ARP, вы можете прочитать Internet Standard здесь RFC 826\nARP соединяет IP-адреса с фиксированными физическими адресами машин, также известными как MAC-адреса, в сети уровня 2.\nFTP - File Transfer Protocol - протокол передачи файлов Позволяет передавать файлы из источника в место назначения. Как правило, этот процесс аутентифицируется, но при настройке можно использовать анонимный доступ. Теперь вы будете чаще видеть FTPS, который обеспечивает подключение SSL/TLS к FTP-серверам от клиента для повышения безопасности. Этот протокол можно найти на прикладном уровне модели OSI.\nSMTP - Simple Mail Transfer Protocol - протокол передачи почты Почтовые серверы, используемые для передачи электронной почты, используют SMTP для отправки и получения почтовых сообщений. Вы по-прежнему обнаружите, что даже с Microsoft 365 протокол SMTP используется для той же цели.\nHTTP - Hyper Text Transfer Protocol - Протокол передачи гипертекста HTTP является основой Интернета и просмотра контента. Дает нам возможность легко получить доступ к нашим любимым веб-сайтам. HTTP по-прежнему широко используется, но HTTPS используется или должен использоваться на большинстве ваших любимых сайтов.\nSSL - Secure Sockets Layer | TLS - Transport Layer Security - Уровень защищенных сокетов | TLS — безопасность транспортного уровня TLS заменил SSL, TLS — это криптографический протокол, который обеспечивает безопасность связи по сети. Его можно найти в почте, мессенджерах и других приложениях, но чаще всего он используется для защиты HTTPS.\nHTTPS - HTTP secured with SSL/TLS - HTTP, защищенный с помощью SSL/TLS Расширение HTTP, используемое для безопасной связи по сети, HTTPS шифруется с помощью TLS, как упоминалось выше. Основное внимание здесь уделялось обеспечению аутентификации, конфиденциальности и целостности при обмене данными между хостами.\nDNS - Domain Name System - система доменных имен DNS используется для сопоставления удобных для человека доменных имен, например, все мы знаем google.com, но если вы откроете браузер и введете 8.8.8.8 вы получите Google в том виде, в каком мы его знаем. Однако удачи вам в попытках запомнить все IP-адреса всех ваших веб-сайтов, на некоторых из них мы даже используем Google для поиска информации.\nИменно здесь в дело вступает DNS, он гарантирует доступность хостов, служб и других ресурсов.\nНа всех хостах, если им требуется подключение к Интернету, они должны иметь DNS, чтобы иметь возможность разрешать эти доменные имена. DNS — это область, на изучение которой вы можете потратить дни и годы. Я бы также сказал по опыту, что DNS в основном является распространенной причиной всех ошибок, когда речь идет о сети. Однако не уверен, что сетевой инженер согласится с этим.\nDHCP - Dynamic Host Configuration Protocol - Протокол динамического конфигурирования сервера Мы много обсуждали протоколы, необходимые для работы наших хостов, будь то доступ в Интернет или передача файлов между собой.\nНа каждом хосте нам нужны 4 вещи, чтобы он мог выполнять обе эти задачи.\nIP Address Subnet Mask Default Gateway DNS Мы рассмотрели IP-адрес, являющийся уникальным адресом для вашего хоста в сети, в которой он находится, мы можем думать об этом как о нашем домашнем номере.\nМаску подсети мы скоро рассмотрим, но вы можете думать об этом как о почтовом индексе или почтовом индексе.\nШлюз по умолчанию — это IP-адрес нашего маршрутизатора, как правило, в нашей сети, предоставляющий нам возможность подключения уровня 3. Вы могли бы думать об этом как о единственной дороге, которая позволяет нам покинуть нашу улицу.\nЗатем у нас есть DNS, как мы только что рассмотрели, чтобы помочь нам преобразовать сложные общедоступные IP-адреса в более подходящие и запоминающиеся доменные имена. Может быть, мы можем думать об этом как о гигантском сортировочном офисе, чтобы убедиться, что мы получаем правильный пост.\nКак я уже сказал, каждому хосту требуются эти 4 вещи, если у вас 1000 или 10 000 хостов, вам потребуется очень много времени, чтобы определить каждый из них по отдельности. Здесь в дело вступает DHCP, который позволяет вам определить область действия вашей сети, а затем этот протокол будет распространяться на все доступные хосты в вашей сети.\nДругой пример: вы идете в кафе, берете кофе и садитесь за свой ноутбук, или ваш телефон позволяет назвать это вашим хостом. Вы подключаете свой хост к Wi-Fi в кофейне, и вы получаете доступ к Интернету, сообщения и почта начинают пинговаться, и вы можете просматривать веб-страницы и социальные сети. Когда вы подключались к Wi-Fi в кофейне, ваша машина получала DHCP-адрес либо от выделенного DHCP-сервера, либо, скорее всего, от маршрутизатора, который также обрабатывает DHCP.\nSubnetting - Подсети Подсеть — это логическое подразделение IP-сети.\nПодсети разбивают большие сети на более мелкие, более управляемые сети, которые работают более эффективно.\nКаждая подсеть является логическим подразделением большей сети. Подключенные устройства с достаточным количеством подсетей имеют общий идентификатор IP-адреса, что позволяет им взаимодействовать друг с другом.\nМаршрутизаторы управляют связью между подсетями.\nРазмер подсети зависит от требований к подключению и используемой сетевой технологии.\nОрганизация несет ответственность за определение своего количества и размера подсетей в пределах адресного пространства. доступны, и детали остаются локальными для этой организации. Подсети также могут быть сегментированы на еще более мелкие подсети для таких вещей, как соединения «точка-точка», или для подсетей, поддерживающих несколько устройств.\nСреди прочих преимуществ сегментация крупных сети в подсети включает IP-адрес перераспределение и уменьшает перегрузку сети, оптимизацию, сетевую связь и эффективность.\nПодсети также могут повысить безопасность сети. Если часть сети скомпрометирована, ее можно поместить в карантин, что затруднит перемещение злоумышленников по более крупной сети.\nРесурсы Computer Networking full course Practical Networking ","description":"Протоколы сети","title":"23. Протоколы сети","uri":"/ru/tracks/90daysofdevops/day23/"},{"content":"Автоматизация сети Основы сетевой автоматизации Основные задачи для сетевой автоматизации\nТестирование устройств и проверка конфигурации; Инициализация развернутых физических устройств и сервисов, а также развертывание и инициализация виртуальных устройств; Сбор сетевых данных, относящихся к устройствам, системам, программному обеспечению, топологии сети, трафику и сервисам в реальном времени; Анализ данных, в том числе упреждающая аналитика ИИ и машинного обучения, для обеспечения информации о текущем и будущем поведении сети; Проверка соответствия конфигурации требованиям для обеспечения правильной работы всех сетевых устройств и сервисов; Обновление программного обеспечения, включая откат программного обеспечения при необходимости; Замкнутая коррекция проблем с сетью, включая поиск и устранение неисправностей, а также исправление сложных и трудновыявляемых сбоев; Подробный анализ отчетов, панелей наблюдения, оповещений и предупреждений; Реализация требований безопасности; Мониторинг сети и ее сервисов для поддержания уровня обслуживания и удовлетворенности клиентов Процесс внедрения автоматизации специфичен для каждого бизнеса. Когда дело доходит до развертывания автоматизации, не существует универсального решения. Способность определить и использовать подход, который лучше всего подходит для вашей организации, имеет решающее значение для продвижения к поддержке и созданию более гибкой среды для пользователей. (Мы обсуждали что-то подобное в самом начале в отношении всего DevOps, изменения культуры и автоматизированного процесса, который это приносит)\nЧтобы разобраться во всем, вам нужно будет определить, как задача или процесс, которые вы пытаетесь автоматизировать, будут улучшать опыт конечного пользователя или ценность для бизнеса, следуя пошаговому систематическому подходу.\n«Если не знаешь, куда идешь, любая дорога приведет тебя туда».\nИмея структуру проекта, которую вы пытаетесь достичь, зная, какова ваша конечная цель, а затем шаг за шагом работая над достижением этой цели, измеряйте успех автоматизации на различных этапах на основе бизнес-результатов.\nСоздавайте концепции, моделируя существующие приложения. Нет необходимости разрабатывать концепции автоматизации в пузыре, потому что их нужно применять к вашему приложению, вашему сервису, вашей инфраструктуре, поэтому начните создавать концепции и моделировать их вокруг вашей существующей инфраструктуры, вы повторно существующие приложения.\nПодход к автоматизации сети Мы должны определить задачи и выполнить обнаружение запросов на изменение сети, чтобы у вас были наиболее распространенные проблемы и проблемы, решение которых нужно автоматизировать.\nСоставьте список всех запросов на изменение и рабочих процессов, которые в настоящее время обрабатываются вручную. Определить наиболее распространенные, трудоемкие и подверженные ошибкам действия. Приоритизируйте запросы, используя бизнес-ориентированный подход. Это основа построения процесса автоматизации, что нужно автоматизировать, а что нет. Затем мы должны разделить задачи и проанализировать, как разные сетевые функции работают и взаимодействуют друг с другом.\nКоманда инфраструктуры/сети получает заявки на изменения на нескольких уровнях для развертывания приложений. На основе сетевых сервисов разделить их на разные области и понять, как они взаимодействуют друг с другом. Оптимизация приложений ADC (контроллер доставки приложений) (Application Delivery Controller) Межсетевой экран DDI (DNS, DHCP, IPAM и т. д.) Маршрутизация Другие Определите различные зависимости, чтобы устранить деловые и культурные различия и обеспечить сотрудничество между командами. Повторно используемые политики, определение и упрощение повторно используемых сервисных задач, процессов и ввода/вывода.\nОпределить предложения для различных услуг, процессов и ввода/вывода. Упрощение процесса развертывания сократит время выхода на рынок как новых, так и существующих рабочих нагрузок. Когда у вас есть стандартный процесс, его можно упорядочить и согласовать с отдельными запросами для многопоточного подхода и доставки. Объедините политики со специфическими для бизнеса действиями. Как внедрение этой политики помогает бизнесу? Экономит время? Экономит деньги? Обеспечивает лучший бизнес-результат?\nУбедитесь, что сервисные задачи совместимы. Свяжите добавочные сервисные задачи, чтобы они соответствовали созданию бизнес-сервисов. Обеспечьте гибкость связывания и повторного связывания сервисных задач по запросу. Разверните возможности самообслуживания и проложите путь к повышению операционной эффективности. Разрешить несколько наборов технологических навыков продолжать вносить свой вклад в надзор и соответствие. Управляйте политиками и процессами, добавляя и улучшая их, сохраняя при этом доступность и обслуживание.\nНачните с малого, автоматизировав существующие задачи. Ознакомьтесь с процессом автоматизации, чтобы вы могли определить другие области, которые могут выиграть от автоматизации. повторяйте свои инициативы по автоматизации, постепенно добавляя гибкость при сохранении требуемой доступности. Использование поэтапного подхода прокладывает путь к успеху! Оркестрируйте сетевой сервис!\nДля быстрой доставки приложений требуется автоматизация процесса развертывания. Создание гибкой сервисной среды требует управления различными элементами в рамках набора технологических навыков. Подготовьтесь к комплексной оркестровке, обеспечивающей контроль над автоматизацией и порядком развертывания. Инструменты автоматизации сети Хорошей новостью здесь является то, что по большей части инструменты, которые мы используем для автоматизации сети, как правило, те же, что мы будем использовать для других областей автоматизации.\nОпреационная система. Большую часть своего обучения я сосредоточился на использовании инструментов под Linux. Но почти все инструменты, которых мы коснемся, кросплатформенные.\nИнтегрированная среда разработки (IDE). Опять же, здесь особо нечего сказать, кроме всего прочего, я бы предложил Visual Studio Code в качестве вашей IDE, основываясь на обширных подключаемых модулях, доступных для стольких разных языков.\nУправление конфигурацией. Мы еще не добрались до раздела «Управление конфигурацией», но совершенно очевидно, что Ansible является фаворитом в этой области для управления и автоматизации конфигураций. Ansible написан на Python, но вам не нужно знать Python. Link to Ansible Network Modules\nМы также коснемся Ansible Tower в разделе управления конфигурацией, рассматривая его как внешний интерфейс с графическим интерфейсом (GUI) для Ansible.\nCI/CD. Мы рассмотрим больше концепций и инструментов, связанных с этим, но важно хотя бы упомянуть здесь, поскольку это охватывает не только сеть, но и все предоставление услуг и платформ.\nВ частности, Jenkins предоставляет или кажется популярным инструментом для сетевой автоматизации.\nОтслеживает репозиторий git на наличие изменений, а затем инициирует их. Контроль версий (Version Control). Углубимся в это позже.\nGit обеспечивает контроль версий вашего кода на локальном устройстве - Кроссплатформенность GitHub, GitLab, BitBucket и т. д. — это онлайн-сайты, на которых вы определяете свои репозитории и загружаете свой код. Language | Scripting. Что-то, что мы здесь не рассмотрели, это Python как язык, я решил вместо этого погрузиться в Go как язык программирования, исходя из моих обстоятельств, я бы сказал, что это был тесный контакт между Golang и Python и Python, кажется, Победитель в категории «Сетевая автоматизация».\nЗдесь стоит упомянуть Nornir, фреймворк автоматизации, написанный на Python. Кажется, что это берет на себя роль Ansible, но особенно в отношении сетевой автоматизации. Документация Nornir Анализ API. Postman — отличный инструмент для анализа RESTful API. Помогает создавать, тестировать и изменять API.\nPOST »\u003e Для создания объектов ресурсов. GET »\u003e Для получения ресурсов. PUT »\u003e Для создания или замены ресурсов. PATCH »\u003e Для создания или обновления объекта ресурсов. Delete »\u003e Чтобы удалить ресурс Postman tool Download\nЕще инструменты Cisco NSO (Network Services Orchestrator)\nNetYCE - Simplify Network Automation\nNetwork Test Automation\nВ течение следующих 3 дней я планирую более подробно изучить некоторые вещи, которые мы рассмотрели, и поработать над Python и сетевой автоматизацией.\nДо сих пор мы далеко не охватили все сетевые темы, но хотели сделать это достаточно широким, чтобы следовать за ним и продолжать учиться на ресурсах, которые я добавляю ниже.\nРесурсы 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation ","description":"Автоматизация сети","title":"24. Автоматизация сети","uri":"/ru/tracks/90daysofdevops/day24/"},{"content":"Python для автоматизации сети Python — это стандартный язык, используемый для автоматизированных сетевых операций.\nХотя это не только автоматизация сети, кажется, что оно везде, когда вы ищете ресурсы, и, как упоминалось ранее, если это не Python, то обычно это Ansible, который также написан на Python.\nЯ думаю, что уже упоминал об этом, но в разделе «Изучение языка программирования» я выбрал Golang, а не Python, по причинам, связанным с тем, что моя компания разрабатывает Go, так что это было хорошей причиной для меня, чтобы учиться, но если это не так, тогда Python взял бы это время.\nУдобочитаемость и простота использования. Кажется, что Python просто имеет смысл. Похоже, что в коде нет требований к {} для начального и конечного блоков. Соедините это с сильной IDE, такой как VS Code, у вас будет довольно легкий старт, если вы хотите запустить какой-либо код Python. Pycharm может быть еще одной IDE, о которой стоит упомянуть.\nБиблиотеки. Расширяемость Python - это настоящая золотая жила, я упоминал ранее, что это не только для сетевой автоматизации, но на самом деле существует множество библиотек для всех видов устройств и конфигураций. Вы можете увидеть огромное количество здесь PyPi Если вы хотите загрузить библиотеку на свою рабочую станцию, вы используете инструмент под названием «pip», чтобы подключиться к PyPI и загрузить его локально. Сетевые поставщики, такие как Cisco, Juniper и Arista, разработали библиотеки для облегчения доступа к своим устройствам.\nМощный и эффективный - Помните, во времена Go я прошел сценарий “Hello World”, и мы прошли, кажется, 6 строк кода? В Питоне это print('hello world') Сложите все вышеперечисленные пункты вместе, и должно быть легко понять, почему Python обычно упоминается как инструмент де-факто при работе над автоматизацией.\nЯ думаю, важно отметить, что, возможно, несколько лет назад существовали сценарии, которые могли взаимодействовать с вашими сетевыми устройствами, чтобы, возможно, автоматизировать резервное копирование конфигурации или собирать журналы и другую информацию о ваших устройствах. Автоматизация, о которой мы здесь говорим, немного отличается, потому что общий сетевой ландшафт также изменился, чтобы лучше соответствовать этому образу мышления и обеспечить большую автоматизацию.\nПрограммно-определяемая сеть (Software-Defined Network). Контроллеры SDN несут ответственность за доставку конфигурации уровня управления на все устройства в сети, что означает только единую точку контакта для любых изменений в сети, больше не требуется telnet или SSH для доступа к каждому устройству, а также полагаются на люди, чтобы сделать это, что имеет повторяющийся шанс отказа или неправильной конфигурации.\nОркестрация высокого уровня (High-Level Orchestration ). Поднимитесь на уровень выше этих контроллеров SDN, и это позволит оркестровать уровни обслуживания, а затем интегрировать этот уровень оркестровки в выбранные вами платформы, VMware, Kubernetes, общедоступные облака и т. д.\nУправление на основе политик (Policy-based management) - Что вы хотите иметь? Какое желаемое состояние? Вы описываете это, и в системе есть все детали, как это понять, чтобы стать желаемым состоянием.\nНастройка рабочей среды Не у всех есть доступ к физическим маршрутизаторам, коммутаторам и другим сетевым устройствам.\nЯ хотел дать нам возможность ознакомиться с некоторыми из ранее упомянутых инструментов, а также получить практические навыки и научиться автоматизировать настройку наших сетей.\nКогда дело доходит до вариантов, есть несколько, из которых мы можем выбрать.\nGNS3 VM Eve-ng Unimus Мы построим нашу среду, используя Eve-ng, как упоминалось ранее, вы можете использовать физическое устройство, но, честно говоря, виртуальная среда означает, что у нас может быть среда-песочница. для тестирования множества различных сценариев. Кроме того, может быть интересна возможность играть с различными устройствами и топологиями.\nМы собираемся делать все на EVE-NG с изданием сообщества.\nНачало Издание сообщества поставляется в форматах ISO и OVF для загрузки.\nМы будем использовать загрузку в формате OVF, но в случае с ISO есть возможность сборки на «голом железе» без использования гипервизора.\nДля нашего пошагового руководства мы будем использовать VMware Workstation, поскольку у меня есть лицензия через мой vExpert, но вы в равной степени можете использовать VMware Player или любой другой вариант, упомянутый в документации. К сожалению, мы не можем использовать нашу ранее созданную среду в Virtual box!\nЗдесь также у меня возникла проблема с GNS3 с Virtual Box, хотя он и поддерживается.\nDownload VMware Workstation Player - FREE\nVMware Workstation PRO. Есть бесплатный пробный период.\nУстановка на VMware Workstation PRO Теперь у нас загружено и установлено программное обеспечение hypervisor, а также загружен файл EVE-NG OVF. Теперь мы готовы к настройке. Откройте VMware Workstation, а затем выберите file -\u003e open.\nКогда вы загружаете образ EVE-NG OVF, он будет находиться в сжатом файле. Извлеките содержимое в свою папку, чтобы оно выглядело так. Перейдите в папку, в которую вы загрузили образ EVE-NG OVF, и начните импорт. Дайте ему узнаваемое имя и сохраните виртуальную машину где-нибудь в вашей системе.\nКогда процесс импорта завершится, увеличьте количество процессоров до 4 и объем выделенной памяти до 8 ГБ. (Это должно быть после импорта с последней версией, если нет, то отредактируйте настройки ВМ)\nТакже убедитесь, что установлен флажок Virtualise Intel VT-x/EPT или AMD-V/RVI. Этот параметр указывает рабочей станции VMware передавать флаги виртуализации гостевой ОС (вложенная виртуализация). Это была проблема, с которой я столкнулся с GNS3 с Virtual Box, хотя мой процессор это позволяет.\nВключение и доступ Примечание и кроличья нора: помните, я упоминал, что это не будет работать с VirtualBox! Ну да, была такая же проблема с VMware Workstation и EVE-NG, но это не вина платформы виртуализации!\nУ меня есть WSL2, работающий на моей машине с Windows, и это, похоже, лишает возможности запускать что-либо, вложенное в вашу среду. Я смущен тем, почему виртуальная машина Ubuntu работает, поскольку она, кажется, устраняет аспект виртуализации Intel VT-d ЦП при использовании WSL2.\nЧтобы решить эту проблему, мы можем запустить следующую команду на нашем компьютере с Windows и перезагрузить систему, обратите внимание, что, пока она отключена, вы не сможете использовать WSL2.\nbcdedit /set hypervisorlaunchtype off\nЕсли вы хотите вернуться и использовать WSL2, вам нужно будет запустить эту команду и перезагрузиться.\nbcdedit /set hypervisorlaunchtype auto\nОбе эти команды нужно запускать от имени администратора!\nХорошо, вернемся к шоу. Теперь у вас должна быть включенная машина в VMware Workstation, и у вас должно появиться приглашение, похожее на это.\nДанные для входа:\nusername = root password = eve\nЗатем вас попросят снова ввести пароль root, который позже будет использоваться для SSH-соединения с хостом. Затем мы можем изменить имя хоста.\nЗатем мы определяем доменное имя DNS, я использовал имя ниже, но я не уверен, нужно ли будет его изменить позже.\nЗатем мы настраиваем сеть, я выбираю статический, чтобы указанный IP-адрес оставался постоянным после перезагрузки. На последнем шаге укажите статический IP-адрес из сети, доступной с вашей рабочей станции. Здесь есть несколько дополнительных шагов, где вам нужно будет указать маску подсети для вашей сети, шлюз по умолчанию и DNS. После завершения он перезагрузится, когда будет выполнено резервное копирование, вы можете взять свой статический IP-адрес и ввести его в свой браузер. Имя пользователя по умолчанию для графического интерфейса — «admin», пароль — «eve», а имя пользователя по умолчанию для SSH — «root» и пароль — «eve», но это было бы изменено, если бы вы изменили его во время установки. Я выбрал HTML5 для консоли вместо нативной, так как это откроет новую вкладку в вашем браузере, когда вы будете перемещаться по разным консолям.\nДалее мы собираемся:\nУстановить клиентский пакет EVE-NG Загрузить некоторые сетевые образы в EVE-NG. Построить топологию сети Добавить “ноды” (машины/хосты, Nodes) Соединить ноды между собой Начнем создавать скрипты Python Посмотрим на telnetlib, Netmiko, Paramiko и Pexpect Ресурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation ","description":"Автоматизация сети с помощью Python","title":"25. Автоматизация сети с помощью Python","uri":"/ru/tracks/90daysofdevops/day25/"},{"content":"Создание нашей лаборатории Мы собираемся продолжить настройку нашей эмулируемой сети с помощью EVE-NG, а затем, надеюсь, развернуть несколько устройств и начать думать о том, как мы можем автоматизировать настройку этих устройств. В День 25 мы рассказали об установке EVE-NG на нашу машину с помощью VMware Workstation.\nУстановка клиента EVE-NG Существует также клиентский пакет, который позволяет нам выбирать, какое приложение используется при подключении к устройствам по SSH. Он также настроит Wireshark для захвата пакетов между ссылками. Вы можете установить клиентский пакет для своей ОС (Windows, macOS, Linux).\nEVE-NG Client Download\nПодсказка: если вы используете Linux в качестве клиента, то есть этот клиентский пакет.\nУстановка проста: next, next и я бы посоветовал оставить значения по умолчанию.\nПолучение сетевых образов Этот шаг непростой, я просмотрел несколько видеороликов, на которые я дам ссылки в конце, которые ссылаются на некоторые ресурсы и загрузки для нашего маршрутизатора и переключают изображения, рассказывая нам, как и куда их загрузить.\nВажно отметить, что я использую все в образовательных целях. Я бы предложил загрузить официальные образы от сетевых поставщиков.\nBlog \u0026 Links to YouTube videos\nHow To Add Cisco VIRL vIOS image to Eve-ng\nВ целом шаги здесь немного сложны и могли бы быть намного проще, но приведенные выше блоги и видео показывают процесс добавления изображений в вашу коробку EVE-NG.\nЯ использовал FileZilla для передачи qcow2 на виртуальную машину через SFTP.\nДля нашей лаборатории нам нужны Cisco vIOS L2 (коммутаторы) и Cisco vIOS (маршрутизатор).\nСоздаем лабораторию Внутри веб-интерфейса EVE-NG мы собираемся создать нашу новую топологию сети. У нас будет четыре коммутатора и один маршрутизатор, который будет нашим шлюзом во внешние сети.\nNode IP Address Router 10.10.88.110 Switch1 10.10.88.111 Switch2 10.10.88.112 Switch3 10.10.88.113 Switch4 10.10.88.114 Добавление наших узлов в EVE-NG Когда вы впервые войдете в EVE-NG, вы увидите экран, как показано ниже, мы хотим начать с создания нашей первой лаборатории.\nДайте вашей лаборатории имя, а остальные поля являются необязательными.\nЗатем увидим пустой экран, чтобы начать создание вашей сети. Щелкните правой кнопкой мыши на своем холсте и выберите ‘add node’.\nДалее появляется длинный список опций. Если вы следовали вышеизложенному, у вас будут два синих, показанных ниже, а остальные будут серыми и недоступными для выбора.\nМы хотим добавить следующее в нашу лабораторию:\n1 x Cisco vIOS Router 4 x Cisco vIOS Switch Соединяем наши ноды Теперь нам нужно добавить возможность подключения между нашими маршрутизаторами и коммутаторами. Мы можем сделать это довольно легко, наведя курсор на устройство и увидев значок подключения, как показано ниже, а затем подключив его к устройству, к которому мы хотим подключиться.\nКогда вы закончите подключение своей среды, вы также можете добавить способ определения физических границ или местоположений с помощью прямоугольников или кругов, которые также можно найти в контекстном меню. Вы также можете добавить текст, который полезен, когда мы хотим определить наши имена или IP-адреса в наших лабораториях.\nЯ пошел дальше и сделал свою лабораторию такой, как показано ниже. You will also notice that the lab above is all powered off, we can start our lab by selecting everything and right-clicking and selecting start selected.\nКак только мы запустим нашу лабораторию, вы сможете подключаться к консоли на каждом устройстве, и вы заметите, что на этом этапе они довольно тупые без настройки. Мы можем добавить некоторую конфигурацию к каждому узлу, скопировав или создав свою собственную в каждом терминале.\nЯ оставлю свою конфигурацию в сетевой папке репозитория для справки.\nNode Configuration Router R1 Switch1 SW1 Switch2 SW2 Switch3 SW3 Switch4 SW4 Ресурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation Большинство примеров, которые я использую здесь, поскольку я не сетевой инженер, взяты из этой обширной книги, которая не является бесплатной, но я использую некоторые примеры оттуда, чтобы помочь понять автоматизацию сети.\nHands-On Enterprise Automation with Python (Book) ","description":"Развертывание виртуальной лаборатории EVE-NG в домашних условиях","title":"26. Развертывание виртуальной лаборатории EVE-NG в домашних условиях","uri":"/ru/tracks/90daysofdevops/day26/"},{"content":"Практическое знакомство с Python и сетью В этом заключительном разделе основ работы с сетью мы рассмотрим некоторые задачи и инструменты автоматизации с помощью нашей лабораторной среды, созданной День 26\nМы будем использовать туннель SSH для подключения к нашим устройствам с нашего клиента по сравнению с telnet. Туннель SSH, созданный между клиентом и устройством, зашифрован. Мы также рассмотрели SSH в разделе Linux в День 18\nДоступ к нашей виртуальной эмулируемой среде Чтобы мы могли взаимодействовать с нашими коммутаторами, нам либо нужна рабочая станция внутри сети EVE-NG, и вы можете развернуть там Linux-систему с установленным Python для выполнения вашей автоматизации (Ресурс для настройки Linux внутри EVE-NG) или можно сделать как я и определить облако для доступа со своей рабочей станции.\nДля этого мы щелкнули правой кнопкой мыши на нашем холсте и выбрали сеть, а затем выбрали “Management(Cloud0)”, чтобы подключиться к нашей домашней сети.\nОднако внутри этой сети у нас ничего нет, поэтому нам нужно добавить соединения из новой сети на каждое из наших устройств. Я вошел в систему на каждом из наших устройств и выполнил следующие команды для интерфейсов, применимых к тому месту, где появляется облако.\nenable config t int gi0/0 ip add dhcp no sh exit exit sh ip int br Последний шаг дает нам адрес DHCP из нашей домашней сети. Список сетей моего устройства выглядит следующим образом:\nNode IP Address Home Network IP Router 10.10.88.110 192.168.169.115 Switch1 10.10.88.111 192.168.169.178 Switch2 10.10.88.112 192.168.169.193 Switch3 10.10.88.113 192.168.169.125 Switch4 10.10.88.114 192.168.169.197 SSH к сетевому устройству Имея все вышеперечисленное, мы теперь можем подключаться к нашим устройствам в нашей домашней сети, используя нашу рабочую станцию. Я использую Putty, но также имею доступ к другим терминалам, таким как git bash, которые дают мне возможность подключаться к нашим устройствам по SSH.\nНиже вы можете видеть, что у нас есть SSH-соединение с нашим маршрутизатором. (Р1)\nИспользование Python для сбора информации с наших устройств Первый пример того, как мы можем использовать Python, — это сбор информации со всех наших устройств, и, в частности, я хочу иметь возможность подключаться к каждому из них и запускать простую команду, чтобы предоставить мне конфигурацию и настройки интерфейса. Я сохранил этот скрипт:\n#!/usr/bin/env python from netmiko import ConnectHandler from getpass import getpass #password = getpass() R1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.115\", \"username\": \"admin\", \"password\": \"access123\", } SW1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.178\", \"username\": \"admin\", \"password\": \"access123\", } SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", } SW3 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.125\", \"username\": \"admin\", \"password\": \"access123\", } SW4 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.197\", \"username\": \"admin\", \"password\": \"access123\", } command = \"show ip int brief\" for device in (R1, SW1, SW2, SW3, SW4): net_connect = ConnectHandler(**device) print(net_connect.find_prompt()) print(net_connect.send_command(command)) net_connect.disconnect() Теперь, когда я запускаю это, я вижу каждую конфигурацию порта на всех моих устройствах.\nЭто может быть удобно, если у вас много разных устройств, создайте этот один скрипт, чтобы вы могли централизованно контролировать и быстро понимать все конфигурации в одном месте.\nИспользование Python для настройки наших устройств Вышеупомянутое полезно, но как насчет использования Python для настройки наших устройств, в нашем сценарии у нас есть транковый порт между ‘SW1’ и ‘SW2’, снова представьте, если бы это нужно было сделать на многих из тех же коммутаторов, которые мы хотим автоматизировать, и не нужно вручную подключаться к каждому коммутатору, чтобы внести изменения в конфигурацию.\nДля этого мы можем использовать следующий скрипт. Это подключится через SSH и выполнит это изменение на нашем ‘SW1’, которое также изменится на ‘SW2’.\nfrom netmiko import ConnectHandler SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", \"secret\": \"access123\", } core_sw_config = [\"int range gig0/1 - 2\", \"switchport trunk encapsulation dot1q\", \"switchport mode trunk\", \"switchport trunk allowed vlan 1,2\"] print(\"########## Connecting to Device {0} ############\".format(SW2)) net_connect = ConnectHandler(**SW2) net_connect.enable() print(\"***** Sending Configuration to Device *****\") net_connect.send_config_set(core_sw_config) Теперь если посмотреть на код, вы увидите, что появляется сообщение «sending configuration to device», но нет подтверждения того, что это произошло. Мы могли бы добавить дополнительный код в наш скрипт, чтобы выполнить эту проверку и проверку на нашем switch или мы могли бы изменить наш сценарий, прежде чем показать нам это.\n#!/usr/bin/env python from netmiko import ConnectHandler from getpass import getpass #password = getpass() SW1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.178\", \"username\": \"admin\", \"password\": \"access123\", } SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", } SW3 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.125\", \"username\": \"admin\", \"password\": \"access123\", } SW4 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.197\", \"username\": \"admin\", \"password\": \"access123\", } command = \"show int trunk\" for device in (SW1, SW2, SW3, SW4): net_connect = ConnectHandler(**device) print(net_connect.find_prompt()) print(net_connect.send_command(command)) net_connect.disconnect() Резервное копирование конфигураций вашего устройства Другим вариантом использования может быть захват наших сетевых конфигураций и обеспечение их резервного копирования, но опять же, мы не хотим подключаться ко всем устройствам, которые у нас есть в нашей сети, поэтому мы также можем автоматизировать это с помощью скрипта\nimport sys import time import paramiko import os import cmd import datetime now = datetime.datetime.now() dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\") print(\"Your backup has started at\", dt_string)\ttic = time.perf_counter() #user = input(\"Enter username:\") #password = input(\"Enter Paswd:\") #enable_password = input(\"Enter enable pswd:\") user = \"admin\" password = \"access123\" enable_password = \"access123\" port=22 f0 = open('backup.txt') for ip in f0.readlines(): ip = ip.strip() filename_prefix ='/Users/shambhu/Documents' + ip ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(ip,port, user, password, look_for_keys=False) chan = ssh.invoke_shell() time.sleep(2) chan.send('enable\\n') chan.send(enable_password +'\\n') time.sleep(1) chan.send('term len 0\\n') time.sleep(1) chan.send('sh run\\n') time.sleep(20) output = chan.recv(999999) filename = \"%s_%.2i%.2i%i_%.2i%.2i%.2i\" % (ip,now.year,now.month,now.day,now.hour,now.minute,now.second) f1 = open(filename, 'a') f1.write(output.decode(\"utf-8\") ) f1.close() ssh.close() f0.close() toc = time.perf_counter() print(\"Congratulations You Have Backed Up Your 90DaysOfDevOps Lab\") print(f\"Your backup duration was {toc - tic:0.4f} seconds\") dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\") print(\"Your backup completed at\", dt_string) Вам также потребуется заполнить backup.txt IP-адресами, для которых вы хотите сделать резервную копию.\n192.168.169.115 192.168.169.178 192.168.169.193 192.168.169.125 192.168.169.197 Запустите свой скрипт, и вы должны увидеть что-то вроде того, что показано ниже.\nЭто может быть я просто пишу простой скрипт печати на питоне, поэтому я также должен показать вам файлы резервных копий. Paramiko Широко используемый модуль Python для SSH. Вы можете узнать больше по официальной ссылке GitHub здесь\nМы можем установить этот модуль с помощью команды pip install paramiko.\nМы можем проверить установку, войдя в оболочку Python и импортировав модуль paramiko.\nNetmiko Модуль netmiko предназначен специально для сетевых устройств, тогда как paramiko — это более широкий инструмент для обработки SSH-соединений в целом.\nNetmiko, который мы использовали выше вместе с paramiko, можно установить с помощью pip install netmiko.\nNetmiko поддерживает множество сетевых поставщиков и устройств, список поддерживаемых устройств можно найти на странице GitHub.\nДругие модули Также стоит упомянуть несколько других модулей, на которые у нас не было возможности взглянуть, но они дают гораздо больше функциональных возможностей, когда речь идет об автоматизации сети.\nnetaddr используется для работы с IP-адресами и управления ими, опять же установка проста с помощью pip install netaddr\nвы можете захотеть сохранить большую часть конфигурации вашего коммутатора в электронной таблице Excel, xlrd позволит вашим сценариям читать книгу Excel и преобразовывать строки и столбцы в матрицу. pip install xlrd, чтобы установить модуль.\nЕще несколько случаев использования сетевой автоматизации, которые я не имел возможности изучить, можно найти здесь\nЯ думаю, что это завершает наш раздел «Сетевые ресурсы» #90DaysOfDevOps. Networking — это одна из областей, которую я действительно не касался какое-то время, и есть так много всего, что нужно осветить, но я надеюсь, что мои заметки и ресурсы, которыми я делюсь, будут полезны для некоторый.\nРесурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation Hands-On Enterprise Automation with Python (Book) Увидимся завтра, где начнем изучать облачные вычисления и получите хорошее представление и базовые знания\n","description":"Работа с сетью в Python","title":"27. Работа с сетью в Python","uri":"/ru/tracks/90daysofdevops/day27/"},{"content":"Общая картина: DevOps и облака Когда дело доходит до облачных вычислений и того, что они предлагают, это очень хорошо сочетается с духом и процессами DevOps. Мы можем думать об облачных вычислениях, предоставляющих технологии и услуги, в то время как DevOps, как мы уже много раз упоминали ранее, касается процессов и их улучшения.\nНо начать с этого путешествия по обучению в облаке сложно, и убедиться, что вы знаете и понимаете все элементы или лучший сервис для выбора по правильной цене, сбивает с толку. Накладывается ли на облака парадигма DevOps? Мой ответ здесь — нет, но чтобы по-настоящему воспользоваться преимуществами облачных вычислений и, возможно, избежать больших счетов за облачные вычисления, от которых пострадало так много людей, важно думать об облачных вычислениях и DevOps вместе.\nЕсли мы посмотрим на то, что мы подразумеваем под Public Cloud в общем смысле, речь идет о снятии некоторой ответственности с управляемой службы, чтобы вы и ваша команда могли сосредоточиться на более важных аспектах, имя которых должно быть приложением и конечными пользователями. . В конце концов, Public Cloud — это просто чей-то компьютер. В этом первом разделе я хочу немного подробнее рассказать о том, что такое Public Cloud, и о некоторых блоках, которые в целом называются Public Cloud .\nSaaS Первая область, которую следует рассмотреть, — это программное обеспечение как услуга (SaaS - Software as a service,). Эта услуга устраняет почти все накладные расходы на управление службой, которую вы, возможно, когда-то запускали локально. Давайте подумаем о Microsoft Exchange для нашей электронной почты. Раньше это была физическая коробка, которая находилась в вашем центре обработки данных или, может быть, в шкафу под лестницей. Вам нужно будет кормить и поить этот сервер. Под этим я подразумеваю, что вам нужно будет обновлять его, и вы будете нести ответственность за покупку серверного оборудования, скорее всего, за установку операционной системы, установку необходимых приложений, а затем за исправление, если что-то пойдет не так, вам придется устранить неполадки и получить вещи встали на свои места.\nО, и вам также нужно будет убедиться, что вы делаете резервную копию своих данных, хотя по большей части это не меняется и с SaaS.\nЧто делает SaaS и, в частности, Microsoft 365, потому что я упомянул, что Exchange устраняет эти накладные расходы на администрирование, и они предоставляют услугу, которая обеспечивает ваши функции обмена по почте, а также многие другие параметры производительности (Office 365) и варианты хранения (OneDrive), которые в целом дают большой опыт для конечного пользователя.\nШироко распространены и другие приложения SaaS, такие как Salesforce, SAP, Oracle, Google, Apple. Все это избавляет от необходимости управлять большим количеством стека.\nЯ уверен, что есть история с приложениями на основе DevOps и SaaS, но я изо всех сил пытаюсь выяснить, что они могут собой представлять. Я знаю, что у Azure DevOps есть отличная интеграция с Microsoft 365, которую я мог бы изучить и сообщить.\nPublic Cloud Далее у нас есть public cloud. Большинство людей думают об этом по-разному, некоторые считают, что это только гипермасштаберы, такие как Microsoft Azure, Google Cloud Platform и AWS. Некоторые также видят в общедоступном облаке гораздо более широкое предложение, включающее не только гиперскейлеры, но и тысячи MSP (managed service provider) по всему миру. В этом посте мы собираемся рассмотреть общедоступное облако, включая гиперскейлеры и MSP, хотя позже мы специально углубимся в один или несколько гиперскейлеров, чтобы получить базовые знания.\nтысячи других компаний могли бы присоединиться к этому, я просто выбираю из местных, региональных, телекоммуникационных и глобальных брендов, с которыми я работал и о которых знаю.\nВ разделе SaaS мы упомянули, что облако сняло ответственность или бремя администрирования частей системы. Если SaaS, мы видим, что многие уровни абстракции удалены, то есть физические системы, сеть, хранилище, операционная система и даже приложения в некоторой степени. Когда дело доходит до облака, существуют различные уровни абстракции, которые мы можем удалить или оставить в зависимости от ваших требований.\nМы уже упоминали SaaS, но есть еще по крайней мере два, которые следует упомянуть в отношении общедоступного облака.\nИнфраструктура как услуга. Вы можете думать об этом уровне как о виртуальной машине, но в то время как локально вам придется заботиться о физическом уровне в облаке, это не так, физический уровень является обязанностью облачных провайдеров, и вы будете управлять и управлять операционной системой, данными и приложениями, которые вы хотите запустить.\nПлатформа как услуга. Это по-прежнему снимает ответственность уровней, и на самом деле это означает, что вы берете под свой контроль данные и приложение, но вам не нужно беспокоиться об аппаратном обеспечении или операционной системе.\nЕсть много других предложений AaS, но это два основных принципа. Вы можете увидеть предложения вокруг StaaS (Storage as a service), которые предоставляют вам уровень хранения, но не нужно беспокоиться об оборудовании под ним. Или вы, возможно, слышали о CaaS для контейнеров как об услуге, к которой мы вернемся позже. Еще одна услуга как услуга, которую мы рассмотрим в течение следующих 7 дней, — это FaaS (Functions as a Service), где, возможно, вам не нужна работающая система. все время, и вы просто хотите, чтобы функция выполнялась как и когда.\nЕсть много способов, которыми общедоступное облако может предоставить уровни абстракции управления, от которых вы хотите отказаться и заплатить за них.\nPrivate Cloud Наличие собственного центра обработки данных не осталось в прошлом. Я думаю, что это стало возрождением среди многих компаний, которым было трудно управлять моделью OPEX, а также набором навыков только в использовании общедоступного облака.\nЗдесь важно отметить, что общедоступное облако, скорее всего, теперь будет вашей ответственностью и будет находиться на вашей территории.\nУ нас есть некоторые интересные вещи, происходящие в этой сфере не только с VMware, которая доминировала в эпоху виртуализации, и с локальными инфраструктурными средами. У нас также есть гиперскейлеры, предлагающие локальную версию своих публичных облаков. Hybrid Cloud В продолжение упоминаний о публичном и частном облаке мы также можем охватить обе эти среды, чтобы обеспечить гибкость между ними, возможно, воспользоваться услугами, доступными в общедоступном облаке, а затем также воспользоваться преимуществами функций и возможностей локальной среды. или это может быть правило, которое предписывает вам хранить данные локально. Собрав все это вместе, у нас есть много вариантов, где мы будем хранить и запускать наши рабочие нагрузки. Прежде чем мы перейдем к конкретному гипермасштабу, я спросил силу Твиттера, куда нам следует двигаться? Link to Twitter Poll\nКакой бы процент ни получил самый высокий процент, мы углубимся в предложения, я думаю, что важно упомянуть, что услуги во всех них очень похожи, поэтому я говорю начать с одного, потому что я обнаружил, что, зная основа одного из них и как создавать виртуальные машины, настраивать сеть и т. д. Я смог перейти к другим и быстро набраться опыта в этих областях.\nВ любом случае, я поделюсь отличными БЕСПЛАТНЫМИ ресурсами, которые охватывают все три гиперскейлера.\nЯ также собираюсь разработать сценарий, как я делал это в других разделах, где мы можем что-то построить по мере продвижения по дням.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Обзор применения инфрастуктуры DevOps в облаке","title":"28. DevOps в облаке","uri":"/ru/tracks/90daysofdevops/day28/"},{"content":"Знакомство с Microsoft Azure Прежде чем мы начнем, победителем опроса в Твиттере стала Microsoft Azure, отсюда и название страницы. Это было довольно интересно увидеть результаты, полученные в течение 24 часов.\nЯ бы сказал, что с точки зрения освещения этой темы я лучше понимаю и пользуюсь услугами, доступных в Microsoft Azure. Сегодня я склоняюсь к Amazon AWS. Однако я выделил разделы для всех трех основных облачных провайдеров.\nЯ ценю, что их больше, и опрос включал только эти 3, и, в частности, были некоторые комментарии об Oracle Cloud. Я хотел бы услышать больше о других облачных провайдерах, которые используются в дикой природе.\nОсновы Предоставляет общедоступные облачные сервисы\nГеографически распределены (более 60 регионов по всему миру)\nДоступ через Интернет и/или частные соединения\nМультитенантная модель\nВыставление счетов на основе потребления - (Плати по мере использования | Плати по мере роста)\nБольшое количество типов услуг и предложений для различных требований.\nMicrosoft Azure Global Infrastructure Сколько бы мы ни говорили о SaaS и Hybrid Cloud, мы не планируем затрагивать эти темы здесь.\nЛучший способ начать и продолжить работу — щелкнуть ссылку, которая позволит вам зарегистрировать Бесплатную учетную запись Microsoft Azure\nРегионы Я связал интерактивную карту выше, но мы можем видеть изображение под широтой регионов, предлагаемых на платформе Microsoft Azure по всему миру. image taken from Microsoft Docs - 01/05/2021\nВы также увидите несколько sovereign облаков, что означает, что они не связаны или не могут взаимодействовать с другими регионами, например, они будут связаны с правительствами, такими как «AzureUSGovernment», а также «AzureChinaCloud» и другими.\nКогда мы развертываем наши службы в Microsoft Azure, мы выбираем регион почти для всего. Однако важно отметить, что не все услуги доступны в каждом регионе. Вы можете увидеть Продукты, доступные по регионам на момент написания моего письма, что в западно-центральной части США мы не можем использовать Azure Databricks.\nЯ также упомянул «почти все» выше, есть определенные службы, связанные с регионом, такие как Azure Bot Services, Bing Speech, Azure Virtual Desktop, статические веб-приложения и некоторые другие.\nЗа кулисами регион может состоять из более чем одного центра обработки данных. Они будут называться зонами доступности.\nНа изображении ниже вы увидите, что это снова взято из официальной документации Microsoft, в которой описывается, что такое регион и как он состоит из зон доступности. Однако не во всех регионах есть несколько зон доступности.\nВ Microsoft хорошая документация, и вы можете прочитать больше о Регионах и зонах доступности здесь.\nПодписки Помните, что мы упоминали, что Microsoft Azure — это облако модели потребления, и вы обнаружите, что все основные поставщики облачных услуг следуют этой модели.\nЕсли вы являетесь Предприятием, вы можете захотеть или заключить соглашение Enterprise с Microsoft, чтобы ваша компания могла использовать эти службы Azure.\nЕсли вы похожи на меня и используете Microsoft Azure для обучения, у нас есть несколько других вариантов.\nУ нас есть Бесплатная учетная запись Microsoft Azure, которая обычно дает вам несколько бесплатных облачных кредитов, которые вы можете потратить в Azure в течение некоторого времени.\nСуществует также возможность использовать подписку Visual Studio, которая дает вам, возможно, несколько бесплатных кредитов каждый месяц вместе с вашей годовой подпиской на Visual Studio, которая много лет назад была широко известна как MSDN. Visual Studio\nЗатем, наконец, вручите кредитную карту и заплатите, как вы идете, модель. Оплата по мере использования\nПодписку можно рассматривать как границу между разными подписками, потенциально являющимися центрами затрат, но совершенно разными средами. Подписка — это место, где создаются ресурсы.\nManagement Groups Группы управления дают нам возможность разделять управление в нашей Azure AD или в нашей клиентской среде. Группы управления позволяют нам контролировать политики, RBAC (Role-based access control) и бюджеты.\nПодписки принадлежат этим группам управления, поэтому у вас может быть много подписок в вашем клиенте Azure AD. Эти подписки также могут управлять политиками, RBAC и бюджетами.\nResource Manager and Resource Groups Azure Resource Manager\nAPI на основе JSON, основанный на поставщиках ресурсов. Ресурсы принадлежат группе ресурсов и имеют общий жизненный цикл. Параллелизм Развертывания на основе JSON являются декларативными, идемпотентными и понимают зависимости между ресурсами для управления созданием и порядком. Resource Groups\nКаждый ресурс Azure Resource Manager существует в одной и только одной группе ресурсов! Группы ресурсов создаются в регионе, который может содержать ресурсы из-за пределов региона. Ресурсы можно перемещать между группами ресурсов Группы ресурсов не отгорожены от других групп ресурсов, между группами ресурсов может быть связь. Группы ресурсов также могут управлять политиками, RBAC и бюджетами. Практика Давайте подключимся и убедимся, что у нас есть Подписка. Мы можем проверить нашу простую готовую Группу управления. Затем мы можем пойти и создать новую выделенную Группу ресурсов в предпочитаемом нами Регионе.\nПри первом входе на наш портал Azure вверху вы увидите возможность поиска ресурсов, служб и документов.\nСначала мы рассмотрим нашу подписку. Здесь вы увидите, что я использую подписку Visual Studio Professional, которая дает мне бесплатный “кредит” каждый месяц.\nЕсли мы углубимся в это, вы получите более широкое представление и посмотрите, что происходит или что можно сделать с подпиской, мы можем увидеть информацию о выставлении счетов с функциями управления слева, где вы можете определить контроль доступа к IAM, а ниже доступно больше ресурсов.\nМожет возникнуть ситуация, когда у вас есть несколько подписок, и вы хотите управлять ими всеми в рамках одной, и именно здесь можно использовать группы управления для разделения групп ответственности. В моем ниже вы можете видеть, что есть только моя корневая группа арендатора с моей подпиской.\nВы также увидите на предыдущем изображении, что родительская группа управления — это тот же идентификатор, который используется в корневой группе арендатора.\nЗатем у нас есть группы ресурсов, здесь мы объединяем наши ресурсы и можем легко управлять ими в одном месте. У меня есть несколько созданных для различных других проектов.\nЧто мы собираемся делать в течение следующих нескольких дней, мы хотим создать нашу группу ресурсов. Это легко сделать в этой консоли, выбрав опцию создания на предыдущем изображении.\nПроисходит этап проверки, после чего у вас есть возможность просмотреть свое творение, а затем создать его. Вы также увидите внизу «Загрузить шаблон для автоматизации», это позволяет нам получить формат JSON, чтобы мы могли выполнить это просто автоматически позже, если мы захотим, мы также рассмотрим это позже. Нажмите «Create», затем в нашем списке групп ресурсов у нас теперь есть группа «90DaysOfDevOps», готовая к тому, что мы будем делать в следующем сеансе. Ресурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Туториал по Microsoft Azure с нуля","title":"29. Знакомство с Microsoft Azure","uri":"/ru/tracks/90daysofdevops/day29/"},{"content":"Жизненный цикл DevOps — ориентированность на приложения По мере того, как мы будем продолжать в течение следующих нескольких недель, мы будем сталкиваться с этими названиями (Continuous Development, Testing, Deployment, Monitor) (непрерывная разработка, тестирование, развертывание, мониторинг) снова и снова. Если вы стремитесь статья инженером DevOps, то повторяемость будет тем, к чему вы привыкнете, но постоянное улучшение каждый раз — это еще одна вещь, которая делает вещи интересными.\nВ этом часе мы рассмотрим общий вид приложения от начала до конца, а затем вернемся назад, как в постоянном цикле.\nРазработка Давайте возьмем совершенно новый пример приложения, для начала у нас ничего не создано, возможно, как разработчик вы должны обсудить с вашим клиентом или конечным пользователем требования и придумать какой-то план или требования для вашего приложения. Затем нам нужно создать согласно требованиям наше новое приложение.\nЧто касается инструментов на данном этапе, здесь нет никаких реальных требований, кроме выбора вашей IDE и языка программирования, который вы хотите использовать для написания своего приложения.\nКак инженер DevOps, помните, что вы, вероятно, не тот, кто создает этот план или создает приложение для конечного пользователя, этим занимается опытный разработчик.\nНо вам также не помешает иметь возможность прочитать часть кода, чтобы вы могли принимать наилучшие решения по инфраструктуре для своего приложения.\nРанее мы упоминали, что приложение может быть написано на любом языке. Важно, чтобы это поддерживалось с помощью системы контроля версий, это то, что мы также подробно рассмотрим позже, и, в частности, мы углубимся в Git.\nТакже вероятно, что над этим проектом будет работать не один разработчик, хотя это может иметь место, но даже в этом случае передовой опыт потребует репозиторий кода для хранения и совместной работы над кодом, он может быть частным или общедоступным и может быть размещен или если говорить о частном развертывании, вы наверняка слышали, как GitHub или GitLab используются в качестве репозитория кода. Мы снова рассмотрим их позже в разделе Git.\nТестирование На данном этапе у нас есть свои требования и наша задача - разработать приложение. Но нам нужно убедиться, что мы тестируем наш код во всех различных средах, которые у нас есть, или, возможно, в выбранном языке программирования.\nЭтот этап позволяет QA тестировать на наличие ошибок, чаще мы видим, что контейнеры используются для моделирования тестовой среды, что в целом может снизить накладные расходы на физическую или облачную инфраструктуру.\nЭтот этап также, вероятно, будет автоматизирован как часть следующей области — непрерывной интеграции.\nВозможность автоматизировать это тестирование по сравнению с 10, 100 или даже 1000 инженерами по контролю качества, которые должны делать это вручную, говорит сама за себя, эти инженеры могут сосредоточиться на чем-то другом в стеке, чтобы гарантировать, что вы двигаетесь быстрее и разрабатываете больше функций по сравнению с тестированием ошибок и программного обеспечения. что, как правило, является задержкой для большинства традиционных выпусков программного обеспечения, использующих методологию водопада (Waterfall).\nИнтеграция Очень важно, что интеграция находится в середине жизненного цикла DevOps. Это практика, когда разработчикам требуется чаще вносить изменения в исходный код. Это может быть ежедневно или еженедельно.\nС каждым коммитом ваше приложение может проходить этапы автоматизированного тестирования, что позволяет на раннем этапе обнаруживать проблемы или ошибки до следующего этапа.\nНа этом этапе вы можете сказать: «Но мы не создаем приложения, мы покупаем их в готовом виде у поставщика программного обеспечения». Не волнуйтесь, многие компании делают это и будут продолжать делать, и именно поставщик программного обеспечения будет концентрируется на трех вышеупомянутых этапах, но вы, возможно, захотите принять последний этап, поскольку это позволит быстрее и эффективнее развертывать готовые развертывания.\nЯ бы также сказал, что очень важно просто иметь эти вышеперечисленные знания, поскольку сегодня вы можете купить готовое программное обеспечение, но что насчет завтра или в будущем … может быть, на следующей работе?\nРазвертывание / Deployment Итак, наше приложение создано и протестировано в соответствии с требованиями нашего конечного пользователя, и теперь нам нужно приступить к развертыванию этого приложения в рабочей среде для использования нашими конечными пользователями.\nЭто этап, когда код развертывается на рабочих серверах, теперь все становится чрезвычайно интересным, и именно здесь оставшиеся 86 дней мы глубже погружаемся в эти области. Потому что разные приложения требуют различного аппаратного обеспечения или конфигураций. Именно здесь Управление конфигурацией приложений и Инфраструктура как код могут сыграть ключевую роль в жизненном цикле DevOps. Возможно, ваше приложение контейнеризовано, но его также можно запустить на виртуальной машине. Это также приводит наше изучение к таким платформам, как Kubernetes, которые будут организовывать эти контейнеры и следить за тем, чтобы желаемое состояние было доступно вашим конечным пользователям.\nВсе эти смелые темы мы рассмотрим более подробно в течение следующих нескольких недель, чтобы лучше понять основы того, что они из себя представляют и когда их использовать.\nМониторинг / Monitoring Все быстро меняется, и у нас есть наше приложение, которое мы постоянно обновляем новыми функциями и функциями, и у нас есть наше тестирование, чтобы убедиться, что функциональность не нарушена. У нас есть приложение, работающее в нашей среде, которое может постоянно поддерживать требуемую конфигурацию и производительность.\nНо теперь мы должны быть уверены, что наши конечные пользователи получают то, что им нужно. Здесь нам нужно убедиться, что производительность нашего приложения постоянно отслеживается, этот этап позволит вашим разработчикам принимать более взвешенные решения об улучшениях приложения в будущих выпусках, чтобы лучше обслуживать конечных пользователей.\nНадежность также является ключевым фактором здесь, в конце концов, мы хотим, чтобы наше приложение было доступно все время, когда оно требуется. Затем это дает возможность другим областям наблюдаемости, безопасности и управления данными, которые следует постоянно контролировать, а обратную связь всегда можно использовать для улучшения, обновления и непрерывного выпуска приложения.\nНекоторый вклад от сообщества здесь, в частности @_ediri, упоминает также часть этого непрерывного процесса, мы также должны привлечь команды FinOps. Приложения и данные работают и хранятся где-то, за чем вы должны постоянно следить, чтобы убедиться, что если что-то изменится с точки зрения ресурсов, ваши расходы не вызовут серьезных финансовых проблем с вашими облачными счетами.\nЯ думаю, что сейчас самое время упомянуть упомянутого выше «инженера DevOps». Я имею в виду, что из разговора с другими членами сообщества звание инженера DevOps не должно быть целью ни для кого, потому что на самом деле любая должность должна включать процессы DevOps и культуру, описанную здесь. DevOps следует использовать на самых разных должностях, таких как облачный инженер/архитектор, администратор виртуализации, облачный архитектор/инженер, администратор инфраструктуры. Это лишь некоторые из них, но причина использования DevOps Engineer, описанная выше, на самом деле заключалась в том, чтобы выделить объем или процесс, используемый любой из вышеперечисленных должностей, и многое другое.\nИсточники Я всегда открыт для добавления дополнительных ресурсов в эти файлы readme, поскольку они здесь в качестве учебного пособия.\nМой совет — посмотрите все, что ниже, и, надеюсь, вы тоже что-то почерпнули из текста и объяснений выше.\nМетодология разработки CI/CD Continuous Development Continuous Testing - IBM YouTube Continuous Integration - IBM YouTube Continuous Monitoring The Remote Flow FinOps Foundation - What is FinOps NOT FREE The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win До встречи в День 4\n","description":"Ориентированность на приложения","title":"3. Ориентированность на приложения","uri":"/ru/tracks/90daysofdevops/day03/"},{"content":"Microsoft Azure Security Models Следуя обзору Microsoft Azure, мы начнем с безопасности Azure и посмотрим, как это может помочь в наши дни. По большей части я обнаружил, что встроенных ролей было достаточно, и зная это, мы можем создавать и работать со многими различными областями аутентификации и конфигураций. Я обнаружил, что Microsoft Azure довольно продвинута с ее инструментом Active Directory по сравнению с другими общедоступными облаками.\nЭто одна из областей, в которой Microsoft Azure, по-видимому, работает иначе, чем другие поставщики общедоступных облаков, в Azure ВСЕГДА есть Azure AD.\nСлужбы каталогов (Directory Services ) Azure Active Directory содержит принципы безопасности, используемые Microsoft Azure и другими облачными службами Microsoft. Аутентификация осуществляется с помощью таких протоколов, как SAML, WS-Federation, OpenID Connect и OAuth2. Запросы выполняются через REST API, который называется Microsoft Graph API. У арендаторов по умолчанию есть имя tenant.onmicrosoft.com, но они также могут иметь собственные доменные имена. Подписки связаны с арендатором Azure Active Directory. Если мы сравним с AWS, эквивалентным предложением будет AWS IAM (управление идентификацией и доступом), хотя все еще очень разные\nAzure AD Connect предоставляет возможность репликации учетных записей из AD в Azure AD. Сюда также могут входить группы и иногда объекты. Это может быть гранулировано и отфильтровано. Поддерживает несколько лесов и доменов.\nВ Microsoft Azure Active Directory (AD) можно создавать облачные учетные записи, но большинство организаций уже учли своих пользователей в собственной локальной Active Directory.\nAzure AD Connect также позволяет вам видеть не только серверы Windows AD, но и другие Azure AD, Google и другие. Это также дает возможность сотрудничать с внешними людьми и организациями, что называется Azure B2B.\nВарианты аутентификации между доменными службами Active Directory и Microsoft Azure Active Directory возможны с синхронизацией удостоверений с хэшем пароля.\nПередача хэша пароля необязательна, если он не используется, требуется сквозная аутентификация.\nНиже приведено видео, в котором подробно рассказывается о сквозной аутентификации.\nUser sign-in with Azure Active Directory Pass-through Authentication\nФедерации (Federation) Справедливости ради стоит сказать, что если вы используете Microsoft 365, Microsoft Dynamics и локальную Active Directory, их довольно легко понять и интегрировать в Azure AD для федерации. Однако вы можете использовать другие службы за пределами экосистемы Microsoft.\nAzure AD может выступать в качестве посредника федерации для этих других приложений сторонних производителей и других служб каталогов.\nЭто будет отображаться на портале Azure как корпоративные приложения, для которых существует большое количество вариантов.\nЕсли вы прокрутите вниз страницу корпоративного приложения, вы увидите длинный список рекомендуемых приложений.\nЭта опция также позволяет «принести свою» интеграцию, приложение, которое вы разрабатываете, или приложение, не являющееся галереей.\nЯ не изучал это раньше, но вижу, что это вполне подходящий набор функций по сравнению с другими облачными провайдерами и возможностями.\nУправление доступом на основе ролей Мы уже рассмотрели в День 29 области, которые мы собираемся охватить здесь, мы можем настроить управление доступом на основе ролей в соответствии с одной из этих областей.\nSubscriptions Management Group Resource Group Resources Роли можно разделить на три, в Microsoft Azure много встроенных ролей. Эти три:\nOwner Contributor Reader Владелец и участник очень похожи по своим границам, однако владелец может изменять разрешения.\nДругие роли относятся к определенным типам ресурсов Azure, а также к пользовательским ролям.\nМы должны сосредоточиться на назначении разрешений группам и пользователям.\nРазрешения наследуются.\nЕсли мы вернемся назад и посмотрим на группу ресурсов «90DaysOfDevOps», которую мы создали, и проверим контроль доступа (IAM) внутри, вы увидите, что у нас есть список участников и администратор доступа пользователей клиента, и у нас есть список владельцев (но Я не могу это показать)\nМы также можем проверить роли, которые мы назначили здесь, являются ли они встроенными ролями и к какой категории они относятся.\nМы также можем использовать вкладку проверки доступа, если мы хотим проверить учетную запись по этой группе ресурсов и убедиться, что учетная запись, к которой мы хотим иметь этот доступ, имеет правильные разрешения, или, может быть, мы хотим проверить, не имеет ли пользователь слишком много доступа.\nMicrosoft Defender for Cloud Microsoft Defender for Cloud (ранее известный как Azure Security Center) предоставляет информацию о безопасности всей среды Azure.\nЕдиная панель мониторинга для просмотра общего состояния безопасности всех ресурсов Azure и других ресурсов (через Azure Arc) и рекомендации по усилению безопасности.\nУровень бесплатного пользования включает постоянную оценку и рекомендации по безопасности.\nПлатные планы для защищенных типов ресурсов (например, серверы, AppService, SQL, хранилище, контейнеры, KeyVault).\nЯ перешел на другую подписку для просмотра Центра безопасности Azure, и вы можете увидеть здесь, основываясь на очень небольшом количестве ресурсов, что у меня есть некоторые рекомендации в одном месте.\nAzure Policy Azure Policy — это собственная служба Azure, которая помогает применять организационные стандарты и оценивать соответствие в масштабе.\nИнтегрирован в Microsoft Defender для облака. Azure Policy проверяет несоответствующие ресурсы и применяет исправления.\nОбычно используется для управления согласованностью ресурсов, соблюдением нормативных требований, безопасностью, стоимостью и стандартами управления.\nИспользует формат JSON для хранения логики оценки и определения того, соответствует ли ресурс требованиям или нет, а также любых действий, которые необходимо предпринять в случае несоответствия (например, аудит, аудит, если не существует, запретить, изменить, развернуть, если не существует).\nБесплатно для использования. Исключение составляют подключенные ресурсы Azure Arc, взимаемые за сервер в месяц за использование гостевой конфигурации политики Azure.\nПрактика Я купил домен и хотел бы добавить этот на свой портал Azure Active Directory, Add your custom domain name using the Azure Active Directory Portal\nТеперь мы можем создать нового пользователя в нашем новом домене Active Directory.\nТеперь мы хотим создать группу для всех наших новых пользователей 90DaysOfDevOps в одной группе. Мы можем создать группу, как показано ниже, обратите внимание, что я использую «Динамический пользователь», это означает, что Azure AD будет запрашивать учетные записи пользователей и добавлять их динамически по сравнению с назначенными, когда вы вручную добавляете пользователя в свою группу.\nСуществует множество вариантов создания вашего запроса, мой план состоит в том, чтобы просто найти основное имя и убедиться, что оно содержит мой запрос.\nТеперь, поскольку мы уже создали нашу учетную запись пользователя, мы можем проверить, работают ли правила. Для сравнения я также добавил здесь еще одну учетную запись, связанную с другим доменом, и вы можете видеть, что из-за этого правила наш пользователь не попадет в эту группу.\nС тех пор я добавил нового пользователя, и если мы пойдем и проверим группу, мы увидим наших участников.\nЕсли у нас есть это требование x100, то мы не собираемся делать все это в консоли, мы собираемся воспользоваться либо массовыми параметрами для создания, приглашения, удаления пользователей, либо вы захотите изучить PowerShell для достичь этого автоматизированного подхода к масштабированию.\nТеперь мы можем перейти к нашей группе ресурсов и указать, что в группе ресурсов 90DaysOfDevOps мы хотим, чтобы владельцем была группа, которую мы только что создали.\nМы также можем войти сюда и запретить доступ назначений к нашей группе ресурсов.\nТеперь, если мы войдем на портал Azure с нашей новой учетной записью пользователя, вы увидите, что у нас есть доступ только к нашей группе ресурсов 90DaysOfDevOps, а не к другим, показанным на предыдущих рисунках, потому что у нас нет доступа.\nВышеприведенное замечательно, если это пользователь, имеющий доступ к ресурсам внутри вашего портала Azure, но не каждый пользователь должен знать о портале, но для проверки доступа мы можем использовать Портал приложений Это портал единого входа, который мы тестируем.\nВы можете настроить этот портал под своим собственным брендом, и мы, возможно, вернемся к этому позже.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Модули безопасности Microsoft Azure","title":"30. Модули безопасности Microsoft Azure","uri":"/ru/tracks/90daysofdevops/day30/"},{"content":"Среда выполнения приложений Вслед за вчерашним обзором основ моделей безопасности в Microsoft Azure, сегодня мы собираемся изучить различные службы вычислений, доступные нам в Azure.\nПараметры службы доступности Этот раздел мне близок, учитывая мою роль в управлении данными. Как и в случае с локальной средой, очень важно обеспечить доступность ваших служб.\nВысокая доступность (Защита в пределах региона) Аварийное восстановление (Защита между регионами) Резервное копирование (Восстановление с момента времени) Microsoft развертывает несколько регионов в пределах геополитических границ.\nДве концепции Azure для доступности услуг.\nНаборы доступности (виртуальных машин) — обеспечивают отказоустойчивость в центре обработки данных.\nЗоны доступности — обеспечивают отказоустойчивость между центрами обработки данных в пределах региона.\nВиртуальные машины Предоставляет виртуальные машины различных серий и размеров с различными возможностями (иногда огромными) Размеры виртуальных машин в Azure Существует множество различных вариантов и фокусов для виртуальных машин, от высокопроизводительных, с малой задержкой до виртуальных машин с большим объемом памяти. У нас также есть расширяемый тип ВМ, который можно найти в серии B. Это отлично подходит для рабочих нагрузок, где у вас могут быть низкие требования к ЦП по большей части, но требуется, чтобы, возможно, один раз в месяц требовалась всплеск производительности. Виртуальные машины размещаются в виртуальной сети, которая может обеспечить подключение к любой сети. Поддержка гостевых ОС Windows и Linux. Существуют также ядра, настроенные для Azure, если речь идет о конкретных дистрибутивах Linux. Ядра, настроенные Azure Шаблоны В Microsoft Azure шаблоны исполнений можно конфигурировать с помощью JSON.\nСуществует несколько различных порталов и консолей управления, которые мы можем использовать для создания наших ресурсов. Предпочтительнее будет через шаблоны JSON.\nИдемпотентные развертывания в инкрементном или полном режиме — т.е. повторяемое желаемое состояние.\nСуществует большой выбор шаблонов, которые могут экспортировать развернутые определения ресурсов. Мне нравится думать об этой функции шаблонов как о чем-то вроде AWS CloudFormation или, возможно, о Terraform для мультиоблачного варианта. Подробнее о Terraform мы расскажем в разделе «Инфраструктура как код».\nМасштабирование Автоматическое масштабирование — это крупная функция общедоступного облака, позволяющая сократить ресурсы, которые вы не используете, или активировать, когда они вам нужны.\nВ Azure у нас есть так называемые масштабируемые наборы виртуальных машин (VMSS) для IaaS. Это позволяет автоматически создавать и масштабировать изображение золотого стандарта на основе расписаний и показателей.\nЭто идеально подходит для обновления окон, чтобы вы могли обновлять свои образы и развертывать их с наименьшими последствиями.\nВ другие службы, такие как службы приложений Azure, встроено автоматическое масштабирование.\nКонтейнеры Мы не рассмотрели контейнеры как пример использования и то, что и как они могут и должны быть необходимы в нашем учебном путешествии по DevOps, но мы должны упомянуть, что у Azure есть некоторые конкретные службы, ориентированные на контейнеры, которые следует упомянуть.\nСлужба Azure Kubernetes (AKS) (Azure Kubernetes Service) — предоставляет управляемое решение Kubernetes.\nЭкземпляры контейнеров Azure — контейнеры как услуга с посекундной оплатой. Запустите образ и интегрируйте его с вашей виртуальной сетью, не нуждаясь в оркестровке контейнеров.\nService Fabric — имеет множество возможностей, но включает оркестрацию для экземпляров контейнеров.\nAzure также имеет реестр контейнеров, который предоставляет частный реестр для образов Docker, диаграмм Helm, артефактов Open Container Initiative (OCI) и образов. Подробнее об этом снова, когда мы дойдем до раздела контейнеров.\nМногие службы контейнеров действительно могут использовать контейнеры “под капотом”, но это абстрагируется от наших требований к управлению.\nСлужбы приложений Службы приложений Azure предоставляют решение для размещения приложений, которое обеспечивает простой способ установки служб. Автоматическое развертывание и масштабирование. Поддерживает решения на базе Windows и Linux. Службы выполняются в плане службы приложений, который имеет тип и размер. Количество различных сервисов, включая веб-приложения, приложения API и мобильные приложения. Поддержка слотов развертывания для надежного тестирования и продвижения. Бессерверные вычисления Цель бессерверных вычислений заключается в том, что мы платим только за время выполнения функции, и нам не нужно постоянно запускать виртуальные машины или приложения PaaS. Мы просто запускаем нашу функцию, когда она нам нужна, а затем она исчезает.\nФункции Azure — предоставляет бессерверный код. Если мы вернемся к нашему первому взгляду на общедоступное облако, вы вспомните уровень абстракции управления, с бессерверными функциями вы будете управлять только кодом.\nУ меня есть план, ориентированный на события в больших масштабах, когда я получу здесь немного практики, надеюсь, позже.\nОбеспечивает входную и выходную привязку ко многим Azure и сторонним службам.\nПоддерживает множество различных языков программирования. (C#, NodeJS, Python, PHP, bash, Golang, Rust или любой исполняемый файл)\nСетка событий Azure позволяет запускать логику из служб и событий.\nПриложение Azure Logic обеспечивает графический рабочий процесс и интеграцию.\nМы также можем рассмотреть пакетную службу Azure, которая может выполнять крупномасштабные задания на узлах Windows и Linux с согласованным управлением и планированием.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Microsoft Azure Среда выполнения приложений","title":"31. Microsoft Azure Среда выполнения приложений","uri":"/ru/tracks/90daysofdevops/day31/"},{"content":"Модели хранилища Службы хранилища Службы хранилища Azure предоставляются учетными записями хранения. Доступ к учетным записям хранения в основном осуществляется через REST API. Учетная запись хранения должна иметь уникальное имя, являющееся частью DNS-имени \u003cStorage Account name\u003e.core.windows.net. Различные варианты репликации и шифрования. Находится в группе ресурсов Мы можем создать нашу группу хранения, просто выполнив поиск группы хранения в строке поиска в верхней части портала Azure.\nЗатем мы можем выполнить шаги по созданию нашей учетной записи хранения, помня, что это имя должно быть уникальным, а также оно должно быть написано строчными буквами, без пробелов, но может включать цифры.\nМы также можем выбрать уровень избыточности, который мы хотели бы использовать для нашей учетной записи хранения и всего, что мы здесь храним. Чем дальше по списку, тем дороже вариант, но также и распространение ваших данных.\nДаже опция избыточности по умолчанию дает нам 3 копии наших данных.\nAzure Storage Redundancy\nКонцепции из ссылки выше:\nЛокально-избыточное хранилище — трижды реплицирует ваши данные в пределах одного центра обработки данных в основном регионе.\nГеоизбыточное хранилище — трижды синхронно копирует ваши данные в одном физическом расположении в основном регионе с помощью LRS.\nХранилище с избыточностью в пределах зоны — синхронно реплицирует данные службы хранилища Azure в трех зонах доступности Azure в основном регионе.\nХранилище с избыточностью в геозонах — сочетает в себе высокую доступность, обеспечиваемую избыточностью в зонах доступности, с защитой от региональных сбоев, обеспечиваемой георепликацией. Данные в учетной записи хранения GZRS копируются в три зоны доступности Azure в основном регионе, а также реплицируются во второй географический регион для защиты от региональных аварий.\nПросто возвращаюсь к параметрам производительности. У нас есть Стандарт и Премиум на выбор. В нашем пошаговом руководстве мы выбрали «Стандартный», но «Премиум» дает вам некоторые специфические опции. Затем в раскрывающемся списке вы можете увидеть, что у нас есть эти три варианта на выбор. Для учетной записи хранения доступно множество дополнительных параметров, но пока нам не нужно вдаваться в это. Эти параметры связаны с шифрованием и защитой данных.\nУправляемые диски Доступ к хранилищу можно получить несколькими способами.\nАутентифицированный доступ через:\nОбщий ключ для полного контроля. Shared Access Signature для делегированного, детализированного доступа. Azure Active Directory (где доступно) Публичный доступ:\nОбщий доступ также может быть предоставлен для включения анонимного доступа, в том числе через HTTP. — Примером этого может быть размещение базового контента и файлов в блочном BLOB-объекте, чтобы браузер мог просматривать и скачивать эти данные. Если вы получаете доступ к своему хранилищу из другой службы Azure, трафик остается в Azure.\nКогда дело доходит до производительности хранилища, у нас есть два разных типа:\nStandard - Максимальное количество операций ввода-вывода в секунду Premium - Гарантированное количество операций ввода-вывода в секунду Существует также разница между неуправляемыми и управляемыми дисками, которую следует учитывать при выборе правильного хранилища для поставленной задачи.\nХранилище виртуальной машины Диски ОС виртуальной машины обычно хранятся в постоянном хранилище. Некоторым рабочим нагрузкам без сохранения состояния не требуется постоянное хранилище, и уменьшение задержки является большим преимуществом. Существуют виртуальные машины, поддерживающие эфемерные управляемые диски ОС, созданные в локальном хранилище узла. Их также можно использовать с масштабируемыми наборами виртуальных машин. Управляемые диски — это надежное блочное хранилище, которое можно использовать с виртуальными машинами Azure. Вы можете иметь Ultra Disk Storage, Premium SSD, Standard SSD, Standard HDD. Они также несут некоторые характеристики.\nПоддержка снимков и изображений Простое перемещение между SKU Лучшая доступность в сочетании с наборами доступности Плата взимается в зависимости от размера диска, а не от использованного хранилища. Хранилище архивов Cool Tier — доступен классный уровень хранилища для блокировки и добавления больших двоичных объектов. Более низкая стоимость хранения Более высокая стоимость сделки. Archive Tier* — Архивное хранилище доступно для блочных больших двоичных объектов. Это настраивается для каждого BLOB-объекта. Более низкая стоимость, более длительная задержка поиска данных. Такая же надежность данных, как и в обычном хранилище Azure. Пользовательские уровни данных могут быть включены по мере необходимости. Общий доступ к файлам Из вышеописанного создания нашей учетной записи хранения теперь мы можем создавать общие файловые ресурсы.\nЭто обеспечит файловые ресурсы SMB2.1 и 3.0 в Azure.\nМожно использовать в Azure и извне через SMB3 и порт 445, открытый для Интернета.\nПредоставляет общее хранилище файлов в Azure.\nМожно сопоставить с помощью стандартных клиентов SMB в дополнение к REST API.\nВы также можете почитать Azure NetApp Files (SMB и NFS)\nСлужбы кэширования и мультимедиа Сеть доставки содержимого Azure предоставляет кэш статического веб-содержимого с местоположениями по всему миру.\nСлужбы мультимедиа Azure предоставляют технологии транскодирования мультимедиа в дополнение к службам воспроизведения.\nМодели баз данных Microsoft Azure Еще в День 28 мы рассмотрели различные варианты обслуживания. Одним из них была PaaS (Platform as a Service) (платформа как услуга), где вы абстрагируете большую часть инфраструктуры и операционной системы, и вам остается контролировать приложение или, в данном случае, модели базы данных.\nРеляционные базы данных База данных SQL Azure предоставляет реляционную базу данных как службу на основе Microsoft SQL Server.\nЭто SQL, работающий с последней веткой SQL с доступным уровнем совместимости базы данных, где требуется конкретная версия функциональности.\nЕсть несколько вариантов того, как это можно настроить: мы можем предоставить единую базу данных, которая предоставляет одну базу данных в экземпляре, в то время как эластичный пул позволяет использовать несколько баз данных, которые совместно используют пул емкости и совместно масштабируются.\nДоступ к этим экземплярам базы данных можно получить как к обычным экземплярам SQL.\nДополнительные управляемые предложения для MySQL, PostgreSQL и MariaDB.\nРешения NoSQL Azure Cosmos DB — это реализация NoSQL, не зависящая от схемы.\n99,99% SLA\nГлобально распределенная база данных с однозначными задержками на 99-м процентиле в любой точке мира с автоматическим возвратом в исходное положение.\nКлюч раздела, используемый для разделения/разбиения/распределения данных.\nПоддерживает различные модели данных (документы, ключ-значение, график, удобный для столбцов)\nПоддерживает различные API (DocumentDB SQL, MongoDB, Azure Table Storage и Gremlin).\nДоступны различные модели согласованности, основанные на теореме CAP.\nКэширование Не вдаваясь в подробности о системах кэширования, таких как Redis, я хотел добавить, что у Microsoft Azure есть служба под названием Azure Cache for Redis.\nКэш Azure для Redis предоставляет хранилище данных в памяти на основе программного обеспечения Redis.\nЭто реализация Redis Cache с открытым исходным кодом. Размещенный безопасный экземпляр кэша Redis. Доступны разные уровни Приложение должно быть обновлено, чтобы использовать кеш. Предназначен для приложения, которое имеет высокие требования к чтению по сравнению с записью. На основе хранилища ключей-значений. Я ценю, что за последние несколько дней было много заметок и теории о Microsoft Azure, но я хотел охватить строительные блоки, прежде чем мы перейдем к практическим аспектам того, как эти компоненты объединяются и работают.\nУ нас есть еще немного теории, связанной с сетью, прежде чем мы сможем запустить и запустить некоторые основанные на сценариях развертывания сервисов. Мы также хотим взглянуть на некоторые различные способы взаимодействия с Microsoft Azure по сравнению с порталом, который мы использовали до сих пор.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course ","description":"Модели хранилища Microsoft Azure","title":"32. Модели хранилища Microsoft Azure","uri":"/ru/tracks/90daysofdevops/day32/"},{"content":"Мы рассмотрим сетевые модели в Microsoft Azure и некоторые варианты управления для Azure. До сих пор мы использовали только платформу Azure, но упомянули и другие области, которые можно использовать для управления и создания наших ресурсов на платформе.\nСетевые модели Azure Виртуальные сети Виртуальная сеть — это конструкция, созданная в Azure. Виртуальной сети назначен один или несколько диапазонов IP-адресов. Виртуальные сети живут в рамках подписки внутри региона. В виртуальной сети создаются виртуальные подсети для разбиения сетевого диапазона. Виртуальные машины размещаются в виртуальных подсетях. Все виртуальные машины в виртуальной сети могут обмениваться данными. 65 536 частных IP-адресов на виртуальную сеть. Платите только за исходящий трафик из региона. (данные покидают регион) Поддерживаются IPv4 и IPv6. IPv6 для общедоступных и внутри виртуальных сетей. Мы можем сравнить виртуальные сети Azure с AWS VPC. Однако следует отметить некоторые отличия:\nВ AWS создается виртуальная сеть по умолчанию, чего нет в Microsoft Azure, вам необходимо создать свою первую виртуальную сеть в соответствии с вашими требованиями. Все виртуальные машины в Azure по умолчанию имеют доступ к Интернету через NAT. Нет шлюзов NAT в соответствии с AWS. В Microsoft Azure нет понятия частных или общедоступных подсетей. Общедоступные IP-адреса — это ресурс, который может быть назначен виртуальным сетевым адаптерам или балансировщикам нагрузки. Виртуальная сеть и подсети имеют свои собственные списки управления доступом, позволяющие делегировать уровень подсети. Подсети в зонах доступности, тогда как в AWS у вас есть подсети для каждой зоны доступности. У нас также есть виртуальный сетевой пиринг. Пиринг между виртуальными сетями позволяет эффективно соединить две Виртуальные сети Azure. После создания пиринговой связи две виртуальные сети выглядят как одна сеть в плане подключения. Точно так же трафик между виртуальными машинами в одноранговых виртуальных сетях использует магистральную инфраструктуру Майкрософт. Как и трафик между виртуальными машинами в одной сети, трафик направляется только через частную сеть корпорации Майкрософт.\nКонтроль доступа Azure использует группы безопасности сети, они сохраняют состояние. Разрешить создавать правила, а затем назначать их группе безопасности сети. Группы безопасности сети применяются к подсетям или виртуальным машинам. При применении к подсети он по-прежнему применяется к сетевой карте виртуальной машины и не является “Edge” устройством. Правила объединены в группу безопасности сети. В зависимости от приоритета возможны гибкие конфигурации. Более низкий номер приоритета означает высокий приоритет. Большая часть логики построена на IP-адресах, но также могут использоваться некоторые теги и метки. Description Priority Source Address Source Port Destination Address Destination Port Action Inbound 443 1005 * * * 443 Allow ILB 1010 Azure LoadBalancer * * 10000 Allow Deny All Inbound 4000 * * * * DENY У нас также есть группы безопасности приложений (Application Security Groups) (ASG) .\nГде журналы потоков групп безопасности) (NSG) (Network Security Groups) сети сосредоточены на диапазонах IP-адресов, которые может быть сложно поддерживать для растущих сред. ASG позволяют определять настоящие имена (моникеры) для различных ролей приложений (веб-серверы, серверы БД, WebApp1 и т. д.). Сетевая карта виртуальной машины становится членом одной или нескольких групп ASG. Затем группы ASG можно использовать в правилах, которые являются частью групп безопасности сети, для управления потоком связи и по-прежнему могут использовать функции NSG, такие как теги обслуживания.\nAction Name Source Destination Port Allow AllowInternettoWeb Internet WebServers 443(HTTPS) Allow AllowWebToApp WebServers AppServers 443(HTTPS) Allow AllowAppToDB AppServers DbServers 1443 (MSSQL) Deny DenyAllinbound Any Any Any Балансировщики нагрузки Load Balancing. В Microsoft Azure есть два отдельных решения для балансировки нагрузки. (От Microsoft Azure и сторонние на маркетплейсе) Оба могут работать с внешними или внутренними конечными ендпоинтами.\nБалансировщик нагрузки (Layer 4), поддерживающий распределение на основе хэшей и переадресацию портов. Шлюз приложений (Layer 7) поддерживает такие функции, как разгрузка SSL, сопоставление сеансов на основе файлов cookie и маршрутизация контента на основе URL-адресов. Кроме того, с помощью шлюза приложений вы можете дополнительно использовать компонент брандмауэра веб-приложения.\nСредства управления Azure Мы потратили большую часть нашего теоретического времени на изучение портала Azure, я бы предположил, что когда дело доходит до следования культуре DevOps и обработки многих этих задач, особенно связанных с подготовкой, будет выполняться через API или инструмент командной строки. Я хотел коснуться некоторых из тех других инструментов управления, которые у нас есть, поскольку нам нужно знать это, когда мы автоматизируем подготовку наших сред Azure.\nПортал Azure Портал Microsoft Azure — это веб-консоль, которая представляет собой альтернативу инструментам командной строки. Вы можете управлять своими подписками на портале Azure. Создавайте, управляйте и контролируйте все, от простого веб-приложения до сложных облачных развертываний. Еще одна вещь, которую вы найдете на портале, — это хлебные крошки. JSON, как упоминалось ранее, является основой всех ресурсов Azure. Возможно, вы начнете с портала, чтобы понять функции, службы и функциональные возможности, а затем позже поймете JSON внизу, чтобы включить в ваши автоматизированные рабочие процессы.\nСуществует также портал Azure Preview, который можно использовать для просмотра и тестирования новых и предстоящих услуг и улучшений.\nPowerShell Прежде чем мы перейдем к Azure PowerShell, стоит сначала познакомиться с PowerShell. PowerShell — это среда автоматизации задач и управления конфигурацией, оболочка командной строки и язык сценариев. Мы могли бы и осмелились сказать это, сравнив это с тем, что мы рассмотрели в разделе Linux, посвященном сценариям оболочки. PowerShell впервые появился в ОС Windows, но теперь он кроссплатформенный.\nAzure PowerShell — это набор командлетов для управления ресурсами Azure непосредственно из командной строки PowerShell.\nПри желании мы можеем подключиться к подписке с помощью команды PowerShell «Connect-AzAccount».\nЗатем, если мы хотим найти некоторые конкретные команды, связанные с виртуальными машинами Azure, мы можем запустить следующую команду. Вы можете потратить часы на изучение и понимание этого языка программирования PowerShell. Microsoft предлагает отличные краткие руководства по началу работы и подготовке служб из PowerShell здесь\nVisual Studio Code Visual Studio Code — это бесплатный редактор исходного кода, созданный Microsoft для Windows, Linux и macOS.\nВ Visual Studio Code встроено множество интеграций и инструментов, которые вы можете использовать для взаимодействия с Microsoft Azure и службами внутри. Cloud Shell Azure Cloud Shell — это интерактивная, аутентифицированная, доступная через браузер оболочка для управления ресурсами Azure. Это обеспечивает гибкость выбора оболочки, которая лучше всего подходит для вашей работы.\nКак видно из рисунка ниже, когда мы впервые запускаем Cloud Shell на портале, мы можем выбирать между Bash и PowerShell.\nЧтобы использовать облачную оболочку, вам нужно будет предоставить немного места в своей подписке.\nКогда вы выбираете использование облачной оболочки, она запускает компьютер, эти компьютеры являются временными, но ваши файлы сохраняются двумя способами; через образ диска и подключенный файловый обменник.\nCloud Shell работает на временном хосте, предоставляемом для каждого сеанса и каждого пользователя. Время ожидания Cloud Shell истекает через 20 минут без интерактивной активности. Cloud Shell требует подключения общего файлового ресурса Azure. — Cloud Shell использует один и тот же файловый ресурс Azure как для Bash, так и для PowerShell. Cloud Shell назначается по одному компьютеру для каждой учетной записи пользователя. Cloud Shell сохраняет $HOME, используя образ размером 5 ГБ, хранящийся в вашей общей папке. Разрешения установлены как у обычного пользователя Linux в Bash Подробнее о Cloud Shell\nAzure CLI Azure CLI можно установить в Windows, Linux и macOS. После установки вы можете ввести «az», а затем другие команды для создания, обновления, удаления и просмотра ресурсов Azure.\nКогда я впервые приступил к изучению Azure, меня немного смутило наличие Azure PowerShell и Azure CLI.\nЯ также хотел бы получить отзывы от сообщества по этому поводу. Но я вижу, что Azure PowerShell — это модуль, добавленный в Windows PowerShell или PowerShell Core (также доступен в других ОС, но не во всех), тогда как Azure CLI — это кроссплатформенная программа командной строки, которая подключается к Azure и выполняет эти команды. .\nОбе эти опции имеют разный синтаксис, хотя, насколько я вижу и что я сделал, они могут выполнять очень похожие задачи.\nНапример, для создания виртуальной машины из PowerShell будет использоваться командлет New-AzVM, а в Azure CLI — az VM create.\nРанее вы видели, что в моей системе установлен модуль Azure PowerShell, но затем у меня также установлен Azure CLI, который можно вызывать через PowerShell на моем компьютере с Windows.\nВывод здесь, как мы уже упоминали, заключается в выборе правильного инструмента. Azure работает на основе автоматизации. Каждое действие, которое вы совершаете внутри портала, где-то преобразуется в код, выполняемый для чтения, создания, изменения или удаления ресурсов.\nСравнение Azure CLI Кроссплатформенный интерфейс командной строки, устанавливаемый на Windows, macOS, Linux Работает в Windows PowerShell, Cmd или Bash и других оболочках Unix. Azure PowerShell Кроссплатформенный модуль PowerShell, работает на Windows, macOS, Linux Требуется Windows PowerShell или PowerShell Если по какой-то причине вы не можете использовать PowerShell в своей среде, но можете использовать .mdor bash, тогда Azure CLI будет вашим выбором.\nЗавтра попробуем создать несколько сценариев и приступим к работе в Azure.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Сетевые модели Microsoft Azure + Управление Azure","title":"33. Сетевые модели Microsoft Azure + Управление Azure","uri":"/ru/tracks/90daysofdevops/day33/"},{"content":"Практические скрипты Microsoft Azure Последние 6 дней были сосредоточены на Microsoft Azure и общедоступном облаке в целом, большая часть этой основы должна была содержать много теории, чтобы понять строительные блоки Azure, но также это будет хорошо перенесено на других крупных облачных провайдеров. .\nВ самом начале я упомянул о базовых знаний об общедоступном облаке и выборе одного провайдера, по крайней мере, для начала. Если вы танцуете между разными облаками, я считаю, что вы можете довольно легко заблудиться, тогда как выбрав одно, вы поймете основы. и когда они у вас есть, довольно легко прыгнуть в другие облака и ускорить свое обучение.\nНа этом заключительном занятии я буду выбирать свои практические скрипты с этой страницы, которая является справочной информацией, созданной Microsoft и используемой для подготовки к AZ-104 Администратор Microsoft Azure\nЗдесь есть некоторые из них, такие как контейнеры и Kubernetes, которые мы еще не рассмотрели подробно, поэтому я не хочу пока вдаваться в них.\nВ предыдущих постах мы создали большинство модулей 1,2 и 3.\nВиртуальная сеть Мы пройдем пройти модуль 04:\nЯ прошел по инструкции и изменил несколько названий на #90DaysOfDevOps. Я также вместо использования Cloud Shell вошел в систему с моим новым пользователем, созданным в предыдущие дни с помощью Azure CLI на моем компьютере с Windows.\nВы можете сделать это, используя az login, который откроет браузер и позволит вам аутентифицировать свою учетную запись.\nЗатем я создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для выполнения некоторых из приведенных ниже задач. Вы можете найти связанные файлы в этой папке. (Облако\\01Виртуальная сеть)\nMod04_90DaysOfDevOps-vms-loop-parameters.json { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"value\": \"Standard_D2s_v3\" }, \"adminUsername\": { \"value\": \"Student\" }, \"adminPassword\": { \"value\": \"Pa55w.rd1234\" } } } Mod04_90DaysOfDevOps-vms-loop-template.json { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"type\": \"string\", \"defaultValue\": \"Standard_D2s_v3\", \"metadata\": { \"description\": \"VM size\" } }, \"vmName\": { \"type\": \"string\", \"defaultValue\": \"90day-vm\", \"metadata\": { \"description\": \"VM name Prefix\" } }, \"vmCount\": { \"type\": \"int\", \"defaultValue\": 2, \"metadata\": { \"description\": \"Number of VMs\" } }, \"adminUsername\": { \"type\": \"string\", \"metadata\": { \"description\": \"Admin username\" } }, \"adminPassword\": { \"type\": \"securestring\", \"metadata\": { \"description\": \"Admin password\" } }, \"virtualNetworkName\": { \"type\": \"string\", \"defaultValue\": \"90daysofdevops\", \"metadata\": { \"description\": \"Virtual network name\" } } }, \"variables\": { \"nic\": \"90daysofdevops\", \"virtualNetworkName\": \"[parameters('virtualNetworkName')]\", \"subnetName\": \"subnet\", \"subnet0Name\": \"subnet0\", \"subnet1Name\": \"subnet1\", \"computeApiVersion\": \"2018-06-01\", \"networkApiVersion\": \"2018-08-01\" }, \"resources\": [ { \"name\": \"[concat(parameters('vmName'),copyIndex())]\", \"copy\": { \"name\": \"VMcopy\", \"count\": \"[parameters('vmCount')]\" }, \"type\": \"Microsoft.Compute/virtualMachines\", \"apiVersion\": \"[variables('computeApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Creating VMs\", \"dependsOn\": [ \"[concat(variables('nic'),copyIndex())]\" ], \"properties\": { \"osProfile\": { \"computerName\": \"[concat(parameters('vmName'),copyIndex())]\", \"adminUsername\": \"[parameters('adminUsername')]\", \"adminPassword\": \"[parameters('adminPassword')]\", \"windowsConfiguration\": { \"provisionVmAgent\": \"true\" } }, \"hardwareProfile\": { \"vmSize\": \"[parameters('vmSize')]\" }, \"storageProfile\": { \"imageReference\": { \"publisher\": \"MicrosoftWindowsServer\", \"offer\": \"WindowsServer\", \"sku\": \"2019-Datacenter\", \"version\": \"latest\" }, \"osDisk\": { \"createOption\": \"fromImage\" }, \"dataDisks\": [] }, \"networkProfile\": { \"networkInterfaces\": [ { \"properties\": { \"primary\": true }, \"id\": \"[resourceId('Microsoft.Network/networkInterfaces', concat(variables('nic'),copyIndex()))]\" } ] } } }, { \"type\": \"Microsoft.Network/virtualNetworks\", \"name\": \"[variables('virtualNetworkName')]\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Virtual Network\", \"properties\": { \"addressSpace\": { \"addressPrefixes\": [ \"10.40.0.0/22\" ] }, \"subnets\": [ { \"name\": \"[variables('subnet0Name')]\", \"properties\": { \"addressPrefix\": \"10.40.0.0/24\" } }, { \"name\": \"[variables('subnet1Name')]\", \"properties\": { \"addressPrefix\": \"10.40.1.0/24\" } } ] } }, { \"name\": \"[concat(variables('nic'),copyIndex())]\", \"copy\":{ \"name\": \"nicCopy\", \"count\": \"[parameters('vmCount')]\" }, \"type\": \"Microsoft.Network/networkInterfaces\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Primary NIC\", \"dependsOn\": [ \"[concat('Microsoft.Network/virtualNetworks/', variables('virtualNetworkName'))]\" ], \"properties\": { \"ipConfigurations\": [ { \"name\": \"ipconfig1\", \"properties\": { \"subnet\": { \"id\": \"[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), concat(variables('subnetName'),copyIndex()))]\" }, \"privateIPAllocationMethod\": \"Dynamic\" } } ] } } ], \"outputs\": {} } Module4_90DaysOfDevOps.ps1 $rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-parameters.json Убедитесь, что вы изменили расположение файла в скрипте в соответствии с вашей средой.\nНа этом первом этапе у нас нет виртуальной сети или виртуальных машин, созданных в нашей среде, у меня есть только место хранения облачной оболочки, настроенное в моей группе ресурсов.\nСначала я запускаю свой скрипт в PowerShell\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-parameters.json Задача 1: Создать и настроить виртуальную сеть\nЗадача 2. Развернуть виртуальные машины в виртуальной сети.\nЗадача 3. Настройка частных и общедоступных IP-адресов виртуальных машин Azure.\nЗадача 4: Настройка групп безопасности сети\nЗадача 5. Настройка Azure DNS для внутреннего разрешения имен. Управление сетевым трафиком Переходим к модулю 06:\nДля этого практического занятия я создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для создания некоторых из приведенных ниже задач.\nЗадача 1: Обеспечение лабораторной среды Запустим PowerShell скрипт\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\02TrafficManagement\\Mod06_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\02TrafficManagement\\Mod06_90DaysOfDevOps-vms-loop-parameters.json $location = (Get-AzResourceGroup -ResourceGroupName $rgName).location $vmNames = (Get-AzVM -ResourceGroupName $rgName).Name foreach ($vmName in $vmNames) { Set-AzVMExtension ` -ResourceGroupName $rgName ` -Location $location ` -VMName $vmName ` -Name 'networkWatcherAgent' ` -Publisher 'Microsoft.Azure.NetworkWatcher' ` -Type 'NetworkWatcherAgentWindows' ` -TypeHandlerVersion '1.4' } Задача 2. Настройка топологии узловой сети Задача 3. Проверка транзитивности пиринга виртуальной сети.\nДля этого моя группа 90DaysOfDevOps не имела доступа к Network Watcher из-за разрешений, я ожидаю, что это связано с тем, что Network Watcher — это один из тех ресурсов, которые не привязаны к группе ресурсов, где наш RBAC был покрыт для этого пользователя. Я добавил в группу 90DaysOfDevOps роль участника Network Watcher из восточной части США.\nЭто ожидаемо, поскольку виртуальные сети с двумя лучами не связаны друг с другом (пиринг виртуальных сетей не является транзитивным).\nЗадача 4. Настройка маршрутизации в топологии «концентратор-луч». У меня была еще одна проблема: моя учетная запись не могла запустить скрипт от имени моего пользователя в группе 90DaysOfDevOps, в чем я не уверен, поэтому я вернулся в свою основную учетную запись администратора. Группа 90DaysOfDevOps является владельцем всего в группе ресурсов 90DaysOfDevOps, поэтому хотелось бы понять, почему я не могу запустить команду внутри виртуальной машины?\nTask 5: Подключаем Azure Load Balancer Task 6: Подключаем Azure Application Gateway Хранищиле Azure Переходим к модулю 07:\nДля этого практического занятия я также создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для создания некоторых из приведенных ниже задач.\nЗадача 1: Обеспечение лабораторной среды Сначала запускаем PowerShell script\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\03Storage\\Mod07_90DaysOfDevOps-vm-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\03Storage\\Mod07_90DaysOfDevOps-vm-parameters.json ` -AsJob Файл `Mod07_90DaysOfDevOps-vm-template.json` ``` { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"type\": \"string\", \"defaultValue\": \"Standard_D2s_v3\", \"metadata\": { \"description\": \"Virtual machine size\" } }, \"adminUsername\": { \"type\": \"string\", \"metadata\": { \"description\": \"Admin username\" } }, \"adminPassword\": { \"type\": \"securestring\", \"metadata\": { \"description\": \"Admin password\" } } }, \"variables\": { \"vmName\": \"90Days-vm0\", \"nicName\": \"90Days-nic0\", \"virtualNetworkName\": \"90Days-vnet0\", \"publicIPAddressName\": \"90Days-pip0\", \"nsgName\": \"90Days-nsg0\", \"vnetIpPrefix\": \"10.70.0.0/22\", \"subnetIpPrefix\": \"10.70.0.0/24\", \"subnetName\": \"subnet0\", \"subnetRef\": \"[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), variables('subnetName'))]\", \"computeApiVersion\": \"2018-06-01\", \"networkApiVersion\": \"2018-08-01\" }, \"resources\": [ { \"name\": \"[variables('vmName')]\", \"type\": \"Microsoft.Compute/virtualMachines\", \"apiVersion\": \"[variables('computeApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"dependsOn\": [ \"[variables('nicName')]\" ], \"properties\": { \"osProfile\": { \"computerName\": \"[variables('vmName')]\", \"adminUsername\": \"[parameters('adminUsername')]\", \"adminPassword\": \"[parameters('adminPassword')]\", \"windowsConfiguration\": { \"provisionVmAgent\": \"true\" } }, \"hardwareProfile\": { \"vmSize\": \"[parameters('vmSize')]\" }, \"storageProfile\": { \"imageReference\": { \"publisher\": \"MicrosoftWindowsServer\", \"offer\": \"WindowsServer\", \"sku\": \"2019-Datacenter\", \"version\": \"latest\" }, \"osDisk\": { \"createOption\": \"fromImage\" }, \"dataDisks\": [] }, \"networkProfile\": { \"networkInterfaces\": [ { \"properties\": { \"primary\": true }, \"id\": \"[resourceId('Microsoft.Network/networkInterfaces', variables('nicName'))]\" } ] } } }, { \"type\": \"Microsoft.Network/virtualNetworks\", \"name\": \"[variables('virtualNetworkName')]\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Virtual Network\", \"properties\": { \"addressSpace\": { \"addressPrefixes\": [ \"[variables('vnetIpPrefix')]\" ] }, \"subnets\": [ { \"name\": \"[variables('subnetName')]\", \"properties\": { \"addressPrefix\": \"[variables('subnetIpPrefix')]\" } } ] } }, { \"name\": \"[variables('nicName')]\", \"type\": \"Microsoft.Network/networkInterfaces\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Primary NIC\", \"dependsOn\": [ \"[variables('publicIpAddressName')]\", \"[variables('nsgName')]\", \"[variables('virtualNetworkName')]\" ], \"properties\": { \"ipConfigurations\": [ { \"name\": \"ipconfig1\", \"properties\": { \"subnet\": { \"id\": \"[variables('subnetRef')]\" }, \"privateIPAllocationMethod\": \"Dynamic\", \"publicIpAddress\": { \"id\": \"[resourceId('Microsoft.Network/publicIpAddresses', variables('publicIpAddressName'))]\" } } } ], \"networkSecurityGroup\": { \"id\": \"[resourceId('Microsoft.Network/networkSecurityGroups', variables('nsgName'))]\" } } }, { \"name\": \"[variables('publicIpAddressName')]\", \"type\": \"Microsoft.Network/publicIpAddresses\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Public IP for Primary NIC\", \"properties\": { \"publicIpAllocationMethod\": \"Dynamic\" } }, { \"name\": \"[variables('nsgName')]\", \"type\": \"Microsoft.Network/networkSecurityGroups\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Network Security Group (NSG) for Primary NIC\", \"properties\": { \"securityRules\": [ { \"name\": \"default-allow-rdp\", \"properties\": { \"priority\": 1000, \"sourceAddressPrefix\": \"*\", \"protocol\": \"Tcp\", \"destinationPortRange\": \"3389\", \"access\": \"Allow\", \"direction\": \"Inbound\", \"sourcePortRange\": \"*\", \"destinationAddressPrefix\": \"*\" } } ] } } ], \"outputs\": {} } ``` Файл `Mod07_90DaysOfDevOps-vm-parameters.json` ``` { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"value\": \"Standard_D2s_v3\" }, \"adminUsername\": { \"value\": \"Student\" }, \"adminPassword\": { \"value\": \"Pa55w.rd1234\" } } } ``` Задача 2. Создание и настройка учетных записей хранения Azure. Задача 3. Управление хранилищем BLOB-объектов Задача 4. Управление проверкой подлинности и авторизацией для службы хранилища Azure. Я был немного нетерпелив, ожидая, что это все сработает, но в конце концов это сработало.\nЗадача 5. Создание и настройка общих папок Azure Files. В команде запуска это не сработает с michael.cade@90DaysOfDevOps.com, поэтому я использовал свою учетную запись с повышенными правами.\nЗадача 6. Управление сетевым доступом для службы хранилища Azure. Serverless (внедрение веб-приложений) Переходим к модулю 09a:\nЗадача 1. Создание веб-приложения Azure. Задача 2. Создание промежуточного слота развертывания. Задача 3. Настройка параметров развертывания веб-приложений. Задача 4. Развертывание кода в промежуточном слоте развертывания. Задача 5: Поменять промежуточные слоты местами Задача 6. Настройка и тестирование автоматического масштабирования веб-приложения Azure. $rgName = '90DaysOfDevOps' $webapp = Get-AzWebApp -ResourceGroupName $rgName #The following following will start an infinite loop that sends the HTTP requests to the web app while ($true) { Invoke-WebRequest -Uri $webapp.DefaultHostName } На этом мы завершаем раздел о Microsoft Azure и public cloud в целом.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course Далее мы углубимся в системы контроля версий, особенно в git, а затем также рассмотрим обзоры репозиториев кода, и мы выберем GitHub, так как это мой предпочтительный вариант.\n","description":"Практические скрипты Microsoft Azure","title":"34. Практические скрипты Microsoft Azure","uri":"/ru/tracks/90daysofdevops/day34/"},{"content":"Общая картина: Git — контроль версий Прежде чем мы перейдем к git, нам нужно понять, что такое контроль версий? В этой статье мы рассмотрим, что такое контроль версий и основы git.\nЧто такое контроль версий? Git — не единственная система контроля версий, поэтому рассмотрим, какие варианты и какие методологии доступны для контроля версий.\nНаиболее очевидным и большим преимуществом контроля версий является возможность отслеживать историю проекта. Мы можем посмотреть на этот репозиторий с помощью git log и увидеть, что у нас есть много коммитов и много комментариев, а также то, что произошло на данный момент в проекте. Не волнуйтесь, мы перейдем к командам позже. А теперь подумайте, если бы это был настоящий программный проект, полный исходного кода, и несколько человек в разное время принимают участие в нашем программном обеспечении, разные авторы, а затем и рецензенты, все регистрируются здесь, чтобы мы знали, что произошло, когда, кем и кто рецензировал.\nУправление версиями, прежде чем это стало крутым, было чем-то вроде ручного создания копии вашей версии, прежде чем вы вносили изменения. Возможно, вы также закомментируете старый бесполезный код на всякий случай.\nТем не менее, Управление версиями не является резервной копией!\nЕще одним преимуществом контроля версий является возможность управления несколькими версиями проекта. Давайте создадим пример, у нас есть бесплатное приложение, доступное во всех операционных системах, а затем у нас есть платное приложение, также доступное во всех операционных системах. БОльшая часть кода используется обоими приложениями. Мы могли бы копировать и вставлять наш код при каждом коммите в каждое приложение, но это будет очень грязно, особенно если вы масштабируете свою разработку более чем на одного человека, а также будут допущены ошибки.\nВ премиум-приложении у нас будут дополнительные функции, назовем их премиальными коммитами, бесплатная версия будет содержать только обычные коммиты.\nСпособ, которым это достигается в системе управления версиями, — это ветвление (branching).\nВетвление позволяет использовать два потока кода для одного и того же приложения, как мы указали выше. Но мы по-прежнему хотим, чтобы новые функции, которые появляются в нашей бесплатной версии исходного кода, были в нашей премиум-версии, и для этого у нас есть то, что называется слиянием.\nТеперь это такое же простое, но слияние может быть сложным, потому что у вас может быть команда, работающая над бесплатной версией, и другая команда, работающая над платной премиальной версией, и что, если обе они изменят код, который влияет на аспекты общего кода. Может быть, переменная обновляется и что-то ломает. Тогда у вас есть конфликт, который нарушает одну из функций. Контроль версий не может устранить конфликты, которые зависят от вас. Но контроль версий позволяет легко управлять этим.\nОсновная причина, по которой вы до сих пор не взялись за управление версиями, — это возможность совместной работы. Возможность делиться кодом между разработчиками, и когда я говорю код, как я уже говорил раньше, все чаще и чаще мы видим гораздо больше вариантов использования по другим причинам для использования системы управления версиями, может быть, это совместная презентация, над которой вы работаете с коллегой, или вызов 90DaysOfDevOps. где у вас есть сообщество, предлагающее свои исправления и обновления на протяжении всего проекта.\nБез контроля версий, как команды разработчиков программного обеспечения вообще справлялись с этим? Когда я работаю над своими проектами, мне достаточно трудно следить за вещами. Я ожидаю, что они разделят код на каждый функциональный модуль. Возможно, небольшая часть головоломки заключалась в том, чтобы собрать воедино кусочки, а затем решить проблемы и проблемы, прежде чем что-либо было выпущено.\nС контролем версий у нас есть единственный источник правды. Мы все еще можем работать над разными модулями, но это позволяет нам лучше взаимодействовать.\nЕще одна вещь, которую следует упомянуть здесь, это то, что не только разработчики могут извлечь выгоду из контроля версий. Все члены команды должны иметь представление, но также и инструменты управления проектом и т.д. У нас также может быть build машина, например Jenkins, о которой мы поговорим в другом модуле. Зада подобных инструментов - создать и упаковывать систему, автоматизируя тесты и предоставляя метрики.\nЧто такое Git? Git — это инструмент, который отслеживает изменения в исходном коде или любом файле, или мы могли бы также сказать, что Git — это распределенная система контроля версий с открытым исходным кодом.\nЕсть много способов, которыми git можно использовать в наших системах, чаще всего или, по крайней мере, для меня я видел его в командной строке, но у нас также есть графические пользовательские интерфейсы и инструменты, такие как Visual Studio Code, которые имеют операции с поддержкой git, которые мы может воспользоваться.\nТеперь мы пройдемся по общему обзору еще до того, как установим Git на нашу локальную машину.\nВозьмем папку, которую мы создали ранее.\nЧтобы использовать эту папку с контролем версий, нам сначала нужно инициировать этот каталог с помощью команды `git init. А пока представьте, что эта команда помещает наш каталог в качестве репозитория в базу данных где-то на нашем компьютере.\nТеперь мы можем создать несколько файлов и папок, и наш исходный код может начаться, или, может быть, он уже есть, и у нас уже есть что-то здесь. Мы можем использовать команду git add ., которая помещает все файлы и папки в нашем каталоге в снимок, но мы еще ничего не зафиксировали в этой базе данных. Мы просто говорим, что все файлы с . готовы к добавлению.\nЗатем мы хотим продолжить и зафиксировать наши файлы, мы делаем это с помощью команды git commit -m \"My First Commit\". Мы можем указать причину нашей фиксации, и это предлагается, чтобы мы знали, что произошло для каждой фиксации.\nТеперь мы можем увидеть, что произошло в истории проекта. С помощью команды git log.\nМы также можем проверить состояние нашего репозитория с помощью git status, это показывает, что нам нечего коммитить, и мы можем добавить новый файл с именем samplecode.ps1. Если мы затем запустим тот же статус `git, вы увидите, что мы файл для фиксации.\nДобавьте наш новый файл с помощью команды git add samplecode.ps1, а затем мы снова запустим git status и увидим, что наш файл готов к фиксации.\nЗатем выполните команду git commit -m “My Second Commit”.\nДругой git status теперь показывает, что все снова чисто.\nЗатем мы можем использовать команду git log, которая показывает последние изменения и первую фиксацию.\nЕсли мы хотим увидеть изменения между нашими коммитами, то есть какие файлы были добавлены или изменены, мы можем использовать git diff b8f8 709a\nЗатем отображается то, что изменилось, в нашем случае мы добавили новый файл.\nМы также можем, и мы углубимся в это позже, но мы можем прыгать вокруг наших коммитов, то есть мы можем путешествовать во времени! Используя наш номер фиксации, мы можем использовать команду git checkout 709a, чтобы вернуться назад во времени, не теряя наш новый файл.\nНо в равной степени мы также захотим двигаться вперед, и мы можем сделать это таким же образом с номером коммита, или вы можете видеть здесь, что мы используем команду git switch -, чтобы отменить нашу операцию.\nTLDR;\nОтслеживание истории проектов Управление несколькими версиями проекта Обмен кодом между разработчиками и более широкий круг команд и инструментов Координация работы в команде Это могло показаться прыжком, но, надеюсь, вы можете увидеть, даже не зная, что команды использовали возможности и общую картину, лежащую в основе контроля версий.\nДалее мы установим и настроим git на вашем локальном компьютере и немного углубимся в некоторые другие варианты использования и команды, которые мы можем реализовать в Git.\nРесурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Git — контроль версий","title":"35. Git — контроль версий","uri":"/ru/tracks/90daysofdevops/day35/"},{"content":"Установка и настройка Git Git — это кроссплатформенный инструмент с открытым исходным кодом для контроля версий. Если я нравлюсь вам, вы используете Ubuntu или большинство сред Linux, вы можете обнаружить, что у вас уже установлен git, но мы собираемся выполнить установку и настройку.\nДаже если у вас уже установлен git в вашей системе, также рекомендуется убедиться, что мы в курсе последних событий.\nУстановка Git Мы будем работать с Windows и Linux, но вы также можете найти macOS в списке здесь\nДля Windows мы можем загрузить наши установщики с официального сайта.\nВы также можете использовать winget на своем компьютере с Windows, думайте об этом как о своем диспетчере пакетов приложений Windows.\nПрежде чем мы что-либо установим, давайте посмотрим, какая версия у нас есть на нашей машине с Windows. Откройте окно PowerShell и запустите git --version\nМы также можем проверить нашу версию Git для Ubuntu.\nЗагружаем последнюю версию установщика. Важно отметить, что git удалит предыдущие версии перед установкой последней.\nЭто означает, что процесс, показанный ниже, по большей части такой же, как если бы вы устанавливали не из git.\nЭто очень простая установка. После загрузки дважды щелкните и начните. Прочтите лицензионное соглашение GNU. Но помните, что это бесплатное программное обеспечение с открытым исходным кодом.\nТеперь мы можем выбрать дополнительные компоненты, которые мы хотели бы также установить, но также связать с git. В Windows я всегда устанавливаю Git Bash, так как это позволяет нам запускать сценарии bash в Windows.\nЗатем мы можем выбрать, какой исполняемый файл SSH мы хотим использовать. IN оставьте это как пакетный OpenSSH, который вы могли видеть в разделе Linux.\nЗатем у нас есть экспериментальные функции, которые мы можем захотеть включить, мне они не нужны, поэтому я не включаю, вы всегда можете вернуться во время установки и включить их позже.\nУстановка завершена, теперь мы можем открыть Git Bash или последние примечания к выпуску.\nПоследняя проверка — посмотреть в нашем окне PowerShell, какая у нас сейчас версия git.\nСупер простые вещи, и теперь мы на последней версии. На нашей машине с Linux мы немного отстали, поэтому мы также можем пройти этот процесс обновления.\nЯ просто запускаю команду sudo apt-get install git.\nВы также можете запустить следующее, которое добавит репозиторий git для установки программного обеспечения.\nsudo add-apt-repository ppa:git-core/ppa -y sudo apt-get update sudo apt-get install git -y git --version Настройка Git Когда мы впервые используем git, нам нужно определить некоторые настройки,\nИмя Эл. адрес Редактор по умолчанию Окончание строки Это можно сделать на трех уровнях\nSystem = Все пользователи Global = все репозитории текущего пользователя Local = текущий репозиторий Пример:\ngit config --global user.name \"My Name\" git config --global user.email email@example.com\" В зависимости от вашей операционной системы будет определять текстовый редактор по умолчанию. На моей машине с Ubuntu без настройки следующая команда использует Тano. Приведенная ниже команда изменит это на код Visual Studio.\ngit config --global core.editor \"code --wait\"\nЧтобы увидеть всю конфигурацию git, мы можем использовать команду git config --global -e\nНа любом компьютере этот файл будет называться .gitconfig, на моем компьютере с Windows вы найдете его в каталоге своей учетной записи пользователя. Теория Git Я упомянул во вчерашнем посте, что существуют и другие типы контроля версий, и мы можем разделить их на два разных типа. Один клиент-сервер, а другой распределенный.\nКлиент-серверный контроль версий До появления git клиент-сервер был де-факто методом контроля версий. Примером этого может быть Apache Subversion, которая представляет собой систему управления версиями с открытым исходным кодом, основанную в 2000 году.\nВ этой модели управления версиями клиент-сервер на первом этапе разработчик загружает исходный код, фактические файлы с сервера. Это не устраняет конфликты, но устраняет сложность конфликтов и способы их разрешения.\nТеперь, например, скажем, у нас есть два разработчика, работающих над одними и теми же файлами, и один из них выигрывает гонку и первым фиксирует или загружает свой файл обратно на сервер со своими новыми изменениями. Когда второй разработчик идет на обновление, у них возникает конфликт.\nИтак, теперь разработчику нужно вывести первое изменение кода разработчика рядом с его проверкой, а затем зафиксировать, как только эти конфликты будут урегулированы.\nРаспределенный контроль версий Git — не единственная распределенная система контроля версий. Но это очень де-факто.\nНекоторые из основных преимуществ Git:\nБыстрый Гибкий Безопасный и надежный В отличие от модели управления версиями клиент-сервер, каждый разработчик загружает исходный репозиторий, то есть все. История коммитов, все ветки и т.д. и т.п.\nРесурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Установка и настройка Git","title":"36. Установка и настройка Git","uri":"/ru/tracks/90daysofdevops/day36/"},{"content":"Знакомство с Git В последних двух постах мы узнали о системах контроля версий и некоторых основных рабочих процессах git как системы контроля версий День 35. Затем мы установили git в нашу систему, обновили и настроили. Мы также немного углубились в теорию между системой контроля версий клиент-сервер и Git, которая является распределенной системой контроля версий День 36.\nТеперь мы пройдемся по некоторым командам и вариантам использования, которые мы все обычно видим в git.\nГде получить помощь по git? Будут времена, когда вы просто не сможете вспомнить или просто не знаете команду, которая вам нужна для работы с git. Вам понадобится помощь.\nСамо собой разумеется, что Google или любая другая поисковая система, вероятно, будет вашим первым портом захода при поиске помощи.\nВо-вторых, следующим местом будет официальный сайт git и документация. git-scm.com/docs Здесь вы найдете не только подробные ссылки на все доступные команды, но и множество различных ресурсов.\nМы также можем получить доступ к этой же документации, которая очень полезна, если у вас нет подключения к терминалу. Например, если мы выбрали команду git add, мы можем запустить git add --help, и мы увидим ниже руководство.\nМы также можем в оболочке использовать git add -h, который даст нам краткий обзор доступных опций.\nМифы Git «У Git нет контроля доступа» — вы можете уполномочить “лидера” поддерживать исходный код.\n«Git слишком тяжелый» — у Git есть возможность предоставлять неглубокие репозитории, что в основном означает меньший объем истории, если у вас большие проекты.\nНедостатки Не идеально подходит для двоичных файлов. Отлично подходит для исходного кода, но не подходит, например, для исполняемых файлов или видео.\nGit не удобен для пользователя, тот факт, что нам приходится тратить время на обсуждение команд и функций инструмента, вероятно, является ключевым признаком этого.\nВ целом, git сложно освоить, но легко использовать.\nЭкосистема git Я хочу кратко рассказать об экосистеме вокруг git, но не углубляться в некоторые из этих областей, но я думаю, что важно отметить их здесь на высоком уровне.\nПочти все современные инструменты разработки поддерживают Git.\nИнструменты разработчика. Мы уже упоминали код Visual Studio, но вы найдете плагины git и интеграции в возвышенный текст и другие текстовые редакторы и IDE.\nКомандные инструменты. Также упоминаются такие инструменты, как Jenkins с точки зрения CI/CD, Slack из среды обмена сообщениями и Jira для управления проектами и отслеживания проблем.\nОблачные провайдеры. Все крупные облачные провайдеры поддерживают git, Microsoft Azure, Amazon AWS, Google Cloud Platform.\nСервисы на основе Git. Затем у нас есть GitHub, GitLab и BitBucket, о которых мы поговорим более подробно позже. Я слышал об этих сервисах как о социальной сети для кода!\nШпаргалка по Git Мы не рассмотрели большинство этих команд, но просмотрев некоторые шпаргалки, доступные в Интернете, я хотел задокументировать некоторые из команд git и их назначение. Нам не нужно запоминать все это, и с большей практикой и использованием вы выберете, по крайней мере, основы git.\nОсновы Git Command Example Description git init git init \u003cdirectory\u003e создает пустой репозиторий git в указанном каталоге. git clone git clone \u003crepo\u003e клонирует репозиторий, расположенный в , на локальный компьютер. git config git config user.name определяет имя автора, которое будет использоваться для всех коммитов в текущем репозитории, system, global, local флаг для установки параметров конфигурации. git add git add \u003cdirectory\u003e он подготовит все изменения в для следующего коммита. Мы также можем добавить и \u003c.\u003e для добавления всех изменененных файлов всего. git commit -m git commit -m \"\u003cmessage\u003e\" фиксирует промежуточный коммит, запишет , чтобы подробно описать, что точно сохраняем. git status git status выведит список файлов, которые помещены в архив, не помещены в архив и не отслеживаются. git log git log Отображение всей истории коммитов в формате по умолчанию. У этой команды есть дополнительные параметры. git diff git diff Показать неустановленные изменения между вашим индексом и рабочим каталогом. Git Отмена изменений Command Example Description git revert git revert \u003ccommit\u003e создает новую фиксацию, которая отменяет все изменения, сделанные в , а затем примените ее к текущей ветке. git reset git reset \u003cfile\u003e убрать из индекса коммита (изменения не теряются). git clean git clean -n увидеть, какие файлы являются лишними, перед их непосредственным удалением git clean git clean -f удалить неотслеживаемые файлы и папки из рабочей копии git clean git clean -fd удалить их Git переписать историю Command Example Description git commit git commit --amend Заменяет последний коммит поэтапными изменениями и последним коммитом. Используйте без статуса stage, чтобы отредактировать сообщение последнего коммита. git rebase git rebase \u003cbase\u003e Перебазировать текущую ветку на . может быть идентификатором фиксации, именем ветки, тегом или относительной ссылкой на HEAD. git reflog git reflog Показать журнал изменений в HEAD локального репозитория. Добавьте флаг –relative-date для отображения информации о дате или –all для отображения всех ссылок. Git Branches Command Example Description git branch git branch Перечислите все ветки в вашем репо. Добавьте аргумент , чтобы создать новую ветку с именем . git checkout git checkout -b \u003cbranch\u003e Создайте и извлеките новую ветку с именем . Отбросьте флаг -b, чтобы проверить существующую ветку. git merge git merge \u003cbranch\u003e Объединить ветку с текущей веткой. Git Remote Repositories Command Example Description git remote add git remote add \u003cname\u003e \u003curl\u003e Создайте новое подключение к удаленному репозиторию. После добавления пульта вы можете использовать в качестве ярлыка для в других командах. git fetch git fetch \u003cremote\u003e \u003cbranch\u003e Выбирает конкретную \u003cветку\u003e из репозитория. Оставьте , чтобы получить все удаленные ссылки. git pull git pull \u003cremote\u003e Получить указанную удаленную копию текущей ветки и немедленно объединить ее с локальной копией. git push git push \u003cremote\u003e \u003cbranch\u003e Отправьте ветку на вместе с необходимыми коммитами и объектами. Создает именованную ветку в удаленном репо, если она не существует. Git Diff Command Example Description git diff HEAD git diff HEAD Показать разницу между рабочим каталогом и последним коммитом. git diff –cached git diff --cached Показать разницу между поэтапными изменениями и последней фиксацией Git Config Command Example Description git config –global user.name \u003cимя\u003e git config --global user.name \u003cимя\u003e Определите имя автора, которое будет использоваться для всех коммитов текущим пользователем. git config –global user.email git config --global user.email \u003cemail\u003e Определите адрес электронной почты автора, который будет использоваться для всех коммитов текущего пользователя. git config –global alias \u003cалиас-имя\u003e git config --global alias \u003calias-name\u003e \u003cgit-command\u003e Создать ярлык для команды git. git config –system core.editor \u003cредактор\u003e git config --system core.editor \u003cредактор\u003e Установите текстовый редактор, который будет использоваться командами для всех пользователей на машине. Аргумент должен быть командой, запускающей нужный редактор. git config –global –edit git config --global --edit Откройте файл глобальной конфигурации в текстовом редакторе для редактирования вручную. Git Rebase Command Example Description git rebase -i git rebase -i \u003cbase\u003e Интерактивно перебазировать текущую ветку на . Запускает редактор для ввода команд того, как каждый коммит будет перенесен в новую базу. Git Pull Command Example Description git pull –rebase git pull --rebase \u003cremote\u003e Получить удаленную копию текущей ветки и перебазировать ее в локальную копию. Использует git rebase вместо слияния для интеграции веток. Git Reset Command Example Description git reset git reset Сбросьте промежуточную область, чтобы она соответствовала самой последней фиксации, но оставьте рабочий каталог без изменений. git reset –hard git reset --hard Сбросить промежуточную область и рабочий каталог, чтобы они соответствовали самой последней фиксации, и перезаписать все изменения в рабочем каталоге git reset git reset \u003ccommit\u003e Переместите конец текущей ветки назад к , сбросьте промежуточную область, чтобы она соответствовала, но оставьте рабочий каталог в покое git reset –hard git reset --hard \u003ccommit\u003e То же, что и предыдущее, но сбрасывает и промежуточную область, и рабочий каталог, чтобы они совпадали. Удаляет незафиксированные изменения и все фиксации после . Git Push Command Example Description git push –force git push \u003cremote\u003e --force Делает git push, даже если это приводит к слиянию без быстрой перемотки вперед. Не используйте флаг –force, если вы абсолютно не уверены, что знаете, что делаете. git push –all git push \u003cremote\u003e --all Переместите все свои локальные ветки на указанный удаленный сервер. git push –tags git push \u003cremote\u003e --tags Теги не добавляются автоматически при отправке ветки или использовании флага –all. Флаг –tags отправляет все ваши локальные теги в удаленное репо. Ресурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"Знакомство с Git","title":"37. Шпаргалка по Git","uri":"/ru/tracks/90daysofdevops/day37/"},{"content":"Working directory Git - это система трёх основных стадий: working directory, staging area и repository. Пройдем поэтапно каждую стадию.\nСоздадим пустую папку.\nmkdir my_fodler cd my_folder Сделаем инициализацию git проекта.\ngit init После инициализации git репозитория создается скрытая папка .git Здесь хранятся сведения о репозитории git, а также информация о наших ветках и коммитах.\nStaging/Stage Сейчас у нас пустая папка. Создадим пустой файл README.md и выполним команду\ngit status Git знает о новом файле, но этот файл еще не зафиксирован в staging. Текущее расположение файла - Working directory, директория, где проиниализирован .git проект.\nstaging - это хранилище для файлов с изменениями, информация о которых попадет в единый коммит\nЧтобы файл перешел в staging, необходимо его добавить. Для этого выполним команду\ngit add README.md После добавления файла в staging area, цвет поменялся на зеленый\nМожно добавить все измененные файлы с помощью команды\ngit add . Знак . означает, что мы хотим добавить все обновленные файлы и папки.\nДалее необходимо зафиксировать изменения в репозитории. Для этого выполним команду\ngit commit -m \"Add README.md (или другой значимый комментарий)\" Коммит изменений В процессе работы мы добавляем много различных файлов. Если мы захотим добавить более длинный и осмысленный коммит, то можно запусть команду без комментария\ngit commit Откроется стандартный редактор текста. Записываем комментарий и сохраняем. Проверим результат\ngit status Требования к именам коммитов У каждой компании/проекта есть свои требования к именам коммитов. В компании может быть несколько проектов, каждый из которых должен иметь свои требования к именам коммитов. В проекте может быть несколько веток, каждая из которых должна иметь свои требования к именам коммитов.\nСуществует гайдлайн, на который можно ориентироваться. Такой подход точно будет понятен для всех новых проектов. Некоторые проекты, соблюдабщие данную конвенцию: angular, electron\nКоммит:\nДолжен использоваться present tense (“add feature” not “added feature”) Должен использоваться imperative mood (“move cursor to…” not “moves cursor to…”) Примеры имен коммитов init: - используется для начала проекта/таска. Примеры:\ninit: start youtube-task init: start mentor-dashboard task feat: - это реализованная новая функциональность из технического задания (добавил поддержку зумирования, добавил footer, добавил карточку продукта). Примеры:\nfeat: add basic page layout feat: implement search box feat: implement request to youtube API feat: implement swipe for horizontal list feat: add additional navigation button feat: add banner feat: add social links feat: add physical security section feat: add real social icons fix: - исправил ошибку в ранее реализованной функциональности. Примеры:\nfix: implement correct loading data from youtube fix: change layout for video items to fix bugs fix: relayout header for firefox fix: adjust social links for mobile refactor: - новой функциональности не добавлял / поведения не менял. Файлы в другие места положил, удалил, добавил. Изменил форматирование кода (white-space, formatting, missing semi-colons, etc). Улучшил алгоритм, без изменения функциональности. Примеры:\nrefactor: изменение структуры проекта refactor: переименование переменных для лучшей читабельности refactor: применить eslint refactor: применить prettier docs: - используется при работе с документацией/readme проекта. Примеры:\ndocs: обновить readme с дополнительной информацией docs: обновить описание метода run() Пропуск Staging Area Можно сразу добавить коммит, добавим параметр -a в git commit:\nУдаление файлов Фиксация удаления как и добавления файлов происхоит через комит\nСоздадим файл -\u003e Добавим в stage -\u003e Удалим файл\ntouch old_file.txt git add old_file.txt git commit -m \"add old_file to be removed\" Удаляем файл\ngit rm old_file.txt git status Переименование/Перемещение файлов Мы можем переименовывать или перемещать файлы в проекте средствами операционной системы. Таке это можно делать командами git.\nПример:\ngit mv old_file.txt new_file.txt Пропуск/игнорирование файлов В Git это можно сделать рзличными способами:\nИгнорировать изменения в неотслеченных файлах с помощью .gitignore файла Игнорировать изменения в неотслеченных файлах с помощью exclude файла Остановка отслеживания файла и пропуск изменений с помощью git update-index Остановка отслеживания файла и пропуск изменений с помощью git rm .gitignore Достаточно в файл .gitignore добавить путь до файлов или папок, которые необходимо игнорировать\nПосле обновления файл переходит в категорию Untracked files\nЕсли файлы уже добавлены в stage, но нужно убрать файл, то можно использовать команду git rm --cached\nStatus сокращенно git status -s Ресурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Git Staging и Изменение файлов","title":"38. Staging и Изменения","uri":"/ru/tracks/90daysofdevops/day38/"},{"content":"GIT - Просмотр, удаление, отмена и восстановление Просмотр файлов в Stagig area и Working area Если некоторые файлы/папки уже добавлены в staging area, то можно просмотреть их рахницу по отношению в главной ветке комадой: git diff --staged\nЭто покажет нам все внесенные изменения и все новые файлы, которые мы добавили или удалили.\nИзменения в измененных файлах обозначаются символами --- или +++ Вы можете видеть ниже, что мы только что добавили +add some text, что означает, что это новые строки.\nМы также можем запустить git diff, чтобы сравнить наш staging area с нашим рабочим каталогом. Если мы внесем некоторые изменения в наш только что добавленный файл code.txt и добавим несколько строк текста.\nИнструменты для визуального отображения Вот несколько инструментов для визуального сравнения коммитов и веток:\nKDiff3 P4Merge WinMerge (только для Windows) VSCode Если запустим git difftool то запустится визуальный инструмент сравнения по умолчанию. Проверить текущие настройки git config --global -e Чтобы установить инструмент в git, выполним следующую команду git config --global diff.tool vscode. Теперь при запуске git difftool откроется vscode После этого открывается редактор VScode на странице diff и сравнивает их, мы изменили только один файл, добавив строку кода с правой стороны. Можем использовать git difftool --staged для сравнения файлов в staging area с “прокомиченными” файлами. VScode, как и большинство IDE, имеют встроенную функциональность, поэтому очень редко вам понадобится запускать эти команды из терминала, хотя это полезно, если у вас по какой-то причине не установлена IDE.\nПросмотр истории изменений Просмотреть историю изменений в Git можно командой git log\nКаждый коммит имеет свою шестнадцатеричную строку, уникальную для репозитория. Здесь вы можете увидеть, над какой веткой мы работаем, а также автора, дату и комментарий коммита.\nУ нас также есть git log --oneline, и это даёт нам гораздо меньшую версию шестнадцатеричной строки, которую мы можем использовать в других командах diff.\nЧтобы просмотреть коммиты с самого первого, а не послденего, как по умолчанию, запустим git log --oneline --reverse, и теперь мы видим наш первый коммит в верхней части страницы.\nПросмотр коммита Можно просмотреть данные ко конкретном коммите более детально: git show или git show \u003ccommit ID\u003e\nМы также можем использовать git show HEAD~1, где 1 - это количество шагов назад от текущей версии, к которой мы хотим вернуться.\nЭто отличный вариант, если вам нужна подробная информация о файлах, но если мы хотим получить список всех файлов в дереве для всего каталога снимков. Мы можем добиться этого, используя команду git ls-tree HEAD~1, снова вернувшись на один снимок назад от последнего коммита. Ниже мы видим два пятна, которые обозначают файлы, в то время как дерево обозначает каталог. В этой информации вы также можете увидеть коммиты и теги.\nПроверим коммит\nUnstaging Бывают случаи, когда вы, возможно, использовали git add ., но на самом деле есть файлы, которые вы пока не хотите фиксировать в этом снапшоте. В этом примере ниже я добавил newfile.txt в область staging, но я не готов зафиксировать этот файл, поэтому я собираюсь использовать git restore --staged newfile.txt, чтобы отменить шаг git add.\nМы также можем сделать то же самое с изменёнными файлами, такими как main.js, и снять фиксацию, см. выше у нас есть greem M для modified, а ниже мы снимаем фиксацию этих изменений.\nЯ нашел эту команду весьма полезной во время 90DaysOfDevOps, поскольку иногда я работаю заранее, когда чувствую, что хочу сделать заметки для следующего дня, но не хочу фиксировать и выкладывать в публичный репозиторий GitHub.\nОтмена локальных изменений Иногда мы можем вносить изменения, но эти изменения нас не устраивают, и мы хотим их отбросить. Мы снова воспользуемся командой git restore и сможем восстановить файлы из наших снимков или предыдущих версий. Мы можем запустить команду git restore . для нашего каталога, и мы восстановим все из нашего снимка, но обратите внимание, что наш неотслеживаемый файл все еще присутствует. Нет предыдущего отслеживаемого файла под названием newfile.txt.\nТеперь, чтобы удалить newfile.txt или любой другой неотслеживаемый файл. Мы можем использовать git clean, но получим только предупреждение.\nИли, если мы знаем о последствиях, мы можем запустить git clean -fd, чтобы принудительно удалить все каталоги.\nВосстановление файла до более ранней версии Как мы уже упоминали, большая часть того, чем может помочь Git, - это возможность восстановления копий файлов из снимков (это не резервное копирование, но это очень быстрая точка восстановления). Я советую вам также сохранять копии вашего кода в других местах, используя для этого решение для резервного копирования.\nВ качестве примера давайте удалим наш самый важный файл в каталоге, обратите внимание, что мы используем команды на базе unix для удаления этого файла из каталога, а не команды git.\nТеперь у нас нет readme.mdin в нашей рабочей директории. Мы могли бы использовать git rm readme.md и тогда это было бы отражено в нашей базе данных git. Давайте также удалим его отсюда, чтобы имитировать его полное удаление.\nТеперь зафиксируем это с сообщением и докажем, что у нас больше нет ничего в рабочем каталоге или в области постановки.\nБыла допущена ошибка, и теперь нам нужно вернуть этот файл!\nМы можем использовать команду git undo, которая отменит последний коммит, но что если это было давно? Мы можем использовать команду git log, чтобы найти наши коммиты, и тогда мы обнаружим, что наш файл находится в последнем коммите, но мы не хотим, чтобы все эти коммиты были отменены, поэтому мы можем использовать эту команду git restore --source=HEAD~1 README.md, чтобы найти файл и восстановить его из нашего снимка.\nВы можете видеть, что с помощью этого процесса мы вернули файл в наш рабочий каталог.\nТеперь у нас есть новый неотслеживаемый файл, и мы можем использовать наши команды, упомянутые ранее, для отслеживания, этапа и фиксации наших файлов и изменений.\nRebase / Merge Это, кажется, самая большая головная боль, когда речь заходит о Git и о том, когда использовать rebase, а когда использовать merge в ваших git-репозиториях.\nПрежде всего, нужно знать, что и git rebase, и git merge решают одну и ту же задачу. Оба они интегрируют изменения из одной ветки в другую. Однако они делают это по-разному.\nДавайте начнем с новой функции в новой выделенной ветке. Основная ветку продолжает работу с новыми коммитами.\nПростой вариант здесь - использовать git merge feature main, который объединит основную ветку с веткую feature.\nСлияние простое, потому что оно неразрушающее. Существующие ветви никак не изменяются. Однако это также означает, что функциональная ветку будет иметь неактуальный коммит слияния каждый раз, когда вам нужно будет включить изменения, внесённые выше по течению. Если main очень занят или активен, это может привести к загрязнению истории функциональной ветви.\nВ качестве альтернативного варианта мы можем перебазировать функциональную ветку на основную ветку с помощью команды\ngit checkout feature git rebase main Это перемещает ветку feature (всю ветку feature), эффективно включая все новые коммиты в main. Но вместо использования коммита слияния, rebasing переписывает историю проекта, создавая совершенно новые коммиты для каждого коммита в исходной ветке.\nСамым большим преимуществом ребасинга является гораздо более чистая история проекта. Это также устраняет ненужные коммиты слияния. и если сравнить последние два изображения, то можно увидеть, что история проекта намного чище.\nХотя это еще не окончательный вывод, потому что выбор более чистой истории также связан с компромиссами. Если вы не будете следовать The Golden rule of rebasing, переписывание истории проекта может стать потенциально катастрофой для вашего рабочего процесса совместной работы. И, что менее важно, при пересборке теряется контекст, предоставляемый коммитом слияния - вы не можете увидеть, когда изменения, внесенные выше по течению, были включены в функцию.\nСсылки What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet Exploring the Git command line – A getting started guide ","description":"Просмотр, удаление, отмена и восстановление версий в Git","title":"39. Просмотр, удаление, отмена и восстановление","uri":"/ru/tracks/90daysofdevops/day39/"},{"content":"DevOps и Agile Вы знаете разницу между DevOps и Agile? Они формировались как самостоятельные понятия. Но теперь эти два термина сливаются.\nВ этом посте мы рассмотрим важные различия между Agile и DevOps и выясним, почему они так тесно связаны.\nЯ думаю, что хорошее место для начала — это немного больше узнать об общем подходе, который я увидел в изучении этой области, а именно о DevOps и Agile, даже несмотря на то, что у них схожие цели и процессы. В этом разделе я, надеюсь, мы разберемся с этим.\nНачнем с определений.\nРазработка Agile Agile — это подход, который фокусируется на более быстром получении небольших результатов, а не на выгрзуке (релизе) одного большого обновления продукта; программное обеспечение разрабатывается итерациями (неболшими изменениями). Команда выпускает новую версию каждую неделю или месяц с дополнительными обновлениями. Итоговая цель Agile — предоставить конечным пользователям оптимальный опыт.\nDevOps В течение последних нескольких дней мы освещали это несколькими различными способами описания конечных целей DevOps. DevOps обычно описывает разработку программного обеспечения и методы доставки, основанные на сотрудничестве между разработчиками программного обеспечения и специалистами по эксплуатации. Основными преимуществами DevOps являются упрощение процесса разработки и минимизация недопонимания.\nВ чем разница между Agile и DevOps Разница в основном в заботах. У Agile и DevOps разные интересы, но они помогают друг другу. Agile требует коротких итераций, что возможно только с автоматизацией, которую обеспечивает DevOps. Agile хочет, чтобы клиент попробовал конкретную версию и быстро дал отзыв, что возможно только в том случае, если DevOps упростит создание новой среды.\nРазные участники Agile фокусируется на оптимизации взаимодействия между конечными пользователями и разработчиками, в то время как DevOps нацелен на разработчиков и членов операционной группы. Можно сказать, что Agile ориентирован на клиентов, тогда как DevOps — это набор внутренних практик.\nКоманда Agile обычно применяется к разработчикам программного обеспечения и руководителям проектов. Компетенции DevOps-инженеров лежат на стыке разработки, QA (обеспечения качества) и операций, поскольку они участвуют во всех этапах цикла продукта и являются частью Agile-команды.\nПрикладные фреймворки В Agile есть много сред управления для достижения гибкости и прозрачности: Scrum \u003e Kanban \u003e Lean \u003e Extreme \u003e Crystal \u003e Dynamic \u003e Feature-Driven. DevOps фокусируется на подходе к разработке в сотрудничестве, но не предлагает конкретных методологий. Тем не менее, DevOps продвигает такие практики, как инфраструктура как код, архитектура как код, мониторинг, самовосстановление, сквозная автоматизация тестирования… Но сама по себе это не структура, а практика.\nОбратная связь В Agile основным источником обратной связи является конечный пользователь, тогда как в DevOps более высокий приоритет имеет обратная связь от заинтересованных сторон и самой команды.\nЦелевые области Agile фокусируется на разработке программного обеспечения больше, чем на развертывании и обслуживании. DevOps также фокусируется на разработке программного обеспечения, но его ценности и инструменты также охватывают этапы развертывания и после выпуска, такие как мониторинг, высокая доступность, безопасность и защита данных.\nДокументация Agile отдает предпочтение гибкости и поставленным задачам, а не документации и мониторингу. С другой стороны, DevOps рассматривает проектную документацию как один из основных компонентов проекта.\nРиски Риски Agile вытекают из гибкости методологии. Гибкие проекты трудно предсказать или оценить, поскольку приоритеты и требования постоянно меняются.\nРиски DevOps возникают из-за неправильного понимания термина и отсутствия подходящих инструментов. Некоторые люди рассматривают DevOps как набор программного обеспечения для развертывания и непрерывной интеграции, не способного изменить базовую структуру процесса разработки.\nИспользуемые инструменты Agile-инструменты ориентированы на совместную управленческую коммуникацию, метрики и обработку отзывов. К наиболее популярным agile-инструментам относятся JIRA, Trello, Slack, Zoom, SurveyMonkey и другие.\nDevOps использует инструменты для командного общения, разработки программного обеспечения, развертывания и интеграции, такие как Jenkins, GitHub Actions, BitBucket и т. д. Несмотря на то, что Agile и DevOps имеют несколько разные фокусы и области действия, ключевые значения почти идентичны, поэтому вы можете комбинировать их.\nСобрать все вместе… хорошая идея или нет? Обсуждать? Сочетание Agile и DevOps дает следующие преимущества:\nГибкое управление и мощные технологии. Практики Agile помогают командам DevOps более эффективно сообщать о своих приоритетах. Стоимость автоматизации, которую вы должны заплатить за свои методы DevOps, оправдана вашим гибким требованием быстрого и частого развертывания. Это приводит к укреплению: команда, внедряющая agile-практики, улучшит сотрудничество, повысит мотивацию команды и снизит текучесть кадров. В результате вы получаете лучшее качество продукции. Agile позволяет вернуться к предыдущим этапам разработки продукта, чтобы исправить ошибки и предотвратить накопление технического долга. Принять Agile и DevOps одновременно просто выполните 7 шагов:\nОбъедините команды разработки и эксплуатации. Создайте команды сборки и запуска, все проблемы, связанные с разработкой и эксплуатацией, обсуждаются всей командой DevOps. Измените свой подход к спринтам и назначьте рейтинги приоритета, чтобы предлагать задачи DevOps, которые имеют такое же значение, как задачи разработки. Поощряйте команды разработчиков и эксплуатации обмениваться мнениями о рабочем процессе других команд и возможных проблемах. Включите контроль качества на все этапы разработки. Выбирайте правильные инструменты. Автоматизируйте все, что можете. Измеряйте и контролируйте, используя материальные числовые результаты. Что вы думаете? У вас разные взгляды? Я хочу услышать от разработчиков, специалистов по эксплуатации, QA или кого-либо, кто лучше разбирается в Agile и DevOps, которые могут поделиться комментариями и отзывами по этому поводу?\nИсточники DevOps for Developers – Day in the Life: DevOps Engineer in 2021 3 Things I wish I knew as a DevOps Engineer How to become a DevOps Engineer feat. Shawn Powers До встречи в День 5\n","description":"DevOps и Agile","title":"4. DevOps и Agile","uri":"/ru/tracks/90daysofdevops/day04/"},{"content":"Социальная сеть для кода Изучение GitHub | GitLab | BitBucket\nСегодня я хочу рассказать о некоторых сервисах на основе git, о которых мы, вероятно, все слышали и ожидаем, что будем использовать их ежедневно.\nGitHub Наиболее распространенным, по крайней мере для меня, является GitHub, GitHub — это веб-хостинг для git. Чаще всего он используется разработчиками программного обеспечения для хранения своего кода. Управление исходным кодом с функциями контроля версий git, а также множеством дополнительных функций. Это позволяет командам или открытым участникам легко общаться и обеспечивает социальный аспект кодирования. (отсюда и название социальной сети) С 2018 года GitHub является частью Microsoft.\nGitHub существует уже довольно давно и был основан в 2007-2008 годах. Сегодня на платформе более 40 миллионов пользователей.\nОсновные возможности GitHub\nCode Repository Pull Requests Project Management toolset - Issues CI / CD Pipeline - GitHub Actions С точки зрения ценообразования GitHub предлагает различные уровни ценообразования для своих пользователей. Дополнительную информацию можно найти на странице Цены.\nДля этого мы рассмотрим бесплатный уровень.\nЯ собираюсь использовать свою уже созданную учетную запись GitHub во время этого пошагового руководства, если у вас нет учетной записи, то на открывающейся странице GitHub есть вариант регистрации и несколько простых шагов для настройки.\nGitHub opening page Когда вы впервые входите в свою учетную запись GitHub, вы получаете страницу, содержащую множество виджетов, дающих вам варианты того, где и что вы хотели бы увидеть или сделать. Во-первых, у нас есть «All Activity», это даст вам представление о том, что происходит с вашими репозиториями или действиями в целом, связанными с вашей организацией или учетной записью.\nЗатем у нас есть наши репозитории кода, либо наши собственные, либо репозитории, с которыми мы недавно взаимодействовали. Мы также можем быстро создавать новые репозитории или репозитории поиска.\nЗатем у нас есть наша недавняя активность, для меня это проблемы и pull requests, которые я недавно создал или в которых участвовал.\nВ правой части страницы есть несколько ссылок на репозитории, которые могут нас заинтересовать, скорее всего, на основе вашей недавней активности или собственных проектов.\nЧестно говоря, я очень редко бываю на своей домашней странице, которую мы только что видели и описали, хотя теперь я вижу, что лента может быть действительно полезной, чтобы помочь взаимодействовать с сообществом немного лучше в определенных проектах.\nДалее, если мы хотим зайти в наш профиль на GitHub, мы можем перейти в правый верхний угол, и на вашем изображении будет выпадающий список, который позволит вам перемещаться по вашему аккаунту. Отсюда для доступа к своему профилю выберите “Ваш профиль”\nДалее появится страница вашего профиля, по умолчанию, если вы не измените свою конфигурацию, вы не увидите того, что есть у меня, я добавил некоторые функции, которые показывают мои последние записи в блоге на vZilla, а также мои последние видео на моем канале YouTube.\nЛично вы не собираетесь тратить много времени на просмотр своего профиля, но это хорошая страница профиля, которой можно поделиться со своей сетью, чтобы они могли увидеть крутые проекты, над которыми вы работаете.\nЗатем мы можем перейти к основному элементу GitHub - репозиториям. Здесь вы увидите свои собственные репозитории, а если у вас есть частные репозитории, они также будут показаны в этом длинном списке.\nПоскольку этот репозиторий так важен для GitHub, позвольте мне выбрать довольно загруженный в последнее время и просмотреть некоторые основные функции, которые мы можем использовать здесь, в дополнение ко всему, что я уже использую, когда дело доходит до редактирования нашего кода в git. моя локальная система.\nПрежде всего, в предыдущем окне я выбрал репозиторий 90DaysOfDevOps, и мы видим это представление. Вы можете видеть из этого представления, что у нас есть много информации, у нас есть наша основная структура кода в середине, показывающая наши файлы и папки, которые хранятся в нашем репозитории. Наш файл readme.md отображается внизу. Справа от страницы у нас есть раздел о репозитории, где у репозитория есть описание и назначение. Затем у нас есть много информации под этим, показывающей, сколько людей отметили проект, разветвились и смотрят.\nЕсли мы прокрутим вниз немного дальше, вы также увидите, что у нас есть Releases, они относятся к части задачи golang. У нас нет никаких пакетов в нашем проекте, здесь перечислены наши соавторы. Затем у нас есть используемые языки, опять же из разных разделов задачи.\nВ верхней части страницы вы увидите список вкладок. Они могут различаться, и их можно изменить, чтобы отображались только те, которые вам нужны. Вы увидите здесь, что я не использую все это, и я должен удалить их, чтобы убедиться, что весь мой репозиторий в порядке.\nВо-первых, у нас была вкладка кода, которую мы только что обсуждали, но эти вкладки всегда доступны при навигации по репозиторию, что очень полезно, так что мы можем быстро и легко переходить между разделами. Далее у нас есть вкладка вопросов.\nПроблемы позволяют отслеживать вашу работу на GitHub, где происходит разработка. В этом конкретном репозитории вы можете увидеть, что у меня есть некоторые проблемы, связанные с добавлением диаграмм или опечаток, но также у нас есть проблема, указывающая на необходимость или требование для китайской версии репозитория.\nЕсли это был репозиторий кода, то это отличное место, чтобы сообщить о проблемах или проблемах с сопровождающими, но помните, будьте внимательны и подробны в отношении того, о чем вы сообщаете, давайте как можно больше подробностей.\nСледующая вкладка — Pull Requests. Pull Requests позволяют вам сообщать другим об изменениях, которые вы отправили в ветку в репозитории. Здесь кто-то мог разветвить ваш репозиторий, внести изменения, такие как исправления ошибок или улучшения функций, или просто опечататься во многих случаях в этом репозитории.\nМы рассмотрим разветвление позже.\nЯ считаю, что следующая вкладка совершенно новая? Но я подумал, что для такого проекта, как #90DaysOfDevOps, это может действительно помочь направить контент, а также помочь сообществу, когда они проходят свой собственный путь обучения. Я создал несколько дискуссионных групп для каждого раздела задачи, чтобы люди могли присоединиться и обсудить.\nВкладка “Actions” позволит вам создавать, тестировать и развертывать код и многое другое прямо из GitHub. GitHub Actions будет чем-то, что мы рассмотрим в разделе задачи, посвященном CI/CD, но именно здесь мы можем установить некоторую конфигурацию, чтобы автоматизировать шаги для нас.\nВ моем основном профиле GitHub я использую GitHub Actions для получения последних сообщений в блогах и видео на YouTube, чтобы обновлять информацию на этом домашнем экране.\nЯ уже говорил о том, что GitHub - это не только хранилище исходного кода, но и инструмент управления проектами. Вкладка “Проект” позволяет нам создавать проектные таблицы типа канбан, чтобы мы могли связывать проблемы и PR для лучшего сотрудничества над проектом и иметь видимость этих задач. Я знаю, что проблемы, как мне кажется, являются хорошим местом для регистрации запросов о возможностях, и это так, но страница вики позволяет составить полную дорожную карту проекта с указанием текущего состояния и в целом лучше документировать ваш проект, будь то устранение неполадок или контент типа how-to.\nНе совсем применимо к этому проекту, но вкладка Security действительно существует для того, чтобы убедиться, что участники проекта знают, как обращаться с определенными задачами, здесь мы можем определить политику, а также дополнения для сканирования кода, чтобы убедиться, что ваш код, например, не содержит секретных переменных окружения.\nДля меня вкладка insights очень важна, она предоставляет так много информации о репозитории, начиная от того, сколько активности происходило и заканчивая коммитами и проблемами, а также сообщает о посещаемости репозитория. В левой части вы можете увидеть список, который позволяет вам подробно ознакомиться с метриками репозитория.\nНаконец, у нас есть вкладка Settings, где мы можем подробно описать, как мы управляем нашим репозиторием, в настоящее время я единственный сопровождающий репозитория, но мы можем разделить эту ответственность. Здесь мы можем определить интеграции и другие подобные задачи.\nЭто был очень быстрый обзор GitHub, я думаю, что есть еще несколько областей, которые я, возможно, упомянул и которые нуждаются в более подробном объяснении. Как уже упоминалось, GitHub содержит миллионы репозиториев, в которых в основном хранится исходный код, и они могут быть общедоступными или частными.\nForking Я собираюсь больше рассказать об Open-Source на завтрашней сессии, но большая часть любого репозитория кода — это возможность сотрудничать с сообществом. Давайте подумаем о сценарии: мне нужна копия репозитория, потому что я хочу внести в него некоторые изменения, может быть, я хочу исправить ошибку или, может быть, я хочу что-то изменить, чтобы использовать его для моего варианта использования, который, возможно, не был предполагаемый вариант использования для первоначального сопровождающего кода. Это то, что мы бы назвали разветвлением репозитория. Форк — это копия репозитория. Разветвление репозитория позволяет вам свободно экспериментировать с изменениями, не затрагивая исходный проект.\nПозвольте мне вернуться на начальную страницу после входа в систему и увидеть один из предложенных репозиториев.\nЕсли мы нажмем на этот репозиторий, мы получим тот же вид, что и репозиторий 90DaysOfDevOps.\nЕсли мы обратим внимание, ниже у нас есть 3 варианта: watch, fork и star.\nWatch - обновление, когда что-то происходит с хранилищем. Fork - копия репозитория. Star - “Я думаю, что ваш проект крутой”. Учитывая наш сценарий, когда нам нужна копия репозитория для работы, мы воспользуемся опцией fork. Если вы являетесь членом нескольких организаций, то вам придётся выбрать, где будет происходить форк, я выберу свой профиль.\nТеперь у нас есть собственная копия репозитория, над которой мы можем свободно работать и изменять по своему усмотрению. Это начало процесса подачи запросов на исправление, о котором мы уже вкратце упоминали, но более подробно рассмотрим завтра. Хорошо, я слышу, как вы говорите, но как мне внести изменения в этот репозиторий и код, если он находится на веб-сайте, ну, вы можете просматривать и редактировать на веб-сайте, но это не будет таким же, как использование вашей любимой IDE в вашей локальной системе. с вашей любимой цветовой темой. Чтобы получить копию этого репозитория на нашем локальном компьютере, мы выполним клонирование репозитория. Это позволит нам работать над вещами локально, а затем отправлять наши изменения обратно в нашу разветвленную копию репозитория.\nУ нас есть несколько вариантов получения копии этого кода, как вы можете видеть ниже.\nДоступна локальная версия GitHub Desktop, которая дает вам визуальное настольное приложение для отслеживания изменений и отправки и получения изменений между локальным и github.\nДля этой небольшой демонстрации я буду использовать URL-адрес HTTPS, который мы видим там.\nТеперь на нашей локальной машине я перейду в каталог, в который я хочу загрузить этот репозиторий, а затем выполню команду git clone url.\nТеперь мы можем обратиться к VScode, чтобы действительно внести некоторые изменения.\nТеперь давайте сделаем некоторые изменения, я хочу изменить все эти ссылки и заменить их на что-то другое.\nТеперь, если мы вернемся на GitHub и найдем наш readme.mdin в этом репозитории, вы сможете увидеть несколько изменений, которые я внес в файл.\nНа данном этапе это может быть завершено, и мы можем быть довольны нашим изменением, поскольку мы единственные люди, которые будут использовать наше новое изменение, но, возможно, это было изменение ошибки, и если это так, то мы захотим внести свой вклад через Pull Request чтобы уведомить сопровождающих исходного репозитория о наших изменениях и посмотреть, примут ли они наши изменения.\nМы можем сделать это, используя кнопку вклада, выделенную ниже. Я расскажу об этом подробнее завтра, когда мы рассмотрим рабочие процессы с открытым исходным кодом.\nЯ долго просматривал GitHub и слышал, как некоторые из вас плачут, но как насчет других вариантов!\nНу, есть, и я собираюсь найти некоторые ресурсы, которые охватывают основы для некоторых из них. В своих путешествиях вы столкнетесь с GitLab и BitBucket, и хотя они основаны на git, у них есть свои отличия.\nВы также столкнетесь с размещенными вариантами. Чаще всего здесь я видел GitLab как размещенную версию по сравнению с GitHub Enterprise (не верите, что есть бесплатный размещенный GitHub?)\nРесурсы Learn GitLab in 3 Hours | GitLab Complete Tutorial For Beginners BitBucket Tutorials Playlist What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"Обзор онлайн репозиториев для Git","title":"40. GitHub | GitLab | BitBucket","uri":"/ru/tracks/90daysofdevops/day40/"},{"content":"Рабочий процесс с открытым исходным кодом Когда мы изучали основы GitHub, мы проходили процесс форка произвольного проекта и внесения изменений в наш локальный репозиторий. Здесь мы хотим сделать еще один шаг вперед и внести свой вклад в проект с открытым исходным кодом. Помните, что вклад не обязательно должен заключаться в исправлении ошибок, кодировании функций, это может быть и документация. Каждая мелочь помогает, и это также позволит вам поработать с некоторыми функциями git, которые мы рассмотрели.\nФорк проекта Первое, что нам нужно сделать, это найти проект, в который мы можем внести свой вклад. Я недавно выступал с презентациями в Kanister Project и хотел бы поделиться своими презентациями, которые теперь есть на YouTube, с основным readme.mdf-файлом проекта.\nПрежде всего, нам нужно форкнуть проект. Давайте проделаем этот процесс. Я собираюсь перейти по ссылке, указанной выше, и форкнуть репозиторий.\nТеперь у нас есть наша копия всего репозитория.\nДля справки в файле Readme.mdfile в списке оригинальных Presenations указаны только эти два, поэтому нам нужно исправить это в нашем процессе.\nКлонирование на локальную машину Теперь у нас есть собственный форк, который мы можем перенести на локальную машину и начать вносить правки в файлы. Используя кнопку code на нашем репозитории, мы можем получить URL, а затем использовать git clone url в каталоге, куда мы хотим поместить репозиторий.\nВносим изменения У нас есть локальный проект, поэтому мы можем открыть VSCode или IDE или текстовый редактор по вашему выбору, чтобы добавить свои изменения.\nФайл readme.mdfile написан на языке markdown, и поскольку я изменяю чужой проект, я собираюсь следовать существующему форматированию проекта для добавления нашего содержимого.\nТестируем свои изменения В качестве лучшей практики мы должны тестировать наши изменения, это совершенно логично, если бы это было изменение кода приложения, вы бы хотели убедиться, что приложение продолжает функционировать после изменения кода, но мы также должны убедиться, что документация отформатирована и выглядит правильно.\nВ VScode у нас есть возможность добавить множество плагинов, одним из которых является возможность предварительного просмотра страниц в формате markdown.\nВерните изменения в наш форкнутый репозиторий У нас нет аутентификации, чтобы отправить наши изменения непосредственно в репозиторий Kanister, поэтому мы должны пойти этим путем. Теперь, когда я доволен нашими изменениями, мы можем выполнить некоторые из этих хорошо известных команд git.\nТеперь мы возвращаемся в GitHub, чтобы еще раз проверить изменения и затем внести вклад в мастер-проект.\nТеперь мы можем вернуться в верхнюю часть нашего форкнутого репозитория для Kanister и увидеть, что мы на 1 коммит опережаем ветку kanisterio:master.\nДалее мы нажимаем на кнопку “Внести вклад”, выделенную выше. Мы видим опцию “Open Pull Request”.\nOpen a pull request На следующем изображении происходит довольно много всего: слева вверху вы видите, что мы находимся в оригинальном или основном репозитории. Затем вы можете увидеть, что мы сравниваем, а это оригинальный основной и наш форкнутый репозиторий. Затем у нас есть кнопка создания запроса на притяжение, к которой мы скоро вернёмся. У нас есть единственный коммит, но если бы изменений было больше, то здесь могло бы быть несколько коммитов. Затем у нас есть изменения, которые мы внесли в readme.mdfile.\nМы просмотрели вышеуказанные изменения и готовы создать pull request, нажав на зеленую кнопку.\nЗатем, в зависимости от того, как мейнтейнер проекта настроил функциональность Pull Request в своём репозитории, у вас может быть или не быть шаблона, который даст вам указания на то, что хочет видеть мейнтейнер.\nЗдесь вам снова нужно составить содержательное описание того, что вы сделали, четкое и краткое, но достаточно подробное. Вы можете видеть, что я сделал простой обзор изменений и отметил документацию.\nСоздайте запрос на исправление Теперь мы готовы к созданию запроса на исправление. После нажатия кнопки “Create Pull Request” в верхней части страницы вы получите краткое описание вашего запроса.\nПрокручивая страницу вниз, вы, вероятно, увидите, что происходит автоматизация, в данном случае нам требуется рецензия, и происходят некоторые проверки. Мы видим, что Travis CI находится в процессе и началась сборка, которая проверит наше обновление и убедится, что перед тем, как что-то будет слито, мы не сломаем что-то своими добавлениями.\nЕще одна вещь, которую следует отметить, это то, что красный цвет на снимке экрана выше, может выглядеть немного пугающе и выглядеть так, как будто вы совершили ошибки! Не волнуйтесь, вы ничего не нарушили, мой главный совет - этот процесс поможет вам и сопровождающим проекта. Если вы допустили ошибку, по крайней мере, по моему опыту, сопровождающий свяжется с вами и посоветует, что делать дальше.\nЭтот запрос на исправление теперь общедоступен для всех added Kanister presentation/resource #1237.\nЯ собираюсь опубликовать это до того, как слияние и запрос на исправление будут приняты, так что, возможно, мы сможем получить небольшой приз для тех, кто всё ещё следит за развитием событий и сможет добавить картинку к успешному PR?\nФоркните этот репозиторий на свой собственный аккаунт GitHub Добавьте свою картинку и, возможно, текст Внесите изменения в свой форкнутый репозиторий. Создайте PR, который я увижу и одобрю. Я придумаю какой-нибудь приз. На этом мы завершаем знакомство с Git и GitHub, далее мы погружаемся в контейнеры, что начинается с рассмотрения общей картины того, как, почему контейнеры, а также с рассмотрения виртуализации и того, как мы к ней пришли.\nРесурсы Learn GitLab in 3 Hours | GitLab Complete Tutorial For Beginners BitBucket Tutorials Playlist What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"","title":"41. Рабочий процесс с открытым исходным кодом","uri":"/ru/tracks/90daysofdevops/day41/"},{"content":"Контейнеры Этот раздел будет посвящен контейнерам. Будем рассматривать Docker, вникая в некоторые ключевые области, чтобы понять больше о контейнерах.\nЯ также попытаюсь провести практические занятия по созданию контейнера, который мы сможем использовать не только в этом разделе, но и в последующих.\nПочему другой способ запуска приложений? Первое, на что мы должны обратить внимание, - зачем нам нужен другой способ запуска программ или приложений? Просто выбор велик, мы можем запускать наши приложения в разных формах, мы можем видеть приложения, развернутые на физическом оборудовании с операционной системой и одним приложением, мы можем видеть виртуальную машину или облачные IaaS экземпляры, запускающие наше приложение, которое затем интегрируется в базу данных снова в виртуальной машине или как PaaS предложение в публичном облаке. Или мы можем увидеть наши приложения, работающие в контейнерах.\nНи один из перечисленных вариантов не является неправильным или правильным, но у каждого из них есть свои причины для существования, и я также твердо уверен, что ни один из них не исчезнет. Я видел много материалов, в которых обсуждаются контейнеры и виртуальные машины, и на самом деле здесь не должно быть спора, поскольку это больше похоже на спор между яблоками и грушами, где они оба являются фруктами (способы запуска наших приложений), но это не одно и то же.\nЯ бы также сказал, что если вы начинаете и разрабатываете приложение, вам следует склониться к контейнерам просто потому, что мы рассмотрим некоторые из этих областей позже, но речь идет об эффективности, скорости и размере. Но за это тоже приходится платить, если вы не имеете представления о контейнерах, то вам придется учиться, чтобы понять, зачем это нужно, и вжиться в этот образ мышления. Если вы разрабатывали свои приложения особым образом или вы не работаете в новой среде, то у вас может быть больше болевых точек, с которыми нужно справиться, прежде чем рассматривать контейнеры.\nУ нас есть много различных вариантов, когда нужно загрузить ту или иную часть программного обеспечения, есть множество различных операционных систем, которые мы можем использовать. И конкретные инструкции о том, что нам нужно сделать, чтобы установить наши приложения.\nВ последнее время я все чаще замечаю, что приложения, для которых раньше требовалась полноценная серверная ОС, виртуальная машина, физический или облачный экземпляр, теперь выпускают версии своего программного обеспечения на основе контейнеров. Я нахожу это интересным, поскольку это открывает мир контейнеров и Kubernetes для всех, а не только для разработчиков приложений.\nКак вы уже, наверное, поняли, я не собираюсь утверждать, что ответ - это контейнеры, в чем вопрос! Но я хотел бы обсудить, что это еще один вариант, о котором мы должны знать при развертывании наших приложений.\nУ нас уже давно существует контейнерная технология, так почему же именно сейчас, за последние 10 лет, она стала популярной, я бы сказал, даже более популярной в последние 5 лет. У нас были контейнеры в течение десятилетий. Все сводится к вызову контейнеров или, лучше сказать, образов, тому, как мы распространяем наше программное обеспечение, потому что если у нас будет только контейнерная технология, то у нас останется много тех же проблем, которые были с управлением программным обеспечением.\nЕсли мы подумаем о Docker как об инструменте, то причина его взлета заключается в экосистеме образов, которые легко найти и использовать. Их легко установить на свои системы и запустить в работу. Важной частью этого является согласованность во всем пространстве, во всех этих различных проблемах, с которыми мы сталкиваемся при работе с программным обеспечением. Неважно, MongoDB это или nodeJS, процесс запуска любого из них будет одинаковым. Процесс остановки любого из них одинаков. Все эти проблемы будут существовать, но самое приятное, что когда мы объединяем хорошие технологии контейнеров и образов, у нас появляется единый набор инструментов для решения всех этих различных проблем. Некоторые из этих проблем перечислены ниже:\nСначала нам нужно найти программное обеспечение в Интернете. Затем мы должны загрузить это программное обеспечение. Доверяем ли мы источнику? Нужна ли нам лицензия? Какая лицензия? Совместима ли она с различными платформами? Что представляет собой пакет? Бинарный? Исполняемый? Менеджер пакетов? Как сконфигурировать программу? Зависимости? Были ли они учтены при загрузке или они нам тоже нужны? Зависимости зависимостей? Как нам запустить приложение? Как мы остановим приложение? Будет ли оно автозапускаться? Запускаться при загрузке? Конфликты ресурсов? Конфликтующие библиотеки? Конфликты портов Безопасность программного обеспечения? Обновления программного обеспечения? Как удалить программное обеспечение? Мы можем разделить вышеперечисленное на 3 области сложности программного обеспечения, с которыми помогают справиться контейнеры и образы.\nРаспространение Установка Эксплуатация Найти Установить Запустить Скачать Конфигурация Безопасность Лицензия Деинсталляция Порты Пакет Зависимости Конфликты с ресурсами Доверие Платформа Автоперезагрузка Поиск Библиотеки Обновления Контейнеры и образы помогут нам устранить некоторые из этих проблем, с которыми мы сталкиваемся при работе с другими программами и приложениями.\nНа высоком уровне мы можем перенести установку и эксплуатацию в один список: образы помогут нам с точки зрения распространения, а контейнеры помогут с установкой и эксплуатацией.\nХорошо, возможно, звучит здорово и захватывающе, но нам все еще нужно понять, что такое контейнер, и теперь я упомянул образы, поэтому давайте рассмотрим эти области далее.\nЕще одна вещь, которую вы могли часто видеть, когда мы говорили о контейнерах для разработки программного обеспечения, - это аналогия с морскими контейнерами: морские контейнеры используются для перевозки различных товаров по морю с помощью больших судов.\nКакое отношение это имеет к нашей теме о контейнерах? Подумайте о коде, который пишут разработчики программного обеспечения, как мы можем перенести этот код с одной машины на другую?\nЕсли мы подумаем о том, что мы уже говорили о распространении программного обеспечения, установке и операциях, то теперь мы начнем выстраивать это в визуальную среду. У нас есть аппаратное обеспечение и операционная система, на которой вы будете запускать несколько приложений. Например, nodejs имеет определенные зависимости и нуждается в определенных библиотеках. Если вы хотите установить MySQL, то ему нужны необходимые библиотеки и зависимости. Каждое программное приложение будет иметь свою библиотеку и зависимость. Нам может крупно повезти, и у нас не будет конфликтов между приложениями, где определенные библиотеки и зависимости сталкиваются, вызывая проблемы, но чем больше приложений, тем больше вероятность или риск конфликтов. Однако речь не идет об одном развертывании, когда все исправления ваших программных приложений будут обновлены, и тогда мы также можем столкнуться с этими конфликтами.\nКонтейнеры могут помочь решить эту проблему. Контейнеры помогают создать ваше приложение, отправить приложение, развернуть и масштабировать эти приложения с легкостью самостоятельно. Давайте рассмотрим архитектуру, у вас есть аппаратное обеспечение и операционная система, а поверх них - контейнерный движок, такой как docker, который мы рассмотрим позже. Программное обеспечение контейнерного движка помогает создавать контейнеры, которые упаковывают библиотеки и зависимости вместе с ними, так что вы можете легко перемещать этот контейнер с одной машины на другую, не беспокоясь о библиотеках и зависимостях, поскольку они поставляются как часть пакета, который является ничем иным, как контейнером, так что вы можете иметь различные контейнеры, которые можно перемещать между системами, не беспокоясь о базовых зависимостях, которые необходимы приложению. потому что все, что нужно приложению для работы, упаковано как контейнер, который можно перемещать.\nПреимущества контейнеров Контейнеры помогают упаковать все зависимости внутри контейнера и изолировать его.\nКонтейнерами легко управлять\nВозможность перехода от одной системы к другой.\nКонтейнеры помогают упаковать программное обеспечение, и вы можете легко отправить его без каких-либо дублирующих усилий.\nКонтейнеры легко масштабируются.\nИспользуя контейнеры, вы можете масштабировать независимые контейнеры и использовать балансировщик нагрузки или сервис, который поможет разделить трафик, и вы сможете масштабировать приложения горизонтально. Контейнеры обеспечивают большую гибкость и облегчают управление приложениями.\nЧто такое контейнер? Когда мы запускаем приложения на нашем компьютере, это может быть веб-браузер или VScode, который вы используете для чтения этого сообщения. Это приложение работает как процесс или то, что известно как процесс. На наших ноутбуках или системах мы обычно запускаем несколько приложений или, как мы сказали, процессов. Когда мы открываем новое приложение или нажимаем на значок приложения, это приложение, которое мы хотим запустить, иногда это приложение может быть службой, которую мы просто хотим запустить в фоновом режиме, наша операционная система полна служб, которые работают в фоновом режиме, предоставляя вам возможность пользоваться системой.\nЗначок приложения представляет собой ссылку на исполняемый файл в файловой системе, после чего операционная система загружает этот файл в память. Интересно, что этот исполняемый файл иногда называют образом, когда речь идет о процессе.\nКонтейнеры - это процессы, а контейнер - это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, чтобы приложение быстро и надежно работало в разных вычислительных средах.\nКонтейнерное программное обеспечение всегда будет работать одинаково, независимо от инфраструктуры. Контейнеры изолируют программное обеспечение от его окружения и обеспечивают его единообразную работу, несмотря на различия, например, между разработкой и постановкой на хранение.\nЯ упоминал образы в последнем разделе, когда речь шла о том, как и почему контейнеры и образы вместе сделали контейнеры популярными в нашей экосистеме.\nЧто такое образ? Образ контейнера - это легкий, автономный, исполняемый пакет программного обеспечения, который включает все необходимое для запуска приложения: код, время выполнения, системные инструменты, системные библиотеки и настройки. Образы контейнеров становятся контейнерами во время выполнения.\nЧто такое контейнер? Когда мы запускаем приложения на нашем компьютере, это может быть веб-браузер или VScode, который вы используете для чтения этого сообщения. Это приложение работает как процесс или то, что известно как процесс. На наших ноутбуках или системах мы склонны запускать несколько приложений или, как мы сказали, процессов. Когда мы открываем новое приложение или нажимаем на значок приложения, это приложение, которое мы хотели бы запустить, иногда это приложение может быть службой, которую мы просто хотим запустить в фоновом режиме, наша операционная система полна служб, которые работают в фон, предоставляющий вам пользовательский опыт, который вы получаете с вашей системой.\nЭтот значок приложения представляет собой ссылку на исполняемый файл где-то в вашей файловой системе, затем операционная система загружает этот исполняемый файл в память. Интересно, что этот исполняемый файл иногда называют образом, когда мы говорим о процессе.\nКонтейнеры — это процессы. Контейнер — это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, чтобы приложение быстро и надежно запускалось из одной вычислительной среды в другую.\nКонтейнерное программное обеспечение всегда будет работать одинаково, независимо от инфраструктуры. Контейнеры изолируют программное обеспечение от его среды и обеспечивают его единую работу, несмотря на различия, например, между разработкой и промежуточной стадией.\nЯ упомянул изображения в предыдущем разделе, когда речь шла о том, как и почему сочетание контейнеров и изображений сделало контейнеры популярными в нашей экосистеме.\nСсылки TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers ","description":"Контенеры Docker для запуска приложений","title":"42. Контейнеры","uri":"/ru/tracks/90daysofdevops/day42/"},{"content":"Что такое Docker и его установка В предыдущей статье я хотя бы раз упомянул Docker, и это потому, что Docker действительно является новатором в создании популярности контейнеров, несмотря на то, что они существуют уже очень давно.\nЗдесь мы будем использовать и объяснять docker, но мы также должны упомянуть [Open Container Initiative (OCI)] (https://www.opencontainers.org/), которая является организацией по отраслевым стандартам, поощряющей инновации и избегающей опасности блокировки поставщиков. Благодаря OCI у нас есть выбор при выборе инструментария для контейнеров, включая Docker, CRI-O, Podman, LXC и другие.\nDocker - это программная среда для создания, запуска и управления контейнерами. Термин “docker” может относиться как к инструментам (командам и демону), так и к формату файлов Dockerfile.\nМы будем использовать Docker Personal, который является бесплатным (для образования и обучения). Он включает в себя все самое необходимое, что нам нужно для получения хорошего фундамента знаний о контейнерах и инструментах.\nВозможно, стоит разделить некоторые инструменты “docker”, которые мы будем использовать и для чего они нужны. Термин docker может относиться к проекту docker в целом, который является платформой для разработчиков и администраторов для разработки, доставки и запуска приложений. Также это может быть ссылка на процесс docker daeemon, запущенный на хосте, который управляет образами и контейнерами и называется Docker Engine.\nDocker Engine Docker Engine - это технология контейнеризации с открытым исходным кодом для создания и контейнеризации приложений. Docker Engine действует как клиент-серверное приложение:\nСервер с долго работающим процессом-демоном dockerd. API, определяющие интерфейсы, которые программы могут использовать для общения и обучения демона Docker. Клиент docker с интерфейсом командной строки (CLI). Вышеизложенное было взято из официальной документации Docker и конкретного Docker Engine Overview\nDocker Desktop У нас есть рабочий стол docker для систем Windows и macOS. Простая в установке, легковесная среда разработки docker. Нативное приложение для ОС, использующее возможности виртуализации на хостовой операционной системе.\nЭто лучшее решение, если вы хотите создавать, отлаживать, тестировать, упаковывать и отправлять Docker-приложения на Windows или macOS.\nНа Windows мы также можем воспользоваться преимуществами WSL2 и Microsoft Hyper-V. Мы рассмотрим некоторые преимущества WSL2 по ходу дела.\nБлагодаря интеграции с возможностями гипервизора на хостовой операционной системе docker предоставляет возможность запускать ваши контейнеры с операционными системами Linux.\nDocker Compose Docker compose - это инструмент, позволяющий запускать более сложные приложения в нескольких контейнерах. Преимуществом является возможность использования одного файла и команды для запуска приложения.\nDocker Hub Централизованный ресурс для работы с Docker и его компонентами. Чаще всего он известен как реестр для размещения образов Docker. Но здесь есть множество дополнительных сервисов, которые можно использовать для автоматизации или интеграции в GitHub, а также для сканирования безопасности.\nDockerfile Dockerfile - это текстовый файл, содержащий команды, которые обычно выполняются вручную для создания образа docker. Docker может собирать образы автоматически, читая инструкции, которые содержатся в нашем dockerfile.\nУстановка Docker Desktop Документация docker documenation просто потрясающая, и если вы только начинаете в нее погружаться, то вам стоит ее просмотреть и прочитать. Мы будем использовать Docker Desktop на Windows с WSL2. Я уже выполнил установку на своей машине, которую мы используем здесь.\nОбратите внимание перед установкой на системные требования, Install Docker Desktop on Windows, если вы используете macOS, включая архитектуру процессора на базе M1, вы также можете взглянуть на Install Docker Desktop on macOS.\nЯ проведу установку Docker Desktop для Windows на другой машине Windows и запишу процесс ниже.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started ","description":"","title":"43. Установка Docker","uri":"/ru/tracks/90daysofdevops/day43/"},{"content":"Образы Docker и практическая работа с Docker Desktop Теперь у нас в системе установлен Docker Desktop. (Если вы используете Linux, у вас все еще есть опции, но нет графического интерфейса, но docker, очевидно, работает на Linux)Install Docker Engine on Ubuntu (Другие дистрибутивы также доступны).\nВ этом посте мы собираемся начать с развертывания некоторых образов в нашей среде. Напомним, что такое образ Docker - образ Docker - это файл, используемый для выполнения кода в контейнере Docker. Образы Docker действуют как набор инструкций для создания контейнера Docker, как шаблон. Образы Docker также служат отправной точкой при использовании Docker.\nСейчас самое время пойти и создать свой аккаунт на DockerHub\nDockerHub - это централизованный ресурс для работы с Docker и его компонентами. Наиболее известен как реестр для размещения образов докеров. Но здесь есть множество дополнительных сервисов, которые можно использовать для автоматизации или интеграции в GitHub, а также для сканирования безопасности.\nЕсли вы прокрутите вниз после входа в систему, вы увидите список образов контейнеров, вы можете увидеть образы баз данных для mySQL, hello-world и т.д. и т.п. Рассматривайте их как отличные базовые образы, или вам может понадобиться просто образ базы данных, и вам лучше всего использовать официальный образ, что означает, что вам не нужно создавать свой собственный.\nМы можем углубиться в просмотр доступных изображений и осуществлять поиск по категориям, операционным системам и архитектурам. Единственное, что я выделил ниже, это Office Image, это должно дать вам уверенность в происхождении этого образа контейнера.\nМы также можем искать конкретное изображение, например, wordpress может быть хорошим базовым изображением, которое нам нужно, мы можем сделать это в верхней части и найти все изображения контейнеров, связанные с wordpress. Ниже обратите внимание, что у нас также есть проверенный издатель.\nОфициальные образы - Официальные образы Docker - это курируемый набор открытых исходных кодов Docker и репозиториев решений “drop-in”.\nПроверенный издатель - высококачественный контент Docker от проверенных издателей. Эти продукты публикуются и поддерживаются непосредственно коммерческой организацией.\nИзучение Docker Desktop У нас в системе установлен Docker Desktop, и если открыть его, то, если он у вас еще не установлен, вы увидите нечто похожее на изображение ниже. Как вы можете видеть, у нас нет запущенных контейнеров, но наш движок docker запущен.\nПоскольку это была не свежая установка для меня, у меня есть некоторые изображения, которые уже загружены и доступны в моей системе. Скорее всего, здесь вы ничего не увидите.\nВ разделе удаленных репозиториев вы найдете все образы контейнеров, которые хранятся в вашем хабе docker. Ниже показано, что у меня нет никаких образов.\nМы также можем уточнить это на нашем сайте dockerhub и подтвердить, что у нас там нет репозиториев.\nДалее у нас есть вкладка Volumes, если у вас есть контейнеры, которым требуется постоянство, то здесь мы можем добавить эти тома в вашу локальную файловую систему или общую файловую систему.\nНа момент написания статьи также существует вкладка Dev Environments, которая поможет вам сотрудничать с вашей командой вместо того, чтобы перемещаться между различными ветками git. Мы не будем ее рассматривать.\nВернувшись на первую вкладку, вы увидите, что там есть команда, которую мы можем запустить - это контейнер для запуска. Давайте запустим docker run -d -p 80:80 docker/getting-started в нашем терминале.\nЕсли мы снова проверим окно рабочего стола docker, то увидим, что у нас есть запущенный контейнер.\nВы могли заметить, что я использую WSL2, и для того, чтобы вы могли использовать его, вам нужно убедиться, что он включен в настройках.\nЕсли теперь мы снова перейдем на вкладку Images, вы должны увидеть используемый образ под названием docker/getting-started.\nВернитесь на вкладку Containers/Apps, нажмите на ваш запущенный контейнер. По умолчанию вы увидите журналы, а в верхней части есть несколько опций на выбор, в нашем случае я уверен, что это будет веб-страница, запущенная в этом контейнере, поэтому мы выберем опцию “Открыть в браузере”.\nКогда мы нажмем на кнопку выше, конечно же, откроется веб-страница на вашем локальном хосте и отобразится что-то похожее на то, что показано ниже.\nЭтот контейнер также содержит более подробную информацию о том, что такое контейнеры и изображения.\nТеперь мы запустили наш первый контейнер. Пока ничего страшного. А что если мы захотим вытащить один из образов контейнера из DockerHub? Может быть, там есть докер-контейнер hello world, который мы могли бы использовать.\nЯ остановил начальный контейнер, не то чтобы он занимал много ресурсов, но для аккуратности, пока мы проходим еще несколько шагов.\nВернемся в терминал и выполним команду docker run hello-world и посмотрим, что произойдет.\nВы можете видеть, что у нас не было локального образа, поэтому мы стянули его, а затем получили сообщение, записанное в образ контейнера, с информацией о том, что он сделал, чтобы запуститься, и некоторые ссылки на точки отсчета.\nОднако, если мы посмотрим в Docker Desktop, у нас нет запущенных контейнеров, но есть вышедший контейнер, который использовал сообщение hello-world, то есть он появился, передал сообщение и затем завершился.\nИ в последний раз, давайте просто проверим вкладку images и увидим, что у нас есть новый образ hello-world локально в нашей системе, что означает, что если мы снова выполним команду docker run hello-world в нашем терминале, нам не придется ничего вытаскивать, если только версия не изменится.\nВ сообщении от контейнера hello-world была поставлена задача запустить что-то более амбициозное.\nВызов принят!\nЗапустив docker run -it ubuntu bash в нашем терминале, мы собираемся запустить контейнерную версию Ubuntu, а не полную копию операционной системы. Вы можете узнать больше об этом конкретном образе на DockerHub.\nВы можете видеть ниже, когда мы выполним команду, у нас появится интерактивная подсказка (-it) и мы запустим оболочку bash в нашем контейнере.\nУ нас есть оболочка bash, но у нас не так много больше, поэтому образ этого контейнера занимает менее 30 мб.\nНо мы все еще можем использовать этот образ, и мы все еще можем установить программное обеспечение, используя наш менеджер пакетов apt, мы можем обновить наш образ контейнера и обновить также.\nИли, может быть, мы хотим установить какое-то программное обеспечение в наш контейнер, я выбрал очень плохой пример, поскольку pinta - это редактор изображений, и его размер превышает 200мб, но, надеюсь, вы поняли, к чему я веду. Это значительно увеличит размер нашего контейнера, но все же мы будем находиться в мб, а не в гб.\nЯ хотел, чтобы вы получили общее представление о Docker Desktop и не таком уж страшном мире контейнеров, когда вы разбиваете его на простые сценарии использования, но нам нужно рассказать о некоторых сетевых возможностях, безопасности и других вариантах, которые у нас есть по сравнению с просто загрузкой образов контейнеров и их использованием таким образом. К концу раздела мы хотим создать что-то, загрузить в наш репозиторий DockerHub и иметь возможность развернуть это.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started ","description":"","title":"44. Установка образов Docker в Docker Desktop","uri":"/ru/tracks/90daysofdevops/day44/"},{"content":"Анатомия образа Docker На прошлом занятии мы рассмотрели некоторые основы использования Docker Desktop в сочетании с DockerHub для развертывания и запуска некоторых проверенных образов. Вкратце о том, что такое образ, вы не забудете, если я продолжу упоминать.\nОбраз Docker - это шаблон, доступный только для чтения, содержащий набор инструкций для создания контейнера, который может работать на платформе Docker. Это удобный способ упаковки приложений и предварительно сконфигурированных серверных сред, которые вы можете использовать для личного пользования или публично делиться ими с другими пользователями Docker. Образы Docker также являются отправной точкой для тех, кто впервые использует Docker.\nЧто произойдет, если мы захотим создать свой собственный образ Docker? Для этого мы создадим Dockerfile. Вы видели, как мы могли взять образ контейнера Ubuntu и добавить наше программное обеспечение, и у нас получился образ контейнера с программным обеспечением, которое мы хотели, и все хорошо, но если этот контейнер выключить или выбросить, то все эти обновления и установки программного обеспечения пропадут, и не будет повторяющейся версии того, что мы сделали. Это отлично подходит для демонстрации возможностей, но не помогает при транспортировке образов в несколько сред с одним и тем же набором программного обеспечения, устанавливаемого при каждом запуске контейнера.\nЧто такое Dockerfile Dockerfile - это текстовый файл, содержащий команды, которые обычно выполняются вручную для создания образа docker. Docker может собирать образы автоматически, читая инструкции, содержащиеся в нашем dockerfile.\nКаждый из файлов, составляющих образ docker, называется слоем. Эти слои образуют серию образов, поэтапно создаваемых друг над другом. Каждый слой зависит от слоя, расположенного непосредственно под ним. Порядок расположения слоев является ключевым фактором эффективности управления жизненным циклом образов docker.\nМы должны расположить слои, которые меняются чаще всего, как можно выше в стеке, потому что при внесении изменений в слой образа Docker перестраивает не только этот слой, но и все слои, созданные на его основе. Поэтому изменение слоя на самом верху требует наименьшего объема работы по пересборке всего образа.\nКаждый раз, когда docker запускает контейнер из образа (как мы делали вчера), он добавляет слой, доступный для записи, известный как слой контейнера. В нем хранятся все изменения, вносимые в контейнер в течение всего времени его работы. Этот слой - единственное различие между работающим контейнером и исходным образом. Любое количество подобных контейнеров может иметь общий доступ к одному и тому же базовому образу, сохраняя при этом свое индивидуальное состояние.\nВернемся к примеру, который мы использовали вчера с образом Ubuntu. Мы можем выполнить одну и ту же команду несколько раз и на первый контейнер установить pinta, а на второй - figlet. Это два разных приложения, разного назначения, разного размера и т.д. и т.п.. Каждый контейнер, который мы установили, имеет один и тот же образ, но не одно и то же состояние, и это состояние исчезает, когда мы удаляем контейнер.\nВ приведенном выше примере используется образ Ubuntu, но также существует множество других готовых образов контейнеров, доступных на DockerHub и в других сторонних репозиториях. Эти образы обычно называют родительским образом. Это фундамент, на котором строятся все остальные слои, и базовые строительные блоки для наших контейнерных сред.\nНаряду с набором отдельных файлов слоев, образ Docker также включает дополнительный файл, известный как манифест. Это, по сути, описание образа в формате JSON, содержащее такую информацию, как теги образа, цифровая подпись и подробные сведения о том, как настроить контейнер для различных типов хост-платформ.\nКак создать образ docker Есть два способа создания образа docker. Мы можем сделать это на лету, используя процесс, который мы начали вчера, мы выбираем наш базовый образ, раскручиваем контейнер, устанавливаем все программное обеспечение и депенансы, которые мы хотим иметь на нашем контейнере.\nЗатем мы можем использовать команду docker commit container name, после чего у нас будет локальная копия этого образа в разделе docker images и на вкладке docker desktop images.\nСупер просто, я бы не рекомендовал этот метод, если вы не хотите понять процесс, будет очень сложно управлять жизненным циклом таким образом и много ручной настройки/переконфигурации. Но это самый быстрый и простой способ создания образа docker. Отлично подходит для тестирования, устранения неполадок, проверки зависимостей и т.д.\nМы собираемся создать наш образ с помощью dockerfile. Это дает нам чистый, компактный и повторяемый способ создания образов. Намного проще управлять жизненным циклом и легко интегрировать в процессы непрерывной интеграции и непрерывной доставки. Но, как вы уже поняли, это немного сложнее, чем первый упомянутый процесс.\nИспользование метода dockerfile гораздо больше соответствует реальным развертываниям контейнеров корпоративного уровня.\nСоздание dockerfile - это трехэтапный процесс, в ходе которого вы создаете dockerfile и добавляете команды, необходимые для сборки образа.\nВ следующей таблице приведены некоторые из утверждений dockerfile, которые мы будем использовать или которые вы, скорее всего, будете использовать.\nКоманда Задача FROM Чтобы указать родительский образ WORKDIR Чтобы задать рабочий каталог для всех последующих команд в Dockerfile. RUN Для установки любых приложений и пакетов, необходимых для контейнера. COPY Для копирования файлов или каталогов из определенного места. ADD Как COPY, но также может работать с удаленными URL и распаковывать сжатые файлы. ENTRYPOINT Команда, которая всегда будет выполняться при запуске контейнера. Если она не указана, по умолчанию используется /bin/sh -c. Аргументы, передаваемые точке входа. Если ENTRYPOINT не задан (по умолчанию /bin/sh -c), .md будут командами, которые выполняет контейнер. EXPOSE Для определения порта, через который будет осуществляться доступ к вашему контейнерному приложению. LABEL Чтобы добавить метаданные к образу. Теперь у нас есть подробная информация о том, как создать наш первый dockerfile, мы можем создать рабочий каталог и создать наш dockerfile. Я создал рабочий каталог в этом репозитории, где вы можете увидеть файлы и папки, которые мне предстоит пройти. Containers\nВ этом каталоге я собираюсь создать файл .dockerignore, аналогичный .gitignore, который мы использовали в предыдущем разделе. В этом файле будут перечислены все файлы, которые могут быть созданы в процессе сборки Docker и которые вы хотите исключить из окончательной сборки.\nПомните, что все, что связано с контейнерами, - это компактность, максимальная скорость и отсутствие лишнего объема.\nСоздадим простой Dockerfile с приведенной ниже схемой, которую также можно найти в папке по ссылке выше.\n# Use the official Ubuntu 18.04 as base FROM ubuntu:18.04 # Install nginx and curl RUN apt-get update \u0026\u0026 apt-get upgrade -y RUN apt-get install -y nginx curl RUN rm -rf /var/lib/apt/lists/* Перейдите в этот каталог в терминале, а затем выполните команду docker build -t 90daysofdevops:0.1 . мы используем -t, а затем задаем имя и тег изображения.\nТеперь, когда мы создали наш образ, мы можем запустить его с помощью Docker Desktop или командной строки docker. Я использовал Docker Desktop Я запустил контейнер, и вы можете видеть, что у нас есть curl, доступный нам в cli контейнера.\nВ Docker Desktop также есть возможность использовать пользовательский интерфейс для выполнения некоторых других задач с этим новым образом.\nМы можем проинспектировать наш образ, при этом очень хорошо виден dockerfile и строки кода, которые мы хотели запустить в нашем контейнере.\nУ нас есть опция pull, теперь она не работает, потому что это изображение нигде не размещено, поэтому мы получим ошибку. Однако у нас есть Push to hub, который позволит нам отправить наш образ на DockerHub.\nЕсли вы используете ту же docker build, которую мы запустили ранее, то это тоже не сработает, вам понадобится команда сборки docker build -t {{username}}/{{imagename}}:{{version}}.\nЕсли мы посмотрим на наш репозиторий DockerHub, то увидим, что мы только что выложили новый образ. Теперь в Docker Desktop мы сможем использовать эту вкладку pull.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image ","description":"","title":"45. Что из себя представляет оьбраз Docker","uri":"/ru/tracks/90daysofdevops/day45/"},{"content":"Docker Compose Возможность запуска одного контейнера может быть отличной, если у вас есть самодостаточный образ, в котором есть все, что вам нужно для одного случая использования, но все становится интересным, когда вы ищете возможность создания нескольких приложений между различными образами контейнеров. Например, если у меня есть фронт-энд сайта, но есть потребность в базе данных бэкенда, я могу поместить все в один контейнер, но лучше и эффективнее было бы иметь собственный контейнер для базы данных.\nИменно здесь на помощь приходит Docker compose - инструмент, позволяющий запускать более сложные приложения в нескольких контейнерах. Преимущество заключается в том, что для запуска приложения можно использовать один файл и команду. Пример, который я собираюсь рассмотреть в этой заметке, взят из [Docker QuickStart sample apps (Quickstart: Compose and WordPress)] (https://docs.docker.com/samples/wordpress/).\nВ этом первом примере мы собираемся:\nИспользовать Docker compose для создания WordPress и отдельного экземпляра MySQL. Использовать YAML файл, который будет называться docker-compose.yml. Соберите проект Настроить WordPress через браузер Выключение и очистка Установка Docker Compose Как уже упоминалось, Docker Compose - это инструмент, если вы работаете на macOS или Windows, то compose включен в вашу установку Docker Desktop. Однако вы можете захотеть запустить свои контейнеры на сервере Windows или Linux, и в этом случае вы можете установить их, используя эти инструкции Install Docker Compose.\nЧтобы убедиться, что docker-compose установлен в нашей системе, мы можем открыть терминал и просто ввести приведенную выше команду.\nDocker-Compose.yml (YAML) Следующее, о чем нужно поговорить, это docker-compose.yml, который вы можете найти в папке container репозитория. Но что более важно, нам нужно немного обсудить YAML в целом.\nYAML можно было бы посвятить отдельную сессию, поскольку вы можете встретить его в самых разных местах. Но по большей части\n“YAML - это удобный для человека язык сериализации данных для всех языков программирования”.\nОн обычно используется для файлов конфигурации и в некоторых приложениях, где данные хранятся или передаются. Вы, несомненно, сталкивались с XML-файлами, которые обычно предлагают тот самый файл конфигурации. YAML предоставляет минимальный синтаксис, но нацелен на те же случаи использования.\nYAML Ain’t Markup Language (YAML) - это язык сериализации, популярность которого неуклонно растет в течение последних нескольких лет. Возможности сериализации объектов делают его реальной заменой таким языкам, как JSON.\nАббревиатура YAML была сокращением от Yet Another Markup Language. Но сопровождающие переименовали его в YAML Ain’t Markup Language, чтобы сделать больший акцент на его функциях, ориентированных на данные.\nВ любом случае, вернемся к файлу docker-compose.yml. Это файл конфигурации того, что мы хотим сделать, когда речь идет о развертывании нескольких контейнеров на нашей единой системе.\nПрямо из приведенного выше руководства вы можете увидеть, что содержимое файла выглядит следующим образом:\nversion: \"3.9\" services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - wordpress_data:/var/www/html ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress volumes: db_data: {} wordpress_data: {} Мы объявляем версию, а затем большая часть этого файла docker-compose.yml состоит из наших служб, у нас есть служба db и служба wordpress. Вы можете видеть, что для каждого из них определено изображение, с которым связан тег версии. В отличие от наших первых прохождений, сейчас мы также вводим состояние в нашу конфигурацию, но теперь мы собираемся создать тома, чтобы мы могли хранить там наши базы данных.\nЗатем у нас есть некоторые переменные окружения, такие как пароли и имена пользователей. Очевидно, что эти файлы могут стать очень сложными, но конфигурационный файл YAML упрощает то, как они выглядят в целом.\nСборка проекта Далее мы можем вернуться в терминал и использовать некоторые команды с помощью нашего инструмента docker-compose. Перейдите в каталог, где находится ваш файл docker-compose.yml.\nВ терминале мы можем просто выполнить команду docker-compose up -d, которая запустит процесс извлечения образов и создания вашего многоконтейнерного приложения.\nСимвол -d в этой команде означает отделенный режим, что означает, что команда Run выполняется или будет выполняться в фоновом режиме.\nЕсли теперь мы выполним команду docker ps, вы увидите, что у нас запущено 2 контейнера, один из которых - wordpress, а другой - mySQL.\nДалее мы можем проверить, что у нас запущен WordPress, открыв браузер и перейдя по адресу http://localhost:8000, вы должны увидеть страницу установки wordpress.\nМы можем выполнить настройку WordPress, а затем начать создавать наш сайт по своему усмотрению в консоли ниже.\nЕсли мы откроем новую вкладку и перейдем по тому же адресу, что и раньше http://localhost:8000, то увидим простую тему по умолчанию с названием нашего сайта “90DaysOfDevOps”, а затем образец поста.\nПрежде чем мы сделаем какие-либо изменения, откройте Docker Desktop и перейдите на вкладку volumes, здесь вы увидите два тома, связанных с нашими контейнерами, один для wordpress и один для db.\nМоя текущая тема для wordpress - “Twenty Twenty-Two”, и я хочу изменить ее на “Twenty Twenty” Вернувшись в панель управления, мы можем внести эти изменения.\nЯ также собираюсь добавить новый пост на свой сайт, и здесь ниже вы видите последнюю версию нашего нового сайта.\nОчищать или нет Если мы сейчас используем команду docker-compose down, это приведет к остановке наших контейнеров. Но наши тома останутся на месте.\nМы можем просто подтвердить в Docker Desktop, что наши тома все еще там.\nЕсли мы захотим вернуть все обратно, мы можем выполнить команду docker up -d из той же директории, и наше приложение снова будет запущено.\nЗатем мы переходим в браузере по тому же адресу http://localhost:8000 и замечаем, что наш новый пост и смена темы все еще на месте.\nЕсли мы хотим избавиться от контейнеров и этих томов, то выполнение команды docker-compose down --volumes также уничтожит тома.\nТеперь, когда мы снова используем docker-compose up -d, мы начнем все сначала, однако образы все еще будут локальными в нашей системе, поэтому вам не нужно будет повторно брать их из репозитория DockerHub.\nЯ знаю, что когда я начал погружаться в docker-compose и его возможности, я был в замешательстве относительно того, где он находится рядом с инструментами оркестровки контейнеров, такими как Kubernetes, ну, все, что мы сделали здесь в этой короткой демонстрации, сосредоточено на одном хосте, у нас есть wordpress и db, запущенные на локальной настольной машине. У нас нет нескольких виртуальных машин или нескольких физических машин, у нас также нет возможности легко увеличивать и уменьшать требования нашего приложения.\nВ следующем разделе мы рассмотрим Kubernetes, но сначала у нас есть еще несколько дней, посвященных контейнерам в целом.\nЭто также отличный ресурс для примеров приложений docker compose с множеством интеграций. Awesome-Compose.\nВ вышеупомянутом репозитории есть отличный пример, который развернет Elasticsearch, Logstash и Kibana (ELK) на одном узле.\nЯ загрузил файлы в папку Containers Когда у вас есть эта папка локально, перейдите туда и вы можете просто использовать docker-compose up -d.\nЗатем мы можем проверить наличие запущенных контейнеров с помощью docker ps.\nТеперь мы можем открыть браузер для каждого из контейнеров:\nЧтобы удалить все, мы можем использовать команду docker-compose down.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute ","description":"","title":"46. Docker Compose","uri":"/ru/tracks/90daysofdevops/day46/"},{"content":"Docker Networking \u0026 Security Во время этой сессии по контейнерам мы уже кое-что сделали, но не рассмотрели, как все работает за кулисами с точки зрения сетевых технологий, а также не затронули безопасность, поэтому мы планируем эту сессию.\nОсновы сетевого взаимодействия Docker Откройте терминал и введите команду docker network - это основная команда для настройки и управления сетями контейнеров.\nНиже показано, как мы можем использовать эту команду и все доступные подкоманды. Мы можем создавать новые сети, составлять список существующих, проверять и удалять сети.\nДавайте посмотрим на существующие сети, которые у нас есть с момента установки, поэтому из коробки Docker networking выглядит как использование команды docker network list.\nКаждая сеть получает уникальный ID и NAME. Каждая сеть также связана с одним драйвером. Обратите внимание, что сеть “bridge” и сеть “host” имеют те же имена, что и их соответствующие драйверы.\nДалее мы можем более детально рассмотреть наши сети с помощью команды docker network inspect.\nЗапустив команду docker network inspect bridge, я могу получить все детали конфигурации конкретного имени сети. Сюда входят имя, ID, драйверы, подключенные контейнеры и, как вы можете видеть, многое другое.\nDocker: Bridge Networking Как вы видели выше, стандартная установка Docker Desktop дает нам предварительно созданную сеть под названием bridge Если вы обратитесь к команде docker network list, то увидите, что сеть под названием bridge связана с драйвером bridge. То, что у них одинаковое имя, не означает, что это одно и то же. Связаны, но не одно и то же.\nВывод выше также показывает, что сеть bridge имеет локальную привязку. Это означает, что сеть существует только на этом хосте Docker. Это справедливо для всех сетей, использующих драйвер моста - драйвер моста обеспечивает работу сети на одном хосте.\nВсе сети, созданные с помощью драйвера моста, основаны на мосте Linux (он же виртуальный коммутатор).\nПодключение контейнера По умолчанию новым контейнерам назначается сеть bridge, то есть, если вы не укажете сеть, все контейнеры будут подключены к сети bridge.\nДавайте создадим новый контейнер командой docker run -dt ubuntu sleep infinity.\nКоманда sleep выше просто будет поддерживать работу контейнера в фоновом режиме, чтобы мы могли возиться с ним.\nЕсли мы затем проверим нашу сеть моста с помощью docker network inspect bridge, вы увидите, что у нас есть контейнер, соответствующий тому, что мы только что развернули, потому что мы не указали сеть.\nМы также можем погрузиться в контейнер, используя docker exec -it 3a99af449ca2 bash, вам придется использовать docker ps, чтобы получить идентификатор контейнера.\nОтсюда наш образ не имеет ничего для пинга, поэтому нам нужно выполнить следующую команду.apt-get update \u0026\u0026 apt-get install -y iputils-ping затем пингуем внешний адрес интерфеса. ping -c5 www.90daysofdevops.com\nЧтобы устранить эту проблему, мы можем запустить docker stop 3a99af449ca2 и снова использовать docker ps для поиска ID вашего контейнера, но это приведет к удалению нашего контейнера.\nНастройте NAT для внешнего подключения На этом шаге мы запустим новый контейнер NGINX и назначим порт 8080 на хосте Docker на порт 80 внутри контейнера. Это означает, что трафик, поступающий на хост Docker по порту 8080, будет передаваться на порт 80 внутри контейнера.\nЗапустите новый контейнер на основе официального образа NGINX, выполнив команду docker run --name web1 -d -p 8080:80 nginx.\nПросмотрите состояние контейнера и сопоставление портов, выполнив команду docker ps.\nВерхняя строка показывает новый контейнер web1, запущенный NGINX. Обратите внимание на команду, которую запускает контейнер, а также на сопоставление портов - 0.0.0.0:8080-\u003e80/tcp сопоставляет порт 8080 на всех интерфейсах хоста с портом 80 внутри контейнера web1. Это сопоставление портов делает веб-сервис контейнера доступным из внешних источников (через IP-адрес хоста Docker на порту 8080).\nТеперь нам нужен IP-адрес нашего реального хоста, мы можем сделать это, зайдя в терминал WSL и используя команду ip addr.\nЗатем мы можем взять этот IP, открыть браузер и перейти по адресу http://172.25.218.154:8080/ Ваш IP может быть другим. Это подтверждает, что NGINX доступен.\nЯ взял эти инструкции с этого сайта с далекого 2017 DockerCon, но они актуальны и сегодня. Однако остальная часть руководства посвящена Docker Swarm, и я не собираюсь рассматривать его здесь. Docker Networking - DockerCon 2017\nОбеспечение безопасности контейнеров Контейнеры обеспечивают безопасную среду для рабочих нагрузок по сравнению с полной конфигурацией сервера. Они позволяют разбить ваши приложения на более мелкие, слабо связанные компоненты, изолированные друг от друга, что помогает уменьшить поверхность атаки в целом.\nНо они не застрахованы от хакеров, которые хотят использовать системы в своих целях. Нам по-прежнему необходимо понимать подводные камни безопасности этой технологии и придерживаться лучших практик.\nОткажитесь от прав root Все контейнеры, которые мы развернули, использовали права root для процессов внутри контейнеров. Это означает, что они имеют полный административный доступ к вашим контейнерам и хост-средам. Теперь для целей прохождения мы знали, что эти системы не будут работать долго. Но вы видели, как легко их запустить.\nМы можем добавить несколько шагов к нашему процессу, чтобы дать возможность не root-пользователям быть предпочтительной лучшей практикой. При создании нашего dockerfile мы можем создать учетные записи пользователей. Вы можете найти этот пример также в папке containers в репозитории.\n# Используем официальную версию Ubuntu 18.04 в качестве базовой FROM ubuntu:18.04 RUN apt-get update \u0026\u0026 apt-get upgrade -y RUN groupadd -g 1000 basicuser \u0026\u0026 useradd -r -u 1000 -g basicuser basicuser пользователь basicuser Мы также можем использовать docker run --user 1009 ubuntu Команда Docker run переопределяет любого пользователя, указанного в вашем Dockerfile. Поэтому в следующем примере ваш контейнер всегда будет запускаться с наименьшими привилегиями при условии, что идентификатор пользователя 1009 также имеет самый низкий уровень прав.\nОднако этот метод не устраняет основной недостаток безопасности самого образа. Поэтому лучше указать в Dockerfile пользователя, не являющегося root, чтобы ваши контейнеры всегда запускались безопасно.\nЧастный репозитории Еще одна область, которую мы активно используем, - это публичные реестры в DockerHub, а частный реестр образов контейнеров, созданный вашей организацией, означает, что вы можете размещать их там, где пожелаете, или же для этого существуют управляемые сервисы, но в целом это дает вам полный контроль над образами, доступными для вас и вашей команды.\nDockerHub отлично подходит для создания базового уровня, но он предоставляет только базовый сервис, где вам придется во многом доверять издателю образа.\nLean \u0026 Clean Мы уже упоминали об этом, хотя это и не связано с безопасностью. Но размер вашего контейнера также может влиять на безопасность с точки зрения поверхности атаки, если у вас есть ресурсы, которые вы не используете в своем приложении, то они не нужны в вашем контейнере.\nЭто также является моей основной проблемой при использовании последних образов, потому что это может принести много лишнего в ваши образы. DockerHub показывает сжатый размер для каждого образа в хранилище.\ndocker image - отличная команда для просмотра размера ваших образов.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute ","description":"","title":"47. Сетевое взаимодействие Docker и безопасность","uri":"/ru/tracks/90daysofdevops/day47/"},{"content":"Альтернативы Docker В самом начале этого раздела я говорил, что мы будем использовать Docker, просто потому, что ресурсов очень много, а сообщество очень большое, но также именно с него начался толчок к популярности контейнеров. Я бы посоветовал вам пойти и посмотреть немного истории о Docker и о том, как он появился, я нашел это очень полезным.\nНо, как я уже упоминал, существуют и другие альтернативы Docker. Если мы подумаем о том, что такое Docker и что мы уже рассмотрели. Это платформа для разработки, тестирования, развертывания и управления приложениями.\nЯ хочу выделить несколько альтернатив Docker, которые вы можете увидеть или увидите в будущем.\nPodman Что такое Podman? Podman - это контейнерный движок без демонов для разработки, управления и запуска OCI-контейнеров в вашей системе Linux. Контейнеры могут быть запущены от имени root или в режиме rootless.\nЯ буду рассматривать это с точки зрения Windows, но знаю, что, как и в случае с Docker, здесь не требуется виртуализация, поскольку он будет использовать базовую ОС, чего нельзя сделать в мире Windows.\nPodman может быть запущен под WSL2, хотя и не так гладко, как в случае с Docker Desktop. Существует также удаленный клиент Windows, с помощью которого можно подключиться к виртуальной машине Linux, где будут запущены ваши контейнеры.\nМой Ubuntu на WSL2 - это версия 20.04. Следуя следующим шагам, вы сможете установить Podman на свой экземпляр WSL.\necho \"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_20.04/ /\" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list Добавим ключ GPG\ncurl -L \"https://download.opensuse.org/repositories/devel:/kubic:\\ /libcontainers:/stable/xUbuntu_20.04/Release.key\" | sudo apt-key add - Запустите обновление системы с помощью команды sudo apt-get update \u0026\u0026 sudo apt-get upgrade. Наконец, мы можем установить podman с помощью команды sudo apt install podman.\nТеперь мы можем использовать многие из тех же команд, которые мы использовали для docker, однако обратите внимание, что у нас нет красивого пользовательского интерфейса рабочего стола docker. Вы можете видеть ниже, я использовал podman images и у меня ничего не появилось после установки, затем я использовал podman pull ubuntu для извлечения образа контейнера ubuntu.\nЗатем мы можем запустить наш образ Ubuntu с помощью podman run -dit ubuntu и podman ps, чтобы увидеть наш запущенный образ.\nЧтобы попасть в этот контейнер, мы можем выполнить команду podman attach dazzling_darwin, имя вашего контейнера, скорее всего, будет другим.\nЕсли вы переходите от docker к podman, то обычно также необходимо изменить ваш конфигурационный файл на alias docker=podman, тогда любая команда, запущенная с помощью docker, будет использовать podman.\nLXC LXC - это механизм контейнеризации, который позволяет пользователям снова создавать несколько изолированных контейнерных сред Linux. В отличие от Docker LXC действует как гипервизор для создания нескольких Linux-машин с отдельными системными файлами, сетевыми функциями. Появился еще до Docker, а затем сделал короткое возвращение из-за недостатков Docker.\nLXC такой же легкий, как и docker, и легко развертывается.\nContainerd Автономная среда выполнения контейнеров. Containerd обеспечивает простоту и надежность, а также, конечно, переносимость. Ранее Containerd был инструментом, работающим как часть контейнерных сервисов Docker, пока Docker не решил вывести свои компоненты в самостоятельные.\nПроект в Cloud Native Computing Foundation, что ставит его в один ряд с такими популярными контейнерными инструментами, как Kubernetes, Prometheus и CoreDNS.\nДругие инструменты Docker Мы могли бы также упомянуть инструменты и опции вокруг Rancher, VirtualBox, но мы можем рассказать о них более подробно в другой раз.\nGradle\nСканирование сборки позволяет командам совместно отлаживать свои скрипты и отслеживать историю всех сборок. Опции выполнения дают командам возможность непрерывной сборки так, чтобы при каждом вводе изменений задание выполнялось автоматически. Настраиваемый макет репозитория дает командам возможность рассматривать любую структуру файловых каталогов как хранилище артефактов. Packer\nВозможность параллельного создания нескольких машинных образов для экономии времени разработчиков и повышения эффективности. Команды могут легко отлаживать сборки с помощью отладчика Packer, который проверяет сбои и позволяет командам опробовать решения перед перезапуском сборки. Поддержка многих платформ с помощью плагинов, что позволяет командам настраивать свои сборки. Logspout\nИнструмент для ведения логов - настраиваемость инструмента позволяет командам отправлять одни и те же логи в несколько мест назначения. Команды могут легко управлять своими файлами, поскольку инструмент требует только доступа к сокету Docker. Полностью с открытым исходным кодом и прост в развертывании. Logstash\nНастройте свой конвейер с помощью подключаемой структуры Logstash. Легко анализируйте и преобразуйте данные для анализа и повышения ценности бизнеса. Разнообразие выходов Logstash позволяет направлять данные туда, куда вам нужно. Portainer\nИспользуйте готовые шаблоны или создавайте свои собственные для развертывания приложений. Создавайте команды и назначайте роли и разрешения для членов команды. Узнайте, что запущено в каждой среде, используя приборную панель инструмента. Ресурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute Podman | Daemonless Docker | Getting Started with Podman LXC - Guide to building a LXC Lab ","description":"","title":"48. Альтернативы Docker","uri":"/ru/tracks/90daysofdevops/day48/"},{"content":"Общая картина: Kubernetes В предыдущем разделе мы рассмотрели контейнеры. Контейнеры не справляются с задачей масштабирования и оркестровки. Лучшее, что мы можем сделать, это использовать docker-compose для объединения нескольких контейнеров. Когда речь заходит о Kubernetes, который является оркестратором контейнеров, это дает нам возможность масштабирования в автоматическом режиме или в зависимости от нагрузки ваших приложений и сервисов.\nКак платформа Kubernetes предлагает возможность оркестровки контейнеров в соответствии с вашими требованиями и желаемым состоянием. Мы рассмотрим Kubernetes в этом разделе, поскольку она быстро развивается как следующая волна инфраструктуры. С точки зрения DevOps, Kubernetes - это лишь одна из платформ, базовое понимание которой вам понадобится. Вам также потребуется понимание “голого металла”, виртуализации и, скорее всего, облачных сервисов. Kubernetes - это просто еще один вариант запуска наших приложений.\nЧто такое оркестровка контейнеров? Я упомянул Kubernetes и упомянул оркестровку контейнеров, Kubernetes - это технология, а оркестровка контейнеров - это концепция или процесс, стоящий за технологией. Kubernetes - не единственная платформа для оркестровки контейнеров, у нас также есть Docker Swarm, HashiCorp Nomad и другие. Но Kubernetes набирает силу, поэтому я хочу рассказать о Kubernetes, но хочу сказать, что она не единственная.\nЧто такое Kubernetes? Первое, что вам следует прочитать, если вы новичок в Kubernetes, - это официальная документация. Мой опыт глубокого погружения в Kubernetes чуть больше года назад показал, что это будет крутая кривая обучения. Будучи выходцем из сферы виртуализации и хранения данных, я думал о том, насколько пугающим это кажется.\nНо на самом деле сообщество, бесплатные учебные ресурсы и документация просто потрясающие. Kubernetes.io\nKubernetes - это портативная, расширяемая платформа с открытым исходным кодом для управления контейнерными рабочими нагрузками и сервисами, которая облегчает как декларативную конфигурацию, так и автоматизацию. Она имеет большую, быстро развивающуюся экосистему. Услуги, поддержка и инструменты Kubernetes широко доступны.\nВажные моменты, которые следует отметить из вышеприведенного цитаты: Kubernetes является открытым исходным кодом с богатой историей, восходящей к Google, который передал проект в фонд Cloud Native computing Foundation (CNCF), и в настоящее время он развивается сообществом открытого исходного кода, а также крупными корпоративными поставщиками, которые внесли свой вклад, чтобы сделать Kubernetes тем, чем он является сегодня.\nЯ уже упоминал, что контейнеры - это здорово, и в предыдущем разделе мы говорили о том, как контейнеры и образы контейнеров изменили и ускорили внедрение облачных нативных систем. Но сами по себе контейнеры не дадут вам готового к производству опыта, который необходим вашему приложению. Kubernetes дает нам следующее:\nОбнаружение сервисов и балансировка нагрузки Kubernetes может открыть контейнер, используя DNS-имя или собственный IP-адрес. Если трафик на контейнер высок, Kubernetes может сбалансировать нагрузку и распределить сетевой трафик так, чтобы развертывание было стабильным.\nОркестровка хранилищ Kubernetes позволяет автоматически монтировать системы хранения по вашему выбору, например, локальные хранилища, общедоступные облачные провайдеры и многое другое.\nАвтоматизированное развертывание и откат Вы можете описать желаемое состояние для развернутых контейнеров с помощью Kubernetes, и он может изменить фактическое состояние на желаемое с контролируемой скоростью. Например, вы можете автоматизировать Kubernetes для создания новых контейнеров для развертывания, удаления существующих контейнеров и переноса всех их ресурсов в новый контейнер.\nАвтоматическая упаковка контейнеров Вы предоставляете Kubernetes кластер узлов, которые он может использовать для выполнения контейнерных задач. Вы сообщаете Kubernetes, сколько процессора и памяти (RAM) требуется каждому контейнеру. Kubernetes может разместить контейнеры на ваших узлах, чтобы наилучшим образом использовать ваши ресурсы.\nСамовосстановление Kubernetes перезапускает вышедшие из строя контейнеры, заменяет контейнеры, уничтожает контейнеры, которые не отвечают на заданную пользователем проверку работоспособности, и не рекламирует их клиентам, пока они не будут готовы к обслуживанию.\nУправление секретами и конфигурациями Kubernetes позволяет хранить и управлять конфиденциальной информацией, такой как пароли, токены OAuth и ключи SSH. Вы можете развертывать и обновлять секреты и конфигурацию приложений, не перестраивая образы контейнеров и не раскрывая секреты в конфигурации стека.\nKubernetes предоставляет вам основу для отказоустойчивого запуска распределенных систем.\nContainer Orchestration управляет развертыванием, размещением и жизненным циклом контейнеров.\nНа нее также возложено множество других обязанностей:\nУправление кластером объединяет узлы в одну цель.\nУправление расписанием распределяет контейнеры по узлам с помощью планировщика.\nОбнаружение сервисов знает, где находятся контейнеры, и распределяет между ними запросы клиентов.\nРепликация обеспечивает наличие необходимого количества узлов и контейнеров для требуемой рабочей нагрузки.\nУправление здоровьем обнаруживает и заменяет нездоровые контейнеры и узлы.\nОсновные компоненты Kubernetes Kubernetes - это контейнерный оркестратор для обеспечения, управления и масштабирования приложений. Вы можете использовать его для управления жизненным циклом контейнерных приложений в кластере узлов, который представляет собой набор рабочих машин, таких как виртуальные машины или физические машины.\nДля работы вашим приложениям может понадобиться множество других ресурсов, таких как тома, сети и секреты, которые помогут вам подключаться к базам данных, общаться с бэкграундом и защищать ключи. С помощью Kubernetes вы можете добавить эти ресурсы в свое приложение. Инфраструктурные ресурсы, необходимые вашим приложениям, управляются декларативно.\nКлючевой парадигмой Kubernetes является ее декларативная модель. Вы предоставляете нужное вам состояние, а Kubernetes его реализует. Если вам нужно пять экземпляров, вы не запускаете пять отдельных экземпляров самостоятельно. Вместо этого вы сообщаете Kubernetes, что вам нужно пять экземпляров, и Kubernetes автоматически согласовывает состояние. Если с одним из ваших экземпляров что-то пойдет не так и он выйдет из строя, Kubernetes все равно будет знать нужное вам состояние и создаст экземпляры на доступном узле.\nУзел План управления\nКаждый кластер Kubernetes требует наличия узла Control Plane, компоненты которого принимают глобальные решения относительно кластера (например, планирование), а также обнаруживают и реагируют на события кластера.\nРабочий узел Рабочая машина, на которой выполняются рабочие нагрузки Kubernetes. Это может быть физическая (bare metal) машина или виртуальная машина (VM). На каждом узле может размещаться один или несколько стручков. Узлы Kubernetes управляются плоскостью управления\nСуществуют и другие типы узлов, но я не буду их здесь рассматривать.\nkubelet\nАгент, который запускается на каждом узле кластера. Он следит за тем, чтобы контейнеры запускались в Pod.\nКуплет принимает набор PodSpecs, которые предоставляются через различные механизмы, и гарантирует, что контейнеры, описанные в этих PodSpecs, запущены и здоровы. Куплет не управляет контейнерами, которые не были созданы Kubernetes.\nkube-proxy\nkube-proxy - это сетевой прокси, который работает на каждом узле вашего кластера, реализуя часть концепции Kubernetes Service.\nkube-proxy поддерживает сетевые правила на узлах. Эти сетевые правила позволяют сетевое взаимодействие с вашими Pods из сетевых сессий внутри или вне вашего кластера.\nkube-proxy использует уровень фильтрации пакетов операционной системы, если он есть и доступен. В противном случае kube-proxy сам перенаправляет трафик.\nВремя выполнения контейнера\nВремя выполнения контейнеров - это программное обеспечение, которое отвечает за запуск контейнеров.\nKubernetes поддерживает несколько сред выполнения контейнеров: Docker, containerd, CRI-O и любую реализацию Kubernetes CRI (Container Runtime Interface).\n​\nКластер Кластер - это группа узлов, где узлом может быть физическая машина или виртуальные машины. На каждом из узлов будет установлена среда выполнения контейнеров (Docker), а также будет запущен сервис kubelet, который является агентом, принимающим команды от главного контроллера (подробнее об этом позже), и прокси, который используется для прокси-соединений с Pods от другого компонента (сервисы, которые мы рассмотрим позже).\nНа нашей плоскости управления, которую можно сделать высокодоступной, будет несколько уникальных ролей по сравнению с рабочими узлами, самой важной из них будет сервер kube API, именно с ним будет происходить любое взаимодействие для получения информации или отправки информации в наш кластер Kubernetes.\nKube API-Server\nСервер API Kubernetes проверяет и настраивает данные для объектов api, которые включают стручки, сервисы, контроллеры репликации и другие. API-сервер обслуживает REST-операции и предоставляет фронтенд к общему состоянию кластера, через который взаимодействуют все остальные компоненты.\nПланировщик\nПланировщик Kubernetes - это процесс в плоскости управления, который назначает Pods узлам. Планировщик определяет, какие узлы являются допустимыми для размещения каждого Pod в очереди планирования в соответствии с ограничениями и доступными ресурсами. Затем планировщик ранжирует каждый допустимый узел и привязывает Pod к подходящему узлу.\nМенеджер контроллера\nМенеджер контроллеров Kubernetes - это демон, который встраивает основные контуры управления, поставляемые с Kubernetes. В приложениях робототехники и автоматизации контур управления - это не завершающийся цикл, который регулирует состояние системы. В Kubernetes контроллер - это контур управления, который следит за общим состоянием кластера через apiserver и вносит изменения, пытаясь переместить текущее состояние в желаемое.\netcd.\nПоследовательное и высокодоступное хранилище значений ключей, используемое в качестве резервного хранилища Kubernetes для всех данных кластера.\nkubectl\nДля управления этим с точки зрения CLI у нас есть kubectl, kubectl взаимодействует с сервером API.\nИнструмент командной строки Kubernetes, kubectl, позволяет выполнять команды для кластеров Kubernetes. Вы можете использовать kubectl для развертывания приложений, проверки и управления ресурсами кластера, а также для просмотра журналов.\nPods Pod - это группа контейнеров, которые образуют логическое приложение. Например, если у вас есть веб-приложение, в котором запущен контейнер NodeJS, а также контейнер MySQL, то оба этих контейнера будут находиться в одном Pod. Pod также может иметь общие тома данных, а также разделять одно и то же сетевое пространство имен. Помните, что Pods являются эфемерными и могут быть подняты и опущены главным контроллером. Kubernetes использует простое, но эффективное средство идентификации Pods с помощью концепции Labels (имя - значения).\nПодсистемы управляют томами, секретами и конфигурацией контейнеров.\nПодсистемы являются эфемерными. Они предназначены для автоматического перезапуска после смерти.\nPods реплицируются при горизонтальном масштабировании приложения с помощью ReplicationSet. Каждый Pod будет выполнять один и тот же код контейнера.\nPods живут на рабочих узлах (Worker Nodes).\nРазвертывания Вы можете просто решить запустить Pods, но когда они умирают, они умирают.\nРазвертывание позволит вашему стручку работать непрерывно.\nРазвертывания позволяют вам обновлять работающее приложение без простоя.\nРазвертывания также определяют стратегию перезапуска стручков, когда они умирают\nReplicaSets Развертывание также может создать набор реплик.\nReplicaSet гарантирует, что ваше приложение имеет необходимое количество Pods.\nReplicaSets будет создавать и масштабировать Pods на основе развертывания\nРазвертывание, наборы реплик, подсистемы не являются исключительными, но могут быть\nStatefulSets Требуется ли вашему приложению хранить информацию о его состоянии?\nБаза данных нуждается в состоянии\nПодсистемы StatefulSet не являются взаимозаменяемыми.\nКаждый Pod имеет уникальный постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nКаждый Pod имеет уникальный, постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nDaemonSets DaemonSets предназначены для непрерывного процесса.\nОни запускают по одному Pod на узел.\nКаждый новый узел, добавленный в кластер, получает запущенный pod.\nПолезны для фоновых задач, таких как мониторинг и сбор логов.\nКаждый Pod имеет уникальный, постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nСервисы единая конечная точка для доступа к Pods\nунифицированный способ маршрутизации трафика к кластеру и, в конечном итоге, к списку Pods.\nИспользуя сервис, Pods можно поднимать и опускать, не затрагивая ничего.\nЭто лишь краткий обзор и заметки о фундаментальных строительных блоках Kubernetes, мы можем использовать эти знания и добавить некоторые другие области, такие как Storage и Ingress, чтобы улучшить наши приложения, но у нас также есть большой выбор, где будет работать наш кластер Kubernetes. Следующая сессия будет посвящена этим вариантам, где я могу запустить кластер Kubernetes, а также изучению некоторых особенностей хранения данных.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"49. Основы Kubernetes","uri":"/ru/tracks/90daysofdevops/day49/"},{"content":"Сегодня мы сосредоточимся на отдельных шагах от начала до конца и на непрерывном цикле приложения в мире DevOps.\nПлан Все начинается с процесса планирования, когда команда разработчиков собирается вместе и выясняет, какие типы функций и исправлений ошибок они собираются внедрить в следующем спринте. Это возможность для вас как инженера DevOps принять участие в этом и узнать, какие вещи будут происходить на вашем пути, с которыми вам нужно участвовать, а также повлиять на их решения или их путь и как бы помочь им работать с инфраструктура, которую вы построили, или направьте их к чему-то, что будет работать лучше для них, если они не на этом пути, и поэтому одна ключевая вещь, на которую здесь следует указать, это то, что разработчики или команда разработчиков программного обеспечения являются вашим клиентом как DevOps инженер, так что это ваша возможность поработать с вашим клиентом до того, как он пойдет по плохому пути.\nCode Теперь, как только эта сессия планирования будет завершена, разработчики начинают писать код, в разработку котоого вы можете быть вовлечены, предоставляя информацю об инфрастуктуре, микросеврисах, если таковые имеются, и т.д. Когда разработчики заканчивают писать код/часть кода, они объединяют (merge) все измененияю и выгруат в репозиторий.\nBuild Здесь мы начнем первый из наших процессов автоматизации, потому что мы “возьмем” их код и построим (скомпилируем, “сбилдим”) его в зависимости от того, какой язык они используют, это может быть транспиляция или компиляция, а может создать образ докера из этого кода в любом случае, мы собираемся пройти этот процесс, используя наш cicd pipeline (“пайплайн”)\nTesting После того, как мы его скомпилировали проект, мы проведем на нем несколько тестов. Команда разработчиков обычно пишет тесты. У вас может быть некоторый вклад в то, какие тесты пишутся, но нам нужно запустить эти тесты. Тестирование — это способ провериь и свести к минимуму появление проблем в рабочей среде. И хотя это не гарантирует полной проверки, но мы хотим максимально точно быть уверенными, что одна из новых функций не создает новых ошибок, а две другие не ломают то, что раньше работало.\nRelease Как только эти тесты пройдены, мы собираемся выполнить процесс выпуска, и, опять же, в зависимости от того, над каким типом приложения вы работаете, это может быть поэтапным. Код может просто находиться в репозитории GitHub или репозитории git или где-то еще, а также это может быть процесс зарузки вашего скомпилированного кода или созданного образа докера и помещения его в реестр или репозиторий, где он находится.\nDeploy Следующее, что мы собираемся сделать - это “деплой” (публикация/развертывание). Развертывание похоже на конечный результат процесса. Потому что после развертывания приложения, когда мы запускаем код в производство, наш бизнес действительно осознает ценность всех временных усилий и тяжелой работы, которые вы и команда разработчиков программного обеспечения вложили в этот продукт до этого момента.\nOperate После того, как код выгружен скомпилирован, мы собираемся эксплуатировать его, и эксплуатация может включать в себя что-то вроде того, что вы начинаете получать звонки от своих клиентов, которые все раздражены тем, что сайт работает медленно или их приложение работает медленно, поэтому вам нужно выяснить, почему это так. А а затем, возможно, создать автоматическое масштабирование, которое связано с увеличением количества серверов, доступных в пиковые периоды, и уменьшением количества серверов в непиковые периоды.\nMonitor Все вышеперечисленные части ведут к последнему шагу - мониторингу, что важно особенно в отношении проблем, возникающих в рельном времени, автоматического масштабирования, устранения неполадок. Во время мониторига мы сохраняем данные об использовании памяти, использовании ЦП на диске, времени отклика, скорость отклика и т.д. Большая часть этого также является журналами. Журналы дают разработчикам возможность видеть, что происходит, без доступа к производственным системам.\nRince \u0026 Repeat Once that’s in place you go right back to the beginning to the planning stage and go through the whole thing again\nContinuous Многие инструменты помогают нам достичь вышеуказанного непрерывного процесса, весь этот код и конечная цель полной автоматизации облачной инфраструктуры или любой среды часто описывается как непрерывная интеграция/непрерывная доставка/непрерывное развертывание или сокращенно «CI/CD». Позже, в течение 90 дней, мы посвятим целую неделю CI/CD с некоторыми примерами и пошаговыми руководствами, чтобы понять основы.\nContinuous Delivery Continuous Delivery = Plan \u003e Code \u003e Build \u003e Test\nContinuous Integration Непрерывная интеграция - это результат описанных выше этапов непрерывной “доставки” и результат этапа выпуска. Это относится как к неудаче, так и к успеху, но это возвращается в непрерывную доставку или перемещается в непрерывное развертывание.\nContinuous Integration = Plan \u003e Code \u003e Build \u003e Test \u003e Release\nContinuous Deployment Если у вас есть успешный релиз, перейдите к непрерывному развертыванию, которое включает следующие этапы.\nВыпуск CI выполнен успешно = непрерывное развертывание = развертывание \u003e эксплуатация \u003e мониторинг\nВы можете рассматривать эти три понятия выше как простой набор фаз жизненного цикла DevOps.\nЭтот последний фрагмент был для меня чем-то вроде подведения итогов третьего дня, но думаю, что на самом деле это проясняет для меня ситуацию.\nИсточники DevOps for Developers – Software or DevOps Engineer? Techworld with Nana -DevOps Roadmap 2022 - How to become a DevOps Engineer? What is DevOps? How to become a DevOps Engineer in 2021 - DevOps Roadmap До встречи в День 6\n","description":"Plan \u003e Code \u003e Build \u003e Testing \u003e Release \u003e Deploy \u003e Operate \u003e Monitor","title":"5. Plan \u003e Code \u003e Build \u003e Testing \u003e Release \u003e Deploy \u003e Operate \u003e Monitor","uri":"/ru/tracks/90daysofdevops/day05/"},{"content":"Выбор платформы Kubernetes Я хотел бы использовать эту сессию для разбора некоторых платформ или, может быть, дистрибутивов - более подходящий термин для этого, одна вещь, которая была проблемой в мире Kubernetes - это устранение сложности.\nKubernetes the hard way рассказывает о том, как построить из ничего полноценный функциональный кластер Kubernetes, очевидно, что это крайность, но все больше и больше людей, по крайней мере, тех, с кем я общаюсь, хотят устранить эту сложность и запустить управляемый кластер Kubernetes. Проблема в том, что это стоит больше денег, но преимущества могут быть следующими: если вы используете управляемый сервис, действительно ли вам нужно знать архитектуру узлов и то, что происходит с точки зрения плоскости управления узлов, когда обычно у вас нет к этому доступа.\nЗатем у нас есть локальные дистрибутивы для разработки, которые позволяют нам использовать наши собственные системы и запускать локальную версию Kubernetes, чтобы разработчики могли иметь полную рабочую среду для запуска своих приложений на платформе, для которой они предназначены.\nОбщая основа всех этих концепций заключается в том, что все они являются разновидностью Kubernetes, что означает, что мы должны иметь возможность свободно мигрировать и перемещать наши рабочие нагрузки туда, куда нам нужно, в соответствии с нашими требованиями.\nВо многом наш выбор будет зависеть от того, какие инвестиции были сделаны. Я уже упоминал об опыте разработчиков, но некоторые из локальных сред Kubernetes, в которых работают наши ноутбуки, отлично подходят для ознакомления с технологией без затрат денег.\nBare-Metal Clusters Вариантом для многих может быть запуск ОС Linux прямо на нескольких физических серверах для создания кластера, это также может быть Windows, но я не слышал о темпах внедрения Windows, контейнеров и Kubernetes. Очевидно, что если вы - компания, и вы приняли решение о покупке физических серверов, то это может быть способом создания кластера Kubernetes, но управление и администрирование здесь означает, что вам придется создавать и управлять всем с нуля.\nВиртуализация Независимо от тестовых и учебных сред или готовых корпоративных кластеров Kubernetes виртуализация является отличным способом продвижения, обычно это возможность запускать виртуальные машины в качестве узлов и затем объединять их в кластер. Вы получаете базовую архитектуру, эффективность и скорость виртуализации, а также возможность эффективно использовать существующие затраты. Например, VMware предлагает отличное решение для виртуальных машин и Kubernetes в различных вариантах.\nМой первый кластер Kubernetes был создан на основе виртуализации с использованием Microsoft Hyper-V на старом сервере, который был способен запускать несколько виртуальных машин в качестве узлов.\nВарианты локального рабочего стола Существует несколько вариантов запуска локального кластера Kubernetes на вашем настольном компьютере или ноутбуке. Как уже говорилось ранее, это дает разработчикам возможность увидеть, как будет выглядеть их приложение, без необходимости создавать несколько дорогостоящих или сложных кластеров. Лично я часто использую этот кластер, в частности, я использую minikube. Он обладает отличной функциональностью и дополнениями, которые меняют способ создания и запуска приложений.\nKubernetes Managed Services Я уже упоминал о виртуализации, и это может быть достигнуто с помощью гипервизоров локально, но мы знаем из предыдущих разделов, что мы также можем использовать виртуальные машины в публичном облаке в качестве узлов. Я говорю об управляемых сервисах Kubernetes - это предложения, которые мы видим у крупных гипермасштабирующих компаний, а также у MSP, которые убирают уровни управления и контроля от конечного пользователя; это может быть удаление плоскости управления от конечного пользователя, что происходит с Amazon EKS, Microsoft AKS и Google Kubernetes Engine. (GKE)\nНепреодолимый выбор Выбор - это здорово, но есть момент, когда он становится чрезмерным, и это не глубокий обзор всех вариантов в каждой из перечисленных выше категорий. В дополнение к вышеперечисленному у нас есть OpenShift от Red Hat, и этот вариант действительно может быть использован во всех вышеперечисленных вариантах у всех основных облачных провайдеров и, вероятно, сегодня обеспечивает наилучшее общее удобство для администраторов независимо от того, где развернуты кластеры.\nИтак, с чего вы начнете свое обучение, как я уже сказал, я начал с пути виртуализации, но это было потому, что у меня был доступ к физическому серверу, который я мог использовать для этой цели, я ценю и фактически с тех пор у меня больше нет такой возможности.\nСейчас я бы посоветовал использовать Minikube в качестве первого варианта или Kind (Kubernetes в Docker), но Minikube дает нам некоторые дополнительные преимущества, которые почти абстрагируют сложность, так как мы можем просто использовать дополнительные модули и быстро создавать вещи, а затем разрушать их, когда мы закончим, мы можем запускать несколько кластеров, мы можем запускать их почти везде, кросс-платформенные и аппаратно-агностические.\nЯ проделал небольшой путь в изучении Kubernetes, поэтому я собираюсь оставить выбор платформы и конкретику здесь, чтобы перечислить варианты, которые я пробовал, чтобы дать мне лучшее понимание платформы Kubernetes и того, где она может работать. Что я мог бы сделать с нижеприведенными записями в блоге, так это еще раз взглянуть на них, обновить их и перенести сюда, вместо того, чтобы они были ссылками на записи в блоге.\nРесурсы Kubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone ","description":"","title":"50. Выбор платформы Kubernetes для проекта","uri":"/ru/tracks/90daysofdevops/day50/"},{"content":"Развертывание первого кластера Kubernetes В этом посте мы собираемся запустить кластер Kubernetes на нашей локальной машине с помощью minikube, это даст нам базовый кластер Kubernetes для остальной части раздела Kubernetes, хотя позже мы рассмотрим развертывание кластера Kubernetes и в VirtualBox. Причина, по которой мы выбрали этот метод, а не развертывание управляемого кластера Kubernetes в публичном облаке, заключается в том, что это будет стоить денег даже при бесплатном уровне, однако я поделился некоторыми блогами, если вы захотите развернуть такую среду в предыдущем разделе День 50.\nЧто такое Minikube? Minikube быстро создает локальный кластер Kubernetes на macOS, Linux и Windows.\nДля начала, независимо от ОС вашей рабочей станции, вы можете запустить minikube. Сначала перейдите на страницу проекта. Первая опция, которая у вас есть, это выбор метода установки. Я не использовал этот метод, но вы можете выбрать мой способ (о моем способе речь впереди).\nНиже упоминается, что вам необходимо иметь “Менеджер контейнеров или виртуальных машин, такой как: Docker, Hyperkit, Hyper-V, KVM, Parallels, Podman, VirtualBox или VMware” - это то, где будет работать MiniKube, и это простой вариант, и если не указано в репозитории, я использую Docker. Вы можете установить Docker на свою систему, используя следующую ссылку.\nПонятное руководство по установке minikube\nМой способ установки minikube Я уже некоторое время использую arkade, чтобы получить все эти инструменты Kubernetes и CLI, вы можете посмотреть шаги установки на этом github репозитории для начала работы с Arkade. Я также упоминал об этом в других записях блога, когда мне нужно было что-то установить. Простота установки: достаточно нажать arkade get и посмотреть, доступен ли ваш инструмент или cli, очень удобна. В разделе Linux мы говорили о менеджере пакетов и процессе получения нашего программного обеспечения, вы можете думать об Arkade как о рынке для всех ваших приложений и clis для Kubernetes. Очень удобный инструмент, который нужно иметь в своих системах, написанный на Golang и кроссплатформенный.\nВ длинном списке доступных приложений в arkade minikube является одним из них, поэтому с помощью простой команды arkade get minikube мы загружаем бинарник и можем приступать.\nНам также понадобится kubectl как часть нашего инструментария, поэтому вы можете получить его через arkade или, как я полагаю, в документации по minikube он представлен как часть команд curl, упомянутых выше. Подробнее о kubectl мы расскажем позже в этом посте.\nПолучение и запуск кластера Kubernetes В этом конкретном разделе я хочу рассказать о доступных нам вариантах запуска кластера Kubernetes на вашей локальной машине. Мы можем просто выполнить следующую команду, и она запустит кластер для использования.\nminikube используется в командной строке, и, проще говоря, после того как вы все установили, вы можете выполнить команду minikube start для развертывания вашего первого кластера Kubernetes. Ниже вы увидите, что драйвер Docker по умолчанию является местом, где мы будем запускать наш вложенный узел виртуализации. В начале статьи я упомянул о других доступных опциях, которые помогут вам расширить вид локального кластера Kubernetes.\nОдин кластер Minikube будет состоять из одного контейнера docker, в котором будут находиться узел плоскости управления и рабочий узел в одном экземпляре. Обычно вы разделяете эти узлы по отдельности. Об этом мы расскажем в следующем разделе, где мы рассмотрим домашние лабораторные среды Kubernetes, но немного ближе к производственной архитектуре.\nЯ уже несколько раз говорил об этом, мне очень нравится minikube из-за доступных дополнений, возможность развернуть кластер с помощью простой команды, включающей все необходимые дополнения с самого начала, действительно помогает мне каждый раз развертывать одну и ту же необходимую установку.\nНиже представлен список этих аддонов, я обычно использую аддоны csi-hostpath-driver и volumesnapshots, но вы можете увидеть длинный список ниже. Конечно, эти аддоны могут быть развернуты с помощью Helm, о чем мы расскажем позже в разделе Kubernetes, но это значительно упрощает работу.\nЯ также определяю в нашем проекте некоторые дополнительные конфигурации, apiserver установлен на 6433 вместо случайного порта API, я определяю время выполнения контейнера также на containerd, однако docker используется по умолчанию, и CRI-O также доступен. Я также устанавливаю определенную версию Kubernetes.\nТеперь мы готовы развернуть наш первый кластер Kubernetes с помощью minikube. Я уже упоминал, что вам также понадобится kubectl для взаимодействия с вашим кластером. Вы можете установить kubectl с помощью arkade, выполнив команду arkade get kubectl.\nили вы можете загрузить кросс-платформенную версию со следующих сайтов\nLinux macOS Windows После установки kubectl мы можем взаимодействовать с нашим кластером с помощью простой команды kubectl get nodes.\nЧто такое kubectl? Теперь у нас есть наш кластер minikube | Kubernetes, и я попросил вас установить Minikube, где я объяснил, что он делает, но я не объяснил, что такое kubectl и что он делает.\nkubectl - это программа, которая используется или позволяет вам взаимодействовать с кластерами Kubernetes, мы используем ее здесь для взаимодействия с нашим кластером minikube, но мы также используем kubectl для взаимодействия с нашими корпоративными кластерами в публичном облаке.\nМы используем kubectl для развертывания приложений, проверки и управления ресурсами кластера. Гораздо лучший Обзор kubectl можно найти здесь, в официальной документации Kubernetes.\nkubectl взаимодействует с сервером API, расположенным на узле Control Plane, о котором мы вкратце рассказывали в одном из предыдущих постов.\nkubectl шпаргалка Наряду с официальной документацией я также обнаружил, что при поиске команд kubectl у меня постоянно открыта эта страница. Unofficial Kubernetes\nListing Resources kubectl get nodes List all nodes in cluster kubectl get namespaces List all namespaces in cluster kubectl get pods List all pods in default namespace cluster kubectl get pods -n name List all pods in “name” namespace kubectl get pods -n name List all pods in “name” namespace Creating Resources kubectl create namespace name Create a namespace called “name” kubectl create -f [filename] Create a resource from a JSON or YAML file: Editing Resources kubectl edit svc/servicename To edit a service More detail on Resources kubectl describe nodes display the state of any number of resources in detail, Delete Resources kubectl delete pod Remove resources, this can be from stdin or file Вы захотите узнать краткие названия некоторых команд kubectl, например, -n - это краткое название для namespace, что облегчает ввод команды, а также, если вы пишете скрипты, вы можете получить гораздо более аккуратный код.\nShort name Full name csr certificatesigningrequests cs componentstatuses cm configmaps ds daemonsets deploy deployments ep endpoints ev events hpa horizontalpodautoscalers ing ingresses limits limitranges ns namespaces no nodes pvc persistentvolumeclaims pv persistentvolumes po pods pdb poddisruptionbudgets psp podsecuritypolicies rs replicasets rc replicationcontrollers quota resourcequotas sa serviceaccounts svc services В заключение хочу добавить, что я создал еще один проект на основе minikube, чтобы помочь мне быстро развернуть демонстрационные среды для демонстрации сервисов данных и защиты этих рабочих нагрузок с помощью Kasten K10, Project Pace можно найти там и буду рад вашим отзывам или взаимодействию, он также показывает или включает некоторые автоматизированные способы развертывания кластеров minikube и создания различных приложений сервисов данных.\nДалее мы перейдем к развертыванию нескольких узлов в виртуальные машины с помощью VirtualBox, но здесь мы будем действовать проще, как мы делали в разделе Linux, где мы использовали vagrant для быстрого запуска машин и развертывания нашего программного обеспечения, как мы хотим.\nЯ добавил этот список к вчерашнему посту, который представляет собой блоги с описанием развертывания различных кластеров Kubernetes.\nKubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone Ресурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"51. Установка minikube","uri":"/ru/tracks/90daysofdevops/day51/"},{"content":"Настройка многоузлового кластера Kubernetes Я хотел назвать эту статью “Настройка многоузлового кластера Kubernetes с помощью Vagrant”, но подумал, что это будет слишком длинно!\nНа вчерашней сессии мы использовали классный проект для развертывания нашего первого кластера Kubernetes и немного поработали с самым важным инструментом CLI, с которым вы столкнетесь при использовании Kubernetes (kubectl).\nЗдесь мы будем использовать VirtualBox в качестве основы, но, как мы уже говорили о Vagrant в разделе Linux, мы можем использовать любой гипервизор или инструмент виртуализации. Это был День 14, когда мы прошли и развернули машину Ubuntu для раздела Linux.\nКраткая информация о Vagrant Vagrant - это утилита CLI, которая управляет жизненным циклом ваших виртуальных машин. Мы можем использовать vagrant для запуска и разворачивания виртуальных машин на различных платформах, включая vSphere, Hyper-v, Virtual Box и Docker. У него есть и другие поставщики, но мы будем придерживаться этого, мы используем Virtual Box, так что все готово.\nЯ собираюсь использовать базовый уровень этого блога и репозитория, чтобы пройтись по конфигурации. Однако я бы посоветовал, если вы впервые развертываете кластер Kubernetes, посмотреть, как это делается вручную, и тогда вы хотя бы будете знать, как это выглядит. Хотя я должен сказать, что эти операции и усилия дня 0 становятся все более эффективными с каждым выпуском Kubernetes. Я сравниваю это с временами VMware и ESX, когда для развертывания 3 серверов ESX требовался по меньшей мере день, а теперь мы можем сделать это за час. Мы движемся в этом направлении, когда речь идет о Kubernetes\".\nЛабораторная среда Kubernetes Я загрузил в папку Kubernetes vagrantfile, который мы будем использовать для создания нашей среды. Возьмите его и перейдите в этот каталог в терминале. Я снова использую Windows, поэтому я буду использовать PowerShell для выполнения команд рабочей станции с vagrant. Если у вас нет vagrant, вы можете использовать arkade, о котором мы говорили вчера при установке minikube и других инструментов. Простая команда arkade get vagrant должна заставить вас загрузить и установить последнюю версию vagrant.\nКогда вы окажетесь в своей директории, вы можете просто запустить vagrant up, и если все настроено правильно, вы должны увидеть в терминале следующее.\nВ терминале вы увидите ряд шагов, но тем временем давайте посмотрим, что мы на самом деле создаем.\nИз приведенного выше изображения видно, что мы собираемся создать 3 виртуальные машины, у нас будет узел плоскости управления и два рабочих узла. Если вы вернетесь к День 49, вы увидите более подробное описание этих областей, которые мы видим на изображении.\nТакже на изображении мы указываем, что наш доступ к kubectl будет происходить извне кластера и попадать в kube apiserver, в то время как на самом деле в рамках инициализации vagrant мы развертываем kubectl на каждом из этих узлов, чтобы мы могли получить доступ к кластеру изнутри каждого из наших узлов.\nПроцесс создания этой лаборатории может занять от 5 до 30 минут в зависимости от вашей установки.\nЯ собираюсь в ближайшее время рассказать о скриптах, но если вы посмотрите в файл vagrant, то заметите, что мы вызываем 3 скрипта как часть развертывания, и именно здесь создается кластер. Мы видели, как легко использовать vagrant для развертывания наших виртуальных машин и установки ОС с помощью боксов vagrant, но возможность запуска скрипта оболочки как часть процесса развертывания - это то, что становится довольно интересным в автоматизации этих лабораторных сборок.\nПосле завершения мы можем подключиться по ssh к одному из наших узлов vagrant ssh master из терминала должен получить доступ, имя пользователя и пароль по умолчанию - vagrant/vagrant.\nВы также можете использовать vagrant ssh node01 и vagrant ssh node02 для получения доступа к рабочим узлам, если хотите.\nТеперь мы находимся на одном из вышеуказанных узлов нашего нового кластера, мы можем выдать команду kubectl get nodes, чтобы показать наш 3-узловой кластер и его статус.\nНа данный момент у нас есть запущенный 3-узловой кластер, с 1 узлом плоскости управления и 2 рабочими узлами.\nVagrantfile и Shell Script walkthrough Если мы посмотрим на наш vagrantfile, вы увидите, что мы определяем количество рабочих узлов, сетевые IP-адреса для мостовой сети в VirtualBox, а также некоторые именования. Еще вы заметите, что мы также вызываем некоторые скрипты, которые мы хотим запустить на определенных хостах.\nNUM_WORKER_NODES=2 IP_NW=\"10.0.0.\" IP_START=10 Vagrant.configure(\"2\") do |config| config.vm.provision \"shell\", inline: \u003c\u003c-SHELL apt-get update -y echo \"$IP_NW$((IP_START)) master-node\" \u003e\u003e /etc/hosts echo \"$IP_NW$((IP_START+1)) worker-node01\" \u003e\u003e /etc/hosts echo \"$IP_NW$((IP_START+2)) worker-node02\" \u003e\u003e /etc/hosts SHELL config.vm.box = \"bento/ubuntu-21.10\" config.vm.box_check_update = true config.vm.define \"master\" do |master| master.vm.hostname = \"master-node\" master.vm.network \"private_network\", ip: IP_NW + \"#{IP_START}\" master.vm.provider \"virtualbox\" do |vb| vb.memory = 4048 vb.cpus = 2 vb.customize [\"modifyvm\", :id, \"--natdnshostresolver1\", \"on\"] end master.vm.provision \"shell\", path: \"scripts/common.sh\" master.vm.provision \"shell\", path: \"scripts/master.sh\" end (1..NUM_WORKER_NODES).each do |i| config.vm.define \"node0#{i}\" do |node| node.vm.hostname = \"worker-node0#{i}\" node.vm.network \"private_network\", ip: IP_NW + \"#{IP_START + i}\" node.vm.provider \"virtualbox\" do |vb| vb.memory = 2048 vb.cpus = 1 vb.customize [\"modifyvm\", :id, \"--natdnshostresolver1\", \"on\"] end node.vm.provision \"shell\", path: \"scripts/common.sh\" node.vm.provision \"shell\", path: \"scripts/node.sh\" end end end Давайте разберем эти выполняемые скрипты. У нас есть три скрипта, перечисленные в вышеуказанном VAGRANTFILE для запуска на определенных узлах.\nmaster.vm.provision \"shell\", path: \"scripts/common.sh\"\nПриведенный выше скрипт будет направлен на подготовку узлов, он будет запущен на всех трех наших узлах и удалит все существующие компоненты Docker и переустановит Docker и ContainerD, а также kubeadm, kubelet и kubectl. Этот скрипт также обновит существующие пакеты программного обеспечения в системе.\nmaster.vm.provision \"shell\", path: \"scripts/master.sh\"\nСкрипт master.sh будет выполняться только на узле плоскости управления, этот скрипт создаст кластер Kubernetes с помощью команд kubeadm. Он также подготовит контекст конфигурации для доступа к этому кластеру, о чем мы расскажем далее.\nnode.vm.provision \"shell\", path: \"scripts/node.sh\"\nЭто просто возьмет конфиг, созданный мастером, и присоединит наши узлы к кластеру Kubernetes, этот процесс присоединения снова использует kubeadm и другой скрипт, который можно найти в папке config.\nДоступ к кластеру Kubernetes Теперь у нас есть два развернутых кластера: кластер minikube, который мы развернули в предыдущем разделе, и новый 3-узловой кластер, который мы только что развернули на VirtualBox.\nТакже в этом конфигурационном файле, к которому у вас будет доступ на машине, с которой вы запускали vagrant, описано, как мы можем получить доступ к нашему кластеру с нашей рабочей станции.\nПрежде чем мы покажем это, позвольте мне коснуться контекста.\nКонтекст важен, необходима возможность доступа к кластеру Kubernetes с рабочего стола или ноутбука. Существует множество различных вариантов, и люди используют различные операционные системы в качестве повседневных драйверов.\nПо умолчанию клиент Kubernetes CLI (kubectl) использует папку C:\\Users\\username.kube\\config для хранения информации о кластере Kubernetes, такой как конечная точка и учетные данные. Если вы развернули кластер, вы сможете увидеть этот файл в этом месте. Но если вы до сих пор использовали главный узел для выполнения всех команд kubectl через SSH или другими способами, то эта статья, надеюсь, поможет вам освоить возможность подключения к рабочей станции.\nЗатем нам нужно получить файл kubeconfig из кластера или мы также можем получить его из нашего файла конфигурации после развертывания, получить содержимое этого файла либо через SCP, либо просто открыть консольный сеанс на главном узле и скопировать на локальную машину windows.\nЗатем мы хотим взять копию этого файла конфигурации и переместить в место $HOME/.kube/config.\nТеперь с локальной рабочей станции вы сможете запустить kubectl cluster-info и kubectl get nodes, чтобы убедиться, что у вас есть доступ к вашему кластеру.\nЭто не только обеспечивает подключение и управление с вашей windows-машины, но и позволяет нам выполнить проброс портов для доступа к определенным сервисам с нашей windows-машины.\nЕсли вам интересно, как управлять несколькими кластерами на рабочей станции, у меня есть более подробное описание здесь.\nЯ добавил этот список, в котором представлены блоги, посвященные различным развертываемым кластерам Kubernetes.\nKubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone Ресурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"52. Настройка многоузлового кластера Kubernetes","uri":"/ru/tracks/90daysofdevops/day52/"},{"content":"Обзор Rancher - практическое применение В этом разделе мы рассмотрим Rancher, до сих пор все, что мы делали, было в cli и с использованием kubectl, но у нас есть несколько действительно хороших пользовательских интерфейсов и инструментов управления несколькими кластерами, чтобы дать нашим операционным командам хорошую видимость управления кластером.\nRancher, согласно их сайту\nRancher - это полный программный стек для команд, внедряющих контейнеры. Он решает операционные проблемы и проблемы безопасности при управлении несколькими кластерами Kubernetes в любой инфраструктуре, обеспечивая команды DevOps интегрированными инструментами для запуска контейнерных рабочих нагрузок.\nRancher позволяет нам развертывать кластеры Kubernetes производственного уровня практически из любого места, а затем обеспечивает централизованную аутентификацию, контроль доступа и наблюдаемость. Я упоминал в предыдущем разделе, что существует почти непреодолимый выбор, когда речь идет о Kubernetes и о том, где вы должны или можете их запустить, но с Rancher действительно не имеет значения, где они находятся.\nРазвертывание Rancher Первое, что нам нужно сделать, это развернуть Rancher на нашей локальной рабочей станции, есть несколько способов и мест, которые вы можете выбрать для выполнения этого шага, я хочу использовать свою локальную рабочую станцию и запустить Rancher как контейнер docker. Выполнив приведенную ниже команду, мы получим образ контейнера и доступ к пользовательскому интерфейсу rancher.\nДоступны и другие методы развертывания rancher Rancher Quick-Start-Guide sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher.\nКак вы можете видеть на нашем рабочем столе Docker, у нас есть запущенный контейнер rancher.\nДоступ к пользовательскому интерфейсу Rancher Запустив вышеуказанный контейнер, мы должны иметь возможность перейти к нему через веб-страницу. По адресу https://localhost откроется страница входа в систему, как показано ниже.\nСледуйте инструкциям ниже, чтобы получить требуемый пароль. Поскольку я использую Windows, я решил использовать bash для Windows, так как для этого требуется команда grep.\nЗатем мы можем взять указанный выше пароль и войти в систему, на следующей странице мы можем задать новый пароль.\nПосле выполнения вышеуказанных действий мы войдем в систему и увидим наш начальный экран. В рамках развертывания Rancher мы также увидим локальный кластер K3s.\nКраткий экскурс по rancher Первое, на что мы посмотрим, это наш локально развернутый кластер K3S. Вы можете видеть ниже, что мы получаем хорошее представление о том, что происходит внутри нашего кластера. Это развертывание по умолчанию, и мы еще ничего не развертывали в этом кластере. Видно, что он состоит из 1 узла и имеет 5 развертываний. Также вы можете видеть, что есть некоторые статистические данные по стручкам, ядрам и памяти.\nВ меню слева есть вкладка Apps \u0026 Marketplace, которая позволяет нам выбрать приложения, которые мы хотели бы запустить на наших кластерах. Как уже упоминалось ранее, Rancher дает нам возможность запускать и управлять несколькими различными кластерами. С помощью рынка мы можем очень легко развернуть наши приложения.\nЕще одна вещь, о которой стоит упомянуть, это то, что если вам понадобится получить доступ к любому кластеру, управляемому Rancher, в правом верхнем углу есть возможность открыть оболочку kubectl для выбранного кластера.\nСоздание нового кластера На последних двух занятиях мы создали кластер minikube локально и использовали Vagrant с VirtualBox для создания 3-узлового кластера Kubernetes, с помощью Rancher мы также можем создавать кластеры. В папке Rancher Folder вы найдете дополнительные файлы vagrant, которые создадут те же 3 узла, но без шагов по созданию нашего кластера Kubernetes (мы хотим, чтобы Rancher сделал это за нас).\nТем не менее, мы хотим установить docker и обновить ОС, поэтому вы увидите скрипт common.sh, запускаемый на каждом из наших узлов. Это также установит Kubeadm, Kubectl и т.д. Но он не запустит команды Kubeadm для создания и объединения наших узлов в кластер.\nМы можем перейти в папку vagrant и просто запустить vagrant up, и это начнет процесс создания наших 3 виртуальных машин в virtualbox.\nТеперь, когда у нас есть наши узлы или ВМ на месте и готовы, мы можем использовать Rancher для создания нашего нового кластера Kubernetes. Первый экран для создания кластера дает вам несколько вариантов того, где находится ваш кластер, то есть используете ли вы службы Kubernetes, управляемые публичным облаком, vSphere или что-то еще.\nМы выберем “custom”, так как не используем ни одну из интегрированных платформ. На открывшейся странице вы определяете имя вашего кластера (ниже написано local, но вы не можете использовать local, наш кластер называется vagrant). Здесь вы можете определить версии Kubernetes, сетевых провайдеров и некоторые другие параметры конфигурации, чтобы запустить ваш кластер Kubernetes.\nНа следующей странице вы найдете регистрационный код, который необходимо запустить на каждом из узлов и включить соответствующие службы: etcd, controlplane и worker. Для нашего главного узла нам нужны etcd и controlplane, поэтому команду можно увидеть ниже.\nsudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.6.3 --server https://10. 0.0.1 --token mpq8cbjjwrj88z4xmf7blqxcfmwdsmq92bmwjpphdkklfckk5hfwc2 --ca-checksum a81944423cbfeeb92be0784edebba1af799735ebc30ba8cbe5cc5f996094f30b --etcd --controlplane Если сетевое взаимодействие настроено правильно, то вы должны довольно быстро увидеть следующее на приборной панели rancher, указывающее на то, что первый мастер-узел сейчас регистрируется и кластер создается.\nЗатем мы можем повторить процесс регистрации для каждого из рабочих узлов с помощью следующей команды, и через некоторое время вы получите свой кластер, способный использовать рынок для развертывания приложений.\nsudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.6.3 --server https://10. 0.0.1 --token mpq8cbjjwrj88z4xmf7blqxcfmwdsmq92bmwjpphdkklfckk5hfwc2 --ca-checksum a81944423cbfeeb92be0784edebba1af799735ebc30ba8cbe5cc5f996094f30b --worker За последние 3 занятия мы использовали несколько различных способов запуска кластера Kubernetes, в оставшиеся дни мы рассмотрим прикладную сторону платформы, вероятно, самую важную. Мы рассмотрим сервисы и возможность предоставления и использования наших сервисов в Kubernetes.\nМне сказали, что требования к загрузке узлов rancher требуют, чтобы эти виртуальные машины имели 4 ГБ оперативной памяти, иначе они будут работать с ошибками, с тех пор я обновил информацию, так как наши рабочие узлы имели 2 ГБ.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"53. Обзор Rancher","uri":"/ru/tracks/90daysofdevops/day53/"},{"content":"Развертывание приложений Kubernetes Теперь мы, наконец, переходим к реальному развертыванию некоторых приложений в наших кластерах, некоторые говорят, что именно для этого существует Kubernetes - для доставки приложений.\nИдея заключается в том, что мы можем взять наши образы контейнеров и развернуть их в виде стручков в нашем кластере Kubernetes, чтобы воспользоваться преимуществами Kubernetes как контейнерного оркестратора.\nРазвертывание приложений в Kubernetes Существует несколько способов развертывания наших приложений в кластере Kubernetes, мы рассмотрим два наиболее распространенных подхода - YAML-файлы и диаграммы Helm.\nДля развертывания приложений мы будем использовать кластер minikube. Мы рассмотрим некоторые из ранее упомянутых компонентов или строительных блоков Kubernetes.\nНа протяжении всего этого раздела и раздела о контейнерах мы говорили об образах и преимуществах Kubernetes, а также о том, как мы можем легко справляться с масштабированием на этой платформе.\nВ этом первом шаге мы просто создадим приложение без статических данных в нашем кластере minikube. Мы будем использовать дефакто стандартное приложение без статики в нашей первой демонстрации nginx. Мы настроим Deployment, который предоставит нам наши стручки, а затем мы также создадим службу, которая позволит нам перейти к простому веб-серверу, размещенному в стручке nginx. Все это будет содержаться в пространстве имен.\nСоздание YAML В первом демо мы хотим определить все, что мы делаем с YAML, мы могли бы создать целый раздел о YAML, но я собираюсь пропустить это и оставить некоторые ресурсы в конце, которые расскажут о YAML более подробно.\nМы можем создать следующее как один YAML-файл или разбить его на части для каждого аспекта нашего приложения, то есть это могут быть отдельные файлы для пространства имен, развертывания и создания сервисов, но в этом файле ниже мы разделили их с помощью --- в одном файле. Вы можете найти этот файл, расположенный здесь\napiVersion: v1 kind: Namespace metadata: name: nginx \"labels\": { \"name\": \"nginx\" } --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: nginx-service namespace: nginx spec: selector: app: nginx-deployment ports: - protocol: TCP port: 80 targetPort: 80 Проверка нашего кластера Перед тем как развернуть что-либо, мы должны убедиться, что у нас нет существующих пространств имен с названием nginx. Мы можем сделать это, выполнив команду kubectl get namespace, и как вы можете видеть ниже, у нас нет пространства имен с названием nginx.\nВремя развернуть наше приложение Теперь мы готовы развернуть наше приложение на нашем кластере minikube, этот же процесс будет работать на любом другом кластере Kubernetes.\nНам нужно перейти к расположению нашего yaml файла, а затем мы можем выполнить команду kubectl create -f nginx-stateless-demo.yaml, после чего вы увидите, что было создано 3 объекта, у нас есть пространство имен, развертывание и сервис.\nДавайте снова выполним команду, чтобы увидеть доступные пространства имен в нашем кластере kubectl get namespace, и теперь вы можете увидеть, что у нас есть наше новое пространство имен.\nЕсли мы затем проверим наше пространство имен на наличие стручков с помощью kubectl get pods -n nginx, вы увидите, что у нас есть 1 стручок в готовом и запущенном состоянии.\nМы также можем проверить, что наш сервис создан, выполнив команду kubectl get service -n nginx.\nНаконец, мы можем пойти и проверить наше развертывание, развертывание - это то, где и как мы сохраняем нашу желаемую конфигурацию.\nВыше приведено несколько команд, которые стоит знать, но вы также можете использовать kubectl get all -n nginx, чтобы увидеть все, что мы развернули с помощью одного YAML-файла.\nВы можете заметить, что у нас также есть replicaset, в нашем развертывании мы определяем, сколько копий нашего образа мы хотим развернуть. Изначально мы установили значение 1, но если мы хотим быстро масштабировать наше приложение, мы можем сделать это несколькими способами.\nМы можем отредактировать наш файл с помощью команды kubectl edit deployment nginx-deployment -n nginx, которая откроет текстовый редактор в вашем терминале и позволит вам изменить развертывание.\nПосле сохранения в текстовом редакторе в терминале, если не возникло проблем и было использовано правильное форматирование, вы должны увидеть дополнительное развертывание в вашем пространстве имен.\nМы также можем изменить количество реплик с помощью kubectl и команды kubectl scale deployment nginx-deployment --replicas=10 -n nginx.\nМы также можем использовать этот метод для уменьшения масштаба нашего приложения до 1 снова, если захотим, используя любой метод. Я использовал опцию edit, но вы также можете использовать команду scale выше.\nНадеюсь, здесь вы можете увидеть пример использования: не только все очень быстро запускается и выключается, но у нас есть возможность быстро увеличивать и уменьшать масштаб наших приложений. Если бы это был веб-сервер, мы могли бы увеличивать масштаб в периоды загруженности и уменьшать, когда нагрузка снижается.\nРаскрытие нашего приложения Но как нам получить доступ к нашему веб-серверу?\nЕсли вы посмотрите выше на наш сервис, вы увидите, что там нет внешнего IP, поэтому мы не можем просто открыть веб-браузер и ожидать, что он будет там волшебным образом. Для доступа у нас есть несколько вариантов.\nClusterIP - IP, который вы видите, является кластерным IP, он находится во внутренней сети кластера. Только объекты внутри кластера могут достичь этого IP.\nNodePort - Выставляет службу на один и тот же порт каждого из выбранных узлов в кластере с помощью NAT.\nLoadBalancer - Создает внешний балансировщик нагрузки в текущем облаке, мы используем minikube, но если вы создали свой собственный кластер Kubernetes, т.е. то, что мы сделали в VirtualBox, вам нужно будет развернуть LoadBalancer, такой как metallb, в вашем кластере, чтобы обеспечить эту функциональность.\nPort-Forward - У нас также есть возможность Port Forward, которая позволяет вам получить доступ и взаимодействовать с внутренними процессами кластера Kubernetes с вашего localhost. На самом деле эта опция используется только для тестирования и поиска неисправностей.\nТеперь у нас есть несколько вариантов на выбор, Minikube имеет некоторые ограничения или отличия от полноценного кластера Kubernetes.\nМы можем просто выполнить следующую команду, чтобы перенаправить порт для доступа, используя нашу локальную рабочую станцию.\nkubectl port-forward deployment/nginx-deployment -n nginx 8090:80.\nОбратите внимание, что при выполнении вышеуказанной команды терминал становится непригодным для использования, поскольку он действует как проброс порта на вашу локальную машину и порт.\nНаконец, в новом терминале запустите minikube --profile='mc-demo' service nginx-service --url -n nginx, чтобы создать туннель для нашего сервиса.\nОткройте браузер или программу управления и нажмите на ссылку в терминале.\nHelm Helm - это еще один способ, с помощью которого мы можем развернуть наши приложения. Известен как “менеджер пакетов для Kubernetes”. Вы можете узнать больше здесь.\nHelm - это менеджер пакетов для Kubernetes. Helm можно считать аналогом yum или apt для Kubernetes. Helm развертывает диаграммы, которые можно представить как упакованное приложение. Это чертеж предварительно сконфигурированных ресурсов приложения, которые можно развернуть в виде одной простой в использовании диаграммы. Затем вы можете развернуть другую версию диаграммы с другим набором конфигураций.\nУ компании есть сайт, на котором можно просмотреть все доступные диаграммы Helm и, конечно, создать свою собственную. Документация также понятна и лаконична и не так пугает, как когда я впервые услышал термин Helm среди всех других новых слов в этой области.\nЗапустить или установить Helm очень просто. Просто. Здесь вы можете найти двоичные файлы и ссылки на загрузку практически для всех дистрибутивов, включая устройства RaspberryPi arm64.\nИли вы можете использовать скрипт установщика, преимущество которого в том, что будет загружена и установлена последняя версия Helm.\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh Наконец, есть также возможность использовать менеджер пакетов для менеджера приложений, homebrew для mac, chocolatey для windows, apt с Ubuntu/Debian, snap и pkg также.\nПока что Helm кажется наиболее удобным способом загрузки и установки различных тестовых приложений в кластере.\nХорошим ресурсом для ссылки здесь будет ArtifactHUB, который является ресурсом для поиска, установки и публикации пакетов Kubernetes. Я также порекомендую KubeApps, который представляет собой пользовательский интерфейс для отображения диаграмм штурвала.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"54. Развертывание приложений Kubernetes","uri":"/ru/tracks/90daysofdevops/day54/"},{"content":"State и Ingress в Kubernetes В этом заключительном разделе, посвященном Kubernetes, мы рассмотрим State и ingress.\nВсе, о чем мы говорили до сих пор, касается stateless, stateless - это когда нашим приложениям не важно, какую сеть они используют, и им не нужно постоянное хранение данных. В то время как приложения с состоянием, например, базы данных, чтобы такое приложение функционировало правильно, вам нужно убедиться, что стручки могут обращаться друг к другу через уникальную идентификацию, которая не меняется (имена хостов, IP… и т.д.). Примерами stateful-приложений являются кластеры MySQL, Redis, Kafka, MongoDB и другие. В принципе, любое приложение, которое хранит данные.\nStateful Application StatefulSets представляют собой набор Pods с уникальными, постоянными идентификаторами и стабильными именами хостов, которые Kubernetes поддерживает независимо от того, где они запланированы. Информация о состоянии и другие устойчивые данные для любого данного StatefulSet Pod хранятся в постоянном дисковом хранилище, связанном с StatefulSet.\nРазвертывание против StatefulSet Репликация stateful-приложений является более сложной задачей. Репликация наших стручков в развертывании (Stateless Application) идентична и взаимозаменяема. Создаем капсулы в случайном порядке со случайными хэшами Один сервис, который балансирует нагрузку на любой стручок. Когда дело доходит до StatefulSets или Stateful Applications, вышеописанное становится сложнее.\nНевозможно одновременно создавать и удалять. Не может быть случайного обращения. реплики Pods не являются идентичными. То, что вы увидите в нашей демонстрации в ближайшее время, заключается в том, что каждая копия имеет свою собственную идентичность. В приложении без статического состояния вы увидите случайные имена. Например, app-7469bbb6d7-9mhxd, в то время как Stateful Application будет иметь имя mongo-0, а затем при масштабировании создаст новую капсулу под названием mongo-1.\nЭти стручки создаются на основе одной и той же спецификации, но они не взаимозаменяемы. Каждая капсула StatefulSet имеет постоянный идентификатор при любом повторном планировании. Это необходимо, потому что когда нам требуются нагрузки с учетом состояния, такие как база данных, где требуется запись и чтение в базу данных, мы не можем иметь две капсулы, пишущие в одно и то же время без осведомленности, так как это приведет к несогласованности данных. Нам нужно убедиться, что в любой момент времени только один из наших стручков записывает данные в базу данных, однако мы можем иметь несколько стручков, читающих эти данные.\nКаждый стручок в StatefulSet будет иметь доступ к своему собственному постоянному тому и копии базы данных для чтения, которая постоянно обновляется с главного сервера. Также интересно отметить, что каждый pod будет хранить свое состояние pod в этом постоянном томе, если mongo-0 умрет, то при инициализации нового pod он возьмет состояние pod, хранящееся в хранилище.\nTLDR; StatefulSets vs Deployments\nPredicatable pod name = mongo-0 Fixed individual DNS name Pod Identity - Retain State, Retain Role Replicating stateful apps is complex There are lots of things you must do: Configure cloning and data synchronisation. Make remote shared storage available. Management \u0026 backup Как сохранять данные в Kubernetes?\nМы упоминали выше, что когда у нас есть приложение с состоянием, нам нужно где-то хранить состояние, и именно здесь возникает необходимость в томе, поскольку из коробки Kubernetes не обеспечивает постоянство данных.\nНам нужен уровень хранения, который не зависит от жизненного цикла стручка. Это хранилище должно быть доступно со всех наших узлов Kubernetes. Хранилище также должно находиться вне кластера Kubernetes, чтобы иметь возможность выжить, даже если кластер Kubernetes потерпит крах.\nПостоянный том Ресурс кластера (например, процессор и оперативная память) для хранения данных. Создается с помощью файла YAML. Требуется реальное физическое хранилище (NAS) Внешняя интеграция в ваш кластер Kubernetes. В вашем хранилище могут быть доступны различные типы хранилищ. PV не имеют пространства имен Локальное хранилище доступно, но оно будет специфично для одного узла в кластере Персистентность базы данных должна использовать удаленное хранилище (NAS) Утверждение о постоянном томе Постоянный том, как описано выше, может существовать и быть доступным, но пока он не заявлен приложением, он не используется.\nСоздается с помощью файла YAML Утверждение постоянного тома используется в конфигурации стручка (атрибут volumes) PVC находятся в том же пространстве имен, что и pod Том монтируется в капсулу Стручки могут иметь несколько различных типов томов (ConfigMap, Secret, PVC). Другой способ представить PVs и PVCs заключается в следующем\nPVs создаются администратором Kubernetes Admin PVC создаются пользователем или разработчиком приложения.\nУ нас также есть два других типа томов, которые мы не будем подробно описывать, но о которых стоит упомянуть:\nConfigMaps | Secrets Конфигурационный файл для вашего стручка. Файл сертификата для вашей капсулы. StorageClass Создается с помощью файла YAML Предоставляет постоянные тома динамически, когда PVC заявляет об этом. Каждый бэкенд хранилища имеет свой собственный провизор Бэкенд хранилища определяется в YAML (через атрибут provisioner) Абстракции базового провайдера хранения Определяет параметры для этого хранилища Время просмотра Во вчерашней сессии мы рассмотрели создание приложения без статических данных, здесь мы хотим сделать то же самое, но использовать наш кластер minikube для развертывания рабочей нагрузки с статическими данными.\nНапомним команду minikube, которую мы используем, чтобы иметь возможность и аддоны для использования персистентности: minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p mc-demo --kubernetes-version=1.21.2.\nЭта команда использует драйвер csi-hostpath-driver, который дает нам наш класс хранилища, что я покажу позже.\nСборка приложения выглядит следующим образом:\nВы можете найти файл конфигурации YAML для этого приложения здесь pacman-stateful-demo.yaml\nКонфигурация класса хранилища Есть еще один шаг, который мы должны выполнить перед началом развертывания нашего приложения, а именно убедиться, что наш класс хранилища (csi-hostpath-sc) является классом по умолчанию. Сначала мы можем проверить это, выполнив команду kubectl get storageclass, но из коробки кластер minikube будет показывать стандартный класс хранения по умолчанию, поэтому мы должны изменить его с помощью следующих команд.\nПервая команда сделает наш класс хранилища csi-hostpath-sc классом по умолчанию.\nkubectl patch storageclass csi-hostpath-sc -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"true\"}}}'}''\nЭта команда удалит аннотацию по умолчанию из стандартного StorageClass.\nkubectl patch storageclass standard -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"false\"}}}'}''\nНачнем с того, что в нашем кластере нет пространства имен pacman. kubectl get namespace\nЗатем мы развернем наш YAML-файл. kubectl create -f pacman-stateful-demo.yaml Из этой команды видно, что мы создаем ряд объектов в нашем кластере Kubernetes.\nТеперь у нас есть наше только что созданное пространство имен.\nИз следующего изображения и команды kubectl get all -n pacman видно, что в нашем пространстве имен происходит несколько вещей. У нас есть pods, запускающий наш NodeJS web front end, у нас есть mongo, запускающий нашу backend базу данных. Есть сервисы для pacman и mongo для доступа к этим стручкам. У нас есть развертывание для pacman и statefulset для mongo.\nУ нас также есть наши постоянные тома и утверждения постоянных томов. Выполнив команду kubectl get pv, мы получим наши постоянные тома, не связанные с именами, а выполнив команду kubectl get pvc -n pacman, мы получим наши утверждения постоянных томов, связанные с именами. Играем в игру | Я имею в виду доступ к нашему критически важному приложению Поскольку мы используем Minikube, как уже упоминалось в приложении без статических данных, нам предстоит преодолеть несколько препятствий, когда дело доходит до доступа к нашему приложению. Однако если бы у нас был доступ к ingress или балансировщику нагрузки в нашем кластере, служба настроена на автоматическое получение IP-адреса от него для получения доступа извне. (Вы можете видеть это выше на изображении всех компонентов в пространстве имен pacman).\nВ данном демонстрационном примере мы будем использовать метод проброса портов для доступа к нашему приложению. Открыв новый терминал и выполнив следующую команду kubectl port-forward svc/pacman 9090:80 -n pacman, открыв браузер, мы получим доступ к нашему приложению. Если вы запускаете это в AWS или в определенных местах, то это также сообщит об облаке и зоне, а также о хосте, который равен вашему стручку в Kubernetes, опять же, вы можете оглянуться назад и увидеть это имя стручка на наших скриншотах выше.\nТеперь мы можем пойти и создать высокий балл, который затем будет сохранен в нашей базе данных.\nХорошо, у нас есть высокий балл, но что произойдет, если мы удалим наш mongo-0 pod? Выполнив команду kubectl delete pod mongo-0 -n pacman, я могу удалить его, и если вы все еще находитесь в приложении, вы увидите, что высокий балл недоступен, по крайней мере, в течение нескольких секунд.\nТеперь, если я вернусь в свою игру, я смогу создать новую игру и увидеть свои высокие баллы. Единственный способ поверить мне в это - попробовать и поделиться в социальных сетях своими высокими результатами!\nС развертыванием мы можем увеличить масштаб с помощью команд, которые мы рассматривали в предыдущей сессии, но в частности здесь, особенно если вы хотите устроить огромную вечеринку pacman, вы можете увеличить масштаб с помощью kubectl scale deployment pacman --replicas=10 -n pacman.\nIngress объяснено Прежде чем мы закончим с Kubernetes, я также хотел бы затронуть важный аспект Kubernetes, и это - ingress.\nЧто такое ingress? До сих пор в наших примерах мы использовали port-forward или определенные команды в minikube, чтобы получить доступ к нашим приложениям, но в производстве это не сработает. Нам нужен лучший способ доступа к нашим приложениям в масштабе с множеством пользователей.\nМы также говорили о возможности использования NodePort, но это опять же должно быть только в тестовых целях.\nIngress дает нам лучший способ открыть наши приложения, он позволяет нам определить правила маршрутизации в нашем кластере Kubernetes.\nДля ingress мы создадим запрос на внутреннюю службу нашего приложения.\nКогда вам нужен ingress? Если вы используете облачный провайдер, управляемое предложение Kubernetes, то, скорее всего, у них будет своя опция ingress для вашего кластера или они предоставят вам свой собственный балансировщик нагрузки. Вам не придется реализовывать это самостоятельно, что является одним из преимуществ управляемого Kubernetes.\nЕсли вы управляете собственным кластером, вам необходимо настроить точку входа.\nНастройка Ingress на Minikube На моем конкретном запущенном кластере под названием mc-demo я могу выполнить следующую команду, чтобы включить ingress на моем кластере.\nminikube --profile='mc-demo' addons enable ingress.\nЕсли теперь мы проверим наши пространства имен, то увидим, что у нас есть новое пространство имен ingress-nginx. kubectl get ns\nТеперь мы должны создать YAML-конфигурацию ingress для запуска нашего сервиса Pacman. Я добавил этот файл в репозиторий pacman-ingress.yaml.\nЗатем мы можем создать его в нашем пространстве имен ingress с помощью kubectl create -f pacman-ingress.yaml.\nЗатем, если мы запустим kubectl get ingress -n pacman\nЗатем мне говорят, что поскольку мы используем minikube, работающий на WSL2 в Windows, мы должны создать туннель minikube, используя minikube tunnel --profile=mc-demo.\nНо я все еще не могу получить доступ к 192.168.49.2 и играть в свою игру pacman.\nЕсли у кого-нибудь есть или есть возможность заставить это работать под Windows и WSL, я буду благодарен за отзывы. Я подниму вопрос об этом в репозитории и вернусь к нему, как только у меня появится время и исправление.\nUPDATE: Мне кажется, что этот блог помогает определить причину того, что игра не работает на WSL Configuring Ingress to run Minikube on WSL2 using Docker runtime\nРесурсы Kubernetes StatefulSet simply explained Kubernetes Volumes explained Kubernetes Ingress Tutorial for Beginners Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! На этом мы завершаем раздел Kubernetes. Существует так много дополнительных материалов, которые мы могли бы осветить на тему Kubernetes, и 7 дней дают нам базовые знания, но есть люди, которые проходят 100DaysOfKubernetes, где вы можете погрузиться в самую гущу событий.\nДалее мы рассмотрим инфраструктуру как код и ту важную роль, которую она играет с точки зрения DevOps.\n","description":"","title":"55. State и Ingress в Kubernetes","uri":"/ru/tracks/90daysofdevops/day55/"},{"content":"Обзор IaC Люди совершают ошибки! Автоматизация - это путь к успеху!\nКак вы строите свои системы сегодня?\nКаков был бы ваш план, если бы вы потеряли все, физические машины, виртуальные машины, облачные виртуальные машины, облачные PaaS и т.д. и т.п.?\nСколько времени у вас уйдет на замену всего?\nИнфраструктура как код предоставляет решение, позволяющее сделать это и одновременно протестировать, не путайте это с резервным копированием и восстановлением, но что касается вашей инфраструктуры и сред, ваших платформ, мы должны быть в состоянии раскрутить их и обращаться с ними как со скотом и домашними животными.\nTLDR; заключается в том, что мы можем использовать код для восстановления всей нашей среды.\nЕсли мы также вспомним, что с самого начала мы говорили о DevOps в целом - это способ преодоления барьеров для безопасной и быстрой доставки систем в производство.\nInfrastructure as code помогает нам поставлять системы, мы говорили о множестве процессов и инструментов. IaC предлагает нам больше инструментов, с которыми мы должны быть знакомы, чтобы обеспечить эту часть процесса.\nВ этом разделе мы сосредоточимся на инфраструктуре как коде. Вы также можете услышать упоминание этого термина как “инфраструктура из кода” или “конфигурация как код”. Я думаю, что наиболее известным термином является Инфраструктура как код.\nДомашние животные против крупного рогатого скота Если мы посмотрим на до DevOps, то при необходимости создания нового приложения мы должны были подготовить наши серверы вручную.\nРазвернуть виртуальные машины | физические серверы и установить операционную систему Настроить сеть Создать таблицы маршрутизации Установить программное обеспечение и обновления Настроить программное обеспечение Установка базы данных Это ручной процесс, выполняемый системными администраторами. Чем больше приложение, тем больше ресурсов и серверов требуется, тем больше ручных усилий потребуется для создания этих систем. Это потребует огромного количества человеческих усилий и времени, но, кроме того, как компания, вы должны будете заплатить за эти ресурсы, чтобы создать эту среду. Как я уже говорил в начале раздела “Люди совершают ошибки! Автоматизация - это путь к успеху!”.\nПосле вышеупомянутой фазы начальной установки вам предстоит обслуживание этих серверов.\nОбновление версий Развертывание новых релизов Управление данными Восстановление приложений Добавление, удаление и масштабирование серверов Конфигурация сети Добавьте сюда сложность нескольких сред тестирования и разработки.\nИменно здесь на помощь приходит Infrastructure as Code. Выше было время, когда мы заботились об этих серверах, как о домашних животных, люди даже называли их домашними именами или, по крайней мере, давали им какие-то имена, потому что они должны были находиться рядом какое-то время, они должны были стать частью “семьи” на какое-то время.\nС Infrastructure as Code у нас есть возможность автоматизировать все эти задачи от конца до конца. Инфраструктура как код - это концепция, и есть инструменты, которые выполняют автоматическое обеспечение инфраструктуры. На данный момент, если с сервером случается что-то плохое, вы выбрасываете его и запускаете новый. Этот процесс автоматизирован, и сервер точно такой же, как определено в коде. В этот момент нам не важно, как они называются, они находятся в поле и служат своей цели до тех пор, пока их больше нет в поле, и нам нужно заменить их либо из-за сбоя, либо из-за обновления части или всего нашего приложения.\nЭто может быть использовано практически во всех платформах, виртуализации, облачных рабочих нагрузках, а также в облачной нативной инфраструктуре, такой как Kubernetes и контейнеры.\nОбеспечение инфраструктуры Не все IaC охватывают все перечисленное ниже, вы увидите, что инструмент, который мы будем использовать в этом разделе, охватывает только первые две области; Terraform - это тот инструмент, который мы будем рассматривать, и он позволяет нам начать с нуля и определить в коде, как должна выглядеть наша инфраструктура, а затем развернуть ее, он также позволит нам управлять этой инфраструктурой и первоначально развернуть приложение, но в этот момент он потеряет контроль над приложением, и здесь на помощь приходит следующий раздел, и что-то вроде Ansible как инструмент управления конфигурацией может работать лучше на этом фронте.\nБез забегания вперед такие инструменты, как chef, puppet и ansible, лучше всего подходят для начальной установки приложений, а затем для управления этими приложениями и их конфигурацией.\nПервоначальная установка и настройка программного обеспечения\nРазвертывание новых серверов Конфигурация сети Создание балансировщиков нагрузки Конфигурация на уровне инфраструктуры Конфигурация инфраструктуры с провизией Установка приложения на серверы Подготовьте серверы для развертывания приложения. Развертывание приложения Развертывание и управление приложением Этап обслуживания Обновления программного обеспечения Реконфигурация Различия инструментов IaC Декларативный и процедурный\nПроцедурный\nПошаговая инструкция Создайте сервер \u003e Добавьте сервер \u003e Внесите это изменение Декларативный\nобъявить конечный результат 2 сервера Изменяемые (домашние животные) против неизменяемых (крупный рогатый скот)\nМутабельный\nИзменение вместо замены Как правило, долгоживущие Неизменяемые\nЗамена вместо изменения Возможно, недолговечна Именно поэтому у нас есть множество различных вариантов Infrastructure as Code, потому что не существует одного инструмента, который бы управлял всеми.\nМы будем в основном использовать terraform и работать с ним, поскольку это лучший способ начать видеть преимущества инфраструктуры как кода в действии. Практическая работа - это также лучший способ приобрести навыки, так как вы будете писать код.\nДалее мы начнем изучать Terraform со 101-го урока, прежде чем приступим к практическому использованию.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"56. Обзор IaC","uri":"/ru/tracks/90daysofdevops/day56/"},{"content":"“Terraform - это инструмент для безопасного и эффективного создания, изменения и управления версиями инфраструктуры”. «Приведенная выше цитата взята из HashiCorp, HashiCorp - это компания, стоящая за Terraform.\n“Terraform - это программный инструмент “инфраструктура как код” с открытым исходным кодом, который обеспечивает последовательный рабочий процесс CLI для управления сотнями облачных сервисов. Terraform кодирует облачные API в декларативные конфигурационные файлы”.\nУ HashiCorp есть отличный ресурс HashiCorp Learn, который охватывает все их продукты и дает несколько отличных демонстрационных примеров, когда вы пытаетесь достичь чего-то с помощью инфраструктуры как кода.\nВсе облачные провайдеры и локальные платформы обычно предоставляют нам доступ к консолям управления, которые позволяют нам создавать наши ресурсы с помощью пользовательского интерфейса, обычно эти платформы также предоставляют доступ к CLI или API для создания тех же ресурсов, но с API у нас есть возможность быстрого предоставления ресурсов.\nИнфраструктура как код позволяет нам подключаться к этим API для развертывания наших ресурсов в нужном состоянии.\nНиже перечислены и другие инструменты, но они не являются исключительными или исчерпывающими. Если у вас есть другие инструменты, пожалуйста, поделитесь с нами через PR.\nCloud Specific Cloud Agnostic AWS CloudFormation Terraform Azure Resource Manager Pulumi Google Cloud Deployment Manager Это еще одна причина, почему мы используем Terraform, мы хотим быть независимыми от облаков и платформ, которые мы хотим использовать для наших демонстраций, а также в целом.\nОбзор Terraform Terraform - это инструмент, ориентированный на обеспечение, Terraform - это CLI, который предоставляет возможности для обеспечения сложных инфраструктурных сред. С помощью Terraform мы можем определить сложные требования к инфраструктуре, существующей локально или удаленно (облако). Terraform позволяет нам не только создавать вещи на начальном этапе, но и поддерживать и обновлять эти ресурсы в течение всего срока их службы.\nЗдесь мы рассмотрим основные моменты, но для получения более подробной информации и множества ресурсов вы можете посетить сайт terraform.io.\nЗапись Terraform позволяет нам создавать декларативные конфигурационные файлы, которые будут создавать наше окружение. Файлы пишутся с помощью языка HashiCorp Configuration Language (HCL), который позволяет кратко описывать ресурсы с помощью блоков, аргументов и выражений. Мы, конечно, будем подробно рассматривать их при развертывании виртуальных машин, контейнеров и в Kubernetes.\nПлан Возможность проверить, что вышеуказанные конфигурационные файлы развернут то, что мы хотим видеть, используя определенные функции terraform cli, чтобы иметь возможность протестировать этот план перед развертыванием чего-либо или изменением чего-либо. Помните, что Terraform - это инструмент для продолжения вашей инфраструктуры, если вы хотите изменить аспект вашей инфраструктуры, вы должны сделать это через terraform, чтобы все это было зафиксировано в коде.\nПрименить Очевидно, что когда вы будете довольны, вы сможете применить эту конфигурацию к множеству провайдеров, доступных в Terraform. Вы можете увидеть большое количество доступных провайдеров здесь.\nЕще одна вещь, о которой следует упомянуть, это то, что также доступны модули, и это похоже на образы контейнеров в том, что эти модули были созданы и выложены в открытый доступ, так что вам не придется создавать их снова и снова, просто используйте лучшую практику развертывания определенного ресурса инфраструктуры одинаковым способом везде. Вы можете найти доступные модули здесь.\nРабочий процесс Terraform выглядит следующим образом: (взято с сайта terraform)\nTerraform vs Vagrant Во время этого испытания мы использовали Vagrant, который является еще одним инструментом с открытым исходным кодом от Hashicorp, сконцентрированным на средах разработки.\nVagrant - это инструмент, ориентированный на управление средами разработки.\nTerraform - это инструмент для создания инфраструктуры.\nОтличное сравнение этих двух инструментов можно найти здесь на официальном сайте Hashicorp\nУстановка Terraform В установке Terraform нет ничего сложного.\nTerraform является кроссплатформенным, и вы можете видеть ниже на моей Linux машине у нас есть несколько вариантов загрузки и установки CLI\nИспользование arkade для установки Terraform, arkade - это удобный инструмент для получения необходимых инструментов, приложений и clis на вашу систему. Простая команда arkade get terraform позволит обновить terraform, если он доступен, или эта же команда также установит Terraform CLI\nМы собираемся больше узнать о HCL, а также начать использовать Terraform для создания некоторых инфраструктурных ресурсов на различных платформах.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"57. Введение в Terraform","uri":"/ru/tracks/90daysofdevops/day57/"},{"content":"Язык конфигурации HashiCorp (HCL) Прежде чем мы начнем создавать вещи с помощью Terraform, мы должны немного погрузиться в язык HashiCorp Configuration Language (HCL). До сих пор в ходе нашей задачи мы рассмотрели несколько различных языков скриптов и программирования, и вот еще один. Мы затронули язык программирования Go, затем скрипты bash, мы даже немного затронули python, когда дело дошло до автоматизации сети.\nТеперь мы должны рассмотреть язык конфигурации HashiCorp (HCL), если вы впервые видите этот язык, он может показаться немного пугающим, но он довольно прост и очень мощный.\nПо мере продвижения по этому разделу мы будем использовать примеры, которые мы можем запустить локально на нашей системе, независимо от того, какую ОС вы используете, мы будем использовать virtualbox, хотя и не инфраструктурную платформу, которую вы обычно используете с Terraform. Тем не менее, запуск этого локально, он бесплатный и позволит нам достичь того, что мы ищем в этой заметке. Мы также можем расширить концепцию этого поста на docker или Kubernetes.\nВ целом, вы будете или должны использовать Terraform для развертывания инфраструктуры в публичном облаке (AWS, Google, Microsoft Azure), а также в средах виртуализации, таких как (VMware, Microsoft Hyper-V, Nutanix AHV). В публичном облаке Terraform позволяет нам делать гораздо больше, чем просто автоматическое развертывание виртуальных машин, мы можем создавать всю необходимую инфраструктуру, такую как рабочие нагрузки PaaS, и все необходимые сетевые ресурсы, такие как VPC и группы безопасности.\nВ Terraform есть два важных аспекта: код, который мы рассмотрим в этой статье, и состояние. Оба этих аспекта вместе можно назвать ядром Terraform. Затем у нас есть среда, в которую мы хотим обратиться и развернуть, которая выполняется с помощью провайдеров Terraform, кратко упомянутых на прошлом занятии, но у нас есть провайдеры AWS, есть провайдеры Azure и т.д. Их сотни. Их сотни.\nБазовое использование Terraform Давайте посмотрим на файл Terraform .tf, чтобы увидеть, как они создаются. Первый пример, который мы рассмотрим, будет кодом для развертывания ресурсов на AWS, для этого также потребуется установить AWS CLI на вашей системе и настроить его для вашей учетной записи.\nProviders В верхней части нашей файловой структуры .tf, обычно называемой main.tf, по крайней мере до тех пор, пока мы не сделаем все более сложным. Здесь мы определим провайдеров, о которых мы упоминали ранее. Наш источник провайдера aws, как вы видите, hashicorp/aws, это означает, что провайдер поддерживается или был опубликован самой компанией hashicorp. По умолчанию вы будете ссылаться на провайдеров, доступных в Terraform Registry, у вас также есть возможность написать свои собственные провайдеры и использовать их локально или самостоятельно опубликовать в Terraform Registry.\nterraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 3.0\" } } } Здесь мы также можем добавить регион, чтобы определить, какой регион AWS мы хотим предоставить, мы можем сделать это, добавив следующее:\nprovider \"aws\" { region = \"ap-southeast-1\" //region where resources need to be deployed } Resources Другой важный компонент конфигурационного файла terraform, который описывает один или несколько объектов инфраструктуры, таких как EC2, Load Balancer, VPC и т.д.\nБлок ресурсов объявляет ресурс заданного типа (“aws_instance”) с заданным локальным именем (“90daysofdevops”).\nТип ресурса и имя вместе служат идентификатором для данного ресурса.\nresource \"aws_instance\" \"90daysofdevops\" { ami = data.aws_ami.instance_id.id instance_type = \"t2.micro\" availability_zone = \"us-west-2a\" security_groups = [aws_security_group.allow_web.name] user_data = \u003c\u003c-EOF #! /bin/bash sudo yum update sudo yum install -y httpd sudo systemctl start httpd sudo systemctl enable httpd echo \" \u003ch1\u003eDeployed via Terraform\u003c/h1\u003e \" | sudo tee /var/www/html/index.html EOF tags = { Name = \"Created by Terraform\" } } Из вышеприведенного видно, что мы также запускаем обновление yum и устанавливаем httpd в наш экземпляр ec2.\nЕсли мы теперь посмотрим на полный файл main.tf, он может выглядеть примерно так.\nterraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 3.27\" } } required_version = \"\u003e= 0.14.9\" } provider \"aws\" { profile = \"default\" region = \"us-west-2\" } resource \"aws_instance\" \"90daysofdevops\" { ami = \"ami-830c94e3\" instance_type = \"t2.micro\" availability_zone = \"us-west-2a\" user_data = \u003c\u003c-EOF #! /bin/bash sudo yum update sudo yum install -y httpd sudo systemctl start httpd sudo systemctl enable httpd echo \" \u003ch1\u003eDeployed via Terraform\u003c/h1\u003e \" | sudo tee /var/www/html/index.html EOF tags = { Name = \"Created by Terraform\" tags = { Name = \"ExampleAppServerInstance\" } } Приведенный выше код позволит развернуть очень простой веб-сервер в качестве экземпляра ec2 в AWS. Самое замечательное в этой и любой другой подобной конфигурации то, что мы можем повторить ее и каждый раз получать один и тот же результат. Кроме вероятности того, что я испортил код, нет никакого взаимодействия с человеком.\nМы можем рассмотреть суперпростой пример, который вы, скорее всего, никогда не будете использовать, но давайте все равно пошутим. Как и во всех хороших скриптах и языках программирования, мы должны начать со скрипта приветствия мира.\nterraform { # This module is now only being tested with Terraform 0.13.x. However, to make upgrading easier, we are setting # 0.12.26 as the minimum version, as that version added support for required_providers with source URLs, making it # forwards compatible with 0.13.x code. required_version = \"\u003e= 0.12.26\" } # website::tag::1:: The simplest possible Terraform module: it just outputs \"Hello, World!\" output \"hello_world\" { value = \"Hello, 90DaysOfDevOps from Terraform\" } Вы найдете этот файл в папке IAC в разделе hello-world, но из коробки он не будет просто работать, есть несколько команд, которые необходимо выполнить, чтобы использовать наш код терраформы.\nВ терминале перейдите в папку, где был создан файл main.tf, он может быть из этого репозитория или вы можете создать новый, используя код выше.\nНаходясь в этой папке, выполните команду terraform init.\nМы должны выполнить эту команду в любой директории, где у нас есть или перед запуском любого кода terraform. Инициализация каталога конфигурации загружает и устанавливает провайдеров, определенных в конфигурации, в данном случае у нас нет провайдеров, но в примере выше это загрузит провайдера aws для этой конфигурации.\nСледующей командой будет terraform plan.\nКоманда terraform plan создает план выполнения, который позволяет вам предварительно просмотреть изменения, которые Terraform планирует внести в вашу инфраструктуру.\nВы можете видеть ниже, что на нашем примере hello-world мы увидим результат, если бы это был экземпляр AWS ec2, мы бы увидели все шаги, которые мы будем создавать.\nНа данном этапе мы инициализировали наш репозиторий, загрузили провайдеров, где это необходимо, запустили тестовый проход, чтобы убедиться, что это то, что мы хотим видеть, теперь мы можем запустить и развернуть наш код.\nКоманда terraform apply позволяет нам это сделать, в нее встроена мера безопасности, и это снова даст вам представление о том, что произойдет, что требует от вас ответа “да”, чтобы продолжить.\nКогда мы вводим “да”, чтобы ввести значение, наш код развертывается. Очевидно, это не так интересно, но вы можете видеть, что у нас есть вывод, который мы определили в нашем коде.\nТеперь мы ничего не развернули, мы ничего не добавили, не изменили и не уничтожили, но если бы мы это сделали, то мы бы увидели, что это также указано выше. Однако если мы что-то развернули и хотим избавиться от всего, что развернули, мы можем использовать команду terraform destroy. Опять же, это имеет ту безопасность, когда вы должны ввести “да”, хотя вы можете использовать --auto-approve в конце ваших команд apply и destroy, чтобы обойти это ручное вмешательство. Но я бы посоветовал использовать это сокращение только в процессе обучения и тестирования, так как все будет исчезать иногда быстрее, чем было создано.\nТаким образом, мы рассмотрели всего 4 команды из Terraform CLI.\nterraform init = подготовить папку проекта с провайдерами terraform plan = показать, что будет создано, изменено во время следующей команды на основе нашего кода. terraform apply = развернет ресурсы, определенные в нашем коде. terraform destroy = уничтожит ресурсы, которые мы создали в нашем проекте. Мы также рассмотрели два важных аспекта наших кодовых файлов.\nproviders = как terraform общается с конечной платформой через API-интерфейсы resources = что именно мы хотим развернуть с помощью кода Еще одна вещь, которую следует отметить, когда мы запускаем terraform init, посмотрите на дерево в папке до и после, чтобы увидеть, что происходит и где мы храним провайдеры и модули.\nTerraform state Нам также необходимо знать о файле состояния, который создается также внутри нашей директории, и для этого примера hello world наш файл состояния прост. Это JSON-файл, который является представлением мира в соответствии с Terraform. Состояние будет радостно демонстрировать ваши конфиденциальные данные, поэтому будьте осторожны и в качестве лучшей практики помещайте файлы .tfstate в папку .gitignore перед загрузкой на GitHub.\nПо умолчанию файл состояния, как вы видите, находится в том же каталоге, что и код вашего проекта, но его можно хранить и удаленно. В производственной среде это, скорее всего, будет общее место, например, ведро S3.\nДругим вариантом может быть Terraform Cloud, это платная управляемая услуга. (Бесплатно до 5 пользователей)\nПлюсы хранения состояния в удаленном месте заключаются в том, что мы получаем:\n{ \"version\": 4, \"terraform_version\": \"1.1.6\", \"serial\": 1, \"lineage\": \"a74296e7-670d-0cbb-a048-f332696ca850\", \"outputs\": { \"hello_world\": { \"value\": \"Hello, 90DaysOfDevOps from Terraform\", \"type\": \"string\" } }, \"resources\": [] } Ресурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"58. Язык конфигурации HashiCorp (HCL)","uri":"/ru/tracks/90daysofdevops/day58/"},{"content":"Создание виртуальной машины с помощью Terraform и переменных В этой сессии мы будем создавать виртуальную машину или две виртуальные машины с помощью Terraform внутри VirtualBox. Это не совсем обычно, VirtualBox - это вариант виртуализации рабочих станций, и на самом деле это не было бы вариантом использования Terraform, но я сейчас нахожусь на высоте 36 000 футов в воздухе, и как бы я ни развертывал ресурсы публичного облака так высоко в облаках, гораздо быстрее сделать это локально на моем ноутбуке.\nЧисто демонстрационная цель, но концепция та же, мы собираемся иметь наш желаемый код конфигурации состояния, а затем мы собираемся запустить его против провайдера virtualbox. В прошлом мы использовали здесь vagrant, и я рассказал о различиях между vagrant и terraform в начале раздела.\nСоздание виртуальной машины в VirtualBox Первое, что мы сделаем, это создадим новую папку под названием virtualbox, затем мы можем создать файл virtualbox.tf, в котором мы определим наши ресурсы. Приведенный ниже код, который можно найти в папке VirtualBox под названием virtualbox.tf, создаст 2 виртуальные машины в Virtualbox.\nВы можете узнать больше о сообществе провайдера Virtualbox здесь\nterraform { required_providers { virtualbox = { source = \"terra-farm/virtualbox\" version = \"0.2.2-alpha.1\" } } } # В настоящее время нет никаких опций конфигурации для самого провайдера. resource \"virtualbox_vm\" \"node\" { count = 2 name = format(\"node-%02d\", count.index + 1) image = \"https://app.vagrantup.com/ubuntu/boxes/bionic64/versions/20180903.0.0/providers/virtualbox.box\" cpus = 2 memory = \"512 mib\" network_adapter { type = \"hostonly\" host_interface = \"vboxnet1\" } } output \"IPAddr\" { value = element(virtualbox_vm.node.*.network_adapter.0.ipv4_address, 1) } output \"IPAddr_2\" { value = element(virtualbox_vm.node.*.network_adapter.0.ipv4_address, 2) } Теперь, когда мы определили наш код, мы можем выполнить terraform init для нашей папки, чтобы загрузить провайдер для virtualbox.\nОчевидно, что в вашей системе также должен быть установлен virtualbox. Затем мы можем запустить terraform plan, чтобы посмотреть, что наш код создаст для нас. Затем следует terraform apply. На рисунке ниже показан завершенный процесс.\nТеперь в Virtualbox вы увидите две виртуальные машины.\nИзменение конфигурации Давайте добавим еще один узел в наше развертывание. Мы можем просто изменить строку count, чтобы показать новое желаемое количество узлов. Когда мы запустим нашу terraform apply, она будет выглядеть примерно так, как показано ниже.\nПосле завершения работы в virtualbox вы можете увидеть, что у нас теперь есть 3 узла.\nКогда мы закончим, мы можем очистить все это с помощью команды terraform destroy, и наши машины будут удалены.\nПеременные и выходные данные Мы упоминали о выводах, когда выполняли пример hello-world на прошлом занятии. Но здесь мы можем остановиться на этом более подробно.\nНо есть много других переменных, которые мы можем использовать здесь, также есть несколько различных способов, которыми мы можем определить переменные.\nМы можем вручную ввести наши переменные с помощью команды terraform plan или terraform apply.\nМы можем определить их в .tf-файле внутри блока\nМы можем использовать переменные окружения в нашей системе, используя TF_VAR_NAME в качестве формата.\nЯ предпочитаю использовать файл terraform.tfvars в папке нашего проекта.\nСуществует опция *auto.tfvars файла\nили мы можем определить, когда запускаем terraform plan или terraform apply с помощью var или var-file.\nПорядок определения переменных будет начинаться снизу вверх.\nМы также упоминали, что файл состояния будет содержать конфиденциальную информацию. Мы можем определить нашу чувствительную информацию как переменную и определить ее как чувствительную.\nvariable \"some resource\" { description = \"something important\" type: string sensitive = true } Ресурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"59. Создание виртуальной машины с помощью Terraform","uri":"/ru/tracks/90daysofdevops/day59/"},{"content":"DevOps - Истории компаний DevOps с самого начала считался недосягаемым для многих из нас, поскольку у нас не было среды или требований, подобных Netflix или Fortune 500, но подумайте, что теперь это начинает становиться нормой, когда мы внедряем практику DevOps внутри. любой вид бизнеса.\nПо второй ссылке ниже в справочных материалах вы увидите множество различных отраслей и вертикалей, использующих DevOps и оказывающих огромное положительное влияние на свои бизнес-цели.\nОчевидно, что основным преимуществом здесь является DevOps, если он выполнен правильно, он должен помочь вашему бизнесу повысить скорость и качество разработки программного обеспечения.\nЯ хотел использовать этот день, чтобы посмотреть на успешные компании, которые внедрили практику DevOps, и поделиться некоторыми ресурсами по этому поводу. Приняли ли вы культуру DevOps в своем бизнесе? Был ли он успешным?\nЯ упомянул Netflix выше и коснусь их снова, поскольку это очень хорошая модель, которая даже до сих пор продвинута к тому, что мы обычно видим сегодня, но также упомяну некоторые другие известные бренды, которые, похоже, преуспевают.\nAmazon В 2010 году Amazon переместила свои физические серверы в облако Amazon Web Services (AWS), что позволило им сэкономить ресурсы за счет увеличения и уменьшения емкости с очень небольшими приращениями. Мы также знаем, что это облако AWS продолжит свое существование и будет приносить огромный доход, продолжая управлять розничным филиалом компании Amazon.\nAmazon внедрила в 2011 году (согласно приведенному ниже ресурсу) непрерывный процесс развертывания, при котором их разработчики могли развертывать код в любое время и на любых серверах, которые им нужны. Это позволило Amazon добиться развертывания нового программного обеспечения на производственных серверах в среднем каждые 11,6 секунды!\nNetFlix Кто не пользуется NetFlix? очевидно, это огромный качественный потоковый сервис, который, по крайней мере, лично для всех, обеспечивает отличный пользовательский опыт.\nПочему этот пользовательский опыт так хорош? Что ж, возможность предоставить услугу без воспоминаний, по крайней мере, о сбоях, требует скорости, гибкости и внимания к качеству.\nРазработчики NetFlix могут автоматически встраивать фрагменты кода в развертываемые веб-образы, не полагаясь на ИТ-операции. По мере обновления изображений они интегрируются в инфраструктуру Netflix с помощью специально созданной веб-платформы.\nНепрерывный мониторинг выполняется таким образом, что в случае сбоя развертывания образов новые образы откатываются, а трафик перенаправляется на предыдущую версию.\nНиже приводится отличная беседа, в которой подробно рассказывается о том, что нужно и чего нельзя делать, по которым Netflix живет и умирает в своих командах.\nEtsy Как и у многих из нас и многих компаний, медленные и болезненные развертывания были настоящим испытанием. В том же духе мы могли бы также работать в компаниях, которые имеют много бункеров и команд, которые не очень хорошо работают вместе.\nИз того, что я могу понять, по крайней мере, из чтения об Amazon и Netflix, Etsy, возможно, разрешила разработчикам развертывать свой собственный код примерно в конце 2009 года, что могло быть до двух других упомянутых. (интересный!)\nИнтересный вывод, который я прочитал здесь, заключался в том, что они поняли, что когда разработчики чувствуют ответственность за развертывание, они также берут на себя ответственность за производительность приложения, время безотказной работы и другие цели.\nКультура обучения является ключевой частью DevOps, даже неудача может стать успехом, если извлечь уроки. (не уверен, откуда на самом деле взялась эта цитата, но она имеет смысл!)\nЯ добавил несколько других историй о том, как DevOps изменил правила игры в некоторых из этих чрезвычайно успешных компаний.\nИсточники How Netflix Thinks of DevOps 16 Popular DevOps Use Cases \u0026 Real Life Applications [2021] DevOps: The Amazon Story How Etsy makes DevOps work Adopting DevOps @ Scale Lessons learned at Hertz, Kaiser Permanente and lBM Interplanetary DevOps at NASA JPL Target CIO explains how DevOps took root inside the retail giant Подведем итоги наших первых дней, посвященных DevOps. DevOps — это комбинация разработки и эксплуатации, которая позволяет одной команде управлять всем жизненным циклом разработки приложения, состоящим из разработки, тестирования, развертывания, эксплуатации.\nОсновное внимание и цель DevOps — сократить жизненный цикл разработки, часто предоставляя функции, исправления и функциональные возможности в тесном соответствии с бизнес-целями.\nDevOps — это подход к разработке программного обеспечения, с помощью которого программное обеспечение может поставляться и разрабатываться надежно и быстро. Вы также можете увидеть это как Непрерывная разработка, тестирование, развертывание, мониторинг\nДо встречи в День 7\nНа седьмой день мы погрузимся в язык программирования. Я не стремлюсь быть разработчиком, но хочу понимать, что делают разработчики.\nМожем ли мы достичь этого за неделю? Вероятно, нет, но если мы потратим 7 дней или 7 часов на изучение чего-то, мы будем знать больше, чем когда мы начинали.\n","description":"DevOps - Истории","title":"6. DevOps - Истории","uri":"/ru/tracks/90daysofdevops/day06/"},{"content":"Контейнеры и модули Docker Вчера мы развернули виртуальную машину с помощью Terraform в нашей локальной среде FREE virtualbox. В этом разделе мы собираемся развернуть контейнер Docker с некоторой конфигурацией в нашей локальной среде Docker.\nDocker Demo Для начала мы используем приведенный ниже блок кода, суть которого заключается в том, что мы хотим развернуть простое веб-приложение в docker и опубликовать его, чтобы оно было доступно в нашей сети. Мы будем использовать nginx и сделаем его доступным извне на нашем ноутбуке через localhost и порт 8000. Мы используем провайдера docker из сообщества, и вы можете видеть образ docker, который мы используем, также указанный в нашей конфигурации.\nterraform { required_providers { docker = { source = \"kreuzwerker/docker\" version = \"2.16.0\" } } } provider \"docker\" {} resource \"docker_image\" \"nginx\" { name = \"nginx:latest\" keep_locally = false } resource \"docker_container\" \"nginx\" { image = docker_image.nginx.latest name = \"tutorial\" ports { internal = 80 external = 8000 } } Первой задачей является использование команды terraform init для загрузки провайдера на нашу локальную машину.\nЗатем мы запускаем команду terraform apply, а затем docker ps, и вы можете увидеть, что у нас есть запущенный контейнер.\nЕсли мы откроем браузер, то перейдем по адресу http://localhost:8000/ и увидим, что у нас есть доступ к нашему контейнеру NGINX.\nВы можете узнать больше информации о Docker Provider.\nВыше приведена очень простая демонстрация того, что можно сделать с помощью Terraform плюс Docker и как мы теперь можем управлять этим в состоянии Terraform. Мы рассматривали docker compose в разделе о контейнерах, и есть небольшое пересечение между этим, инфраструктурой как код, а также Kubernetes.\nДля демонстрации того, как Terraform может справиться с более сложными задачами, мы возьмем файл docker compose для wordpress и mysql, который мы создали с помощью docker compose, и поместим его в Terraform. Вы можете найти docker-wordpress.tf\nterraform { required_providers { docker = { source = \"kreuzwerker/docker\" version = \"2.16.0\" } } } provider \"docker\" {} variable wordpress_port { default = \"8080\" } resource \"docker_volume\" \"db_data\" { name = \"db_data\" } resource \"docker_network\" \"wordpress_net\" { name = \"wordpress_net\" } resource \"docker_container\" \"db\" { name = \"db\" image = \"mysql:5.7\" restart = \"always\" network_mode = \"wordpress_net\" env = [ \"MYSQL_ROOT_PASSWORD=wordpress\", \"MYSQL_PASSWORD=wordpress\", \"MYSQL_USER=wordpress\", \"MYSQL_DATABASE=wordpress\" ] mounts { type = \"volume\" target = \"/var/lib/mysql\" source = \"db_data\" } } resource \"docker_container\" \"wordpress\" { name = \"wordpress\" image = \"wordpress:latest\" restart = \"always\" network_mode = \"wordpress_net\" env = [ \"WORDPRESS_DB_HOST=db:3306\", \"WORDPRESS_DB_USER=wordpress\", \"WORDPRESS_DB_NAME=wordpress\", \"WORDPRESS_DB_PASSWORD=wordpress\" ] ports { internal = \"80\" external = \"${var.wordpress_port}\" } } Мы снова помещаем это в новую папку и затем запускаем команду terraform init, чтобы извлечь необходимые нам провайдеры.\nЗатем мы запускаем команду terraform apply и смотрим на вывод docker ps, мы должны увидеть наши только что созданные контейнеры.\nЗатем мы можем перейти к нашему фронт-энду WordPress. Точно так же, как мы проходили этот процесс с docker-compose в разделе о контейнерах, теперь мы можем выполнить установку, и наши посты wordpress будут жить в нашей базе данных MySQL.\nОчевидно, что теперь мы рассмотрели контейнеры и Kubernetes в некоторых деталях, мы, вероятно, знаем, что это подходит для тестирования, но если бы вы действительно собирались запустить веб-сайт, вы бы не стали делать это только с помощью контейнеров и рассмотрели бы использование Kubernetes для достижения этой цели, Далее мы рассмотрим использование Terraform с Kubernetes.\nProvisioners Провайдеры существуют для того, чтобы если что-то не может быть декларировано, у нас был способ разобрать это для нашего развертывания.\nЕсли у вас нет другой альтернативы, и добавление такой сложности в ваш код - это то, что вам нужно, то вы можете сделать это, выполнив что-то похожее на следующий блок кода.\nресурс \"docker_container\" \"db\" { # ... provisioner \"local-exec\" { command = \"echo The server's IP address is ${self.private_ip}\" } } Удаленный исполнительный провайдер вызывает скрипт на удаленном ресурсе после его создания. Это может быть использовано для чего-то специфического для ОС, или это может быть использовано для обертывания в инструмент управления конфигурацией. Хотя заметьте, что некоторые из них мы уже рассмотрели в собственных провайдерах.\nСредство подготовки удаленных исполняемых файлов вызывает скрипт на удаленном ресурсе после его создания. Это может быть использовано для чего-то определенного для ОС или может быть использовано для включения инструмента управления конфигурацией. Хотя обратите внимание, что у нас есть некоторые из них, покрытые их собственными провизорами. Подробнее о провизорах](https://www.terraform.io/language/resources/provisioners/syntax)\nfile local-exec remote-exec vendor ansible chef puppet Модули Модули - это контейнеры для нескольких ресурсов, которые используются вместе. Модуль состоит из коллекции файлов .tf в одном каталоге.\nМодули - это хороший способ разделить ресурсы инфраструктуры, а также возможность использовать уже созданные сторонние модули, чтобы не изобретать колесо.\nНапример, если бы мы хотели использовать один и тот же проект для создания нескольких виртуальных машин, VPC, групп безопасности, а затем кластера Kubernetes, мы бы, вероятно, захотели разделить наши ресурсы на модули, чтобы лучше определить наши ресурсы и их группировку.\nЕще одним преимуществом модулей является то, что вы можете взять эти модули и использовать их в других проектах или публично поделиться ими, чтобы помочь сообществу.\nМы разбиваем нашу инфраструктуру на компоненты, компоненты известны здесь как модули.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"60. Контейнеры, провайдеры и модули Docker","uri":"/ru/tracks/90daysofdevops/day60/"},{"content":"Kubernetes и множественные среды До сих пор в этом разделе, посвященном инфраструктуре как коду, мы рассматривали развертывание виртуальных машин, хотя и с помощью virtualbox, но суть одна и та же: мы определяем в коде, как должна выглядеть наша виртуальная машина, а затем развертываем ее. То же самое касается контейнеров Docker, и на этом занятии мы рассмотрим, как Terraform можно использовать для взаимодействия с ресурсами, поддерживаемыми Kubernetes.\nЯ использовал Terraform для развертывания своих кластеров Kubernetes в демонстрационных целях на трех основных облачных провайдерах, и вы можете найти репозиторий tf_k8deploy.\nОднако вы также можете использовать Terraform для взаимодействия с объектами внутри кластера Kubernetes, это может быть использование Kubernetes provider или Helm provider для управления развертыванием диаграмм.\nТеперь мы можем использовать kubectl, как мы показывали в предыдущих разделах. Но есть некоторые преимущества использования Terraform в вашей среде Kubernetes.\nУнифицированный рабочий процесс - если вы использовали Terraform для развертывания кластеров, вы можете использовать тот же рабочий процесс и инструмент для развертывания в кластерах Kubernetes.\nУправление жизненным циклом - Terraform - это не просто инструмент инициализации, он позволяет вносить изменения, обновления и удаления.\nПростая демонстрация Kubernetes Подобно демо, которое мы создали на прошлом занятии, мы можем развернуть nginx в нашем кластере Kubernetes, я снова буду использовать minikube в демонстрационных целях. Мы создаем наш файл Kubernetes.tf, который вы можете найти в папке.\nВ этом файле мы определим нашего провайдера Kubernetes, укажем на наш файл kubeconfig, создадим пространство имен nginx, затем создадим развертывание, содержащее 2 реплики и, наконец, сервис.\nterraform { required_providers { kubernetes = { source = \"hashicorp/kubernetes\" version = \"\u003e= 2.0.0\" } } } provider \"kubernetes\" { config_path = \"~/.kube/config\" } resource \"kubernetes_namespace\" \"test\" { metadata { name = \"nginx\" } } resource \"kubernetes_deployment\" \"test\" { metadata { name = \"nginx\" namespace = kubernetes_namespace.test.metadata.0.name } spec { replicas = 2 selector { match_labels = { app = \"MyTestApp\" } } template { metadata { labels = { app = \"MyTestApp\" } } spec { container { image = \"nginx\" name = \"nginx-container\" port { container_port = 80 } } } } } } resource \"kubernetes_service\" \"test\" { metadata { name = \"nginx\" namespace = kubernetes_namespace.test.metadata.0.name } spec { selector = { app = kubernetes_deployment.test.spec.0.template.0.metadata.0.labels.app } type = \"NodePort\" port { node_port = 30201 port = 80 target_port = 80 } } } Первое, что мы должны сделать в папке нашего нового проекта, это выполнить команду terraform init.\nА затем, прежде чем мы выполним команду terraform apply, позвольте мне показать вам, что у нас нет пространств имен.\nКогда мы запустим нашу команду apply, она создаст эти 3 новых ресурса, пространство имен, развертывание и сервис в нашем кластере Kubernetes.\nТеперь мы можем взглянуть на развернутые ресурсы в нашем кластере.\nТеперь, поскольку мы используем minikube, и вы видели в предыдущем разделе, это имеет свои собственные ограничения, когда мы пытаемся играть с сетью docker для ingress. Но если мы просто выполним команду kubectl port-forward -n nginx svc/nginx 30201:80 и откроем браузер на http://localhost:30201/, мы увидим нашу страницу NGINX.\nЕсли вы хотите попробовать более подробные демонстрации с Terraform и Kubernetes, то на сайте HashiCorp Learn site вы сможете ознакомиться с ними.\nМножественные окружения Если мы хотим взять любой из демонстрационных примеров, которые мы проверили, но теперь хотим, чтобы определенные среды производства, постановки и разработки выглядели одинаково и использовали этот код, есть два подхода для достижения этого с помощью Terraform\nтерраформенные рабочие пространства - несколько именованных разделов в рамках одного бэкенда\nфайловая структура - расположение каталогов обеспечивает разделение, модули обеспечивают повторное использование.\nКаждый из этих подходов имеет свои плюсы и минусы.\nterraform workspaces Плюсы\nЛегко начать работу Удобное выражение terraform.workspace Минимизирует дублирование кода Минусы\nСклонность к человеческим ошибкам (мы пытались устранить это, используя TF) Состояние хранится в одном бэкенде Кодовая база не показывает однозначно конфигурации развертывания. Файловая структура Плюсы\nИзоляция бэкендов повышенная безопасность снижен потенциал для человеческих ошибок Кодовая база полностью представляет развернутое состояние Минусы\nТребуется многократное применение terraform для обеспечения окружения больше дублирования кода, но его можно минимизировать с помощью модулей. Ресурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"61. Kubernetes и множественные среды","uri":"/ru/tracks/90daysofdevops/day61/"},{"content":"Тестирование, инструменты и альтернативы Завершая этот раздел об инфраструктуре как коде, мы должны упомянуть о тестировании нашего кода, различных доступных инструментах, а также о некоторых альтернативах Terraform для достижения этой цели. Как я уже говорил в начале раздела, я остановился на Terraform, поскольку он, во-первых, бесплатный и с открытым исходным кодом, во-вторых, он кроссплатформенный и не зависит от окружения. Но есть и альтернативы, которые следует рассмотреть, но общая цель состоит в том, чтобы донести до людей, что это способ развертывания инфраструктуры.\nCode Rot Первая область, которую я хочу затронуть в этой сессии, - это гниение кода. В отличие от кода приложений, инфраструктура как код может использоваться, а затем не использоваться в течение очень долгого времени. Возьмем пример: мы собираемся использовать Terraform для развертывания нашей среды VM в AWS, все идеально, все работает с первого раза, и у нас есть наша среда, но эта среда не меняется слишком часто, поэтому код остается в состоянии, возможно, или, надеюсь, хранится в центральном месте, но код не меняется.\nА что если что-то изменится в инфраструктуре? Но это делается вне диапазона, или другие вещи меняются в нашей среде.\nВнеполосные изменения (Out of band changes) Неприкрепленные версии (Unpinned versions) Утратившие актуальность зависимости (Deprecated dependancies) Неприменимые изменения (Unapplied changes) Тестирование Еще одна огромная область, которая следует за гниением кода и в целом, это возможность протестировать ваш IaC и убедиться, что все области работают так, как должны.\nПрежде всего, есть несколько встроенных команд тестирования, на которые мы можем взглянуть:\nCommand Description terraform fmt Rewrite Terraform configuration files to a canonical format and style. terraform validate Validates the configuration files in a directory, referring only to the configuration terraform plan Creates an execution plan, which lets you preview the changes that Terraform plans to make Custom validation Validation of your input variables to ensure they match what you would expect them to be У нас также есть некоторые инструменты тестирования, доступные вне Terraform:\ntflint\nНайти возможные ошибки (Find possible errors) Предупреждать об устаревшем синтаксисе, неиспользуемых объявлениях. (Warn about deprecated syntax, unused declarations.) Применять лучшие практики, соглашения об именовании. (Enforce best practices, naming conventions.) Инструменты сканирования\ncheckov - сканирование конфигураций облачной инфраструктуры для поиска неправильных конфигураций до их развертывания. tfsec - сканер безопасности статического анализа для кода Terraform. terrascan - статический анализатор кода для Infrastructure as Code. terraform-compliance - легковесный тестовый фреймворк, ориентированный на безопасность и соответствие требованиям, для terraform, позволяющий проводить негативное тестирование вашей инфраструктуры как кода. snyk - сканирует код Terraform на предмет неправильной конфигурации и проблем безопасности. Управляемое облачное предложение\nTerraform Sentinel - встроенный фреймворк политики как кода, интегрированный с продуктами HashiCorp Enterprise. Она позволяет принимать решения о политике на основе логики и может быть расширена для использования информации из внешних источников. Автоматизированное тестирование\nTerratest - Terratest - это библиотека Go, которая предоставляет шаблоны и вспомогательные функции для инфраструктуры тестирования. Стоит упомянуть\nTerraform Cloud - Terraform Cloud - это управляемый сервис компании HashiCorp. Оно устраняет необходимость в ненужных инструментах и документации для практиков, команд и организаций для использования Terraform в производстве.\nTerragrunt - Terragrunt - это тонкая обертка, которая предоставляет дополнительные инструменты для сохранения DRY конфигураций, работы с несколькими модулями Terraform и управления удаленным состоянием.\nAtlantis - Terraform Pull Request Automation.\nАльтернативы В день 57, когда мы начали этот раздел, мы упоминали, что есть некоторые альтернативы, и я очень планирую изучить их после завершения этой задачи.\nCloud Specific Cloud Agnostic AWS CloudFormation Terraform Azure Resource Manager Pulumi Google Cloud Deployment Manager Я использовал AWS CloudFormation, вероятно, больше всего из вышеперечисленного списка, он является родным для AWS, но я не использовал другие, кроме Terraform. Как вы можете себе представить, версии для конкретных облаков очень хороши для конкретного облака, но если у вас несколько облачных сред, то вам будет сложно перенести эти конфигурации или у вас будет несколько плоскостей управления для ваших усилий IaC.\nЯ думаю, что следующим интересным шагом для меня будет уделить некоторое время и узнать больше о Pulumi.\nИз сравнения Pulumi на их сайте\n“И Terraform, и Pulumi предлагают модель инфраструктуры желаемого состояния как кода, где код представляет желаемое состояние инфраструктуры, а механизм развертывания сравнивает это желаемое состояние с текущим состоянием стека и определяет, какие ресурсы должны быть созданы, обновлены или удалены”.\nСамое большое отличие, которое я вижу, заключается в том, что в отличие от HashiCorp Configuration Language (HCL) Pulumi позволяет использовать языки общего назначения, такие как Python, TypeScript, JavaScript, Go и .NET.\nКраткий обзор Introduction to Pulumi: Modern Infrastructure as Code Мне нравится простота и возможность выбора, которую вам предлагают, и я хочу разобраться в этом немного подробнее.\nНа этом мы завершаем раздел “Инфраструктура как код” и переходим к тому, что немного пересекается с управлением конфигурацией, и, в частности, по мере того, как мы переходим к общей картине управления конфигурацией, мы будем использовать Ansible для некоторых из этих задач и демонстраций.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform Pulumi - IaC in your favorite programming language! ","description":"","title":"62. Terraform - Тестирование, инструменты и альтернативы","uri":"/ru/tracks/90daysofdevops/day62/"},{"content":"Введение: Управление конфигурацией Сразу после раздела, посвященного инфраструктуре как коду, мы, вероятно, будем говорить об управлении конфигурацией или управлении конфигурацией приложений.\nУправление конфигурацией - это процесс поддержания приложений, систем и серверов в требуемом состоянии. Пересечение с Infrastructure as code заключается в том, что IaC гарантирует, что ваша инфраструктура находится в желаемом состоянии, но после этого, особенно terraform, не будет заботиться о желаемом состоянии настроек вашей ОС или приложений, и именно здесь на помощь приходят инструменты управления конфигурацией. Убедитесь, что система и приложения работают так, как ожидается, поскольку изменения происходят в Deane.\nУправление конфигурацией убережет вас от внесения мелких или крупных изменений, которые останутся недокументированными.\nПочему вы хотите использовать управление конфигурацией Сценарий или почему вы хотите использовать управление конфигурацией, познакомьтесь с Дином. Он наш системный администратор, и Дин - счастливый турист, который работает над всеми своими системами. работает над всеми системами в своем окружении.\nЧто произойдет, если их система выйдет из строя, если случится пожар, сервер выйдет из строя? Дин точно знает, что делать, он может легко устранить пожар, но если несколько серверов начнут выходить из строя, особенно если у вас большая и расширяющаяся среда, вот почему Дину действительно необходимо иметь инструмент управления конфигурацией. Инструменты управления конфигурацией могут помочь Дину выглядеть как рок-звезда, все, что ему нужно сделать, это настроить правильные коды, которые позволят ему быстро, эффективно и масштабно передать инструкции по настройке каждого из серверов.\nИнструменты управления конфигурацией Существует множество инструментов управления конфигурацией, и каждый из них имеет специфические особенности, которые делают его лучше для одних ситуаций, чем для других.\nНа этом этапе мы быстро рассмотрим варианты, показанные на рисунке выше, прежде чем сделать выбор, какой из них мы будем использовать и почему.\nChef\nChef обеспечивает последовательное применение конфигурации в любой среде, в любом масштабе с помощью автоматизации инфраструктуры. Chef - это инструмент с открытым исходным кодом, разработанный компанией OpsCode и написанный на Ruby и Erlang. Chef лучше всего подходит для организаций, которые имеют гетерогенную инфраструктуру и ищут зрелые решения. Рецепты и Cookbooks определяют код конфигурации для ваших систем. Pro - Доступна большая коллекция рецептов Pro - Хорошо интегрируется с Git, что обеспечивает надежный контроль версий. Против - Крутая кривая обучения, требуется значительное количество времени. Против - Главный сервер не имеет большого контроля. Архитектура - сервер / клиенты Простота настройки - Умеренная Язык - Процедурный - Указать, как выполнить задачу Puppet\nPuppet - это инструмент управления конфигурацией, который поддерживает автоматическое развертывание. Puppet построен на Ruby и использует DSL для написания манифестов. Puppet также хорошо работает с гетерогенной инфраструктурой, где основное внимание уделяется масштабируемости. За - Большое сообщество поддержки. За - Хорошо развитый механизм отчетности. Против - Продвинутые задачи требуют знания языка Ruby. Против - Главный сервер не имеет большого контроля. Архитектура - сервер / клиенты Простота установки - Умеренная Язык - Декларативный - указывать только то, что нужно делать Ansible\nAnsible - это инструмент автоматизации ИТ, который автоматизирует управление конфигурацией, предоставление облака, развертывание и оркестровку. Ядро плейбуков Ansible написано на языке YAML. (Следует сделать раздел о YAML, так как мы уже несколько раз сталкивались с этим). Ansible хорошо работает в средах, где основное внимание уделяется быстрой настройке и запуску. Работает на основе плейбуков, которые предоставляют инструкции вашим серверам. Pro - Не нужны агенты на удаленных узлах. Pro - YAML легко изучить. Против - Скорость работы часто ниже, чем у других инструментов (быстрее, чем Дин делает это сам вручную). Против - YAML не такой мощный, как Ruby, но его легче освоить. Архитектура - Только клиент Простота настройки - Очень просто Язык - Процедурный - Указать, как выполнить задачу SaltStack\nSaltStack - это инструмент на основе CLI, который автоматизирует управление конфигурацией и удаленное выполнение. SaltStack основан на Python, а инструкции написаны на YAML или собственном DSL. Идеально подходит для сред, где приоритетом является масштабируемость и отказоустойчивость. Плюсы - Простота использования при запуске Плюсы - Хороший механизм отчетности Против - Фаза установки сложная Против - Новый веб-уи, который гораздо менее проработан, чем другие. Архитектура - сервер / клиенты Простота установки - Умеренная Язык - Декларативный - указывайте только то, что нужно делать Ansible vs Terraform Инструментом, который мы будем использовать для этого раздела, будет Ansible. (Простой в использовании и требуются основы языка).\nЯ думаю, что важно коснуться некоторых различий между Ansible и Terraform, прежде чем мы рассмотрим инструментарий немного подробнее. | |Ansible |Terraform | | ————- | ————————————————————- | —————————————————————– | |Type |Ansible is a configuration management tool |Terraform is a an orchestration tool | |Infrastructure |Ansible provides support for mutable infrastructure |Terraform provides support for immutable infrastructure | |Language |Ansible follows procedural language |Terraform follows a declartive language | |Provisioning |Ansible provides partial provisioning (VM, Network, Storage) |Terraform provides extensive provisioning (VM, Network, Storage) | |Packaging |Ansible provides complete support for packaging \u0026 templating |Terraform provides partial support for packaging \u0026 templating | |Lifecycle Mgmt |Ansible does not have lifecycle management |Terraform is heavily dependant on lifecycle and state mgmt |\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! ","description":"","title":"63. Инструменты управления конфигурацией - Ansible/Terraform","uri":"/ru/tracks/90daysofdevops/day63/"},{"content":"Основы Ansible\nAnsible: Начало работы Мы немного рассказали о том, что такое Ansible, на вчерашней большой сессии, но здесь мы собираемся начать с более подробной информации. Во-первых, Ansible поставляется компанией RedHat. Во-вторых, это агент, подключается через SSH и выполняет команды. В-третьих, он кроссплатформенный (Linux \u0026 macOS, WSL2) и с открытым исходным кодом (есть также платный корпоративный вариант) Ansible толкает конфигурацию по сравнению с другими моделями.\nУстановка Ansible Как вы можете себе представить, RedHat и команда Ansible проделали фантастическую работу по документированию Ansible. Обычно это начинается с шагов по установке, которые вы можете найти здесь. Помните, мы говорили, что Ansible - это инструмент автоматизации без агентов, инструмент развертывается на системе, называемой “узел управления”, с этого узла управления осуществляется управление машинами и другими устройствами (возможно, сетевыми) по SSH.\nВ документации по ссылке выше говорится, что ОС Windows не может использоваться в качестве узла управления.\nДля моего узла управления и, по крайней мере, для этой демонстрации я собираюсь использовать виртуальную машину Linux, которую мы создали еще в разделе Linux в качестве узла управления.\nЭта система работала под управлением Ubuntu, и для ее установки достаточно выполнить следующие команды.\nsudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible Теперь у нас должна быть установлена ansible на нашем узле управления, вы можете проверить это, запустив ansible --version, и вы должны увидеть что-то похожее на это ниже.\nПрежде чем мы перейдем к управлению другими узлами в нашей среде, мы также можем проверить функциональность ansible, выполнив команду на нашей локальной машине ansible localhost -m ping будет использовать Ansible Module, и это быстрый способ выполнить одну задачу на многих различных системах. Я имею в виду, что это не очень весело только с локальным хостом, но представьте, что вы хотите получить что-то или убедиться, что все ваши системы работают, а у вас 1000+ серверов и устройств.\nИли реальное использование модуля в реальной жизни может быть чем-то вроде ansible webservers --m service -a \"name=httpd state=started\", это скажет нам, запущена ли служба httpd на всех наших веб-серверах. Я привел термин webservers, используемый в этой команде.\nhosts Как я использовал localhost выше для запуска простого модуля ping против системы, я не могу указать другую машину в моей сети, например, в среде, которую я использую, мой хост Windows, на котором работает VirtualBox, имеет сетевой адаптер с IP 10.0.0.1, но вы можете видеть ниже, что я могу связаться с ним с помощью ping, но я не могу использовать ansible для выполнения этой задачи.\nДля того чтобы указать наши узлы или узлы, которые мы хотим автоматизировать с помощью этих задач, нам необходимо их определить. Мы можем определить их, перейдя в каталог /etc/ansible в вашей системе.\nФайл, который мы хотим отредактировать - это файл hosts, используя текстовый редактор, мы можем зайти в него и определить наши хосты. Файл hosts содержит множество отличных инструкций по использованию и изменению файла. Мы хотим прокрутить вниз и создать новую группу под названием [windows] и добавить наш IP-адрес 10.0.0.1 для этого хоста. Сохраните файл.\nОднако помните, я говорил, что вам понадобится SSH, чтобы Ansible мог подключиться к вашей системе. Как вы можете видеть ниже, когда я запускаю ansible windows -m ping, мы получаем недостижимый результат, потому что не удалось подключиться через SSH.\nТеперь я также начал добавлять дополнительные хосты в наш инвентарь, другое название для этого файла, так как здесь вы собираетесь определить все ваши устройства, это могут быть сетевые устройства, например, коммутаторы и маршрутизаторы, которые также будут добавлены сюда и сгруппированы. В нашем файле hosts я также добавил свои учетные данные для доступа к группе систем linux.\nТеперь, если мы запустим ansible linux -m ping, мы получим успех, как показано ниже.\nДалее у нас есть требования к узлам, это целевые системы, на которых вы хотите автоматизировать конфигурацию. Мы не устанавливаем на них ничего для Ansible (то есть, мы можем установить программное обеспечение, но нам не нужен клиент Ansible). Ansible будет устанавливать соединение по SSH и отправлять все по SFTP (если вы хотите и у вас настроен SSH, вы можете использовать SCP против SFTP).\nКоманды Ansible Вы видели, что мы смогли запустить ansible linux -m ping на нашей Linux машине и получить ответ, в принципе, с Ansible у нас есть возможность запускать множество специальных команд. Но очевидно, что вы можете запустить это против группы систем и получить эту информацию обратно. ad hoc commands\nЕсли вы сталкиваетесь с повторением команд или, что еще хуже, вам приходится входить в отдельные системы для выполнения этих команд, то Ansible может помочь в этом случае. Например, простая команда ниже даст нам вывод всех сведений об операционной системе для всех систем, которые мы добавим в нашу группу linux. ansible linux -a \"cat /etc/os-release\".\nДругими вариантами использования могут быть перезагрузка систем, копирование файлов, управление упаковщиками и пользователями. Вы также можете объединить специальные команды с модулями Ansible.\nСпециальные команды используют декларативную модель, рассчитывая и выполняя действия, необходимые для достижения заданного конечного состояния. Они достигают идемпотентности, проверяя текущее состояние перед началом работы и ничего не делая, если текущее состояние не отличается от заданного конечного состояния.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! ","description":"","title":"64. Ansible Введение","uri":"/ru/tracks/90daysofdevops/day64/"},{"content":"Ansible Playbooks В этом разделе мы рассмотрим основную причину, которую я вижу, по крайней мере, для Ansible. Я имею в виду, что это здорово - взять одну команду и обратиться ко многим различным серверам для выполнения простых команд, таких как перезагрузка длинного списка серверов и избавление от необходимости подключаться к каждому из них по отдельности.\nНо как насчет того, чтобы взять голую операционную систему, объявить программное обеспечение и службы, которые мы хотим запустить на этой системе, и убедиться, что все они работают в нужном состоянии.\nЗдесь на помощь приходят учебники Ansible. Плейбук позволяет нам взять группу серверов и выполнить задачи конфигурации и установки для этой группы.\nФормат плейбука Плейбук \u003e Игры \u003e Задачи\nЕсли вы занимаетесь спортом, вы, возможно, сталкивались с термином “плейбук”. Плейбук рассказывает команде о том, как вы будете играть, состоящий из различных пьес и задач. Если мы считаем пьесы декорациями в спорте или игре, а задачи связаны с каждой пьесой, у вас может быть несколько задач, составляющих пьесу, а в плейбуке может быть несколько различных пьес.\nЭти плейбуки написаны на YAML (YAML - это не язык разметки), вы найдете много разделов, которые мы уже рассмотрели, особенно контейнеры и Kubernetes, в которых используются файлы конфигурации в формате YAML.\nДавайте рассмотрим простой плейбук под названием playbook.yml.\n- name: Simple Play hosts: localhost connection: local tasks: - name: Ping me ping: - name: print os debug: msg: \"{{ ansible_os_family }}\" Вы найдете вышеуказанный файл simple_play. Если мы затем используем команду ansible-playbook simple_play.yml, то пройдем следующие шаги.\nВы видите, что первая задача “сбор шагов” произошла, но мы не вызывали или не просили об этом? Этот модуль автоматически вызывается плейбуками для сбора полезных переменных об удаленных хостах. ansible.builtin.setup\nНашей второй задачей было установить ping, это не ICMP ping, а python скрипт, который сообщает pong об успешном соединении с удаленным или локальным хостом. ansible.builtin.ping\nЗатем наша третья или на самом деле вторая определенная задача, так как первая будет выполняться, если вы не отключите печать сообщения, сообщающего нам о нашей ОС. В этой задаче мы используем условия, мы можем запустить этот плейбук на всех различных типах операционных систем, и это вернет нам имя ОС. Мы просто передаем этот вывод для удобства, но мы могли бы добавить задачу, чтобы сказать что-то вроде:\ntasks: - name: \"shut down Debian flavoured systems\" command: /sbin/shutdown -t now when: ansible_os_family == \"Debian\" Vagrant для настройки нашего окружения Мы будем использовать Vagrant для настройки нашего узлового окружения, я собираюсь оставить разумные 4 узла, но вы, надеюсь, увидите, что их может быть 300 или 3000. В этом и заключается сила Ansible и других инструментов управления конфигурацией, чтобы иметь возможность настраивать ваши серверы.\nВы можете найти этот файл здесь (Vagrantfile)\nVagrant.configure(\"2\") do |config| servers=[ { :hostname =\u003e \"db01\", :box =\u003e \"bento/ubuntu-21.10\", :ip =\u003e \"192.168.169.130\", :ssh_port =\u003e '2210' }, { :hostname =\u003e \"web01\", :box =\u003e \"bento/ubuntu-21.10\", :ip =\u003e \"192.168.169.131\", :ssh_port =\u003e '2211' }, { :hostname =\u003e \"web02\", :box =\u003e \"bento/ubuntu-21.10\", :ip =\u003e \"192.168.169.132\", :ssh_port =\u003e '2212' }, { :hostname =\u003e \"loadbalancer\", :box =\u003e \"bento/ubuntu-21.10\", :ip =\u003e \"192.168.169.134\", :ssh_port =\u003e '2213' } ] config.vm.base_address = 600 servers.each do |machine| config.vm.define machine[:hostname] do |node| node.vm.box = machine[:box] node.vm.hostname = machine[:hostname] node.vm.network :public_network, bridge: \"Intel(R) Ethernet Connection (7) I219-V\", ip: machine[:ip] node.vm.network \"forwarded_port\", guest: 22, host: machine[:ssh_port], id: \"ssh\" node.vm.provider :virtualbox do |v| v.customize [\"modifyvm\", :id, \"--memory\", 2048] v.customize [\"modifyvm\", :id, \"--name\", machine[:hostname]] end end end end Используйте команду vagrant up, чтобы запустить эти машины в VirtualBox, Вы можете добавить больше памяти, а также определить разные частные_сетевые адреса для каждой машины, но это работает в моей среде. Помните, что наш блок управления - это рабочий стол Ubuntu, который мы установили в разделе Linux.\nЕсли вы ограничены в ресурсах, вы также можете запустить vagrant up web01 web02, чтобы поднять только веб-серверы, которые мы используем здесь.\nКонфигурация хоста Ansible Теперь, когда наша среда готова, мы можем проверить ansible, и для этого мы будем использовать наш рабочий стол Ubuntu (вы можете использовать его, но вы также можете использовать любую машину на базе Linux в вашей сети, доступную для сети ниже) в качестве нашего управления, давайте также добавим новые узлы в нашу группу в файле ansible hosts, Вы можете считать этот файл инвентаризацией, альтернативой этому может быть другой файл инвентаризации, который вызывается как часть вашей команды ansible с -i filename, это может быть полезно по сравнению с использованием файла host, так как вы можете иметь разные файлы для разных сред, например, production, test и staging. Поскольку мы используем стандартный файл hosts, нам не нужно его указывать, так как он будет использоваться по умолчанию.\nЯ добавил следующее в файл hosts по умолчанию.\n[control] ansible-control [proxy] loadbalancer [webservers] web01 web02 [database] db01 Прежде чем двигаться дальше, мы хотим убедиться, что можем выполнить команду для наших узлов, давайте выполним ansible nodes -m command -a hostname, эта простая команда проверит, что у нас есть подключение и сообщит имена наших узлов.\nТакже обратите внимание, что я добавил эти узлы и IP на мой узел управления Ubuntu в файл /etc/hosts для обеспечения подключения. Нам также может понадобиться выполнить конфигурацию SSH для каждого узла с блока Ubuntu.\n192.168.169.140 ansible-control 192.168.169.130 db01 192.168.169.131 web01 192.168.169.132 web02 192.168.169.133 loadbalancer На этом этапе мы хотим выполнить настройку SSH ключей между узлами управления и сервера. Это то, что мы будем делать дальше, другим способом здесь может быть добавление переменных в ваш файл hosts для указания имени пользователя и пароля. Я бы не советовал этого делать, так как это никогда не будет лучшей практикой.\nЧтобы настроить SSH и общий доступ между узлами, выполните следующие шаги, вам будет предложено ввести пароль (vagrant), и вам, вероятно, придется нажать y несколько раз, чтобы согласиться.\nssh-keygen\nssh-copy-id localhost\nТеперь, если все ваши ВМ включены, вы можете запустить команду ssh-copy-id web01 \u0026\u0026 ssh-copy-id web02 \u0026\u0026 ssh-copy-id loadbalancer \u0026\u0026 ssh-copy-id db01, которая запросит у вас пароль, в нашем случае пароль vagrant.\nЯ не запускаю все свои виртуальные машины, а запускаю только веб-серверы, поэтому я выдал команду sh-copy-id web01 \u0026\u0026 ssh-copy-id web02.\nПеред запуском любых плейбуков я хочу убедиться, что у меня есть простое соединение с моими группами, поэтому я запустил ansible webservers -m ping для проверки соединения.\nНаш первый “настоящий” плейбук Ansible Наш первый плейбук Ansible будет настраивать наши веб-серверы, мы сгруппировали их в нашем файле hosts под группировкой [webservers].\nПеред запуском нашего плейбука мы можем убедиться, что на web01 и web02 не установлен apache. В верхней части скриншота ниже показано расположение папок и файлов, которые я создал в моей системе управления ansible для запуска этого плейбука, у нас есть playbook1.yml, затем в папке templates у нас есть файлы index.html.j2 и ports.conf.j2. Вы можете найти эти файлы в папке, указанной выше в репозитории.\nЗатем мы подключаемся по SSH к web01, чтобы проверить, установлен ли у нас apache?\nИз вышеприведенного видно, что у нас не установлен apache на web01, поэтому мы можем исправить это, запустив следующий плейбук.\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps\" tasks: - name: ensure apache is at the latest version apt: name: apache2 state: latest - name: write the apache2 ports.conf config file template: src: templates/ports.conf.j2 dest: /etc/apache2/ports.conf notify: - restart apache - name: write a basic index.html file template: src: templates/index.html.j2 dest: /var/www/html/index.html notify: - restart apache - name: ensure apache is running service: name: apache2 state: started handlers: - name: restart apache service: name: apache2 state: restarted Разбираем вышеприведенный плейбук:\n- hosts: webservers означает, что наша группа, на которой будет запущен этот плейбук, называется webservers. become: yes означает, что наш пользователь, запускающий плейбук, станет root на наших удаленных системах. Вам будет предложено ввести пароль root. Затем у нас есть vars, и это определяет некоторые переменные окружения, которые мы хотим использовать на наших веб-серверах. После этого мы приступаем к выполнению наших задач,\nЗадача 1 - убедиться, что apache работает на последней версии. Задача 2 - написать файл ports.conf из нашего исходного файла, который находится в папке templates. Задача 3 - создание базового файла index.html Задача 4 - убедиться, что apache запущен. Наконец, у нас есть раздел обработчиков, Handlers: Running operations on change\n“Иногда вы хотите, чтобы задача выполнялась только тогда, когда на машине происходят изменения. Например, вы можете захотеть перезапустить службу, если задача обновляет конфигурацию этой службы, но не перезапускать ее, если конфигурация не изменилась. Для решения этой задачи в Ansible используются обработчики. Обработчики - это задачи, которые выполняются только при получении уведомления. Каждый обработчик должен иметь глобально уникальное имя”.\nНа этом этапе вы можете подумать, но мы развернули 5 виртуальных машин (включая нашу машину Ubuntu Desktop, которая действует как наш Ansible Control) Остальные системы будут задействованы в оставшейся части раздела.\nЗапуск нашего плейбука Теперь мы готовы запустить наш учебник на наших узлах. Для запуска нашего плейбука мы можем использовать ansible-playbook playbook1.yml Мы определили наши узлы, на которых будет работать наш учебник, и это позволит выполнить наши задачи, которые мы определили.\nПосле завершения команды мы получим результат, показывающий наши пьесы и задачи, это может занять некоторое время, вы можете видеть на изображении ниже, что это заняло некоторое время, чтобы пойти и установить наше желаемое состояние.\nЗатем мы можем дважды проверить это, зайдя в узел и проверив, что на нашем узле установлено программное обеспечение.\nТеперь, когда мы развернули два автономных веб-сервера, мы можем перейти на соответствующие IP, которые мы определили, и получить наш новый веб-сайт.\nМы будем опираться на это руководство по ходу работы над остальной частью этого раздела. Мне также интересно взять наш рабочий стол Ubuntu и посмотреть, сможем ли мы загрузить наши приложения и конфигурацию с помощью Ansible, поэтому мы также можем коснуться этого. Вы видели, что мы можем использовать локальный хост в наших командах, мы также можем запускать плейбуки, например, на нашем локальном хосте.\nЕще одна вещь, которую следует добавить, заключается в том, что мы работаем только с виртуальными машинами Ubuntu, но Ansible не зависит от целевых систем. Альтернативы, которые мы уже упоминали ранее для управления системами, могут быть сервер за сервером (не масштабируемый, когда вы получаете большое количество серверов, плюс боль даже с 3 узлами), мы также можем использовать скрипты оболочки, которые мы рассматривали в разделе Linux, но эти узлы потенциально разные, так что да, это можно сделать, но тогда кто-то должен поддерживать и управлять этими скриптами. Ansible бесплатна и позволяет легко справиться с этой задачей по сравнению с необходимостью иметь специализированный скрипт.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"65. Ansible Playbooks - Часть 1","uri":"/ru/tracks/90daysofdevops/day65/"},{"content":"Ansible Playbooks Продолжение… В нашем последнем разделе мы начали с создания небольшой лаборатории, используя файл Vagrant для развертывания 4 машин, и мы использовали нашу Linux-машину, которую мы создали в этом разделе, в качестве нашей системы управления Ansible.\nМы также проверили несколько скриптов плейбуков, и в конце у нас был плейбук, который сделал наши web01 и web02 отдельными веб-серверами.\nНаведение порядка Прежде чем перейти к дальнейшей автоматизации и развертыванию, мы должны рассказать о том, как сохранить наш плейбук аккуратным и опрятным и как мы можем разделить наши такты и обработчики по подпапкам.\nВ основном мы собираемся копировать наши задачи в их собственный файл в папке.\n- name: ensure apache is at the latest version apt: name=apache2 state=latest - name: write the apache2 ports.conf config file template: src=templates/ports.conf.j2 dest=/etc/apache2/ports.conf notify: restart apache - name: write a basic index.html file template: src: templates/index.html.j2 dest: /var/www/html/index.html notify: - restart apache - name: ensure apache is running service: name: apache2 state: started и то же для обработчиков.\n- name: restart apache service: name: apache2 state: restarted Затем в нашем плейбуке, который теперь называется playbook2.yml, мы указываем на эти файлы. Все эти файлы можно найти по адресу ansible-scenario2.\nВы можете проверить это на своей контрольной машине. Если вы скопировали файлы из репозитория, вы должны были заметить, что кое-что изменилось в пункте “написать основной файл index.html”\nДавайте выясним, какое простое изменение я сделал. Использование curl web01:8000\nМы только что привели в порядок наш плейбук и начали разделять области, которые могут сделать плейбук очень перегруженным в масштабе.\nРоли и Ansible Galaxy На данный момент мы развернули 4 виртуальные машины и настроили 2 из них как веб-серверы, но у нас есть еще несколько специфических функций, а именно: сервер базы данных и балансировщик нагрузки или прокси. Для того чтобы сделать это и привести в порядок наш репозиторий, мы можем использовать роли в Ansible.\nДля этого мы воспользуемся командой ansible-galaxy, которая предназначена для управления ролями Ansible в общих репозиториях.\nМы собираемся использовать ansible-galaxy для создания роли для apache2, где мы собираемся разместить специфику наших веб-серверов.\nПриведенная выше команда ansible-galaxy init roles/apache2 создаст структуру папок, которую мы показали выше. Следующим шагом нам нужно переместить существующие задачи и шаблоны в соответствующие папки в новой структуре.\nКопировать и вставить легко для перемещения этих файлов, но нам также нужно внести изменения в tasks/main.yml, чтобы указать его на apache2_install.yml.\nНам также нужно изменить наш playbook, чтобы он ссылался на нашу новую роль. В playbook1.yml и playbook2.yml мы определяем наши задачи и обработчики по-разному, так как мы изменили их между двумя версиями. Нам нужно изменить наш плейбук, чтобы использовать эту роль, как показано ниже:\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\" roles: - apache2 Теперь мы можем запустить наш плейбук снова, на этот раз с новым именем плейбука ansible-playbook playbook3.yml Вы заметите обесценивание, мы можем исправить это дальше.\nХорошо, амортизация хотя наш плейбук запустился, теперь мы должны исправить наши пути, для этого я изменил опцию include в tasks/main.yml на import_tasks, как показано ниже.\nВы можете найти эти файлы в папке ansible-scenario3.\nМы также собираемся создать еще несколько ролей, используя ansible-galaxy, которые мы собираемся создать:\ncommon = for all of our servers (ansible-galaxy init roles/common) nginx = for our loadbalancer (ansible-galaxy init roles/nginx) Я собираюсь оставить этот вариант здесь, а в следующей сессии мы начнем работать над другими узлами, которые мы развернули, но еще ничего не сделали.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"66. Ansible Playbooks - Часть 2","uri":"/ru/tracks/90daysofdevops/day66/"},{"content":"На последнем занятии мы рассмотрели роли и использовали команду ansible-galaxy, чтобы помочь создать структуру папок для некоторых ролей, которые мы будем использовать. В итоге мы получили гораздо более аккуратное рабочее хранилище для нашего кода конфигурации, поскольку все спрятано в папках ролей.\nОднако мы использовали только роль apache2 и получили рабочий playbook3.yaml для работы с нашими веб-серверами.\nНа данном этапе, если вы использовали только vagrant up web01 web02, пришло время запустить vagrant up loadbalancer, который откроет другую систему Ubuntu, которую мы будем использовать в качестве балансировщика нагрузки/прокси.\nМы уже определили эту новую машину в нашем файле hosts, но у нас нет настроенного ssh-ключа, пока он не доступен, поэтому нам нужно также запустить ssh-copy-id loadbalancer, когда система будет запущена и готова.\nОбщая роль В конце вчерашней сессии я создал роль common, роль common будет использоваться на всех наших серверах, в то время как другие роли специфичны для конкретных случаев использования, сейчас приложения, которые я собираюсь установить в качестве common, не так просты, и я не вижу много причин для этого, но это показывает цель. В структуре папок нашей общей роли перейдите в папку tasks, и у вас появится файл main.yml. В этом yaml нам нужно указать на наш файл install_tools.yml, и мы делаем это, добавляя строку - import_tasks: install_tools.yml. Раньше это был include, но он скоро будет устаревшим, поэтому мы используем import_tasks.\n- name: \"Install Common packages\" apt: name={{ item }} state=latest with_items: - neofetch - tree - figlet Затем в нашем плейбуке мы добавляем общую роль для каждого блока хоста.\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\" roles: - common - apache2 nginx Следующим этапом будет установка и настройка nginx на нашем виртуальном компьютере loadbalancer. Как и в общей структуре папок, у нас есть nginx, основанный на последнем сеансе.\nПрежде всего, мы добавим блок host в наш playbook. Этот блок будет включать нашу общую роль, а затем нашу новую роль nginx.\nПлейбук можно найти здесь. playbook4.yml\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\" roles: - common - apache2 - hosts: proxy become: yes roles: - common - nginx Для того чтобы это что-то значило, мы должны определить наши задачи, которые мы хотим запустить, таким же образом мы изменим main.yml в задачах, чтобы указать на два файла, один для установки и один для конфигурации.\nЕсть и другие файлы, которые я изменил в зависимости от желаемого результата, посмотрите в папке ansible-scenario4 все измененные файлы. Вам следует проверить папки tasks, handlers и templates в папке nginx, и вы найдете эти дополнительные изменения и файлы.\nЗапуск обновленного плейбука Со вчерашнего дня мы добавили роль common, которая теперь будет устанавливать некоторые пакеты в нашей системе, а затем мы также добавили роль nginx, которая включает установку и настройку.\nДавайте запустим наш playbook4.yml, используя ansible-playbook playbook4.yml.\nТеперь, когда мы настроили наши веб-серверы и loadbalancer, мы должны иметь возможность перейти по адресу http://192.168.169.134/, который является IP-адресом нашего loadbalancer.\nЕсли вы следите за развитием событий и у вас нет такого состояния, то это может быть связано с IP-адресами серверов в вашем окружении. Файл находится в templates\\mysite.j2 и выглядит примерно так, как показано ниже: Вам необходимо обновить IP-адреса ваших веб-серверов.\nupstream webservers { server 192.168.169.131:8000; server 192.168.169.132:8000; } server { listen 80; location / { proxy_pass http://webservers; } } Я уверен, что все, что мы установили, в порядке, но давайте воспользуемся специальной командой с помощью ansible, чтобы проверить установку этих общих инструментов.\nansible loadbalancer -m command -a neofetch.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible TЭтот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"67. Роли и развертывание балансировщика нагрузки","uri":"/ru/tracks/90daysofdevops/day67/"},{"content":"Теги Поскольку мы оставили наш плейбук во время вчерашней сессии, нам нужно будет запустить все задачи и пьесы в рамках этого плейбука. Это означает, что нам придется запустить веб-серверы и балансировщик нагрузки до конца.\nОднако теги могут позволить нам отделить их друг от друга, если мы захотим. Это может быть эффективным шагом, если в нашей среде есть очень большие и длинные плейбуки.\nВ нашем файле плейбука, в данном случае мы используем ansible-scenario5\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\" roles: - common - apache2 tags: web - hosts: proxy become: yes roles: - common - nginx tags: proxy Затем мы можем подтвердить это с помощью команды ansible-playbook playbook5.yml --list-tags, а список тегов будет содержать теги, которые мы определили в нашем плейбуке.\nТеперь, если мы хотим нацелиться только на прокси, мы можем сделать это, выполнив ansible-playbook playbook5.yml --tags proxy, и это, как вы можете видеть ниже, запустит плейбук только против прокси.\nТеги могут быть добавлены и на уровне задач, так что мы можем получить действительно подробную информацию о том, где и что вы хотите, чтобы произошло. Это могут быть теги, ориентированные на приложения, например, мы можем пройтись по задачам и пометить наши задачи на основе установки, настройки или удаления. Еще один очень полезный тег, который вы можете использовать, это\ntag: always, который гарантирует, что независимо от того, какие -теги вы используете в вашей команде, если что-то помечено значением always, то оно всегда будет запущено при выполнении команды ansible-playbook.\nС помощью тегов мы также можем объединить несколько тегов вместе, и если мы выполним команду ansible-playbook playbook5.yml --tags proxy,web, то будут запущены все элементы с этими тегами. Очевидно, что в нашем случае это будет означать то же самое, что и запуск самого плейбука, но если бы у нас было несколько других плейбуков, то это имело бы смысл.\nВы также можете определить более одного тега.\nПеременные В Ansible существует два основных типа переменных.\nСозданная пользователем (User created) Факты Ansible (Ansible Facts) Факты Ansible Каждый раз, когда мы запускали наши плейбуки, у нас была задача, которую мы не определяли, называемая “Сбор фактов”, мы можем использовать эти переменные или факты, чтобы заставить вещи происходить с нашими задачами автоматизации.\nЕсли мы выполним следующую команду ansible proxy -m setup, то увидим много выходных данных в формате JSON. Однако на вашем терминале будет много информации, чтобы действительно использовать ее, поэтому мы хотим вывести ее в файл, используя команду ansible proxy -m setup \u003e\u003e facts.json, вы можете увидеть этот файл в этом репозитории, ansible-scenario5\nЕсли открыть этот файл, то можно увидеть всевозможную информацию для нашей команды. Мы можем получить наши IP-адреса, архитектуру, версию биоса. Много полезной информации, если мы захотим использовать ее в наших плейбуках.\nИдея заключается в том, чтобы потенциально использовать одну из этих переменных в шаблоне nginx mysite.j2, где мы жестко закодировали IP-адреса наших веб-серверов. Вы можете сделать это, создав цикл for в вашем mysite.j2, который будет проходить через группу [webservers], что позволит нам иметь более двух веб-серверов, автоматически и динамически созданных или добавленных в эту конфигурацию балансировщика нагрузки.\n#Dynamic Config for server {{ ansible_facts['nodename'] }} upstream webservers { {% for host in groups['webservers'] %} server {{ hostvars[host]['ansible_facts']['nodename'] }}:8000; {% endfor %} } server { listen 80; location / { proxy_pass http://webservers; } } Результат вышеописанных действий будет выглядеть так же, как и сейчас, но если мы добавим больше веб-серверов или удалим один, это динамически изменит конфигурацию прокси. Чтобы это работало, необходимо настроить разрешение имен.\nСозданные пользователем Переменные, созданные пользователем, - это то, что мы создали сами. Если вы посмотрите в наш playbook, то увидите, что у нас есть vars:, а затем список из трех переменных, которые мы используем.\n- hosts: webservers become: yes vars: http_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\" roles: - common - apache2 tags: web - hosts: proxy become: yes roles: - common - nginx tags: proxy Однако мы можем очистить наш плейбук от переменных, переместив их в собственный файл. Мы так и сделаем, но перенесем их в папку ansible-scenario6. В корне этой папки мы создадим папку group_vars. Затем мы создадим еще одну папку под названием all (все группы получат эти переменные). В ней мы создадим файл под названием common_variables.yml и скопируем в него наши переменные из нашего плейбука. Удалим их из плейбука вместе с vars:.\nhttp_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\" Поскольку мы связываем это с глобальной переменной, мы также можем добавить сюда наши серверы NTP и DNS. Переменные устанавливаются из созданной нами структуры папок. Ниже вы можете видеть, как чисто выглядит наш Playbook.\n- hosts: webservers become: yes roles: - common - apache2 tags: web - hosts: proxy become: yes roles: - common - nginx tags: proxy Одной из этих переменных был http_port, мы можем использовать его снова в нашем цикле for в файле mysite.j2, как показано ниже:\n#Dynamic Config for server {{ ansible_facts['nodename'] }} upstream webservers { {% for host in groups['webservers'] %} server {{ hostvars[host]['ansible_facts']['nodename'] }}:{{ http_port }}; {% endfor %} } server { listen 80; location / { proxy_pass http://webservers; } } Мы также можем определить ansible fact в нашем файле roles/apache2/templates/index.html.j2, чтобы мы могли понять, на каком веб-сервере мы находимся.\n\u003chtml\u003e \u003ch1\u003e{{ html_welcome_msg }}! I'm webserver {{ ansible_facts['nodename'] }} \u003c/h1\u003e \u003c/html\u003e Результаты выполнения команды ansible-playbook playbook6.yml с нашими изменениями переменных означают, что когда мы нажимаем на наш loadbalancer, вы можете увидеть, что мы нажимаем на любой из веб-серверов, которые есть в нашей группе. Мы также можем добавить папку host_vars и создать web01.yml и иметь определенное сообщение или изменить то, как это выглядит для каждого хоста, если захотим.\nФайлы инвентаризации До сих пор мы использовали файл hosts по умолчанию в папке /etc/ansible для определения наших хостов. Однако мы можем иметь разные файлы для разных окружений, например, production и staging. Я не собираюсь создавать больше окружений. Но мы можем создавать свои собственные файлы хостов.\nМы можем создать несколько файлов для нашего различного количества серверов и узлов. Мы будем вызывать их с помощью ansible-playbook -i dev playbook.yml Вы также можете определить переменные в файле hosts и затем распечатать их или использовать эти переменные где-нибудь еще в своих плейбуках. Например, в примере и учебном курсе, за которым я слежу ниже, они добавили переменную окружения, созданную в файле host, в шаблон веб-страницы loadbalancer, чтобы показать окружение как часть сообщения веб-страницы.\nРазвертывание нашего сервера базы данных У нас осталась еще одна машина, которую мы еще не включили и не настроили. Мы можем сделать это с помощью команды vagrant up db01 из места, где находится наш Vagrantfile. Когда машина будет запущена и доступна, нам нужно убедиться, что SSH-ключ скопирован с помощью ssh-copy-id db01, чтобы мы могли получить доступ.\nМы будем работать из папки ansible-scenario7.\nЗатем воспользуемся командой ansible-galaxy init roles/mysql, чтобы создать новую структуру папок для новой роли под названием “mysql”.\nВ нашем плейбуке мы собираемся добавить новый блок для конфигурации базы данных. В файле /etc/ansible/hosts мы определили нашу группу базы данных. Затем мы указываем нашей группе базы данных роль common и новую роль mysql, которую мы создали в предыдущем шаге. Мы также помечаем нашу группу базы данных тегами database, что означает, как мы обсуждали ранее, что мы можем выбрать запуск только с этими тегами, если захотим.\n- hosts: webservers become: yes roles: - common - apache2 tags: web - hosts: proxy become: yes roles: - common - nginx tags: proxy - hosts: database become: yes roles: - common - mysql tags: database Теперь в структуре папок с нашими ролями автоматически создается дерево, в котором нам нужно заполнить следующее:\nHandlers - main.yml\n# handlers file for roles/mysql - name: restart mysql service: name: mysql state: restarted Tasks - install_mysql.yml, main.yml \u0026 setup_mysql.yml\ninstall_mysql.yml - this task is going to be there to install mysql and ensure that the service is running.\n- name: \"Install Common packages\" apt: name={{ item }} state=latest with_items: - python3-pip - mysql-client - python3-mysqldb - libmysqlclient-dev - name: Ensure mysql-server is installed latest version apt: name=mysql-server state=latest - name: Installing python module MySQL-python pip: name: PyMySQL - name: Ensure mysql-server is running service: name: mysql state: started main.yml is a pointer file that will suggest that we import_tasks from these files.\n# tasks file for roles/mysql - import_tasks: install_mysql.yml - import_tasks: setup_mysql.yml setup_mysql.yml - This task will create our database and database user.\n- name: Create my.cnf configuration file template: src=templates/my.cnf.j2 dest=/etc/mysql/conf.d/mysql.cnf notify: restart mysql - name: Create database user with name 'devops' and password 'DevOps90' with all database privileges community.mysql.mysql_user: login_unix_socket: /var/run/mysqld/mysqld.sock login_user: \"{{ mysql_user_name }}\" login_password: \"{{ mysql_user_password }}\" name: \"{{db_user}}\" password: \"{{db_pass}}\" priv: '*.*:ALL' host: '%' state: present - name: Create a new database with name '90daysofdevops' mysql_db: login_user: \"{{ mysql_user_name }}\" login_password: \"{{ mysql_user_password }}\" name: \"{{ db_name }}\" state: present Вы можете видеть, что мы используем некоторые переменные для определения некоторых конфигураций, таких как пароли, имена пользователей и базы данных, все это хранится в файле group_vars/all/common_variables.yml.\nhttp_port: 8000 https_port: 4443 html_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\" mysql_user_name: root mysql_user_password: \"vagrant\" db_user: devops db_pass: DevOps90 db_name: 90DaysOfDevOps У нас также есть файл my.cnf.j2 в папке templates, который выглядит следующим образом:\n[mysql] bind-address = 0.0.0.0 Запуск плейбука Теперь наша виртуальная машина запущена и работает, и у нас есть наши конфигурационные файлы на месте, теперь мы готовы запустить наш плейбук, который будет включать все, что мы сделали раньше, если мы запустим следующий ansible-playbook playbook7.yml или мы можем выбрать просто развертывание на нашу группу баз данных с помощью команды ansible-playbook playbook7.yml --tags database, которая просто запустит наши новые конфигурационные файлы.\nЯ запустил только тег database, но наткнулся на ошибку. Эта ошибка говорит мне, что у нас не установлен pip3 (Python). Мы можем исправить это, добавив это в наши общие задачи и установив\nМы исправили вышеуказанное и запустили плейбук снова, и у нас получилось успешное изменение.\nМы должны убедиться, что на нашем новом настроенном сервере db01 все так, как мы хотим. Мы можем сделать это с нашего узла управления с помощью команды ssh db01.\nДля подключения к MySQL я использовал команду sudo /usr/bin/mysql -u root -p и указал пароль vagrant для root.\nКогда мы подключились, давайте сначала убедимся, что у нас создан пользователь devops. select user, host from mysql.user;\nТеперь мы можем выполнить команду SHOW DATABASES;, чтобы увидеть нашу новую базу данных, которая также была создана.\nНа самом деле я использовал root для подключения, но теперь мы можем войти в систему под учетной записью devops, используя команду sudo /usr/bin/mysql -u devops -p, но пароль здесь будет DevOps90.\nЯ обнаружил, что в нашем setup_mysql.yml мне пришлось добавить строку login_unix_socket: /var/run/mysqld/mysqld.sock для успешного подключения к моему экземпляру db01 mysql, и теперь каждый раз, когда я запускаю это, он сообщает об изменении при создании пользователя, любые предложения будут очень признательны.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"68. Теги, переменные, инвентаризация и конфигурация сервера базы данных","uri":"/ru/tracks/90daysofdevops/day68/"},{"content":"Завершая раздел об управлении конфигурацией, я хотел бы рассмотреть другие области, с которыми вы можете столкнуться при работе с Ansible.\nСуществует множество продуктов, составляющих платформу Ansible Automation.\nRed Hat Ansible Automation Platform - это основа для создания и эксплуатации автоматизации в организации. Платформа включает в себя все инструменты, необходимые для внедрения автоматизации в масштабах предприятия.\nЯ постараюсь осветить некоторые из них в этом посте. Но для получения более подробной информации на официальном сайте Red Hat Ansible есть много другой информации. Ansible.com\nAnsible Automation Controller | AWX Я объединил эти два продукта вместе, потому что Automation Controller и AWX очень похожи в том, что они предлагают.\nПроект AWX или сокращенно AWX - это проект сообщества с открытым исходным кодом, спонсируемый Red Hat, который позволяет вам лучше контролировать ваши проекты Ansible в ваших средах. AWX - это основной проект, из которого взят компонент контроллера автоматизации.\nЕсли вы ищете корпоративное решение, то вам нужен контроллер автоматизации, или вы могли слышать его как Ansible Tower. Контроллер автоматизации Ansible - это плоскость управления для платформы автоматизации Ansible.\nИ AWX, и контроллер автоматизации обладают следующими характеристиками, превосходящими все, что мы рассмотрели в этом разделе до сих пор.\nПользовательский интерфейс Управление доступом на основе ролей Рабочие процессы Интеграция CI/CD Automation Controller - это корпоративное предложение, в котором вы платите за поддержку.\nМы рассмотрим развертывание AWX в нашей среде minikube Kubernetes.\nРазвертывание Ansible AWX AWX не нужно развертывать в кластере Kubernetes, github для AWX от ansible даст вам эту подробную информацию. Однако, начиная с версии 18.0, AWX Operator является предпочтительным способом установки AWX.\nПрежде всего, нам нужен кластер minikube. Мы можем сделать это, если вы следили за разделом Kubernetes, создав новый кластер minikube с помощью команды minikube start --cpus=4 --memory=6g --addons=ingress.\nОфициальный Ansible AWX Operator можно найти здесь. Как указано в инструкции по установке, вы должны клонировать этот репозиторий, а затем выполнить развертывание.\nЯ сделал форк вышеуказанного репозитория, а затем выполнил команду git clone https://github.com/MichaelCade/awx-operator.git. Я советую вам сделать то же самое и не использовать мой репозиторий, так как я могу что-то изменить или его там может не быть.\nВ клонированном репозитории вы найдете файл awx-demo.yml, в котором нам нужно изменить NodePort на ClusterIP, как показано ниже:\n--- apiVersion: awx.ansible.com/v1beta1 kind: AWX metadata: name: awx-demo spec: service_type: ClusterIP Следующим шагом будет определение нашего пространства имен, в котором мы будем развертывать оператор awx, используя команду export NAMESPACE=awx, а затем команду make deploy, мы начнем развертывание.\nПри проверке у нас есть наше новое пространство имен, и у нас есть наш awx-operator-controller pod, запущенный в нашем пространстве имен. kubectl get pods -n awx.\nВ клонированном репозитории вы найдете файл awx-demo.yml. Теперь мы хотим развернуть его в нашем кластере Kubernetes и нашем пространстве имен awx. kubectl create -f awx-demo.yml -n awx.\nВы можете следить за прогрессом с помощью kubectl get pods -n awx -w, который будет визуально следить за происходящим.\nУ вас должно получиться что-то похожее на изображение, которое вы видите ниже, когда все работает.\nТеперь мы должны иметь доступ к нашей awx установке после запуска в новом терминале minikube service awx-demo-service --url -n $NAMESPACE, чтобы открыть ее через minikube ingress.\nЕсли мы откроем браузер по этому адресу [], вы увидите, что нам будет предложено ввести имя пользователя и пароль.\nПо умолчанию имя пользователя - admin, чтобы получить пароль, мы можем выполнить следующую команду kubectl get secret awx-demo-admin-password -o jsonpath=\"{.data.password}\" -n awx| base64 --decode.\nОчевидно, что это дает вам пользовательский интерфейс для централизованного управления плейбуком и задачами управления конфигурацией, а также позволяет вам работать вместе, в отличие от того, что мы делали до сих пор, когда мы работали с одной станции управления ansible.\nЭто еще одна из тех областей, где вы, вероятно, могли бы провести еще много времени, изучая возможности этого инструмента.\nЯ приведу отличный ресурс от Джеффа Гирлинга, который более подробно рассказывает об использовании Ansible AWX. Ansible 101 - Episode 10 - Ansible Tower and AWX\nВ этом видео он также подробно рассказывает о различиях между Automation Controller (ранее Ansible Tower) и Ansible AWX (Free and Open Source).\nAnsible Vault ansible-vault позволяет нам шифровать и расшифровывать файлы данных Ansible. На протяжении всего этого раздела мы пропустили и поместили часть нашей конфиденциальной информации в открытый текст.\nВстроенный в двоичный файл Ansible ansible-vault позволяет нам скрыть эту конфиденциальную информацию.\nУправление секретами постепенно становится еще одной областью, которой следовало бы уделить больше времени наряду с такими инструментами, как HashiCorp Vault или AWS Key Management Service. Я отмечу эту область как ту, в которую следует погрузиться глубже.\nЯ собираюсь дать ссылку на отличный ресурс и демонстрационный пример от Jeff Geerling Ansible 101 - Episode 6 - Ansible Vault and Roles\nAnsible Galaxy (Docs) Итак, мы уже использовали ansible-galaxy для создания некоторых ролей и файловой структуры для нашего демо-проекта. Но у нас также есть документация по Ansible Galaxy\n“Galaxy - это центр для поиска и обмена содержимым Ansible”.\nТестирование Ansible Ansible Molecule - проект Molecule предназначен для помощи в разработке и тестировании ролей Ansible.\nAnsible Lint - CLI-инструмент для линтинга плейбуков, ролей и коллекций.\nДругой ресурс Документация Ansible Ресурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате. В этом посте мы завершаем рассмотрение управления конфигурацией, далее мы перейдем к CI/CD Pipelines и некоторым инструментам и процессам, которые мы можем увидеть и использовать для достижения этого рабочего процесса при разработке и выпуске приложений.\n","description":"","title":"69. Ansible - контроллер автоматизации (Tower), AWX, Vault","uri":"/ru/tracks/90daysofdevops/day69/"},{"content":"Общая картина: DevOps и изучение языка программирования Я думаю, будет справедливо сказать, что для достижения успеха в качестве инженера DevOps в долгосрочной перспективе необходимо знать хотя бы один язык программирования на базовом уровне. Я хочу провести это первое занятие в этой статье, чтобы выяснить, почему это такой важный навык, и, надеюсь, к концу этой недели или раздела вы будете лучше понимать, почему, как и что делать. делайте, чтобы продвигаться в своем учебном путешествии.\nЯ думаю, что если бы я спросил в социальных сетях, нужны ли вам навыки программирования для ролей, связанных с DevOps, ответ, скорее всего, будет утвердительным? Дайте мне знать, если вы думаете иначе? Хорошо, но тогда более важный вопрос, и здесь вы не получите такого четкого ответа, какой язык программирования? Наиболее распространенным ответом, который я видел здесь, был Python, или все чаще мы видим, что Golang или Go должны быть языком, который вы изучаете.\nЧтобы быть успешным в DevOps, вы должны хорошо знать навыки программирования, по крайней мере, мой вывод из этого. Но мы должны понять, зачем нам это нужно, чтобы выбрать правильный путь.\nПонимание зачем вам нужно изучать язык программирования Причина, по которой Python и Go так часто рекомендуются инженерам DevOps, заключается в том, что многие инструменты DevOps написаны либо на Python, либо на Go, что имеет смысл, если вы собираетесь создавать инструменты DevOps. Теперь это важно, так как это действительно определит, что вы должны изучить, и это, вероятно, будет наиболее полезным. Если вы собираетесь создавать инструменты DevOps или присоединяетесь к команде, которая занимается этим, имеет смысл выучить тот же язык. Если вы собираетесь активно участвовать в Kubernetes или контейнерах, то, скорее всего, вы захотите выберите Go в качестве языка программирования. Для меня компания, в которой я работаю (Kasten by Veeam), находится в экосистеме Cloud-Native, ориентированной на управление данными для Kubernetes, и все написано на Go.\nНо тогда у вас может не быть четких рассуждений, подобных этим, чтобы выбрать, быть ли вам студентом или менять карьеру без реального решения за вас. Я думаю, что в этой ситуации вы должны выбрать тот, который, кажется, резонирует и подходит для приложений, с которыми вы хотите работать.\nПомните, что я не собираюсь становиться здесь разработчиком программного обеспечения, я просто хочу немного больше узнать о языке программирования, чтобы я мог читать и понимать, что делают эти инструменты, а затем это, возможно, приведет к тому, как мы можем помочь улучшить ситуацию.\nЯ также хотел бы знать, как вы взаимодействуете с этими инструментами DevOps, такими как Kasten K10 или Terraform и HCL. Это то, что мы будем называть конфигурационными файлами, и именно так вы взаимодействуете с этими инструментами DevOps, чтобы что-то происходило, обычно это будет YAML. (Мы можем использовать последний день этого раздела, чтобы немного погрузиться в YAML)\nЯ только что отговорил себя от изучения языка программирования? Большую часть времени или в зависимости от роли вы будете помогать инженерным командам внедрять DevOps в свой рабочий процесс, много тестировать приложение и следить за тем, чтобы созданный рабочий процесс соответствовал тем принципам DevOps, которые мы упоминали в первые несколько дней. . Но на самом деле много времени уходит на устранение проблем с производительностью приложений или что-то в этом роде. Это возвращает меня к моей первоначальной точке зрения и рассуждениям: язык программирования, который мне нужно знать, — это тот, на котором написан код? Если их приложение написано на NodeJS, это не сильно поможет, если у вас есть значок Go или Python.\nПочему Go Почему Golang — следующий язык программирования для DevOps? В последние годы Go стал очень популярным языком программирования. Согласно опросу StackOverflow за 2021 год, Go занял четвертое место среди самых востребованных языков программирования, сценариев и разметки, а Python был на первом месте, но выслушайте меня. StackOverflow 2021 Developer Survey – Most Wanted Link\nКак я уже упоминал, некоторые из самых известных инструментов и платформ DevOps написаны на Go, такие как Kubernetes, Docker, Grafana и Prometheus.\nКакие характеристики Go делают его идеальным для DevOps?\nСборка и развертывание программ Go Преимущество использования такого языка, как Python, который интерпретируется в роли DevOps, заключается в том, что вам не нужно компилировать программу Python перед ее запуском. Особенно для небольших задач автоматизации вы не хотите, чтобы процесс сборки, требующий компиляции, замедлялся, несмотря на то, что Go — компилируемый язык программирования, Go компилируется непосредственно в машинный код. Go также известен быстрым временем компиляции.\nGo или Python для DevOps Программы Go статически связаны, это означает, что когда вы компилируете программу Go, все включается в один исполняемый двоичный файл, не требуется никаких внешних зависимостей, которые необходимо установить на удаленной машине, это упрощает развертывание программ Go, по сравнению с программой Python, которая использует внешние библиотеки, где вы должны убедиться, что все эти библиотеки установлены на удаленной машине, на которой вы хотите работать.\nGo — это независимый от платформы язык, что означает, что вы можете создавать двоичные исполняемые файлы для * всех операционных систем, Linux, Windows, macOS и т. д., и это очень легко сделать. С Python не так просто создавать эти двоичные исполняемые файлы для конкретных операционных систем.\nGo — очень производительный язык, он имеет быструю компиляцию и быстрое время выполнения с меньшим использованием ресурсов, таких как процессор и память, особенно по сравнению с python, в языке Go были реализованы многочисленные оптимизации, которые делают его таким производительным. (Ресурсы ниже)\nВ отличие от Python, который часто требует использования сторонних библиотек для реализации конкретной программы Python, go включает в себя стандартную библиотеку, которая имеет большую часть функций, которые вам понадобятся для DevOps, встроенных непосредственно в нее. Это включает в себя функциональную обработку файлов, веб-службы HTTP, обработку JSON, встроенную поддержку параллелизма и параллелизма, а также встроенное тестирование.\nЭто ни в коем случае не бросает Python под автобус, я просто излагаю свои причины выбора Go, но они не являются вышеупомянутым Go против Python, это обычно потому, что это имеет смысл, поскольку компания, в которой я работаю, разрабатывает программное обеспечение на Go, вот почему.\nЯ скажу, что как только как только вы выучите свой первый язык программирования, вам станет легче осваивать другие языки. Вероятно, у вас никогда не будет ни одной работы в какой-либо компании, где бы вам не приходилось иметь дело с управлением, архитектурой, оркестровкой, отладкой приложений JavaScript и Node JS.\nИсточники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Теперь в течение следующих 6 дней этой темы я намерен работать с некоторыми из ресурсов, перечисленных выше, и документировать свои заметки на каждый день. Вы заметите, что они, как правило, составляют около 3 часов в качестве полного курса, я хотел поделиться своим полным списком, чтобы, если у вас есть время, вы могли двигаться вперед и работать над каждым, если позволяет время, я буду придерживаться моего часа обучения каждый день.\nДо встречи в День 8\n","description":"DevOps - изучение языка программирования","title":"7. DevOps - изучение языка программирования","uri":"/ru/tracks/90daysofdevops/day07/"},{"content":"Реализация конвейера CI/CD (Continous Integration/Continous Deployment) является основой современной среды DevOps.\nОн устраняет разрыв между разработкой и операциями, автоматизируя сборку, тестирование и развертывание приложений.\nМы много говорили об этой мантре Continous во вступительном разделе задачи. Но повторим еще раз:\nContinous Integration (CI) - это более современная практика разработки программного обеспечения, при которой инкрементные изменения кода вносятся чаще и надежнее. Автоматизированные шаги рабочего процесса сборки и тестирования, запускаемые Contininous Integration, обеспечивают надежность изменений кода, сливаемых в репозиторий.\nЗатем этот код / приложение быстро и беспрепятственно доставляется в рамках процесса непрерывного развертывания.\nВажность CI/CD? Доставка программного обеспечения быстро и эффективно Облегчает эффективный процесс вывода приложений на рынок как можно быстрее. Непрерывный поток исправлений ошибок и новых функций без ожидания месяцев или лет выпуска версии. Возможность для разработчиков регулярно вносить небольшие важные изменения означает, что мы быстрее получаем исправления и новые функции.\nХорошо, так что же это значит? В День 5 мы рассмотрели много теории, лежащей в основе DevOps, и, как уже упоминалось здесь, CI/CD Pipeline является основой современной среды DevOps.\nЯ хочу повторить некоторые ключевые моменты на этом изображении выше, теперь, когда мы немного продвинулись в изучении основ DevOps.\nМы имеем в виду жизненный цикл разработки программного обеспечения (SDLC).\nЭтапы обычно записываются в бесконечном цикле, поскольку этот цикл повторяется вечно.\nThe steps in the cycle are, developers write the code then it gets built or all compiled together then it’s tested for bugs then it’s deployed into production where it’s used (Operated) by end users or customers then we monitor and collect feedback and finally we plan improvements around that feedback rinse and repeat.\nДавайте немного углубимся в CI/CD CI CI - это практика разработки, которая требует от разработчиков интегрировать код в общий репозиторий несколько раз в день.\nКогда код написан и помещен в репозиторий, такой как github или gitlab, вот тут-то и начинается волшебство.\nКод проверяется автоматизированной сборкой, что позволяет командам или владельцу проекта обнаружить любые проблемы на ранней стадии.\nПосле этого код анализируется и подвергается серии автоматизированных тестов.\nЮнит-тестирование - тестирование отдельных частей исходного кода. тестирование на валидность - проверяется, что программное обеспечение удовлетворяет или соответствует предполагаемому использованию. Тестирование формата проверяет синтаксис и другие ошибки форматирования. Эти тесты создаются как рабочий процесс и затем запускаются каждый раз, когда вы продвигаете мастер-ветку, поэтому практически каждая крупная команда разработчиков имеет какой-то рабочий процесс CI/CD, и помните, что в команде разработчиков новый код может поступать из команд по всему миру в разное время суток от разработчиков, работающих над самыми разными проектами, поэтому эффективнее построить автоматизированный рабочий процесс тестов, которые убеждаются, что все находятся на одной странице, прежде чем код будет принят. Человеку потребуется гораздо больше времени, чтобы сделать это каждый раз.\nКак только мы завершили наши тесты и они прошли успешно, мы можем скомпилировать их и отправить в наш репозиторий. Для примера я использую Docker Hub, но это может быть любое другое хранилище, которое затем будет использовано для CD-аспекта конвейера.\nИтак, этот процесс, очевидно, очень похож на процесс разработки программного обеспечения: мы создаем наше приложение, добавляем, исправляем ошибки и т.д., затем обновляем контроль исходных текстов и версионируем их, одновременно тестируя.\nПереходим к следующему этапу - элементу CD, который на самом деле все больше и больше является тем, что мы обычно видим от любого готового программного обеспечения, я бы утверждал, что мы увидим тенденцию, что если мы получим наше программное обеспечение от такого поставщика, как Oracle или Microsoft, мы будем потреблять его из репозитория типа Docker Hub, а затем мы будем использовать наши конвейеры CD для развертывания этого в наших средах.\nCD Теперь у нас есть протестированная версия нашего кода, и мы готовы к развертыванию на природе. Как я уже сказал, поставщик программного обеспечения пройдет через этот этап, но я твердо уверен, что именно так мы все будем развертывать готовое программное обеспечение, которое нам понадобится в будущем.\nТеперь пришло время выпустить наш код в среду. Это будет включать в себя производственную среду, но также, вероятно, и другие среды, такие как staging.\nСледующим шагом, по крайней мере, в день 1 v1 развертывания программного обеспечения, является то, что нам нужно убедиться, что мы переносим правильную кодовую базу в правильную среду. Это может быть извлечение элементов из репозитория программного обеспечения (DockerHub), но более чем вероятно, что мы также извлечем дополнительную конфигурацию из другого репозитория кода, например, конфигурацию для приложения. На диаграмме ниже мы извлекаем последний релиз программного обеспечения из DockerHub, а затем выпускаем его в нашу среду, при этом, возможно, получая конфигурацию из репозитория Git. Наш CD-инструмент выполняет это и передает все в нашу среду.\nСкорее всего, это делается не одновременно, т.е. мы переходим в промежуточную среду и запускаем ее с нашей собственной конфигурацией, чтобы убедиться, что все правильно, и это может быть ручным шагом для тестирования или автоматизированным (давайте остановимся на автоматизированном), прежде чем позволить этому коду быть развернутым в продакшн.\nПосле этого, когда выйдет v2 приложения, мы прополощем и повторим шаги, на этот раз мы убедимся, что наше приложение + конфигурация развернуты в staging, убедимся, что все хорошо, и затем развернем в production.\nЗачем использовать CI/CD? Я думаю, мы уже неоднократно рассказывали о преимуществах, но они заключаются в том, что CI/CD автоматизирует то, что в противном случае пришлось бы делать вручную. Он находит небольшие проблемы до того, как они проникнут в основную кодовую базу. Вы, вероятно, можете себе представить, что если вы выкладываете плохой код своим клиентам, то у вас будут плохие времена!\nЭто также помогает предотвратить то, что мы называем техническим долгом - идею о том, что поскольку основные репозитории кода постоянно дорабатываются с течением времени, то быстрое исправление, сделанное в первый день, становится экспоненциально более дорогим исправлением годы спустя, потому что теперь этот пластырь исправления будет так глубоко переплетен и вплетен во все кодовые базы и логику.\nИнструментарий Как и в других разделах, мы будем работать с некоторыми инструментами, которые обеспечивают процесс конвейера CI/CD.\nЯ считаю важным отметить, что не все инструменты должны делать и CI, и CD. Мы рассмотрим ArgoCD, который, как вы догадались, отлично справляется с CD-элементом развертывания нашего программного обеспечения в кластере Kubernetes. Но что-то вроде Jenkins может работать на разных платформах.\nЯ планирую рассмотреть следующее:\nJenkins ArgoCD GitHub Actions Ресурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"70. Конвейеры CI/CD","uri":"/ru/tracks/90daysofdevops/day70/"},{"content":" Jenkins - это инструмент непрерывной интеграции, который позволяет непрерывно разрабатывать, тестировать и развертывать вновь созданный код.\nЭтого можно достичь двумя способами: ночные сборки или непрерывная разработка. Первый вариант заключается в том, что наши разработчики в течение дня занимаются своими задачами и в конце рабочего дня вносят свои изменения в репозиторий исходного кода. Затем в течение ночи мы проводим модульные тесты и собираем программное обеспечение. Это можно считать старым способом интеграции всего кода.\nДругой вариант и более предпочтительный способ заключается в том, что наши разработчики по-прежнему фиксируют свои изменения в исходном коде, а затем, после фиксации кода, непрерывно запускается процесс сборки.\nПриведенные выше методы означают, что при распределении разработчиков по всему миру у нас нет определенного времени каждый день, когда мы должны прекратить фиксацию изменений в коде. Именно здесь на помощь приходит Jenkins, который выступает в роли CI-сервера, контролирующего тесты и процессы сборки.\nЯ знаю, что мы говорим о Jenkins, но я также хочу добавить еще несколько, которые можно будет рассмотреть позже, чтобы понять, почему я вижу Jenkins как наиболее популярный, почему это так и что другие могут сделать по сравнению с Jenkins.\nTravisCI - Размещенный, распределенный сервис непрерывной интеграции, используемый для сборки и тестирования программных проектов, размещенных на GitHub.\nBamboo - может запускать несколько сборок параллельно для более быстрой компиляции, имеет встроенную функциональность для связи с репозиториями и задачи сборки для Ant, Maven.\nBuildbot - это фреймворк с открытым исходным кодом для автоматизации процессов сборки, тестирования и выпуска программного обеспечения. Он написан на языке Python и поддерживает распределенное, параллельное выполнение заданий на нескольких платформах.\nApache Gump - специфичен для Java-проектов, разработан с целью сборки и тестирования этих Java-проектов каждую ночь. обеспечивает совместимость всех проектов как на уровне API, так и на уровне функциональности.\nПоскольку мы сейчас сосредоточимся на Jenkins - Jenkins, как и все вышеперечисленные инструменты, имеет открытый исходный код и представляет собой сервер автоматизации, написанный на Java. Он используется для автоматизации процесса разработки программного обеспечения посредством непрерывной интеграции и облегчает непрерывную доставку.\nОсобенности Jenkins Как и следовало ожидать, Jenkins имеет множество функций, охватывающих множество областей.\nПростая установка - Jenkins - это самостоятельная программа на базе java, готовая к работе с пакетами для операционных систем Windows, macOS и Linux.\nПростая конфигурация - Простая установка и настройка через веб-интерфейс, включающий проверку ошибок и встроенную помощь.\nПлагины - Множество плагинов доступно в Центре обновления и интегрируется со многими инструментами в инструментальной цепочке CI / CD.\nРасширяемость - В дополнение к доступным плагинам, Jenkins может быть расширен за счет архитектуры плагинов, что обеспечивает практически бесконечное количество вариантов того, для чего он может быть использован.\nРаспределенность - Jenkins легко распределяет работу по нескольким машинам, помогая ускорить сборку, тестирование и развертывание на различных платформах.\nJenkins Pipeline Вы уже видели этот конвейер, но он используется гораздо шире, и мы не говорили о конкретных инструментах.\nВы собираетесь фиксировать код в Jenkins, который затем будет собирать ваше приложение со всеми автоматизированными тестами, а затем выпускать и развертывать этот код после завершения каждого этапа. Jenkins позволяет автоматизировать этот процесс.\nАрхитектура Jenkins Во-первых, чтобы не изобретать велосипед, всегда стоит начать с Документации Jenkins, но я собираюсь изложить свои заметки и выводы и здесь.\nJenkins может быть установлен на многих различных операционных системах, Windows, Linux и macOS, а также имеет возможность развертывания в виде контейнера Docker и в Kubernetes. Установка Jenkins\nПо мере изучения этого вопроса мы, вероятно, рассмотрим установку Jenkins в кластере minikube, имитируя развертывание в Kubernetes. Но это будет зависеть от скриптов, которые мы составим в оставшейся части раздела.\nТеперь давайте разберем изображение ниже.\nШаг 1 - Разработчики фиксируют изменения в репозитории исходного кода.\nШаг 2 - Jenkins проверяет репозиторий через регулярные промежутки времени и извлекает любой новый код.\nШаг 3 - Сервер сборки затем собирает код в исполняемый файл, в данном примере мы используем maven как хорошо известный сервер сборки. Еще одна область, которую необходимо охватить.\nШаг 4 - Если сборка не удалась, то разработчикам отправляется обратная связь.\nШаг 5 - Jenkins развертывает собранное приложение на тестовом сервере, в данном примере мы используем selenium как хорошо известный тестовый сервер. Еще одна область, которую необходимо охватить.\nШаг 6 - Если тест не прошел, то обратная связь передается разработчикам.\nШаг 7 - Если тесты прошли успешно, мы можем выпустить продукт в производство.\nЭтот цикл непрерывен, именно это позволяет обновлять приложения за минуты, а не за часы, дни, месяцы, годы!\nАрхитектура Jenkins может быть описана гораздо подробнее, если вам это нужно, у них есть возможность работы в режиме master-slave, что позволяет ведущему распределять задачи между подчиненными jenkins.\nДля справки, поскольку Jenkins является открытым исходным кодом, будет много предприятий, которым требуется поддержка, CloudBees - это корпоративная версия Jenkins, которая предоставляет поддержку и, возможно, другие функциональные возможности для платного корпоративного клиента.\nПримером такого клиента является компания Bosch, вы можете ознакомиться с примером Bosch здесь.\nЯ собираюсь найти пошаговый пример приложения, которое мы могли бы использовать, чтобы пройтись по Jenkins, а затем использовать его с другими инструментами.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"71. Введение в Jenkins","uri":"/ru/tracks/90daysofdevops/day71/"},{"content":"Сегодня мы планируем немного поработать с Jenkins и сделать что-то в рамках нашего конвейера CI, рассматривая некоторые примеры кодовых баз, которые мы можем использовать.\nЧто такое конвейер? Прежде чем мы начнем, нам нужно знать, что такое конвейер, когда речь идет о CI, и мы уже рассмотрели это на вчерашнем занятии с помощью следующего изображения.\nМы хотим взять процессы или шаги, описанные выше, и автоматизировать их, чтобы в итоге получить результат, то есть развернутое приложение, которое мы можем отправить нашим клиентам, конечным пользователям и т.д.\nЭтот автоматизированный процесс позволяет нам иметь контроль версий для наших пользователей и клиентов. Каждое изменение, улучшение функций, исправление ошибок и т.д. проходит через этот автоматизированный процесс, подтверждая, что все в порядке, без излишнего ручного вмешательства, чтобы убедиться, что наш код хорош.\nЭтот процесс включает в себя создание программного обеспечения надежным и повторяемым способом, а также продвижение созданного программного обеспечения (называемого “сборкой”) через несколько этапов тестирования и развертывания.\nКонвейер jenkins записывается в текстовый файл Jenkinsfile. Который сам должен быть зафиксирован в репозитории контроля исходного кода. Это также известно как Pipeline as code, мы также можем сравнить это с Infrastructure as code, о которой мы рассказывали несколько недель назад.\nJenkins Pipeline Definition\nРазвертывание Jenkins Я получил некоторое удовольствие от развертывания Jenkins, Вы заметите из документации, что есть много вариантов того, где вы можете установить Jenkins.\nУчитывая, что у меня под рукой есть minikube, и мы уже использовали его несколько раз, я хотел использовать его и для этой задачи. (Хотя шаги, описанные в Kubernetes Installation, привели к тому, что я уперся в стену и не смог запустить систему, вы можете сравнить эти два варианта, когда я задокументирую свои шаги здесь.\nПервым шагом будет запуск нашего кластера minikube, мы можем сделать это с помощью команды minikube start.\nЯ добавил папку со всеми конфигурациями и значениями YAML, которые можно найти здесь Теперь, когда у нас есть наш кластер, мы можем выполнить следующие действия для создания пространства имен jenkins. kubectl create -f jenkins-namespace.yml\nМы будем использовать Helm для развертывания jenkins в нашем кластере, о Helm мы рассказывали в разделе Kubernetes. Сначала нам нужно добавить репозиторий jenkinsci в helm helm repo add jenkinsci https://charts.jenkins.io, затем обновить наши таблицы helm repo update.\nИдея Jenkins заключается в том, что он будет сохранять состояние для своих пайплайнов, вы можете запустить вышеупомянутую установку helm без персистентности, но если эти pods будут перезагружены, изменены или модифицированы, то все пайплайны или конфигурации, которые вы создали, будут потеряны. Мы создадим том для персистентности, используя файл jenkins-volume.yml с помощью команды kubectl apply -f jenkins-volume.yml.\nНам также нужна учетная запись службы, которую мы можем создать с помощью этого yaml-файла и команды. kubectl apply -f jenkins-sa.yml\nНа этом этапе мы готовы к развертыванию с помощью схемы helm, сначала мы определим нашу схему с помощью chart=jenkinsci/jenkins, а затем развернем с помощью этой команды, где jenkins-values.yml содержит учетные записи персистентности и сервисов, которые мы ранее развернули на нашем кластере. helm install jenkins -n jenkins -f jenkins-values.yml $chart.\nНа этом этапе наши капсулы будут извлекать образ, но у капсулы не будет доступа к хранилищу, поэтому никакая конфигурация не может быть начата с точки зрения запуска Jenkins.\nИменно здесь документация не помогла мне понять, что должно произойти. Но мы видим, что у нас нет разрешения на запуск установки jenkins.\nДля того чтобы исправить вышеописанное или решить проблему, нам нужно убедиться, что мы предоставили доступ или правильное разрешение для того, чтобы наши jenkins pods могли писать в это место, которое мы предложили. Мы можем сделать это, используя minikube ssh, который введет нас в докер-контейнер minikube, на котором мы работаем, а затем, используя sudo chown -R 1000:1000 /data/jenkins-volume, мы можем убедиться, что у нас установлены разрешения на наш том данных.\nВышеописанный процесс должен исправить капсулы, однако если это не так, вы можете заставить капсулы обновиться с помощью команды kubectl delete pod jenkins-0 -n jenkins. На этом этапе у вас должно быть 2/2 запущенных стручка под названием jenkins-0.\nТеперь нам нужен наш пароль администратора, и мы можем сделать это с помощью следующей команды. kubectl exec --namespace jenkins -it svc/jenkins -c jenkins -- /bin/cat /run/secrets/chart-admin-password \u0026\u0026 echo\nТеперь откройте новый терминал, так как мы собираемся использовать команду port-forward, чтобы получить доступ с нашей рабочей станции. kubectl --namespace jenkins port-forward svc/jenkins 8080:8080.\nТеперь мы должны быть в состоянии открыть браузер и войти на http://localhost:8080 и аутентифицироваться с именем пользователя: admin и паролем, которые мы собрали в предыдущем шаге.\nПосле аутентификации наша страница приветствия Jenkins должна выглядеть примерно так:\nОтсюда я бы предложил перейти к “Manage Jenkins”, и вы увидите “Manage Plugins”, где будут доступны некоторые обновления. Выберите все эти плагины и выберите “Загрузить сейчас и установить после перезапуска”.\nЕсли вы хотите пойти еще дальше и автоматизировать развертывание Jenkins с помощью shell-скрипта, этот замечательный репозиторий был предоставлен мне в twitter mehyedes/nodejs-k8s\nJenkinsfile Теперь у нас есть Jenkins, развернутый в нашем кластере Kubernetes, мы можем вернуться назад и подумать об этом Jenkinsfile.\nКаждый Jenkinsfile, скорее всего, будет начинаться примерно так: сначала вы определяете шаги вашего конвейера, в данном случае это Build \u003e Test \u003e Deploy. Но на самом деле мы не делаем ничего, кроме использования команды echo для вызова определенных этапов.\nJenkinsfile (декларативный конвейер) pipeline { agent any stages { stage('Build') { steps { echo 'Building..' } } stage('Test') { steps { echo 'Testing..' } } stage('Deploy') { steps { echo 'Deploying....' } } } } В нашей приборной панели Jenkins выберите “New Item” дайте элементу имя, я собираюсь “echo1” Я собираюсь предложить, что это Pipeline.\nНажмите Ok, и у вас появятся вкладки (General, Build Triggers, Advanced Project Options и Pipeline) для простого теста нас интересует только Pipeline. В разделе Pipeline у вас есть возможность добавить скрипт, мы можем скопировать и вставить приведенный выше скрипт в поле.\nКак мы уже говорили выше, это не даст многого, но покажет нам этапы нашей сборки \u003e тестирования \u003e развертывания\nНажмите Save, теперь мы можем запустить нашу сборку, используя сборку, показанную ниже.\nМы также должны открыть терминал и выполнить команду kubectl get pods -n jenkins, чтобы посмотреть, что произойдет.\nХорошо, очень просто, но теперь мы можем видеть, что наше развертывание и установка Jenkins работает правильно, и мы можем начать видеть здесь строительные блоки конвейера CI.\nВ следующем разделе мы будем строить конвейер Jenkins.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"72. Работа с Jenkins","uri":"/ru/tracks/90daysofdevops/day72/"},{"content":"В предыдущем разделе мы развернули Jenkins на нашем кластере Minikube и создали очень простой Jenkins Pipeline, который не делал ничего особенного, кроме как повторял этапы Pipeline.\nВы также могли заметить, что в процессе создания Jenkins Pipeline нам доступны некоторые примеры скриптов для запуска.\nПервый демонстрационный скрипт - “Declartive (Kubernetes)”, и вы можете увидеть его этапы ниже.\n// Uses Declarative syntax to run commands inside a container. pipeline { agent { kubernetes { // Rather than inline YAML, in a multibranch Pipeline you could use: yamlFile 'jenkins-pod.yaml' // Or, to avoid YAML: // containerTemplate { // name 'shell' // image 'ubuntu' // command 'sleep' // args 'infinity' // } yaml ''' apiVersion: v1 kind: Pod spec: containers: - name: shell image: ubuntu command: - sleep args: - infinity ''' // Can also wrap individual steps: // container('shell') { // sh 'hostname' // } defaultContainer 'shell' } } stages { stage('Main') { steps { sh 'hostname' } } } } Ниже показан результат того, что происходит при выполнении этого конвейера.\nСоздание задания Цели\nСоздать простое приложение и сохранить его в публичном репозитории GitHub (https://github.com/scriptcamp/kubernetes-kaniko.git).\nС помощью Jenkins собрать образ нашего docker-контейнера и выложить в docker hub. (Для этого мы будем использовать частный репозиторий).\nЧтобы добиться этого в нашем кластере Kubernetes, работающем в Minikube или с его помощью, нам нужно использовать нечто под названием Kaniko В общем, если вы используете Jenkins в реальном кластере Kubernetes или запускаете его на сервере, вы можете указать агента, который даст вам возможность выполнять команды сборки docker и загружать их в DockerHub.\nУчитывая вышесказанное, мы также собираемся развернуть секрет в Kubernetes с нашими учетными данными GitHub.\nkubectl create secret docker-registry dockercred \\ --docker-server=https://index.docker.io/v1/ \\ --docker-username=\u003cdockerhub-username\u003e \\ --docker-password=\u003cdockerhub-password\u003e\\ --docker-email=\u003cdockerhub-email\u003e На самом деле я хочу поделиться еще одним замечательным ресурсом от DevOpsCube.com, где рассматривается многое из того, о чем мы будем говорить здесь.\nДобавление учетных данных в Jenkins Однако если вы используете систему Jenkins, в отличие от нашей, то вы, скорее всего, захотите определить свои учетные данные в Jenkins, а затем использовать их несколько раз в своих конвейерах и конфигурациях. Мы можем ссылаться на эти учетные данные в конвейерах, используя ID, который мы определили при создании. Я пошел дальше и создал учетные данные для DockerHub и GitHub.\nСначала выберите “Manage Jenkins”, а затем “Manage Credentials”.\nВ центре страницы вы увидите магазины, предназначенные для Jenkins, нажмите на Jenkins здесь.\nТеперь выберите Global Credentials (Unrestricted).\nЗатем в левом верхнем углу у вас есть Добавить учетные данные\nЗаполните данные вашей учетной записи и затем выберите OK, помните, что ID - это то, на что вы будете ссылаться, когда захотите вызвать эту учетную запись. Мой совет здесь также заключается в том, что вы должны использовать специальные маркеры доступа, а не пароли.\nДля GitHub вы должны использовать Personal Access Token.\nЛично мне процесс создания этих учетных записей показался не очень интуитивным, поэтому, хотя мы не используем их, я хотел поделиться процессом, так как он не совсем понятен из пользовательского интерфейса.\nПостроение конвейера У нас есть учетные данные DockerHub, развернутые как секрет в нашем кластере Kubernetes, к которым мы будем обращаться на этапе docker deploy to DockerHub в нашем конвейере.\nСценарий конвейера - это то, что вы видите ниже, это, в свою очередь, может стать нашим Jenkinsfile, расположенным в нашем репозитории GitHub, который, как вы можете видеть, также указан на этапе Get the project в конвейере.\npodTemplate(yaml: ''' apiVersion: v1 kind: Pod spec: containers: - name: maven image: maven:3.8.1-jdk-8 command: - sleep args: - 99d - name: kaniko image: gcr.io/kaniko-project/executor:debug command: - sleep args: - 9999999 volumeMounts: - name: kaniko-secret mountPath: /kaniko/.docker restartPolicy: Never volumes: - name: kaniko-secret secret: secretName: dockercred items: - key: .dockerconfigjson path: config.json ''') { node(POD_LABEL) { stage('Get the project') { git url: 'https://github.com/scriptcamp/kubernetes-kaniko.git', branch: 'main' container('maven') { stage('Test the project') { sh ''' echo pwd ''' } } } stage('Build \u0026 Test the Docker Image') { container('kaniko') { stage('Deploy to DockerHub') { sh ''' /kaniko/executor --context `pwd` --destination michaelcade1/helloworld:latest ''' } } } } } Чтобы начать работу на приборной панели Jenkins, нам нужно выбрать “Новый элемент”\nЗатем мы дадим нашему элементу имя, выберем Pipeline и нажмем OK.\nМы не будем выбирать общие триггеры или триггеры сборки, но поиграйте с ними, так как здесь есть несколько интересных расписаний и других конфигураций, которые могут быть полезны.\nНас интересует только вкладка Pipeline в конце.\nВ определении пайплайн мы скопируем и вставим скрипт пайплайна, который мы описали выше, в раздел Script и нажмем кнопку save.\nДалее мы выберем опцию “Build Now” в левой части страницы.\nТеперь вам нужно подождать некоторое время, меньше минуты, и вы должны увидеть в статусе этапы, которые мы определили выше в нашем скрипте.\nЧто еще более важно, если мы теперь перейдем на наш DockerHub и проверим, что у нас есть новая сборка.\nВ целом это заняло некоторое время, но я хотел придерживаться этого, чтобы получить практический опыт и проработать скрипт, который может выполнить каждый, используя minikube и доступ к github и dockerhub.\nРепозиторий DockerHub, который я использовал для этого демо, был частным. Но в следующем разделе я хочу продвинуть некоторые из этих этапов и заставить их действительно что-то делать, а не просто выводить pwd, и действительно запустить некоторые тесты и этапы сборки.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"73. Построение конвейера Jenkins","uri":"/ru/tracks/90daysofdevops/day73/"},{"content":"Здравствуй мир - Jenkinsfile App Pipeline В предыдущем разделе мы построили простой конвейер в Jenkins, который будет перемещать наш образ докера из нашего dockerfile в публичном репозитории GitHub в наш частный репозиторий Dockerhub.\nВ этом разделе мы хотим сделать еще один шаг вперед и добиться следующего с помощью нашего простого приложения.\nЦель Dockerfile (Hello World) Jenkinsfile Jenkins Pipeline для запуска при обновлении репозитория GitHub Используйте репозиторий GitHub в качестве источника. Запуск - Clone/Get Repository, Build, Test, Deploy Stages Развертывание на DockerHub с инкрементными номерами версий Stretch Goal для развертывания на нашем кластере Kubernetes (для этого потребуется еще одно задание и репозиторий манифеста с использованием учетных данных GitHub). Шаг первый У нас есть наш GitHub репозиторий В настоящее время он содержит наш Dockerfile и наш index.html\nЭто то, что мы использовали в качестве источника в нашем конвейере, теперь мы хотим добавить этот скрипт Jenkins Pipeline в наш репозиторий GitHub.\nТеперь вернемся к нашей приборной панели Jenkins и создадим новый пайплайн, но теперь вместо вставки нашего скрипта мы будем использовать “Pipeline script from SCM” Мы будем использовать приведенные ниже параметры конфигурации.\nДля справки мы будем использовать https://github.com/MichaelCade/Jenkins-HelloWorld.git в качестве URL репозитория.\nНа этом этапе мы можем нажать кнопку сохранить и применить, после чего мы сможем вручную запустить наш Pipeline для сборки нового образа Docker, загруженного в наш репозиторий DockerHub.\nОднако я также хочу убедиться, что мы установили расписание, по которому при каждом изменении нашего репозитория или исходного кода будет запускаться сборка. Мы можем использовать веб-крючки или запланированное извлечение.\nЭто важный момент, потому что если вы используете дорогостоящие облачные ресурсы для хранения конвейера и у вас много изменений в репозитории кода, то вы понесете большие расходы. Мы знаем, что это демонстрационная среда, поэтому я использую опцию “poll scm”. (Также я считаю, что при использовании minikube мне не хватает возможности использовать webhooks)\nОдна вещь, которую я изменил со вчерашней сессии, это то, что теперь я хочу загружать изображение в публичный репозиторий, который в данном случае будет michaelcade1\\90DaysOfDevOps, мой Jenkinsfile уже содержит это изменение. И из предыдущих разделов я удалил все существующие образы демо-контейнеров.\nДвигаясь назад, мы создали наш Pipeline, а затем, как было показано ранее, добавили нашу конфигурацию.\nНа данном этапе наш конвейер еще не запущен, и вид сцены будет выглядеть примерно так.\nТеперь нажмем кнопку “Build Now”. и в представлении этапа будут отображены наши этапы.\nЕсли мы перейдем к нашему репозиторию DockerHub, у нас должно быть 2 новых образа Docker. У нас должен быть идентификатор сборки 1 и последняя версия, потому что каждая сборка, которую мы создаем на основе команды “Upload to DockerHub”, отправляет версию, используя переменную окружения Jenkins Build_ID, а также выпускает последнюю версию.\nДавайте создадим обновление файла index.html в нашем репозитории GitHub, как показано ниже, я позволю вам пойти и узнать, что говорила версия 1 файла index.html.\nЕсли мы вернемся в Jenkins и снова выберем “Build Now”. Мы увидим, что наша сборка #2 прошла успешно.\nЗатем быстро взглянув на DockerHub, мы увидим, что у нас есть наш тег версии 2 и наш последний тег.\nЗдесь стоит отметить, что я добавил в свой кластер Kubernetes секрет, который позволяет мне получить доступ и аутентификацию для отправки моих сборок docker в DockerHub. Если вы следуете этому примеру, вам следует повторить этот процесс для своей учетной записи, а также внести изменения в Jenkinsfile, связанный с моим репозиторием и учетной записью.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"74. Hello World - Jenkinsfile App Pipeline","uri":"/ru/tracks/90daysofdevops/day74/"},{"content":"Обзор действий GitHub В этом разделе я хотел бы перейти к рассмотрению, возможно, другого подхода, чем тот, на который мы только что потратили время. На этом занятии мы сосредоточимся на GitHub Actions.\nGitHub Actions - это платформа CI/CD, которая позволяет нам строить, тестировать и развертывать, помимо прочих задач, наш конвейер. В ней есть концепция рабочих процессов, которые собираются и тестируются на основе репозитория GitHub. Вы также можете использовать GitHub Actions для управления другими рабочими процессами на основе событий, происходящих в вашем репозитории.\nРабочие процессы В целом, в GitHub Actions наша задача называется рабочий процесс.\nРабочий процесс** - это настраиваемый автоматизированный процесс. Определяется как файлы YAML. Содержит и запускает одно или несколько заданий. Запускается при срабатывании события в вашем хранилище или может быть запущен вручную. Вы можете использовать несколько рабочих процессов для каждого хранилища. рабочий процесс содержит задание, а затем шаги для достижения этого задания. В рамках рабочего процесса у нас также будет запускающий механизм, на котором будет выполняться наш рабочий процесс. Например, у вас может быть один рабочий процесс для создания и тестирования запросов, другой рабочий процесс для развертывания вашего приложения каждый раз, когда создается релиз, и еще один рабочий процесс, который добавляет метку каждый раз, когда кто-то открывает новую проблему.\nСобытия События - это определенные события в хранилище, которые запускают рабочий процесс на выполнение.\nЗадания Задание - это набор шагов рабочего процесса, которые выполняются на бегунке.\nШаги Каждый шаг в задании может быть скриптом оболочки, который выполняется, или действием. Шаги выполняются по порядку и зависят друг от друга.\nДействия Повторяющееся пользовательское приложение, используемое для часто повторяющихся задач.\nБегуны Бегунок - это сервер, который запускает рабочий процесс, каждый бегунок выполняет одно задание за раз. GitHub Actions предоставляет возможность запуска бегунов для Ubuntu Linux, Microsoft Windows и macOS. Вы также можете разместить свой собственный на определенной ОС или оборудовании.\nНиже вы можете увидеть, как это выглядит: у нас есть событие, запускающее наш рабочий процесс \u003e наш рабочий процесс состоит из двух заданий \u003e внутри наших заданий есть шаги, а затем действия.\nYAML Прежде чем мы приступим к рассмотрению реального случая использования, давайте взглянем на приведенное выше изображение в виде примера YAML-файла.\nЯ добавил #, чтобы прокомментировать, где мы можем найти компоненты рабочего процесса YAML.\n#Workflow name: 90DaysOfDevOps #Event on: [push] #Jobs jobs: check-bats-version: #Runners runs-on: ubuntu-latest #Steps steps: #Actions - uses: actions/checkout@v2 - uses: actions/setup-node@v2 with: node-version: '14' - run: npm install -g bats - run: bats -v Приступаем к работе с GitHub Actions Я думаю, что у GitHub Actions есть много возможностей, да, они удовлетворят ваши потребности в CI/CD, когда речь идет о сборке, тестировании, развертывании вашего кода и последующих шагах.\nЯ вижу множество вариантов и других автоматизированных задач, для которых мы могли бы использовать GitHub Actions.\nИспользование GitHub Actions для линтинга вашего кода Один из вариантов - убедиться, что ваш код чист и аккуратен в вашем репозитории. Это будет наш первый демонстрационный пример.\nЯ собираюсь использовать некоторый пример кода, связанный в одном из ресурсов для этого раздела, мы будем использовать github/super-linter для проверки нашего кода.\nname: Super-Linter on: push jobs: super-lint: name: Lint code base runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Run Super-Linter uses: github/super-linter@v3 env: DEFAULT_BRANCH: main GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} github/super-linter Вы можете видеть, что для одного из наших шагов у нас есть действие под названием github/super-linter, которое ссылается на шаг, уже написанный сообществом. Вы можете узнать больше об этом здесь Super-Linter\n“Этот репозиторий предназначен для GitHub Action для запуска Super-Linter. Это простая комбинация различных линтеров, написанных на bash, чтобы помочь проверить ваш исходный код.”\nТакже в приведенном фрагменте кода упоминается GITHUB_TOKEN, поэтому мне было интересно узнать, зачем и для чего это нужно.\n“ПРИМЕЧАНИЕ: Если вы передадите переменную окружения GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} в вашем рабочем процессе, то GitHub Super-Linter будет отмечать статус каждого отдельного запуска линтера в разделе “Проверки” запроса на выгрузку. Без этого вы будете видеть только общий статус всего прогона. Не нужно устанавливать GitHub Secret, так как он автоматически устанавливается GitHub, его нужно только передать в действие.”.\nВыделенный жирным текст важно отметить на данном этапе. Мы используем его, но нам не нужно устанавливать какую-либо переменную окружения в нашем репозитории.\nДля тестирования мы будем использовать наш репозиторий, который мы использовали в нашей демонстрации Jenkins.Jenkins-HelloWorld.\nВот наш репозиторий в том виде, в котором мы оставили его в сессии Jenkins.\nДля того, чтобы воспользоваться преимуществами, мы должны использовать вкладку Actions выше, чтобы выбрать из рынка, о котором я расскажу в ближайшее время, или мы можем создать наши собственные файлы, используя наш код супер-лайнера выше, чтобы создать свой собственный, вы должны создать новый файл в вашем репозитории именно в этом месте. .github/workflows/workflow_name, очевидно, убедившись, что имя workflow_name - это что-то полезное для вас, узнаваемое. Здесь мы можем иметь множество различных рабочих процессов, выполняющих различные задания и задачи в нашем репозитории.\nМы создадим .github/workflows/super-linter.yml.\nЗатем мы можем вставить наш код и зафиксировать его в нашем репозитории, если мы перейдем на вкладку Actions, то увидим наш рабочий процесс Super-Linter в списке, как показано ниже,\nМы определили в нашем коде, что этот рабочий процесс будет запускаться, когда мы будем перемещать что-либо в наш репозиторий, поэтому при перемещении файла super-linter.yml в наш репозиторий мы запустили рабочий процесс.\nКак вы можете видеть из вышеприведенного, у нас есть некоторые ошибки, скорее всего, из-за моих способностей к взлому и кодированию.\nХотя на самом деле это был не мой код, по крайней мере пока, запустив его и получив ошибку, я обнаружил вот это issue\nДубль #2 Я изменил версию Super-Linter с версии 3 на 4 и запустил задачу снова.\nКак и ожидалось, мой хакерский кодинг вызвал некоторые проблемы, и вы можете увидеть их здесь, в рабочем процессе.\nЯ хотел показать, как теперь выглядит наш репозиторий, когда что-то в рабочем процессе не сработало или сообщило об ошибке.\nТеперь, если мы решим проблему с моим кодом и внесем изменения, наш рабочий процесс снова запустится (как видно из изображения, потребовалось некоторое время, чтобы устранить наши “ошибки”). Удаление файла, вероятно, не рекомендуется, но это очень быстрый способ показать, что проблема решена.\nЕсли вы нажмете кнопку “Новый рабочий процесс”, выделенную выше, это откроет вам дверь к огромному количеству действий. Вы, наверное, заметили, что мы не хотим изобретать колесо, мы хотим стоять на плечах гигантов и делиться нашим кодом, автоматизацией и навыками, чтобы сделать нашу жизнь проще.\nО, я не показал вам зеленую галочку на репозитории, когда наш рабочий процесс был успешным.\nЯ думаю, что на этом основы GitHub Actions исчерпаны, но если вы похожи на меня, то вы наверняка видите, как еще можно использовать GitHub Actions для автоматизации множества задач.\nДалее мы рассмотрим другую область CD, мы рассмотрим ArgoCD для развертывания наших приложений в наших средах.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"75. Обзор GitHub Actions","uri":"/ru/tracks/90daysofdevops/day75/"},{"content":"Обзор ArgoCD “Argo CD - это декларативный инструмент непрерывной доставки GitOps для Kubernetes”.\nКонтроль версий - ключевой момент здесь. Вы когда-нибудь вносили изменения в вашу среду на лету и не помните об этих изменениях, а поскольку свет горит и все вокруг зеленое, вы продолжаете упорно двигаться вперед? Вы когда-нибудь вносили изменения и ломали все или часть всего? Вы могли бы знать, что внесли изменение, и вы можете быстро откатить свое изменение, тот плохой скрипт или опечатку. А теперь сделайте это в массовом масштабе, и, возможно, это были не вы, или, возможно, ошибка была обнаружена не сразу, и теперь бизнес страдает. Поэтому контроль версий очень важен. Не только это, но и “определения приложений, конфигурации и окружения должны быть декларативными и контролируемыми по версиям”. В дополнение к этому (что взято из ArgoCD), они также упоминают, что “развертывание приложений и управление жизненным циклом должно быть автоматизировано, проверяемо и просто для понимания”.\nС точки зрения операционной деятельности, но много играя с Infrastructure as Code, это следующий шаг к обеспечению того, чтобы все эти хорошие вещи были улажены по пути с помощью рабочих процессов непрерывного развертывания/доставки.\nЧто такое ArgoCD\nРазвертывание ArgoCD Для этого развертывания мы снова будем использовать наш надежный кластер minikube Kubernetes локально.\nkubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml Убедитесь, что все подсистемы ArgoCD запущены и работают с помощью команды kubectl get pods -n argocd.\nТакже проверим все, что мы развернули в пространстве имен с помощью kubectl get all -n argocd\nКогда все выглядит хорошо, мы должны рассмотреть возможность доступа к этому через порт. Используя команду kubectl port-forward svc/argocd-server -n argocd 8080:443. Сделайте это в новом терминале.\nЗатем откройте новый веб-браузер и перейдите по адресу https://localhost:8080.\nДля входа в систему вам понадобится имя пользователя admin, а для получения созданного вами секрета в качестве пароля используйте команду kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d \u0026\u0026 echo\nПосле входа в систему у вас будет чистый холст CD.\nРазвертывание нашего приложения Теперь у нас есть ArgoCD, и мы можем начать использовать его для развертывания наших приложений из наших Git-репозиториев, а также Helm.\nПриложение, которое я хочу развернуть, это Pac-Man, да, именно так, знаменитая игра и то, что я использую во многих демонстрациях, когда речь идет об управлении данными, это не последний раз, когда мы видим Pac-Man.\nВы можете найти репозиторий для Pac-Man здесь.\nВместо того чтобы описывать каждый шаг с помощью снимков экрана, я решил, что будет проще создать видеоролик с описанием шагов, предпринятых для развертывания этого конкретного приложения.\nArgoCD Demo - 90DaysOfDevOps\nПримечание - Во время видео есть служба, которая никогда не удовлетворяется как здоровое приложение, это потому, что тип LoadBalancer, установленный для службы pacman, находится в состоянии ожидания, в Minikube у нас нет настроенного loadbalancer. Если вы хотите проверить это, вы можете изменить YAML для службы на ClusterIP и использовать проброс портов для игры.\nНа этом мы завершаем раздел CICD Pipelines, я считаю, что в настоящее время в индустрии уделяется большое внимание этой области, и вы также услышите термины GitOps, связанные с методологиями, используемыми в CICD в целом.\nСледующий раздел, в который мы переходим, посвящен Observability, еще одной концепции или области, которая не является новой, но становится все более важной, поскольку мы смотрим на наши среды по-другому.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"76. Обзор ArgoCD","uri":"/ru/tracks/90daysofdevops/day76/"},{"content":"Введение: Мониторинг В этом разделе мы поговорим о мониторинге, что это такое, зачем он нам нужен?\nЧто такое мониторинг? Мониторинг - это процесс пристального наблюдения за всей инфраструктурой.\nи зачем он нам нужен? Предположим, что мы управляем тысячей серверов, которые включают в себя множество специализированных серверов, таких как серверы приложений, серверы баз данных и веб-серверы. Мы также можем усложнить эту задачу за счет дополнительных сервисов и различных платформ, включая публичные облачные предложения и Kubernetes.\nМы отвечаем за то, чтобы все сервисы, приложения и ресурсы на серверах работали так, как должны.\nКак мы это делаем? Есть три способа:\nВойти вручную на все наши серверы и проверить все данные, относящиеся к процессам и ресурсам служб. Написать скрипт, который заходит на серверы за нас и проверяет данные. Оба варианта потребуют от нас значительного объема работы,\nТретий вариант проще, мы можем использовать решение для мониторинга, которое доступно на рынке.\nNagios и Zabbix - это возможные решения, которые легко доступны и позволяют нам расширить нашу инфраструктуру мониторинга, чтобы включить столько серверов, сколько мы захотим.\nNagios Nagios - это инструмент мониторинга инфраструктуры, созданный одноименной компанией. Версия этого инструмента с открытым исходным кодом называется Nagios core, а коммерческая версия называется Nagios XI. Сайт Nagios\nЭтот инструмент позволяет нам следить за нашими серверами и видеть, достаточно ли они используются или есть какие-либо задачи, требующие решения.\nПо сути, мониторинг позволяет нам достичь этих двух целей, проверить состояние наших серверов и сервисов и определить здоровье нашей инфраструктуры. Он также дает нам возможность увидеть всю инфраструктуру с высоты 40 000 метров, чтобы увидеть, работают ли наши серверы, правильно ли работают приложения, доступны или нет веб-серверы.\nОн сообщит нам, что объем нашего диска увеличивался на 10 процентов в течение последних 10 недель на определенном сервере, что он будет полностью исчерпан в течение следующих четырех или пяти дней, и мы не сможем ответить в ближайшее время. Он предупредит нас, когда ваш диск или сервер находится в критическом состоянии, чтобы мы могли принять соответствующие меры, чтобы избежать возможных сбоев.\nВ этом случае мы можем освободить некоторое дисковое пространство и гарантировать, что наши серверы не выйдут из строя и наши пользователи не пострадают.\nСложный вопрос для большинства инженеров по мониторингу - что мы отслеживаем, а что нет?\nКаждая система имеет ряд ресурсов, за какими из них мы должны внимательно следить, а на какие можем закрыть глаза, например, нужно ли следить за использованием процессора, ответ “да” очевиден, тем не менее, это все равно решение, которое нужно принять, нужно ли следить за количеством открытых портов в системе, мы можем следить или не следить в зависимости от ситуации, если это сервер общего назначения, то, вероятно, не нужно, но если это веб-сервер, то, вероятно, нужно.\nПостоянный мониторинг Мониторинг не является чем-то новым, и даже непрерывный мониторинг был идеалом, который многие предприятия приняли в течение многих лет.\nЕсть три ключевых области, на которых необходимо сосредоточиться, когда речь заходит о мониторинге.\nМониторинг инфраструктуры Мониторинг приложений Мониторинг сети Важно отметить, что существует множество доступных инструментов, мы упомянули две общие системы и инструменты в этой сессии, но их очень много. Реальная польза от решения для мониторинга появляется тогда, когда вы действительно потратили время на то, чтобы убедиться, что вы ответили на вопрос, что мы должны отслеживать, а что нет?\nМы можем включить решение мониторинга в любой из наших платформ, и оно начнет собирать информацию, но если этой информации просто слишком много, вам будет трудно извлечь пользу из этого решения, вам придется потратить время на настройку.\nНа следующем занятии мы попробуем использовать инструмент мониторинга и посмотрим, что мы можем начать отслеживать.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring ","description":"","title":"77. Мониторинг","uri":"/ru/tracks/90daysofdevops/day77/"},{"content":"Инструменты мониторинга своими руками На последнем занятии я говорил об общей картине мониторинга и рассмотрел Nagios, для этого было две причины. Во-первых, это программное обеспечение, о котором я много слышал на протяжении многих лет, поэтому хотел узнать немного больше о его возможностях.\nСегодня я буду изучать Prometheus, я все больше и больше вижу Prometheus в ландшафте Cloud-Native, но его также можно использовать для присмотра за физическими ресурсами вне Kubernetes и тому подобного.\nPrometheus - мониторинг практически всего Прежде всего, Prometheus - это Open-Source, который может помочь вам контролировать контейнеры и системы на базе микросервисов, а также физические, виртуальные и другие сервисы. За Prometheus стоит большое сообщество.\nPrometheus имеет большой набор интеграций и экспортеров Ключевым моментом является экспорт существующих метрик в метрики Prometheus. Кроме того, он также поддерживает несколько языков программирования.\nПодход Pull - Если вы работаете с тысячами микросервисов или систем и сервисов, то метод push - это метод, при котором сервис, как правило, обращается к системе мониторинга. При этом возникают некоторые проблемы, связанные с переполнением сети, высокой производительностью процессора и единой точкой отказа. Метод Pull дает нам гораздо лучший опыт, когда Prometheus будет получать данные из конечной точки метрики на каждом сервисе.\nИ снова мы видим YAML для конфигурации Prometheus.\nПозже вы увидите, как это выглядит при развертывании в Kubernetes, в частности, у нас есть PushGateway, который получает наши метрики от наших заданий/экспортеров.\nУ нас есть AlertManager, который рассылает оповещения, и именно здесь мы можем интегрироваться во внешние сервисы, такие как электронная почта, slack и другие инструменты.\nЗатем у нас есть сервер Prometheus, который управляет получением этих метрик из PushGateway, а затем отправляет эти оповещения в AlertManager. Сервер Prometheus также хранит данные на локальном диске. Хотя можно использовать решения для удаленного хранения данных.\nУ нас также есть PromQL - язык, используемый для взаимодействия с метриками, который можно увидеть позже в веб-интерфейсе Prometheus, но позже в этом разделе вы также увидите, как он используется в инструментах визуализации данных, таких как Grafana.\nСпособы развертывания Prometheus Существуют различные способы установки Prometheus, Download Section Также доступны образы Docker.\ndocker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus.\nНо мы сосредоточим наши усилия на развертывании в Kubernetes. У которого также есть несколько вариантов.\nСоздание конфигурационных YAML-файлов Использование оператора (менеджер всех компонентов prometheus) Использование диаграммы helm для развертывания оператора Развертывание в Kubernetes Для этой быстрой и простой установки мы снова будем использовать наш локальный кластер minikube. Как и в предыдущих случаях с minikube, мы будем использовать helm для развертывания диаграммы Prometheus helm.\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts.\nКак видно из вышеприведенного, мы также выполнили обновление репо helm, теперь мы готовы развернуть Prometheus в нашей среде minikube с помощью команды helm install stable prometheus-community/prometheus.\nЧерез пару минут вы увидите, что появилось несколько новых подкастов, для этого демо я развернул их в пространство имен по умолчанию, обычно я бы развернул их в собственное пространство имен.\nПосле запуска всех подсистем мы также можем посмотреть на все развернутые аспекты Prometheus.\nТеперь, чтобы получить доступ к пользовательскому интерфейсу сервера Prometheus, мы можем использовать следующую команду для проброса портов.\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl --namespace default port-forward $POD_NAME 9090 Когда мы впервые открываем наш браузер на http://localhost:9090, мы видим следующий очень пустой экран.\nПоскольку мы развернули наш кластер Kubernetes, мы будем автоматически получать метрики из нашего Kubernetes API, поэтому мы можем использовать некоторые PromQL, чтобы убедиться, что мы получаем метрики container_cpu_usage_seconds_total.\nКоротко об изучении PromQL и применении его на практике. Это очень похоже на то, о чем я говорил ранее: получение метрик - это здорово, как и мониторинг, но вы должны знать, что вы отслеживаете и почему, и что вы не отслеживаете и почему!\nЯ хочу вернуться к Prometheus, но пока я думаю, что нам нужно подумать об управлении журналами и визуализации данных, чтобы позже вернуться к Prometheus.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples ","description":"","title":"78. Hands-On Monitoring Tools","uri":"/ru/tracks/90daysofdevops/day78/"},{"content":"Введение: Управление журналами В продолжение проблем и решений в области мониторинга инфраструктуры, управление журналами - это еще один пазл в общей картине наблюдаемости.\nУправление и агрегация журналов Давайте поговорим о двух основных концепциях, первая из которых - агрегация журналов, это способ сбора и маркировки журналов приложений от множества различных служб в единую приборную панель, по которой можно легко осуществлять поиск.\nОдной из первых систем, которые должны быть построены в системе управления производительностью приложений, является агрегация журналов. Управление производительностью приложений - это та часть жизненного цикла devops, когда все было создано и развернуто, и вам нужно убедиться, что они постоянно работают, что им выделено достаточно ресурсов и что ошибки не показываются пользователям. В большинстве производственных развертываний существует множество связанных событий, которые передают журналы по сервисам, в google один поиск может попасть в десять различных сервисов, прежде чем будет возвращен пользователю, если вы получили неожиданные результаты поиска, это может означать логическую проблему в любом из десяти сервисов, и агрегация журналов помогает таким компаниям, как google, диагностировать проблемы в производстве.\nВ этом суть хорошей платформы для агрегации журналов, которая эффективно собирает журналы отовсюду, откуда они исходят, и делает их легко доступными для поиска в случае повторного возникновения неисправности.\nПример приложения Наш пример приложения - это веб-приложение, у нас есть типичный фронт-энд и бэк-энд, хранящий наши важные данные в базе данных MongoDB.\nЕсли бы пользователь сказал нам, что страница стала белой и вывела сообщение об ошибке, мы бы с трудом диагностировали проблему с помощью нашего текущего стека. Пользователь должен вручную отправить нам ошибку, а мы должны сопоставить ее с соответствующими журналами в трех других сервисах.\nELK Давайте посмотрим на ELK, популярный стек агрегации логов с открытым исходным кодом, названный в честь его трех компонентов elasticsearch, logstash и kibana, если мы установим его в той же среде, что и наше приложение.\nВеб-приложение подключается к фронтенду, который затем подключается к бэкенду, бэкенд отправляет журналы в logstash, а затем то, как работают эти три компонента.\nКомпоненты elk Elasticsearch, logstash и Kibana заключается в том, что все сервисы отправляют журналы в logstash, logstash принимает эти журналы, которые являются текстом, испускаемым приложением. Например, веб-приложение, когда вы посещаете веб-страницу, может зарегистрировать доступ посетителя к этой странице в это время, и это пример сообщения журнала, которое будет отправлено в logstash.\nЗатем Logstash извлекает из них информацию, так что для этого сообщения пользователь сделал что-то, в время. Он извлечет время, извлечет сообщение, извлечет пользователя и включит все это в качестве тегов, так что сообщение будет объектом тегов и сообщений, так что вы можете легко искать по ним, вы можете найти все запросы, сделанные определенным пользователем, но logstash не хранит вещи самостоятельно, он хранит вещи в elasticsearch, который является эффективной базой данных для запроса текста, и elasticsearch раскрывает результаты как Kibana, а Kibana - это веб-сервер, который подключается к elasticsearch и позволяет администраторам, таким как devops или другим людям в вашей команде, дежурному инженеру просматривать журналы в производстве при возникновении серьезных неполадок. Вы, как администратор, подключаетесь к Kibana, Kibana запрашивает elasticsearch на предмет журналов, соответствующих тому, что вы хотите.\nВы можете сказать: “Эй, Kibana, в строке поиска я хочу найти ошибки”, и Kibana скажет elasticsearch найти сообщения, которые содержат строку error, а затем elasticsearch вернет результаты, которые были заполнены logstash. Logstash получил бы эти результаты от всех других служб.\nкак бы мы использовали elk для диагностики производственной проблемы Пользователь говорит, что я увидел код ошибки один два три четыре пять шесть семь, когда я попытался сделать это с помощью настройки elk, мы должны зайти в kibana, ввести один два три четыре пять шесть семь в строке поиска, нажать enter, а затем это покажет нам журналы, которые соответствуют этому, и один из журналов может сказать внутреннюю ошибку сервера, возвращающую один два три четыре пять шесть семь, и мы увидим, что служба, которая выдала этот журнал. и мы увидим, что служба, которая выдала этот журнал, была backend, и мы увидим, в какое время был выдан этот журнал, поэтому мы можем перейти ко времени в этом журнале и посмотреть на сообщения выше и ниже него в backend, и тогда мы сможем увидеть лучшую картину того, что произошло для запроса пользователя, и мы сможем повторить этот процесс, переходя к другим службам, пока не найдем, что на самом деле вызвало проблему у пользователя.\nБезопасность и доступ к журналам Важной частью головоломки является обеспечение того, чтобы журналы были видны только администраторам (или пользователям и группам, которым абсолютно необходим доступ). Журналы могут содержать конфиденциальную информацию, такую как токены, поэтому важно, чтобы только аутентифицированные пользователи могли получить к ним доступ. Вы не захотите выставлять Kibana в интернет без какого-либо способа аутентификации.\nПримеры инструментов управления журналами Примерами платформ для управления журналами являются\nElasticsearch Logstash Kibana Fluentd - популярный вариант с открытым исходным кодом Datadog - хостинговое предложение, обычно используется на крупных предприятиях, LogDNA - хостируемое предложение Splunk Облачные провайдеры также предоставляют протоколирование, например, AWS CloudWatch Logs, Microsoft Azure Monitor и Google Cloud Logging.\nУправление журналами является ключевым аспектом общей наблюдаемости ваших приложений и среды инфраструктур для диагностики проблем в производстве. Относительно просто установить готовое решение, такое как ELK или CloudWatch, и это значительно упрощает диагностику и устранение проблем в производстве.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained ","description":"","title":"79. Log Management","uri":"/ru/tracks/90daysofdevops/day79/"},{"content":"Настройка DevOps окружения для запуска Hello World на Go Прежде чем мы приступим к некоторым основам Go, мы должны установить Go на нашу рабочую станцию и сделать то, чему нас учит каждый модуль «Изучение программирования 101», а именно создать приложение Hello World. Так как здесь будут описаны шаги по установке Go на ваш ПК, мы попытаемся задокументировать процесс в картинках, чтобы людям было легко следовать за ним.\nВозможные варианты установки Golang\nИсполняемый файл Пакет из исходного кода Mac Os Homebrew #Homebrew install command brew install go Быстрый тьюториал для ознакомления с языком Go\nРассмотрим вараинт установки с помощью инсталляционного файла\nЕсли мы зашли так далеко, вы, вероятно, знаете, какая операционная система рабочей станции у вас установлена, поэтому выберите соответствующую загрузку, и тогда мы сможем приступить к установке. Я использую Windows для этого пошагового руководства. На следующем шаге мы можем оставить все значения по умолчанию. (Отмечу, что на момент написания это была последняя версия, поэтому скриншоты могут быть устаревшими)\nТакже обратите внимание, что если у вас установлена более старая версия Go, вам придется удалить ее перед установкой, поскольку в Windows она встроена в установщик, и она будет удалена и установлена как единое целое.\nПосле завершения вы должны открыть командную строку / терминал, и мы хотим проверить, установлен ли Go. Если вы не получите вывод, который мы видим ниже, значит, Go не установлен, и вам нужно будет повторить свои шаги.\ngo version Далее мы хотим проверить нашу среду на наличие Go. Это всегда полезно проверить, чтобы убедиться, что ваши рабочие каталоги настроены правильно, как вы можете видеть ниже, нам нужно убедиться, что в вашей системе есть следующий каталог.\nХорошо, давайте создадим этот каталог для простоты. Я собираюсь использовать команду mkdir в своем терминале PowerShell. Нам также нужно создать 3 папки в папке Go, как вы увидите ниже.\nТеперь у нас установлен Go, и у нас есть рабочий каталог Go, готовый к действию. Теперь нам нужна интегрированная среда разработки (IDE). Сейчас есть много доступных, которые вы можете использовать, но наиболее распространенным и тем, который я использую, является Visual Studio Code или Code. Вы можете узнать больше об IDE здесь.\nЕсли вы еще не загрузили и не установили VSCode на свою рабочую станцию, вы можете сделать это, перейдя по ссылке. Как вы можете видеть ниже, у вас есть разные варианты ОС.\nПочти так же, как и при установке Go, мы собираемся загрузить и установить и сохранить значения по умолчанию. После завершения вы можете открыть VSCode, выбрать «Открыть файл» и перейти в наш каталог Go, который мы создали выше.\nВы можете получить всплывающее окно о доверии, прочитать его, если хотите, а затем нажать «Да, доверять авторам». (Позже я не несу ответственности, если вы начнете открывать вещи, которым не доверяете!)\nТеперь вы должны увидеть три папки, которые мы также создали ранее, и теперь мы хотим щелкнуть правой кнопкой мыши папку src и создать новую папку с именем «Hello».\nДовольно простые вещи, я бы сказал до этого момента? Теперь мы собираемся создать нашу первую программу Go, не понимая, что мы вкладываем в этот следующий этап.\nЗатем создайте файл с именем main.go в папке Hello. Как только вы нажмете Enter на main.go, вас спросят, хотите ли вы установить расширение Go, а также пакеты, вы также можете проверить этот пустой файл pkg, который мы сделали несколько шагов назад, и обратите внимание, что у нас должны быть новые пакеты. там сейчас?\nТеперь давайте запустим это приложение Hello World, скопируйте следующий код в новый файл main.go и сохраните его.\npackage main import \"fmt\" func main() { fmt.Println(\"Hello #90DaysOfDevOps\") } Я понимаю, что вышеизложенное может не иметь никакого смысла, но мы подробнее расскажем о функциях, пакетах и многом другом позже. А пока давайте запустим наше приложение. Вернувшись в терминал и в нашу папку Hello, мы можем проверить, все ли работает. Используя приведенную ниже команду, мы можем проверить, работает ли наша общая программа обучения.\ngo run main.go Однако на этом это не заканчивается, что, если теперь мы захотим взять нашу программу и запустить ее на других машинах с Windows? Мы можем сделать это, создав наш двоичный файл, используя следующую команду\ngo build main.go Попробуем запустить\n#Windows ./main.exe #Linux/Mac Os ./main Источники Быстрое погружение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 9-й день\n","description":"Настройка DevOps окружения для запуска Hello World на Go","title":"8. Настройка DevOps окружения для запуска Hello World на Go","uri":"/ru/tracks/90daysofdevops/day08/"},{"content":"ELK Stack На этом занятии мы немного подробнее рассмотрим некоторые из упомянутых нами опций.\nELK Stack ELK Stack - это комбинация трех отдельных инструментов:\nElasticsearch - это распределенный, бесплатный и открытый поисковый и аналитический механизм для всех типов данных, включая текстовые, числовые, геопространственные, структурированные и неструктурированные.\nLogstash - свободный и открытый конвейер обработки данных на стороне сервера, который получает данные из множества источников, преобразует их, а затем отправляет в ваш любимый “тайник”.\nKibana - это бесплатный и открытый пользовательский интерфейс, позволяющий визуализировать данные Elasticsearch и перемещаться по стеку Elastic Stack. Делайте все, что угодно: от отслеживания загрузки запросов до понимания того, как запросы проходят через ваши приложения.\nСтек ELK позволяет нам надежно и безопасно получать данные из любого источника, в любом формате, затем искать, анализировать и визуализировать их в режиме реального времени.\nВ дополнение к вышеперечисленным компонентам вы также можете увидеть Beats - легковесные агенты, которые устанавливаются на пограничных узлах для сбора различных типов данных для передачи в стек.\nЖурналы: Определяются журналы сервера, которые необходимо проанализировать.\nLogstash: Собирает журналы и данные о событиях. Он даже анализирует и преобразует данные.\nElasticSearch: Преобразованные данные из Logstash хранятся, ищутся и индексируются.\nKibana использует БД Elasticsearch для изучения, визуализации и обмена данными\nИзображение взято с сайта Guru99\nХороший ресурс, объясняющий это The Complete Guide to the ELK Stack\nС добавлением битов стек ELK теперь также известен как Elastic Stack.\nДля практического скрипта существует множество мест, где можно развернуть Elastic Stack, но мы будем использовать docker compose для локального развертывания в нашей системе.\nStart the Elastic Stack with Docker Compose\nОригинальные файлы и руководство, которые я использовал, вы найдете здесь deviantony/docker-elk\nТеперь мы можем запустить docker-compose up -d, при первом запуске потребуется вытащить изображения.\nЕсли вы следите за этим репозиторием или за тем, который использовал я, у вас будет пароль “changeme” или в моем репозитории пароль “90DaysOfDevOps”. Имя пользователя - “elastic”.\nЧерез несколько минут мы можем перейти на сайт http://localhost:5601/, который является нашим сервером Kibana / Docker-контейнером.\nВаш начальный главный экран будет выглядеть примерно так.\nВ разделе “Get started by adding integrations” есть пункт “try sample data”, нажмите на него, и мы сможем добавить одну из показанных ниже интеграций.\nЯ собираюсь выбрать “Sample web logs”, но это действительно для того, чтобы получить представление о том, какие наборы данных можно получить в стеке ELK.\nКогда вы выбрали “Добавить данные”, требуется некоторое время, чтобы заполнить некоторые из этих данных, а затем у вас появляется опция “Просмотр данных” и список доступных способов просмотра этих данных в выпадающем списке.\nКак указано в представлении приборной панели:\nОбразцы данных журналов\nЭта приборная панель содержит образцы данных, с которыми вы можете поиграть. Вы можете просматривать их, искать и взаимодействовать с визуализациями. Для получения дополнительной информации о Kibana ознакомьтесь с нашей документацией.\nЗдесь используется Kibana для визуализации данных, которые были добавлены в ElasticSearch через Logstash. Это не единственный вариант, но я лично хотел развернуть и посмотреть на это.\nВ какой-то момент мы рассмотрим Grafana, и вы увидите некоторые сходства в визуализации данных между ними, вы также видели Prometheus.\nКлючевой момент, который я уловил между Elastic Stack и Prometheus + Grafana, заключается в том, что Elastic Stack или ELK Stack сосредоточен на журналах, а Prometheus - на метриках.\nЯ читал эту статью от MetricFire Prometheus vs. ELK, чтобы лучше понять различные предложения.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? [Fluentd simply explained](https://www.youtube.com/watch?v=5ofsNyHZwWE\u0026t=14s ","description":"","title":"80. ELK Stack","uri":"/ru/tracks/90daysofdevops/day80/"},{"content":"Fluentd и FluentBit Еще одним коллектором данных, который я хотел изучить в рамках раздела о наблюдаемости, был Fluentd. Это унифицированный уровень протоколирования с открытым исходным кодом.\nFluentd имеет четыре ключевые особенности, которые делают его подходящим для создания чистых, надежных конвейеров протоколирования:\nУнифицированное протоколирование с JSON: Fluentd старается структурировать данные в виде JSON, насколько это возможно. Это позволяет Fluentd унифицировать все аспекты обработки данных журналов: сбор, фильтрацию, буферизацию и вывод журналов из нескольких источников и мест назначения. Последующая обработка данных намного проще с JSON, так как он имеет достаточную структуру, чтобы быть доступным без принуждения к жестким схемам.\nПодключаемая архитектура: Fluentd имеет гибкую систему плагинов, которая позволяет сообществу расширять его функциональность. Более 300 плагинов, созданных сообществом, соединяют десятки источников данных с десятками выходных данных, манипулируя данными по мере необходимости. Используя плагины, вы можете сразу же повысить эффективность использования ваших журналов.\nТребуется минимум ресурсов: Коллектор данных должен быть легким, чтобы его можно было легко запустить на загруженной машине. Fluentd написан на комбинации C и Ruby и требует минимальных системных ресурсов. Ванильный экземпляр работает на 30-40 МБ памяти и может обрабатывать 13 000 событий/секунду/ядро.\nВстроенная надежность: Потеря данных никогда не должна произойти. Fluentd поддерживает буферизацию на основе памяти и файлов для предотвращения потери данных между узлами. Fluentd также поддерживает надежное восстановление после отказа и может быть настроен на высокую доступность.\nУстановка Fluentd\nКак приложения записывают данные в журнал? Запись в файлы. Файлы .log (трудно анализировать без инструмента и в масштабе) Вести журнал непосредственно в базу данных (каждое приложение должно быть настроено на правильный формат) Сторонние приложения (NodeJS, NGINX, PostgreSQL). Вот почему нам нужен единый уровень логирования.\nFluentD позволяет использовать 3 типа данных, показанных выше, и дает нам возможность собирать, обрабатывать и отправлять их по назначению, это может быть отправка логов в базы данных Elastic, MongoDB, Kafka, например.\nЛюбые данные, любой источник данных может быть отправлен в FluentD, и эти данные могут быть отправлены в любое место назначения. FluentD не привязан к какому-либо конкретному источнику или месту назначения.\nИзучая Fluentd, я постоянно натыкался на Fluent bit как еще один вариант, и похоже, что если вы хотите развернуть инструмент протоколирования в среде Kubernetes, то Fluent bit даст вам такую возможность, хотя Fluentd также может быть развернут как на контейнерах, так и на серверах.\nFluentd \u0026 Fluent Bit\nFluentd и Fluentbit будут использовать входные плагины для преобразования данных в формат Fluent Bit, затем у нас есть выходные плагины для любой цели вывода, например, elasticsearch.\nМы также можем использовать теги и соответствия между конфигурациями.\nЯ не вижу веских причин для использования Fluentd, и кажется, что Fluent Bit - лучший способ начать работу. Хотя в некоторых архитектурах они могут использоваться вместе.\nFluent Bit в Kubernetes Fluent Bit в Kubernetes развертывается как DaemonSet, что означает, что он будет запущен на каждом узле кластера. Каждая капсула Fluent Bit на каждом узле будет читать каждый контейнер на этом узле и собирать все доступные журналы. Он также будет собирать метаданные с сервера Kubernetes API Server.\nАннотации Kubernetes можно использовать в конфигурационном YAML наших приложений.\nПрежде всего, мы можем развернуть приложение из репозитория fluent helm. helm repo add fluent https://fluent.github.io/helm-charts, а затем установить с помощью команды helm install fluent-bit fluent/fluent-bit.\nВ моем кластере я также запускаю prometheus в моем пространстве имен по умолчанию (в тестовых целях), нам нужно убедиться, что наш fluent-bit pod запущен и работает. Мы можем сделать это с помощью команды kubectl get all | grep fluent, которая покажет нам наш запущенный pod, сервис и набор демонов, о которых мы говорили ранее.\nЧтобы Fluentbit знал, откуда получать журналы, у нас есть конфигурационный файл, в этом развертывании Fluentbit на Kubernetes у нас есть configmap, который напоминает конфигурационный файл.\nЭта ConfigMap будет выглядеть примерно так:\nName: fluent-bit Namespace: default Labels: app.kubernetes.io/instance=fluent-bit app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=fluent-bit app.kubernetes.io/version=1.8.14 helm.sh/chart=fluent-bit-0.19.21 Annotations: meta.helm.sh/release-name: fluent-bit meta.helm.sh/release-namespace: default Data ==== custom_parsers.conf: ---- [PARSER] Name docker_no_time Format json Time_Keep Off Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L fluent-bit.conf: ---- [SERVICE] Daemon Off Flush 1 Log_Level info Parsers_File parsers.conf Parsers_File custom_parsers.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 Health_Check On [INPUT] Name tail Path /var/log/containers/*.log multiline.parser docker, cri Tag kube.* Mem_Buf_Limit 5MB Skip_Long_Lines On [INPUT] Name systemd Tag host.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service Read_From_Tail On [FILTER] Name kubernetes Match kube.* Merge_Log On Keep_Log Off K8S-Logging.Parser On K8S-Logging.Exclude On [OUTPUT] Name es Match kube.* Host elasticsearch-master Logstash_Format On Retry_Limit False [OUTPUT] Name es Match host.* Host elasticsearch-master Logstash_Format On Logstash_Prefix node Retry_Limit False Events: \u003cnone\u003e Теперь мы можем перенаправить наш pod на наш localhost, чтобы убедиться, что у нас есть соединение. Сначала узнайте имя вашего pod с помощью kubectl get pods | grep fluent и затем используйте kubectl port-forward fluent-bit-8kvl4 2020:2020 откройте веб-браузер на http://localhost:2020/.\nЯ также нашел эту замечательную статью на Medium, в которой рассказывается о Fluent Bit.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained Fluent Bit explained | Fluent Bit vs Fluentd ) ","description":"","title":"81. Fluentd и FluentBit","uri":"/ru/tracks/90daysofdevops/day81/"},{"content":"EFK Stack В предыдущем разделе мы говорили о ELK Stack, который использует Logstash в качестве сборщика логов в стеке, в EFK Stack мы меняем его на FluentD или FluentBit.\nНаша задача в этом разделе - отслеживать журналы Kubernetes с помощью EFK.\nОбзор EFK Мы развернем следующее в нашем кластере Kubernetes.\nСтек EFK представляет собой набор из 3 программ, объединенных вместе, включая:\nElasticsearch : NoSQL база данных используется для хранения данных и предоставляет интерфейс для поиска и журнал запросов.\nFluentd : Fluentd - это сборщик данных с открытым исходным кодом для унифицированного уровня логирования. Fluentd позволяет унифицировать сбор и потребление данных для лучшего использования и понимания данных.\nKibana : Интерфейс для управления и статистики журналов. Отвечает за чтение информации из elasticsearch .\nРазвертывание EFK на Minikube Мы будем использовать наш надежный кластер minikube для развертывания нашего стека EFK. Давайте запустим кластер с помощью minikube start на нашей системе. Я использую ОС Windows с включенным WSL2.\nЯ создал efk-stack.yaml, который содержит все необходимое для развертывания стека EFK в нашем кластере, используя команду kubectl create -f efk-stack.yaml мы видим, что все развернуто.\nВ зависимости от вашей системы и если вы уже выполняли эту процедуру и получили изображения, теперь вам нужно посмотреть, как стручки переходят в состояние готовности, прежде чем мы сможем двигаться дальше, вы можете проверить прогресс с помощью следующей команды. kubectl get pods -n kube-logging -w Это может занять несколько минут.\nПриведенная выше команда позволяет нам следить за ситуацией, но я люблю уточнять, все ли в порядке, выполняя следующую команду kubectl get pods -n kube-logging, чтобы убедиться, что все pods теперь работают.\nПосле того, как мы запустили все наши pods, и на этом этапе мы должны увидеть\n3 стручка, связанные с ElasticSearch 1 стручок, связанный с Fluentd 1 стручок, связанный с Kibana Мы также можем использовать kubectl get all -n kube-logging, чтобы показать все в нашем пространстве имен, fluentd, как объяснялось ранее, развернут как набор демонов, kibana как развертывание и ElasticSearch как набор состояний.\nТеперь все наши pods работают, и мы можем ввести в новом терминале команду port-forward, чтобы мы могли получить доступ к нашей приборной панели kibana. Обратите внимание, что имя вашего pod будет отличаться от команды, которую мы видим здесь. kubectl port-forward kibana-84cf7f59c-v2l8v 5601:5601 -n kube-logging.\nТеперь мы можем открыть браузер и перейти по этому адресу, http://localhost:5601 вас встретит либо экран, который вы видите ниже, либо вы можете увидеть экран с примерами данных, либо продолжить и настроить самостоятельно. В любом случае и непременно посмотрите на эти тестовые данные, это то, что мы рассмотрели при изучении стека ELK в предыдущей сессии.\nДалее нам нужно перейти на вкладку “discover” в левом меню и добавить “*” к нашему шаблону индекса. Перейдите к следующему шагу, нажав кнопку “Следующий шаг”.\nНа шаге 2 из 2 мы будем использовать опцию @timestamp из выпадающего списка, так как это позволит отфильтровать наши данные по времени. Когда вы нажмете кнопку создать шаблон, это может занять несколько секунд.\nЕсли через несколько секунд мы вернемся на вкладку “discover”, вы должны увидеть данные, поступающие с вашего кластера Kubernetes.\nТеперь, когда у нас установлен и работает стек EFK и мы собираем журналы с нашего кластера Kubernetes через Fluentd, мы можем взглянуть на другие источники, которые мы можем выбрать. Если вы перейдете на главный экран, нажав на логотип Kibana в левом верхнем углу, вас встретит та же страница, которую мы видели при первом входе в систему.\nУ нас есть возможность добавить APM, данные журнала, метрические данные и события безопасности из других плагинов или источников.\nЕсли мы выберем “Добавить данные журнала”, то увидим ниже, что у нас есть большой выбор, откуда мы хотим получать наши журналы, вы можете увидеть, что там упоминается Logstash, который является частью стека ELK.\nПод данными метрик вы увидите, что можно добавить источники для Prometheus и многих других сервисов. Переведено с помощью www.DeepL.com/Translator (бесплатная версия)\nAPM (Мониторинг производительности приложений) Также есть возможность собрать APM (мониторинг производительности приложений), который собирает подробные показатели производительности и ошибки изнутри вашего приложения. Он позволяет отслеживать производительность тысяч приложений в режиме реального времени.\nЯ не буду здесь углубляться в APM, но вы можете узнать больше на сайте Elastic.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained See you on Day 83\n","description":"","title":"82. EFK Stack","uri":"/ru/tracks/90daysofdevops/day82/"},{"content":"Визуализация данных - Grafana Мы много говорили о Kibana в этом разделе, посвященном Observability. Но мы также должны уделить некоторое время Grafana. Но это не одно и то же, и они не полностью конкурируют друг с другом.\nОсновной функцией Kibana является запрос и анализ данных. Используя различные методы, пользователи могут искать в данных, проиндексированных в Elasticsearch, определенные события или строки в данных для анализа и диагностики первопричин. На основе этих запросов пользователи могут использовать функции визуализации Kibana, которые позволяют визуализировать данные различными способами, используя графики, таблицы, географические карты и другие виды визуализации.\nGrafana фактически началась как форк Kibana, целью Grafana была поддержка метрик и мониторинга, которые в то время Kibana не предоставляла.\nGrafana - это бесплатный инструмент визуализации данных с открытым исходным кодом. Обычно мы видим Prometheus и Grafana вместе в полевых условиях, но мы также можем увидеть Grafana вместе с Elasticsearch и Graphite.\nКлючевое различие между этими двумя инструментами - это логирование и мониторинг. В начале раздела мы рассмотрели мониторинг с помощью Nagios, затем Prometheus и перешли к логированию, где мы рассмотрели стеки ELK и EFK.\nGrafana предназначена для анализа и визуализации таких показателей, как использование системного процессора, памяти, дисков и ввода-вывода. Платформа не позволяет выполнять полнотекстовые запросы данных. Kibana работает поверх Elasticsearch и используется в основном для анализа сообщений журнала.\nКак мы уже выяснили, Kibana довольно проста в развертывании, а также в выборе места установки, то же самое можно сказать и о Grafana.\nОба поддерживают установку на Linux, Mac, Windows, Docker или сборку из исходников.\nНесомненно, есть и другие, но Grafana - это инструмент, который, по моим наблюдениям, охватывает виртуальные, облачные и облачно-нативные платформы, поэтому я хотел рассказать о нем в этом разделе.\nОператор Prometheus + развертывание Grafana Мы уже рассказывали о Prometheus в этом разделе, но поскольку мы так часто видим эти пары, я хотел создать среду, которая позволила бы нам хотя бы увидеть, какие метрики мы могли бы отображать в визуализации. Мы знаем, что мониторинг наших сред очень важен, но просмотр этих метрик в Prometheus или любом другом метрическом инструменте будет громоздким и не будет масштабироваться. Именно здесь на помощь приходит Grafana, которая предоставляет нам интерактивную визуализацию этих метрик, собранных и сохраненных в базе данных Prometheus.\nС помощью этой визуализации мы можем создавать пользовательские графики, диаграммы и оповещения для нашей среды. В этом руководстве мы будем использовать наш кластер minikube.\nДля начала мы клонируем его в нашу локальную систему. Используя git clone https://github.com/prometheus-operator/kube-prometheus.git и cd kube-prometheus.\nПервая задача - создать наше пространство имен в кластере minikube kubectl create -f manifests/setup, если вы не следили за предыдущими разделами, мы можем использовать minikube start для создания нового кластера.\nДалее мы собираемся развернуть все необходимое для нашего демо с помощью команды kubectl create -f manifests/, как вы можете видеть, это развернет множество различных ресурсов в нашем кластере.\nЗатем нам нужно подождать, пока наши стручки поднимутся, и, находясь в запущенном состоянии, мы можем использовать команду kubectl get pods -n monitoring -w, чтобы следить за стручками.\nКогда все запущено, мы можем проверить, что все pods находятся в рабочем и здоровом состоянии, используя команду kubectl get pods -n monitoring.\nПри развертывании мы развернули ряд сервисов, которые мы будем использовать позже в демо, вы можете проверить их с помощью команды kubectl get svc -n monitoring.\nИ, наконец, давайте проверим все ресурсы, развернутые в нашем новом пространстве имен мониторинга, используя команду kubectl get all -n monitoring.\nОткрыв новый терминал, мы готовы получить доступ к нашему инструменту Grafana и начать собирать и визуализировать некоторые из наших метрик, команда для использования - kubectl --namespace monitoring port-forward svc/grafana 3000.\nОткройте браузер и перейдите по адресу http://localhost:3000, вам будет предложено ввести имя пользователя и пароль.\nПо умолчанию имя пользователя и пароль для доступа следующие\nИмя пользователя: admin Пароль: admin Однако при первом входе в систему вам будет предложено ввести новый пароль. На начальном экране или домашней странице вы увидите несколько областей для изучения, а также некоторые полезные ресурсы для ознакомления с Grafana и ее возможностями. Обратите внимание на виджеты “Добавить свой первый источник данных” и “Создать свою первую приборную панель”, мы будем использовать их позже.\nВы увидите, что источник данных prometheus уже добавлен в источники данных Grafana, однако, поскольку мы используем minikube, нам нужно также перенаправить prometheus, чтобы он был доступен на нашем localhost, открыв новый терминал, мы можем выполнить следующую команду. kubectl --namespace monitoring port-forward svc/prometheus-k8s 9090 если на главной странице Grafana мы теперь заходим в виджет “Add your first data source” и отсюда выбираем Prometheus.\nДля нашего нового источника данных мы можем использовать адрес http://localhost:9090, и нам также нужно будет изменить выпадающий список на браузер, как показано ниже.\nВнизу страницы мы можем нажать кнопку сохранить и протестировать. Это должно дать нам результат, который вы видите ниже, если проброс порта для prometheus работает.\nВернитесь на главную страницу и найдите опцию “Create your first dashboard”, выберите “Add a new panel”.\nНиже вы увидите, что мы уже собираем данные из нашего источника данных Grafana, но мы хотели бы собирать метрики из нашего источника данных Prometheus, выберите выпадающий список источников данных и выберите наш недавно созданный “Prometheus-1”\nЕсли затем выбрать браузер Metrics, то появится длинный список метрик, собираемых из Prometheus, связанных с нашим кластером minikube.\nДля целей демонстрации я собираюсь найти метрику, которая дает нам некоторые данные о наших системных ресурсах, cluster:node_cpu:ratio{} дает нам некоторые подробности об узлах в нашем кластере и доказывает, что эта интеграция работает.\nЕсли вас устраивает такая визуализация, нажмите кнопку “Применить” в правом верхнем углу, и вы добавите этот график на свою приборную панель. Разумеется, вы можете добавлять дополнительные графики и другие диаграммы, чтобы обеспечить нужную вам визуализацию.\nОднако мы можем воспользоваться тысячами ранее созданных приборных панелей, которые мы можем использовать, чтобы не изобретать велосипед.\nЕсли мы выполним поиск по Kubernetes, то увидим длинный список готовых приборных панелей, из которых мы можем выбирать.\nМы выбрали приборную панель Kubernetes API Server и изменили источник данных, чтобы соответствовать нашему недавно добавленному источнику данных Prometheus-1, и мы видим некоторые метрики, отображаемые как показано ниже.\nОповещение Вы также можете использовать развернутый нами alertmanager для отправки оповещений в slack или другие интеграции, для этого вам нужно перенести сервис alertmanager, используя следующие данные.\nkubectl --namespace monitoring port-forward svc/alertmanager-main 9093 http://localhost:9093\nНа этом мы завершаем наш раздел о наблюдаемости. Лично я считаю, что этот раздел подчеркнул, насколько широка эта тема, но в равной степени, насколько она важна для наших ролей, и что будь то метрика, логирование или трассировка, вам необходимо иметь хорошее представление о том, что происходит в наших широких средах в будущем, особенно когда они могут так сильно измениться благодаря автоматизации, которую мы уже рассмотрели в других разделах.\nДалее мы рассмотрим управление данными и то, как принципы DevOps также необходимо учитывать, когда речь идет об управлении данными.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained ","description":"","title":"83. Визуализация данных - Grafana","uri":"/ru/tracks/90daysofdevops/day83/"},{"content":"Введение: Управление данными Управление данными - это далеко не новая стена, на которую нужно карабкаться, хотя мы знаем, что данные стали более важными, чем несколько лет назад. Ценные и постоянно меняющиеся, они также могут стать огромным кошмаром, когда мы говорим об автоматизации и непрерывной интеграции, тестировании и развертывании частых выпусков программного обеспечения. Вводим постоянные данные и базовые службы данных, которые часто являются главным виновником, когда что-то идет не так.\nНо прежде чем я перейду к управлению данными в облаке, нам нужно подняться на уровень выше. В ходе этой задачи мы затронули множество различных платформ. Будь то физические, виртуальные, облачные и Cloud-Native, включая Kubernetes, ни одна из этих платформ не обеспечивает отсутствие требований к управлению данными.\nКаким бы ни был наш бизнес, более чем вероятно, что вы найдете базу данных, скрывающуюся где-то в среде, будь то для самой критически важной системы в бизнесе или, по крайней мере, какой-то винтик в цепи хранит эти постоянные данные на каком-то уровне системы.\nDevOps и данные Как и в самом начале этой серии статей, где мы говорили о принципах DevOps, для улучшения процесса работы с данными вам необходимо привлечь нужных людей. Это могут быть DBA, но в равной степени это должны быть и люди, которые заботятся о резервном копировании этих сервисов данных.\nВо-вторых, нам также необходимо определить различные типы данных, домены, границы, которые мы связываем с нашими данными. Таким образом, данные не будут рассматриваться изолированно среди администраторов баз данных, инженеров по хранению данных или инженеров, специализирующихся на резервном копировании. Таким образом, вся команда может определить наилучший маршрут действий при разработке и размещении приложений для более широкого бизнеса и сосредоточиться на архитектуре данных, а не на том, о чем подумали позже.\nЭто может охватывать множество различных областей жизненного цикла данных, мы можем говорить о вводе данных, где и как данные будут вводиться в наш сервис или приложение? Как сервис, приложение или пользователи будут получать доступ к этим данным. Но затем нам также необходимо понять, как мы будем защищать данные, и как мы будем защищать эти данные.\nУправление данными 101 Управление данными, согласно Data Management Body of Knowledge, - это “разработка, выполнение и контроль планов, политик, программ и практик, которые контролируют, защищают, предоставляют и повышают ценность данных и информационных активов”.\nДанные - самый важный аспект вашего бизнеса - Данные - это только одна часть вашего бизнеса в целом. Я встречал выражение “Данные - это жизненная сила нашего бизнеса”, и, скорее всего, это абсолютно верно. Это заставило меня задуматься о том, что кровь очень важна для организма, но сама по себе она ничего не значит, нам все еще нужны аспекты организма, чтобы сделать кровь чем-то другим, кроме жидкости.\nКачество данных важно как никогда - Мы должны относиться к данным как к бизнес-активу, что означает, что мы должны уделять им должное внимание, чтобы они работали с нашими принципами автоматизации и DevOps.\nСвоевременный доступ к данным - Ни у кого не хватит терпения не иметь доступа к нужным данным в нужное время для принятия эффективных решений. Данные должны быть доступны в упорядоченном и своевременном виде независимо от формы представления.\nУправление данными должно стать помощником DevOps - я уже упоминал о рационализации, мы должны включить требования к управлению данными в наш цикл и обеспечить не только доступность этих данных, но и другие важные политические меры защиты этих точек данных, а также полностью протестированные модели восстановления.\nDataOps DataOps и DevOps применяют лучшие практики разработки и эксплуатации технологий для повышения качества, увеличения скорости, снижения угроз безопасности, восхищения клиентов и обеспечения значимой и сложной работы для квалифицированных специалистов. DevOps и DataOps имеют общие цели - ускорить доставку продукта путем автоматизации как можно большего количества этапов процесса. Для DataOps целью является устойчивый конвейер данных и надежные выводы из аналитики данных.\nНекоторые из наиболее распространенных областей более высокого уровня, которые фокусируются на DataOps, - это машинное обучение, большие данные и аналитика данных, включая искусственный интеллект.\nУправление данными - это управление информацией В этом разделе я не буду углубляться в машинное обучение или искусственный интеллект, а сосредоточусь на защите данных с точки зрения защиты информации. Этот подраздел называется “Управление данными - это управление информацией”, и мы можем считать, что информация = данные.\nТри ключевые области, которые мы должны рассмотреть на этом пути с данными, следующие:\nТочность - Убедитесь в том, что производственные данные точны, также нам необходимо убедиться в том, что наши данные в виде резервных копий также работают и протестированы на восстановление, чтобы быть уверенными в том, что в случае сбоя или возникновения причины нам необходимо иметь возможность восстановить работоспособность как можно быстрее.\nПоследовательность - Если наши службы данных расположены в нескольких местах, то для производства нам необходимо обеспечить последовательность во всех местах расположения данных, чтобы мы получали точные данные. Это также относится к защите данных, когда речь идет о защите этих служб данных, особенно служб данных, нам необходимо обеспечить последовательность на разных уровнях, чтобы убедиться, что мы делаем хорошую чистую копию этих данных для наших резервных копий, реплик и т. д.\nБезопасность - контроль доступа, а также просто хранение данных в целом - актуальная тема в настоящее время во всем мире. Убедиться в том, что нужные люди имеют доступ к вашим данным, - первостепенная задача, и это опять же относится к защите данных, где мы должны убедиться, что только необходимый персонал имеет доступ к резервным копиям и возможность восстановления из них, а также клонирования и предоставления других версий бизнес-данных.\nЛучшие данные = лучшие решения\nДни управления данными В течение следующих 6 занятий мы рассмотрим базы данных, резервное копирование и восстановление, аварийное восстановление, мобильность приложений с элементами демонстрации и практической работы.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"84. Управление данными","uri":"/ru/tracks/90daysofdevops/day84/"},{"content":"Службы данных Базы данных являются наиболее распространенными службами данных, с которыми мы сталкиваемся в наших средах. На этом занятии я хотел бы рассмотреть некоторые из этих различных типов баз данных и некоторые случаи их использования. Некоторые из них мы уже использовали и видели в ходе решения задачи.\nС точки зрения разработки приложений выбор правильной службы данных или базы данных будет иметь огромное значение для производительности и масштабируемости вашего приложения.\nhttps://www.youtube.com/watch?v=W2Z7fbCLSTw\nКлюч-значение База данных “ключ-значение” - это тип нереляционной базы данных, которая использует простой метод “ключ-значение” для хранения данных. База данных “ключ-значение” хранит данные в виде набора пар “ключ-значение”, в которых ключ служит уникальным идентификатором. И ключи, и значения могут быть любыми, от простых объектов до сложных составных объектов. Базы данных “ключ-значение” хорошо поддаются разделению и позволяют горизонтальное масштабирование в таких масштабах, которые недостижимы для других типов баз данных.\nПримером базы данных типа “ключ-значение” является Redis.\n*Redis - это хранилище структур данных в памяти, используемое как распределенная база данных ключей-значений в памяти, кэш и брокер сообщений с возможностью долговечности. Redis поддерживает различные виды абстрактных структур данных, таких как строки, списки, карты, множества, сортированные множества, HyperLogLogs, растровые изображения, потоки и пространственные индексы.\nКак вы можете видеть из описания Redis, это означает, что наша база данных работает быстро, но мы ограничены в пространстве в качестве компромисса. Также нет запросов или объединений, что означает, что возможности моделирования данных очень ограничены.\nЛучше всего подходит для:\nКэширование Pub/Sub Лидерборды корзины покупок Обычно используется в качестве кэша над другим постоянным слоем данных.\nШирокий столбец База данных с широкими колонками - это база данных NoSQL, которая организует хранение данных в гибких колонках, которые могут быть распределены по нескольким серверам или узлам базы данных, используя многомерное отображение для ссылки на данные по столбцам, строкам и временным меткам.\nCassandra - это бесплатная система управления базами данных NoSQL с открытым исходным кодом, распределенная, с широким хранилищем колонок, разработанная для обработки больших объемов данных на множестве серверов, обеспечивающая высокую доступность без единой точки отказа.\nНет схемы, что означает возможность работы с неструктурированными данными, однако это может рассматриваться как преимущество для некоторых рабочих нагрузок.\nЛучше всего подходит для:\nВременные ряды Исторические записи Высокая запись, низкий уровень чтения Документ База данных документов (также известная как документо-ориентированная база данных или хранилище документов) - это база данных, которая хранит информацию в документах.\nMongoDB - это кросс-платформенная кросс-платформенная программа базы данных, ориентированная на документы. Классифицируемая как NoSQL база данных, MongoDB использует JSON-подобные документы с необязательными схемами. MongoDB разработана компанией MongoDB Inc. и лицензирована по лицензии Server Side Public License..\nДокументальные базы данных NoSQL позволяют предприятиям хранить простые данные без использования сложных кодов SQL. Быстрое хранение без ущерба для надежности.\nЛучше всего подходит для:\nБольшинство приложений Игры Интернет вещей Реляционная Если вы новичок в области баз данных, но знаете о них, то, скорее всего, вы сталкивались с реляционной базой данных.\nРеляционная база данных - это цифровая база данных, основанная на реляционной модели данных, предложенной Э. Ф. Коддом в 1970 году. Система, используемая для ведения реляционных баз данных, - это система управления реляционными базами данных. Многие системы реляционных баз данных имеют возможность использования SQL для запросов и ведения базы данных.\nMySQL - это система управления реляционными базами данных с открытым исходным кодом. Ее название представляет собой комбинацию слов “My”, имя дочери соучредителя Майкла Видениуса, и “SQL”, аббревиатура для языка структурированных запросов.\nMySQL является одним из примеров реляционной базы данных, существует множество других вариантов.\nПри изучении реляционных баз данных часто упоминается термин или аббревиатура ACID (atomicity, consistency, isolation, durability) - это набор свойств транзакций базы данных, призванных гарантировать достоверность данных, несмотря на ошибки, сбои питания и другие казусы. В контексте баз данных последовательность операций с базой данных, удовлетворяющая свойствам ACID (которую можно воспринимать как одну логическую операцию над данными), называется транзакцией. Например, перевод средств с одного банковского счета на другой, даже включающий несколько изменений, таких как дебетование одного счета и кредитование другого, является одной транзакцией.\nЛучше всего подходит для:\nБольшинство приложений (существует уже много лет, но это не значит, что он лучший). Она не идеальна для неструктурированных данных или способности к масштабированию - некоторые из других NoSQL обеспечивают лучшую способность к масштабированию для определенных рабочих нагрузок.\nGraph Графовая база данных хранит узлы и отношения вместо таблиц или документов. Данные хранятся так же, как вы можете набросать идеи на доске. Ваши данные хранятся без ограничения их заранее определенной моделью, что позволяет очень гибко подходить к их осмыслению и использованию.\nNeo4j - это система управления графовыми базами данных, разработанная компанией Neo4j, Inc. Разработчики описывают ее как ACID-совместимую транзакционную базу данных со встроенными средствами хранения и обработки графов.\nЛучшая для:\nГрафы Графы знаний Рекомендательные движки Поисковая система В предыдущем разделе мы фактически использовали базу данных поисковой системы на пути к Elasticsearch.\nБаза данных поисковой системы - это тип нереляционной базы данных, предназначенной для поиска данных. Базы данных поисковых систем используют индексы для категоризации схожих характеристик данных и облегчения поиска.\nElasticsearch - это поисковая система, основанная на библиотеке Lucene. Она представляет собой распределенную полнотекстовую поисковую систему с поддержкой многопользовательского доступа, веб-интерфейсом HTTP и документами JSON без схем.\nЛучшее для:\nПоисковые системы Typeahead Поиск по журналу Мультимодель Многомодельная база данных - это система управления базой данных, разработанная для поддержки нескольких моделей данных на основе единого интегрированного бэкенда. В отличие от этого, большинство систем управления базами данных организованы вокруг одной модели данных, которая определяет, как данные могут быть организованы, храниться и манипулироваться. Документ, граф, реляционная модель и модель ключ-значение - это примеры моделей данных, которые могут поддерживаться многомодельной базой данных.\nFauna - это гибкая, удобная для разработчиков, транзакционная база данных, предоставляемая в виде безопасного и масштабируемого облачного API со встроенным GraphQL..\nЛучшее решение для:\nВы не привязаны к выбору модели данных. Соответствует стандарту ACID Быстрая Отсутствие накладных расходов на инициализацию Как вы хотите использовать свои данные и предоставить облаку выполнять всю работу. На этом мы закончим обзор баз данных, независимо от того, в какой отрасли вы работаете, вы обязательно столкнетесь с одной из областей баз данных. Далее в этом разделе мы рассмотрим некоторые из этих примеров и управление данными и, в частности, защиту и хранение этих сервисов данных.\nСуществует масса ресурсов, ссылки на которые я привел ниже, и вы можете потратить 90 лет на глубокое погружение во все типы баз данных и все, что с этим связано.\nРесурсы Redis Crash Course - the What, Why and How to use Redis as your primary database Redis: How to setup a cluster - for beginners Redis on Kubernetes for beginners Intro to Cassandra - Cassandra Fundamentals MongoDB Crash Course MongoDB in 100 Seconds What is a Relational Database? Learn PostgreSQL Tutorial - Full Course for Beginners MySQL Tutorial for Beginners [Full Course] What is a graph database? (in 10 minutes) What is Elasticsearch? FaunaDB Basics - The Database of your Dreams Fauna Crash Course - Covering the Basics ","description":"","title":"85. Службы данных","uri":"/ru/tracks/90daysofdevops/day85/"},{"content":"Резервное копирование всех платформ В ходе всего этого задания мы обсудили множество различных платформ и сред. Всех их объединяет то, что все они нуждаются в определенном уровне защиты данных!\nЗащита данных существует уже много лет, но богатство данных, которые мы имеем сегодня, и ценность, которую эти данные приносят, означает, что мы должны быть уверены не только в устойчивости к сбоям инфраструктуры за счет наличия нескольких узлов и высокой доступности приложений, но мы также должны учитывать, что нам нужна копия этих данных, этих важных данных в безопасном и надежном месте, если произойдет сбой.\nВ наши дни мы часто слышим о киберпреступности и программах-выкупах, и не поймите меня неправильно - это серьезная угроза, и я уверен, что вы подвергнетесь атаке программ-выкупов. Это не вопрос “если”, это вопрос “когда”. Поэтому еще больше причин убедиться в том, что ваши данные надежно защищены на тот случай, если такое время настанет. Однако самой распространенной причиной потери данных является не выкупное ПО или киберпреступность, а просто случайное удаление!\nМы все это делали, удаляли то, что не должны были удалять, и тут же сожалели об этом.\nНесмотря на все технологии и автоматизацию, о которых мы говорили в этой статье, требование защищать любые данные с состоянием или даже сложные конфигурации без состояния все еще существует, независимо от платформы.\nНо мы должны быть в состоянии выполнить эту защиту данных с учетом автоматизации и возможности интеграции в наши рабочие процессы.\nЕсли мы посмотрим, что такое резервное копирование:\nВ информационных технологиях резервная копия или резервное копирование данных - это копия компьютерных данных, снятая и сохраненная в другом месте, чтобы ее можно было использовать для восстановления оригинала после потери данных. Глагольная форма, обозначающая процесс создания такой копии, - “резервное копирование”, а существительное и прилагательное - “резервное копирование”.\nЕсли мы разберем это в самой простой форме, то резервное копирование - это копирование и вставка данных в новое место. Проще говоря, я могу сделать резервную копию прямо сейчас, скопировав файл с диска C: на диск D:, и у меня будет копия на случай, если что-то случится с диском C: или что-то будет неправильно отредактировано в файлах. Я могу вернуться к копии, которая находится на диске D:. Теперь, если мой компьютер умрет, где находятся оба диска C и D, я не буду защищен, поэтому мне придется искать решение или копировать данные вне моей системы, может быть, на NAS-накопитель у себя дома? Но тогда что произойдет, если что-то случится с моим домом, может быть, мне нужно подумать о хранении данных на другой системе в другом месте, может быть, облако - это вариант. Может быть, я могу хранить копии важных файлов в нескольких местах, чтобы снизить риск сбоя?\n3-2-1 Методика резервного копирования Сейчас самое время поговорить о правиле 3-2-1 или методологии резервного копирования. На самом деле я провел lightening talk, посвященный этой теме.\nМы уже упоминали о некоторых крайностях того, почему нам нужно защищать наши данные, но ниже перечислены еще несколько:\nЭто позволяет мне рассказать о методологии 3-2-1. Моя первая копия или резервная копия данных должна быть как можно ближе к моей производственной системе, причина этого заключается в скорости восстановления и, опять же, возвращаясь к исходному пункту о случайном удалении, это будет наиболее распространенной причиной для восстановления. Но я хочу хранить эти данные на подходящем втором носителе за пределами исходной или рабочей системы.\nЗатем мы хотим убедиться, что мы также отправляем копию наших данных на внешний носитель или за пределы системы, и здесь нам на помощь приходит второе место, будь то другой дом, здание, центр обработки данных или публичное облако.\nОтветственность за резервное копирование\nМы, скорее всего, слышали все мифы о том, что резервное копирование не нужно, например, такие как “Все не имеет состояния”. Если все не имеет состояния, то что тогда бизнес? Нет баз данных? документов? Очевидно, что каждый человек в компании несет определенную ответственность за обеспечение своей защиты, но, скорее всего, именно операционные команды должны обеспечить процесс резервного копирования критически важных приложений и данных.\nЕще одна хорошая фраза: “Высокая доступность - это моя резервная копия, мы встроили несколько узлов в наш кластер, поэтому он ни за что не выйдет из строя!”, кроме тех случаев, когда вы допускаете ошибку в базе данных, и она реплицируется на все узлы кластера, или когда происходит пожар, наводнение, что означает, что кластер больше недоступен, а вместе с ним и важные данные. Речь идет не об упрямстве, а о том, чтобы быть в курсе данных и сервисов, абсолютно все должны учитывать высокую доступность и отказоустойчивость в своей архитектуре, но это не заменяет необходимости резервного копирования!\nРепликация также может дать нам копию данных вне офиса, и, возможно, упомянутый выше кластер действительно живет в нескольких местах, однако первая случайная ошибка все равно будет реплицирована туда. Но, опять же, требование резервного копирования должно стоять в одном ряду с репликацией приложений или системной репликацией в среде.\nТеперь, учитывая все вышесказанное, можно впасть в крайность и отправить копии данных в слишком большое количество мест, что приведет не только к большим затратам, но и к увеличению риска подвергнуться атаке, поскольку площадь вашей поверхности теперь значительно увеличилась.\nВ любом случае, кто заботится о резервном копировании? В каждом предприятии это будет по-разному, но кто-то должен понимать требования к резервному копированию. Но также необходимо понимать план восстановления!\nНикому нет дела, пока всем нет дела Резервное копирование является ярким примером: никто не заботится о резервном копировании, пока вам не понадобится что-то восстановить. Наряду с требованием резервного копирования данных нам также необходимо подумать о том, как мы будем восстанавливать данные!\nВ нашем примере с текстовыми документами речь идет об очень маленьких файлах, поэтому возможность копирования туда и обратно является простой и быстрой. Но если речь идет о файлах размером более 100 ГБ, то на это потребуется время. Также необходимо учитывать уровень, на котором требуется восстановление, например, если мы возьмем виртуальную машину.\nУ нас есть вся виртуальная машина, у нас есть операционная система, установка приложений, а если это сервер баз данных, то у нас есть и некоторые файлы баз данных. Если мы допустили ошибку и вставили неправильную строку кода в нашу базу данных, мне, вероятно, не нужно восстанавливать всю виртуальную машину, я хочу быть детальным в том, что я восстанавливаю.\nСценарий резервного копирования Теперь я хочу начать строить скрипт защиты некоторых данных, в частности, я хочу защитить некоторые файлы на моей локальной машине (в данном случае Windows, но инструмент, который я собираюсь использовать, на самом деле не только бесплатный и с открытым исходным кодом, но и кроссплатформенный). Я хочу убедиться, что они защищены на устройстве NAS, которое у меня есть дома, а также в облачном хранилище Object Storage bucket.\nЯ хочу сделать резервную копию этих важных данных, так получилось, что это репозиторий для 90DaysOfDevOps, который, да, также отправляется на GitHub, где вы, вероятно, сейчас это читаете, но что, если моя машина умрет, а GitHub будет закрыт? Как бы кто-нибудь смог прочитать содержимое, а также как бы я мог восстановить эти данные на другом сервисе.\nСуществует множество инструментов, которые могут помочь нам достичь этого, но я собираюсь использовать инструмент под названием Kopia - это инструмент резервного копирования с открытым исходным кодом, который позволит нам шифровать, дедупировать и сжимать наши резервные копии, а также отправлять их во многие места.\nВы найдете релизы для загрузки здесь на момент написания статьи я буду использовать версию 0.10.6.\nУстановка Kopia Существует Kopia CLI и GUI, мы будем использовать GUI, но знайте, что вы можете иметь и CLI версию для тех Linux серверов, которые не дают вам GUI.\nЯ буду использовать KopiaUI-Setup-0.10.6.exe.\nДействительно быстрая установка, а затем, когда вы откроете приложение, вам предложат выбрать тип хранилища, которое вы хотите использовать в качестве хранилища резервных копий.\nНастройка хранилища Сначала мы хотим создать хранилище на локальном NAS-устройстве и собираемся сделать это с помощью SMB, но можно использовать и NFS.\nНа следующем экране мы собираемся определить пароль, этот пароль используется для шифрования содержимого хранилища.\nТеперь, когда хранилище настроено, мы можем запустить adhoc snapshot, чтобы начать запись данных в хранилище. [18:26, 16.06.2022] evgschegolkova: Прежде всего, нам нужно ввести путь к тому, что мы хотим сделать снимок, и в нашем случае мы хотим сделать копию папки 90DaysOfDevOps. Вскоре мы вернемся к аспекту планирования.\nМы можем определить хранение наших снимков.\nВозможно, есть файлы или типы файлов, которые мы хотим исключить.\nЕсли бы мы хотели определить расписание, мы могли бы сделать это на следующем экране, когда вы впервые создаете этот снимок, это начальная страница для определения.\nИ вы увидите ряд других настроек, которые могут быть обработаны здесь.\nВыберите snapshot now, и данные будут записаны в ваше хранилище.\nВнесетевое резервное копирование на S3 С помощью Kopia мы можем настроить только одно хранилище одновременно. Но через пользовательский интерфейс мы можем проявить творческий подход и, по сути, иметь несколько файлов конфигурации хранилища на выбор для достижения нашей цели - иметь локальную и внесетевую копию в Object Storage.\nХранилище Object Storage, в которое я решил отправить свои данные, будет Google Cloud Storage. Сначала я вошел в свой аккаунт Google Cloud Platform и создал себе ведро хранения. В моей системе уже был установлен Google Cloud SDK, но выполнение команды gcloud auth application-default login позволило мне аутентифицироваться в моей учетной записи.\nЗатем я использовал CLI Kopia, чтобы показать мне текущее состояние моего хранилища после того, как мы добавили наше SMB хранилище в предыдущих шагах. Я сделал это с помощью команды \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status.\nТеперь мы готовы заменить конфигурацию хранилища для целей демонстрации. Если бы мы хотели получить долгосрочное решение для обоих хранилищ, мы бы создали файл smb.config и файл object.config и могли бы запускать обе эти команды для отправки наших копий данных в каждое место. Для добавления нашего хранилища мы выполнили команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository create gcs --bucket 90daysofdevops.\nПриведенная выше команда учитывает, что ведро Google Cloud Storage, которое мы создали, называется 90daysofdevops.\nТеперь, когда мы создали наше новое хранилище, мы можем снова запустит [18:27, 16.06.2022] evgschegolkova: Прежде всего, нам нужно ввести путь к тому, что мы хотим сделать снимок, и в нашем случае мы хотим сделать копию папки 90DaysOfDevOps. Вскоре мы вернемся к аспекту планирования.\nМы можем определить хранение наших снимков.\nВозможно, есть файлы или типы файлов, которые мы хотим исключить.\nЕсли бы мы хотели определить расписание, мы могли бы сделать это на следующем экране, когда вы впервые создаете этот снимок, это начальная страница для определения.\nИ вы увидите ряд других настроек, которые могут быть обработаны здесь.\nВыберите snapshot now, и данные будут записаны в ваше хранилище.\nВнесетевое резервное копирование на S3 С помощью Kopia мы можем настроить только одно хранилище одновременно. Но через пользовательский интерфейс мы можем проявить творческий подход и, по сути, иметь несколько файлов конфигурации хранилища на выбор для достижения нашей цели - иметь локальную и внесетевую копию в Object Storage.\nХранилище Object Storage, в которое я решил отправить свои данные, будет Google Cloud Storage. Сначала я вошел в свой аккаунт Google Cloud Platform и создал себе ведро хранения. В моей системе уже был установлен Google Cloud SDK, но выполнение команды gcloud auth application-default login позволило мне аутентифицироваться в моей учетной записи.\nЗатем я использовал CLI Kopia, чтобы показать мне текущее состояние моего хранилища после того, как мы добавили наше SMB хранилище в предыдущих шагах. Я сделал это с помощью команды \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status.\nТеперь мы готовы заменить конфигурацию хранилища для целей демонстрации. Если бы мы хотели получить долгосрочное решение для обоих хранилищ, мы бы создали файл smb.config и файл object.config и могли бы запускать обе эти команды для отправки наших копий данных в каждое место. Для добавления нашего хранилища мы выполнили команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository create gcs --bucket 90daysofdevops.\nПриведенная выше команда учитывает, что ведро Google Cloud Storage, которое мы создали, называется 90daysofdevops.\nТеперь, когда мы создали наше новое хранилище, мы можем снова запустить команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status, которая теперь покажет конфигурацию хранилища GCS.\nСледующее, что нам нужно сделать, это создать снимок и отправить его в наш только что созданный репозиторий. Используя команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config kopia snapshot create \"C:\\Users\\micha\\demo\\90DaysOfDevOps\" мы можем запустить этот процесс. В браузере ниже вы можете увидеть, что в нашем ведре Google Cloud Storage теперь есть файлы kopia, основанные на нашей резервной копии.\nС помощью вышеописанного процесса мы смогли решить нашу задачу по отправке важных данных в 2 разных места, одно из которых находится вне помещения в Google Cloud Storage, и, конечно же, у нас все еще есть наша производственная копия данных на другом типе носителя.\nВосстановление Восстановление - это еще один важный момент, Kopia дает нам возможность не только восстанавливать данные в существующее местоположение, но и в новое.\nЕсли мы выполним команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config snapshot list, это приведет к списку снимков, которые в настоящее время находятся в нашем настроенном хранилище (GCS).\nЗатем мы можем смонтировать эти снимки непосредственно из GCS, используя команду ``C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe’’ –config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config mount all Z:`.\nМы также можем восстановить содержимое снимка с помощью команды kopia snapshot restore kdbd9dff738996cfe7bcf99b45314e193.\nОчевидно, что приведенные выше команды очень длинные, и это потому, что я использовал KopiaUI версию kopia.exe, как объяснялось в верхней части руководства, вы можете скачать kopia.exe и поместить в путь, чтобы вы могли просто использовать команду kopia.\nНа следующем занятии мы сосредоточимся на защите рабочих нагрузок в Kubernetes.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"86. Резервное копирование всех платформ","uri":"/ru/tracks/90daysofdevops/day86/"},{"content":"Резервное копирование и восстановление своими руками На прошлом занятии мы рассмотрели Kopia - инструмент резервного копирования с открытым исходным кодом, который мы использовали для переноса важных данных на локальный NAS и в облачное хранилище объектов.\nВ этом разделе я хочу погрузиться в мир резервного копирования Kubernetes. Это платформа, которую мы рассматривали в The Big Picture: Kubernetes ранее в этой задаче.\nМы снова будем использовать наш кластер minikube, но на этот раз мы воспользуемся некоторыми из доступных аддонов.\nНастройка кластера Kubernetes Для настройки нашего кластера minikube мы выполним команду minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p 90daysofdevops --kubernetes-version=1.21.2. Вы заметите, что мы используем volumesnapshots и csi-hostpath-driver, поскольку мы будем использовать их для создания резервных копий.\nНа данном этапе я знаю, что мы еще не развернули Kasten K10, но мы хотим выполнить следующую команду, когда ваш кластер будет запущен, но мы хотим аннотировать класс volumesnapshotclass, чтобы Kasten K10 мог использовать его.\nkubectl annotate volumesnapshotclass csi-hostpath-snapclass \\ k10.kasten.io/is-snapshot-class=true Мы также собираемся изменить класс хранения по умолчанию со стандартного класса хранения по умолчанию на класс хранения csi-hostpath, используя следующее.\nkubectl patch storageclass csi-hostpath-sc -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"true\"}}}}'' kubectl patch storageclass standard -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"false\"}}}}'' Развертывание Kasten K10 Добавьте репозиторий Kasten Helm\nhelm repo add kasten https://charts.kasten.io/.\nМы могли бы использовать arkade kasten install k10 и здесь, но для целей демонстрации мы выполним следующие шаги. Подробнее\nСоздайте пространство имен и разверните K10, обратите внимание, что это займет около 5 минут\nhelm install k10 kasten/k10 --namespace=kasten-io --set auth.tokenAuth.enabled=true --set injectKanisterSidecar.enabled=true --set-string injectKanisterSidecar.namespaceSelector.matchLabels.k10/injectKanisterSidecar=true --create-namespace.\nВы можете наблюдать за появлением стручков, выполнив следующую команду.\nkubectl get pods -n kasten-io -w\nЧтобы получить доступ к приборной панели K10, откройте новый терминал и выполните следующую команду\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1) TOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode) echo \"Значение токена: \" echo $TOKEN Теперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nРазвертывание нашего stateful-приложения Используйте stateful-приложение, которое мы использовали в разделе Kubernetes.\nВы можете найти конфигурационный файл YAML для этого приложения здесьpacman-stateful-demo.yaml\nМы можем использовать kubectl get all -n pacman, чтобы проверить появление наших стручков.\nВ новом терминале мы можем перенаправить фронт-енд pacman. kubectl port-forward svc/pacman 9090:80 -n pacman.\nОткройте другую вкладку в браузере на http://localhost:9090/\nНайдите время, чтобы записать несколько высоких результатов в базе данных backend MongoDB.\nЗащитите наши высокие баллы Теперь у нас есть некоторые важные данные в нашей базе данных, и мы не хотим их потерять. Мы можем использовать Kasten K10 для защиты всего приложения.\nЕсли мы вернемся на вкладку приборной панели Kasten K10, вы увидите, что количество наших приложений увеличилось с 1 до 2 с добавлением нашего приложения pacman в наш кластер Kubernetes.\nЕсли вы нажмете на карточку Applications, вы увидите автоматически обнаруженные приложения в нашем кластере.\nВ Kasten K10 у нас есть возможность использовать моментальные снимки на основе хранилища, а также экспортировать наши копии в объектные хранилища.\nДля целей демонстрации мы создадим ручной снимок хранилища в нашем кластере, а затем добавим некоторые неавторизованные данные в наши высокие результаты, чтобы имитировать случайную ошибку или нет?\nДля начала мы можем воспользоваться приведенным ниже вариантом ручного снапшота.\nДля демонстрации я собираюсь оставить все по умолчанию\nВернувшись на приборную панель, вы получите отчет о состоянии задания в процессе его выполнения, а после завершения оно должно выглядеть так же успешно, как и здесь.\nСценарий неудачи Теперь мы можем внести фатальное изменение в наши критически важные данные, просто добавив предписывающее плохое изменение в наше приложение.\nКак вы можете видеть ниже, у нас есть два входа, которые мы, вероятно, не хотим видеть в нашей производственной критически важной базе данных.\nВосстановление данных Очевидно, что это простая демонстрация и в некотором роде нереалистичная, хотя вы видели, как легко можно сбросить базы данных?\nТеперь мы хотим, чтобы список высоких результатов выглядел немного чище и как он выглядел до того, как были допущены ошибки.\nВернемся в карточку приложений и на вкладку pacman, теперь у нас есть 1 точка восстановления, которую мы можем использовать для восстановления.\nПри выборе восстановления вы можете увидеть все связанные снимки и экспорты для этого приложения.\nВыберите восстановление и появится боковое окно, мы сохраним настройки по умолчанию и нажмем восстановить.\nПодтвердите, что вы действительно хотите, чтобы это произошло.\nЗатем вы можете вернуться на приборную панель и просмотреть ход восстановления. Вы должны увидеть что-то вроде этого.\nНо более важно то, как выглядит наш список High-Score в нашем критически важном приложении. Вам придется снова запустить проброс портов в pacman, как мы уже рассказывали ранее.\nЭто очень простая демонстрация, которая лишь слегка касается того, чего Kasten K10 может достичь в области резервного копирования. В будущем я буду создавать более подробные видеоматериалы по некоторым из этих областей. Мы также будем использовать Kasten K10 для освещения некоторых других важных областей управления данными, когда речь идет об аварийном восстановлении и мобильности ваших данных.\nДалее мы рассмотрим согласованность приложений.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"87. Резервное копирование и восстановление","uri":"/ru/tracks/90daysofdevops/day87/"},{"content":"Резервное копирование, ориентированное на приложения В День 85 мы уже потратили некоторое время на обсуждение служб данных или приложений с интенсивным использованием данных, таких как базы данных. Для этих служб данных мы должны подумать о том, как управлять согласованностью, особенно когда речь идет о согласованности приложений.\nВ этой статье мы рассмотрим требования к защите данных приложения в последовательной манере.\nДля этого мы выберем инструмент Kanister\nПредставляем Kanister Kanister - это проект с открытым исходным кодом от Kasten, который позволяет нам управлять (резервное копирование и восстановление) данными приложений на Kubernetes. Вы можете развернуть Kanister как helm-приложение в своем кластере Kubernetes.\nKanister использует пользовательские ресурсы Kubernetes, основные пользовательские ресурсы, которые устанавливаются при развертывании Kanister, следующие\nProfile - целевое место для хранения резервных копий и восстановления. Чаще всего это объектное хранилище. Blueprint - шаги, которые необходимо предпринять для резервного копирования и восстановления базы данных, должны быть сохранены в Blueprint. ActionSet - действия по перемещению целевой резервной копии в наш профиль, а также действия по восстановлению. Описание выполнения Прежде чем приступить к работе, мы должны рассмотреть рабочий процесс, который использует Kanister для защиты данных приложения. Во-первых, наш контроллер развертывается с помощью helm в нашем кластере Kubernetes, Kanister живет в своем собственном пространстве имен. Мы берем наш Blueprint, для которого существует множество поддерживаемых сообществом Blueprint, мы рассмотрим это более подробно в ближайшее время. Затем у нас есть рабочая нагрузка базы данных.\nЗатем мы создаем наш ActionSet.\nActionSet позволяет нам запускать действия, определенные в чертеже, против конкретной службы данных.\nActionSet, в свою очередь, использует функции Kanister (KubeExec, KubeTask, Resource Lifecycle) и выталкивает нашу резервную копию в целевое хранилище (Profile).\nЕсли действие выполнено/не выполнено, соответствующий статус обновляется в наборе действий.\nРазвертывание Kanister И снова мы будем использовать кластер minikube для создания резервной копии приложения. Если у вас он все еще работает с предыдущей сессии, то мы можем продолжать использовать его.\nНа момент написания статьи мы имеем версию образа 0.75.0. С помощью следующей команды helm мы установим kanister в наш кластер Kubernetes.\nhelm install kanister --namespace kanister kanister/kanister-operator --set image.tag=0.75.0 --create-namespace.\nМы можем использовать kubectl get pods -n kanister, чтобы убедиться, что pod запущен и работает, а также проверить, что наши пользовательские определения ресурсов теперь доступны (Если вы только установили Kanister, то вы увидите выделенные 3) Развертывание базы данных Развертывание mysql через helm:\nAPP_NAME=my-production-app kubectl create ns ${APP_NAME} helm repo add bitnami https://charts.bitnami.com/bitnami helm install mysql-store bitnami/mysql --set primary.persistence.size=1Gi,volumePermissions.enabled=true --namespace=${APP_NAME} kubectl get pods -n ${APP_NAME} -w Заполните базу данных mysql исходными данными, выполнив следующее:\nMYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace ${APP_NAME} mysql-store -o jsonpath=\"{.data.mysql-root-password}\" | base64 --decode) MYSQL_HOST=mysql-store.${APP_NAME}.svc.cluster.local MYSQL_EXEC=\"mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD} -DmyImportantData -t\" echo MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} Создание MySQL CLIENT Мы запустим другой образ контейнера, который будет выступать в качестве нашего клиента\nAPP_NAME=my-production-app kubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash Примечание: если у вас уже запущен существующий mysql client pod, удалите его с помощью команды kubectl delete pod -n ${APP_NAME} mysql-client Добавление данных в MySQL echo \"create database myImportantData;\" | mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD} MYSQL_EXEC=\"mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD} -DmyImportantData -t\" echo \"drop table Accounts\" | ${MYSQL_EXEC} echo \"create table if not exists Accounts(name text, balance integer); insert into Accounts values('nick', 0);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('albert', 112);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('alfred', 358);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('beatrice', 1321);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('bartholomew', 34);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('edward', 5589);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('edwin', 144);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('edwina', 233);\" | ${MYSQL_EXEC} echo \"insert into Accounts values('rastapopoulos', 377);\" | ${MYSQL_EXEC} echo \"select * from Accounts;\" | ${MYSQL_EXEC} exit Вы должны увидеть некоторые данные, как показано ниже.\nСоздание профиля Kanister Kanister предоставляет CLI, kanctl и другую утилиту kando, которая используется для взаимодействия с провайдером объектного хранилища из blueprint и обе эти утилиты.\nCLI Download\nЯ пошел и создал AWS S3 Bucket, который мы будем использовать в качестве цели профиля и места восстановления. Я буду использовать переменные окружения, чтобы иметь возможность показать вам команды, которые я выполняю с помощью kanctl для создания нашего профиля kanister.\nkanctl create profile s3compliant --access-key $ACCESS_KEY --secret-key $SECRET_KEY --bucket $BUCKET --region eu-west-2 --namespace my-production-app.\nВремя чертежа Не волнуйтесь, вам не нужно создавать свой собственный с нуля, если только ваш сервис данных не указан в Примерах Канистера, но, конечно, вклад сообщества - это то, как этот проект становится известным.\nМы будем использовать следующую схему.\napiVersion: cr.kanister.io/v1alpha1 kind: Blueprint metadata: name: mysql-blueprint actions: backup: outputArtifacts: mysqlCloudDump: keyValue: s3path: \"{{ .Phases.dumpToObjectStore.Output.s3path }}\" phases: - func: KubeTask name: dumpToObjectStore objects: mysqlSecret: kind: Secret name: '{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}' namespace: '{{ .StatefulSet.Namespace }}' args: image: ghcr.io/kanisterio/mysql-sidecar:0.75.0 namespace: \"{{ .StatefulSet.Namespace }}\" command: - bash - -o - errexit - -o - pipefail - -c - | s3_path=\"/mysql-backups/{{ .StatefulSet.Namespace }}/{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}/{{ toDate \"2006-01-02T15:04:05.999999999Z07:00\" .Time | date \"2006-01-02T15-04-05\" }}/dump.sql.gz\" root_password=\"{{ index .Phases.dumpToObjectStore.Secrets.mysqlSecret.Data \"mysql-root-password\" | toString }}\" mysqldump --column-statistics=0 -u root --password=${root_password} -h {{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }} --single-transaction --all-databases | gzip - | kando location push --profile '{{ toJson .Profile }}' --path ${s3_path} - kando output s3path ${s3_path} restore: inputArtifactNames: - mysqlCloudDump phases: - func: KubeTask name: restoreFromBlobStore objects: mysqlSecret: kind: Secret name: '{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}' namespace: '{{ .StatefulSet.Namespace }}' args: image: ghcr.io/kanisterio/mysql-sidecar:0.75.0 namespace: \"{{ .StatefulSet.Namespace }}\" command: - bash - -o - errexit - -o - pipefail - -c - | s3_path=\"{{ .ArtifactsIn.mysqlCloudDump.KeyValue.s3path }}\" root_password=\"{{ index .Phases.restoreFromBlobStore.Secrets.mysqlSecret.Data \"mysql-root-password\" | toString }}\" kando location pull --profile '{{ toJson .Profile }}' --path ${s3_path} - | gunzip | mysql -u root --password=${root_password} -h {{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }} delete: inputArtifactNames: - mysqlCloudDump phases: - func: KubeTask name: deleteFromBlobStore args: image: ghcr.io/kanisterio/mysql-sidecar:0.75.0 namespace: \"{{ .Namespace.Name }}\" command: - bash - -o - errexit - -o - pipefail - -c - | s3_path=\"{{ .ArtifactsIn.mysqlCloudDump.KeyValue.s3path }}\" kando location delete --profile '{{ toJson .Profile }}' --path ${s3_path} Чтобы добавить его, мы воспользуемся командой kubectl create -f mysql-blueprint.yml -n kanister.\nСоздаем наш ActionSet и защищаем наше приложение Теперь мы создадим резервную копию данных MySQL с помощью ActionSet, определяющего резервное копирование для этого приложения. Создайте ActionSet в том же пространстве имен, что и контроллер.\nkubectl get profiles.cr.kanister.io -n my-production-app Эта команда покажет нам профиль, который мы ранее создали, здесь может быть настроено несколько профилей, поэтому мы можем захотеть использовать определенные профили для разных ActionSet’ов.\nЗатем мы создадим наш ActionSet следующей командой с помощью kanctl.\nkanctl create actionset --action backup --namespace kanister --blueprint mysql-blueprint --statefulset my-production-app/mysql-store --profile my-production-app/s3-profile-dc5zm --secrets mysql=my-production-app/mysql-store.\nИз приведенной выше команды видно, что мы определяем blueprint, который мы добавили в пространство имен, statefulset в нашем пространстве имен my-production-app, а также секреты для входа в приложение MySQL.\nПроверьте состояние ActionSet, взяв имя ActionSet и используя эту команду kubectl --namespace kanister describe actionset backup-qpnqv.\nНаконец, мы можем пойти и подтвердить, что теперь у нас есть данные в нашем ведре AWS S3.\nВосстановление Нам нужно нанести некоторый ущерб, прежде чем мы сможем что-либо восстановить, мы можем сделать это, уронив нашу таблицу, возможно, это был несчастный случай, а возможно и нет.\nПодключитесь к нашему MySQL pod.\nAPP_NAME=my-production-app kubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash Вы можете увидеть, что наша база данных importantdata находится там с помощью echo \"SHOW DATABASES;\" | ${MYSQL_EXEC}.\nЗатем для удаления мы запустили echo \"DROP DATABASE myImportantData;\" | ${MYSQL_EXEC}.\nИ подтвердили, что все исчезло, сделав несколько попыток показать нашу базу данных.\nТеперь мы можем использовать Kanister, чтобы вернуть наши важные данные в рабочее состояние, используя команду kubectl get actionset -n kanister, чтобы узнать имя нашего ActionSet, который мы взяли ранее. Затем мы создадим ActionSet восстановления для восстановления наших данных, используя kanctl create actionset -n kanister --action restore --from \"backup-qpnqv\".\nМы можем подтвердить, что наши данные восстановлены, используя следующую команду для подключения к нашей базе данных.\nAPP_NAME=my-production-app kubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash Теперь мы находимся внутри клиента MySQL, мы можем выполнить команду echo \"SHOW DATABASES;\" | ${MYSQL_EXEC} и мы увидим, что база данных восстановлена. Мы также можем выполнить команду echo \"select * from Accounts;\" | ${MYSQL_EXEC} для проверки содержимого базы данных, и наши важные данные будут восстановлены.\nВ следующем посте мы рассмотрим аварийное восстановление в Kubernetes.\nРесурсы Kanister Overview - An extensible open-source framework for app-lvl data management on Kubernetes Application Level Data Operations on Kubernetes Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"88. Резервное копирование, ориентированное на приложения","uri":"/ru/tracks/90daysofdevops/day88/"},{"content":"Аварийное восстановление Мы уже упоминали о том, что различные скрипты сбоев требуют различных требований к восстановлению. Когда речь идет о скриптах пожара, наводнения и крови, мы можем рассматривать их как аварийные ситуации, в которых нам может потребоваться, чтобы наши рабочие нагрузки были запущены в совершенно другом месте как можно быстрее или, по крайней мере, с почти нулевым временем восстановления (RTO).\nЭтого можно достичь только в масштабе, если автоматизировать репликацию всего стека приложений в резервную среду.\nЭто позволяет быстро переходить от одного облачного региона к другому, облачным провайдерам или между локальной и облачной инфраструктурой.\nПродолжая тему, мы сосредоточимся на том, как этого можно достичь с помощью Kasten K10, используя наш кластер minikube, который мы развернули и настроили несколько занятий назад.\nЗатем мы создадим еще один кластер minikube с установленным Kasten K10 в качестве резервного кластера, который теоретически может находиться в любом месте.\nKasten K10 также имеет встроенную функциональность для обеспечения того, что если что-то случится с кластером Kubernetes, на котором он работает, данные каталога будут реплицированы и доступны на новом K10 Disaster Recovery.\nДобавление объектного хранилища в K10 Первое, что нам нужно сделать, это добавить ведро объектного хранилища в качестве целевого местоположения для наших резервных копий. Это не только выступает в качестве удаленного хранилища, но мы также можем использовать его в качестве исходных данных для аварийного восстановления.\nЯ очистил ведро S3, которое мы создали для демонстрации Kanister на прошлом занятии.\nЧтобы получить доступ к приборной панели K10, откройте новый терминал и выполните следующую команду:\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1) TOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode) echo \"Token value: \" echo $TOKEN Теперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nТеперь, когда мы вернулись в приборную панель Kasten K10, мы можем добавить наш профиль местоположения, выберите “Настройки” в верхней части страницы и “Новый профиль”.\nНа изображении ниже видно, что у нас есть выбор, где будет находиться этот профиль местоположения, мы выбираем Amazon S3, и добавляем наши учетные данные доступа, регион и имя ведра.\nЕсли мы прокрутим окно создания нового профиля вниз, то увидим, что у нас также есть возможность включить неизменяемое резервное копирование, которое использует API блокировки объектов S3. В данном демо мы не будем использовать эту возможность.\nНажмите “Сохранить профиль”, и теперь вы можете увидеть наш только что созданный или добавленный профиль местоположения, как показано ниже.\nСоздание политики для защиты приложения Pac-Man в объектном хранилище В предыдущем сеансе мы создали только специальный снимок нашего приложения Pac-Man, поэтому нам нужно создать политику резервного копирования, которая будет отправлять резервные копии нашего приложения в наше недавно созданное объектное хранилище.\nЕсли вы вернетесь на приборную панель и выберете карточку Policy, вы увидите окно, как показано ниже. Выберите “Создать новую политику”.\nВо-первых, мы можем дать нашей политике полезное имя и описание. Мы также можем определить частоту резервного копирования, для демонстрационных целей я использую “по требованию”.\nДалее мы хотим включить резервное копирование через Snapshot exports, что означает, что мы хотим отправлять наши данные в наш профиль местоположения. Если у вас их несколько, вы можете выбрать, в какой из них вы хотите отправлять резервные копии.\nДалее выбираем приложение по имени или по меткам, я собираюсь выбрать по имени и все ресурсы.\nВ разделе Advanced settings мы не будем использовать ничего из этого, но, основываясь на нашем вчерашнем walkthrough of Kanister, мы можем использовать Kanister как часть Kasten K10 для создания согласованных с приложением копий наших данных.\nНаконец, выберите “Создать политику”, и теперь вы увидите политику в нашем окне политики.\nВ нижней части созданной политики появится “Show import details”, нам нужна эта строка, чтобы иметь возможность импортировать в наш резервный кластер. Скопируйте ее в безопасное место.\nПрежде чем двигаться дальше, нам нужно выбрать “run once”, чтобы получить резервную копию, отправленную нашему ведру объектного хранилища.\nНиже, на скриншоте просто показано успешное резервное копирование и экспорт наших данных.\nСоздание нового кластера MiniKube и развертывание K10 Затем нам нужно развернуть второй кластер Kubernetes, и где это может быть любая поддерживаемая версия Kubernetes, включая OpenShift, в целях обучения мы будем использовать очень бесплатную версию MiniKube с другим названием.\nИспользуя minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p standby --kubernetes-version=1.21.2 мы можем создать наш новый кластер.\nЗатем мы можем развернуть Kasten K10 в этом кластере, используя:\nhelm install k10 kasten/k10 --namespace=kasten-io --set auth.tokenAuth.enabled=true --set injectKanisterSidecar.enabled=true --set-string injectKanisterSidecar.namespaceSelector.matchLabels.k10/injectKanisterSidecar=true --create-namespace.\nЭто займет некоторое время, но тем временем мы можем использовать kubectl get pods -n kasten-io -w, чтобы наблюдать за прогрессом перехода наших pods в статус запущенных.\nСтоит отметить, что поскольку мы используем MiniKube, наше приложение будет запущено, когда мы запустим политику импорта, наш класс хранилища будет таким же на этом резервном кластере. Однако то, что мы рассмотрим на последнем занятии, касается мобильности и трансформации.\nКогда капсулы запущены, мы можем выполнить шаги, которые мы проделали в предыдущих шагах на другом кластере.\nПеренесите порт вперед для доступа к приборной панели K10, откройте новый терминал и выполните следующую команду\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1) TOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode) echo \"Token value: \" echo $TOKEN Теперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nИмпортируем Pac-Man в новый кластер MiniKube На данном этапе мы можем создать политику импорта в резервном кластере, подключиться к резервным копиям объектного хранилища и определить, что и как мы хотим, чтобы выглядело.\nВо-первых, мы добавляем наш профиль местоположения, который мы рассмотрели ранее на другом кластере, используя темный режим, чтобы показать разницу между нашей производственной системой и резервным местоположением DR.\nТеперь вернемся к приборной панели и перейдем на вкладку политик, чтобы создать новую политику.\nСоздайте политику импорта в соответствии с приведенным ниже изображением. После завершения мы можем создать политику. Здесь есть опция восстановления после импорта, и некоторые люди могут захотеть воспользоваться этой опцией, которая будет восстановлена в нашем резервном кластере по завершении. У нас также есть возможность изменить конфигурацию приложения при восстановлении, и это то, что я описал в Day 90.\nЯ выбрал импорт по требованию, но вы, очевидно, можете установить расписание, когда вы хотите, чтобы этот импорт происходил. В связи с этим я собираюсь выполнить один раз.\nНиже вы можете видеть успешное выполнение задания политики импорта.\nЕсли мы теперь вернемся на приборную панель и зайдем в карточку Applications, мы можем выбрать выпадающий список, где вы видите ниже “Removed”, здесь вы увидите наше приложение. Выберите “Восстановить\nЗдесь мы видим доступные нам точки восстановления; это было задание резервного копирования, которое мы выполнили на первичном кластере для нашего приложения Pac-Man.\nЯ не буду менять никаких настроек по умолчанию, так как хочу рассмотреть это более подробно на следующем занятии.\nКогда вы нажмете кнопку “Восстановить”, появится запрос на подтверждение.\nНиже мы видим, что мы находимся в резервном кластере, и если мы проверим наши pods, мы увидим, что у нас есть наше запущенное приложение.\nЗатем мы можем перенаправить порт (в реальной жизни/производственной среде вам не понадобится этот шаг для доступа к приложению, вы будете использовать ingress)\nДалее мы рассмотрим мобильность и трансформацию приложений.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"89. Аварийное восстановление","uri":"/ru/tracks/90daysofdevops/day89/"},{"content":"Разберемся как работает hello-world Как работает Go Вчера мы прошли процедуру установки Go на ПК, а затем создали наше первое приложение Go.\nВ этом разделе мы собираемся глубже изучить код и понять еще несколько вещей о языке Go.\nЧто такое компиляция? Прежде чем мы перейдем к 6 строкам кода Hello World, которые написали вчера, нам нужно немного разобраться в компиляции.\nЯзыки программирования, которые мы обычно используем, такие как Python, Java, Go и C++, являются языками высокого уровня. Это означает, что они удобочитаемы для человека, но когда машина пытается выполнить программу, она должна быть в форме, понятной машине. Мы должны перевести наш человекочитаемый код в машинный код, что называется компиляцией.\nИз приведенного выше вы можете видеть, что мы сделали в День 8 - мы создали простой Hello World main.go, а затем использовали команду go build main.go для компиляции нашего исполняемого файла.\npackage main import \"fmt\" func main() { fmt.Println(\"Hello #90DaysOfDevOps\") } Что такое пакеты? Пакет — это набор исходных файлов в одном каталоге, которые скомпилированы вместе. Мы можем упростить это еще больше, пакет — это набор файлов .go в одном каталоге. Помните нашу папку Hello из Дня 8? Когда вы попадете в более сложные программы Go, вы можете обнаружить, что у вас есть папка1, папка2 и папка3, содержащие разные файлы .go, которые составляют вашу программу с несколькими пакетами.\nМы используем пакеты, чтобы мы могли повторно использовать код других людей, нам не нужно писать все с нуля. Возможно, нам нужен калькулятор как часть нашей программы, вы, вероятно, могли бы найти существующий пакет Go, содержащий математические функции, которые вы могли бы импортировать в свой код, что в конечном итоге сэкономит вам много времени и усилий.\nGo рекомендует организовывать код в пакеты, чтобы его было легко повторно использовать и поддерживать исходный код.\nHello #90DaysOfDevOps шаг за шагом Теперь давайте посмотрим на наш файл main.go Hello #90DaysOfDevOps и пройдемся по строкам. В первой строке у нас есть package main, что означает, что этот файл принадлежит пакету с именем main. Все файлы .go должны принадлежать пакету, они также должны иметь «package something» в открывающей строке.\nПакет можно назвать как угодно. Мы должны назвать этот main, так как это начальная точка программы, которая будет в этом пакете, это правило. Всякий раз, когда мы хотим скомпилировать и выполнить наш код, мы должны сообщить машине, где должно начаться выполнение. Мы делаем это, написав функцию с именем main. Машина будет искать функцию с именем main, чтобы найти точку входа в программу.\nФункция — это блок кода, который может выполнять определенную задачу и может использоваться во всей программе.\nВы можете объявить функцию с любым именем, используя func, но в этом случае нам нужно назвать ее main, так как именно здесь начинается код.\nДалее мы рассмотрим строку 3 нашего кода, импорт, это в основном означает, что вы хотите добавить другой пакет в свою основную программу. fmt — это стандартный пакет, используемый здесь, предоставленный Go, этот пакет содержит функцию Println(), и, поскольку мы импортировали ее, мы можем использовать ее в строке 6. Существует ряд стандартных пакетов, которые вы можете включить в свою программу и используйте или повторно используйте их в своем коде, избавляя вас от необходимости писать с нуля. Println(), который у нас есть, — это способ записи в стандартный вывод на терминал, где когда-либо исполняемый файл был успешно выполнен. Не стесняйтесь изменять сообщение между скобками (). TLDR Что такое TLDR\nСтрока 1 = Этот файл будет находиться в пакете с именем main, и его нужно назвать main, поскольку он включает точку входа программы. Строка 3 = Чтобы использовать Println(), мы должны импортировать пакет fmt, чтобы использовать его в строке 6. Строка 5 = фактическая начальная точка, это функция main. Строка 6 = Это позволит нам напечатать «Hello #90DaysOfDevOps» в нашей системе. Источники Стандартная библиотека Go Golang | Все Основы за 4 Часа Для Начинающих StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 10-й день\n","description":"Как работает hello-world на Golang","title":"9. Как работает hello-world на Golang","uri":"/ru/tracks/90daysofdevops/day09/"},{"content":"Мобильность данных и приложений День 90 из #90DaysOfDevOps Challenge! В этой заключительной сессии я собираюсь рассказать о мобильности наших данных и приложений. Я сосредоточусь конкретно на Kubernetes, но потребность в мобильности между платформами и между платформами - это то, что является постоянно растущей потребностью и встречается на практике.\nСценарий использования таков: “Я хочу переместить рабочую нагрузку, приложение и данные из одного места в другое” по разным причинам, будь то стоимость, риск или предоставление бизнесу более качественных услуг.\nНа этом занятии мы возьмем нашу рабочую нагрузку и рассмотрим перемещение рабочей нагрузки Kubernetes с одного кластера на другой, но при этом мы изменим то, как наше приложение находится в целевом месте.\nФактически, здесь используются многие характеристики, которые мы рассмотрели в статье Аварийное восстановление\nТребование Наш текущий кластер Kubernetes не справляется со спросом, а наши затраты стремительно растут, поэтому мы хотим переместить наш производственный кластер Kubernetes в место аварийного восстановления, расположенное в другом публичном облаке, которое обеспечит возможность расширения, но при этом будет дешевле. Мы также сможем воспользоваться некоторыми собственными облачными сервисами, доступными в целевом облаке.\nНаше текущее критически важное приложение (Pac-Man) имеет базу данных (MongoDB) и работает на медленном хранилище, мы хотели бы перейти на новый более быстрый уровень хранения.\nТекущий фронтенд Pac-Man (NodeJS) не очень хорошо масштабируется, и мы хотели бы увеличить количество доступных стручков в новом месте.\nПриступаем к ИТ У нас есть бриф, и на самом деле мы уже импортировали наши импорты в кластер Disaster Recovery Kubernetes.\nПервое, что нам нужно сделать, это удалить операцию восстановления, которую мы выполнили в день 89 для тестирования Disaster Recovery.\nМы можем сделать это с помощью команды kubectl delete ns pacman на “резервном” кластере minikube.\nЧтобы начать работу, зайдите в Kasten K10 Dashboard, выберите карточку Applications. Из выпадающего списка выберите “Удаленные”\nЗатем мы получим список доступных точек восстановления. Мы выберем ту, которая доступна, так как она содержит важные данные. (В этом примере у нас только одна точка восстановления).\nКогда мы работали над процессом аварийного восстановления, мы оставили все по умолчанию. Однако эти дополнительные опции восстановления существуют, если у вас есть процесс Disaster Recovery, который требует преобразования вашего приложения. В данном случае нам требуется изменить хранилище и количество реплик. Выберите опцию “Применить преобразования к восстановленным ресурсам”.\nТак получилось, что два встроенных примера преобразования, которые мы хотим выполнить, соответствуют нашим требованиям.\nПервое требование заключается в том, что на нашем основном кластере мы использовали класс хранения под названием csi-hostpath-sc, а в нашем новом кластере мы хотим использовать standard, поэтому мы можем сделать это изменение здесь.\nВыглядит хорошо, нажимаем кнопку create transform внизу.\nСледующее требование заключается в том, что мы хотим масштабировать развертывание нашего фронтенда Pac-Man до “5”\nЕсли вы следите за развитием событий, вы должны увидеть оба наших преобразования, как показано ниже.\nТеперь вы можете видеть на изображении ниже, что мы собираемся восстановить все артефакты, перечисленные ниже, если бы мы захотели, мы могли бы также детализировать то, что мы хотим восстановить. Нажмите кнопку “Восстановить”\nСнова нам будет предложено подтвердить действия.\nИ последнее, что мы покажем, если мы вернемся в терминал и посмотрим на наш кластер, вы увидите, что у нас теперь 5 стручков для стручков pacman и наш класс хранения теперь установлен на стандартный, а не на csi-hostpath-sc\nСуществует множество различных вариантов, которые могут быть достигнуты с помощью трансформации. Это может охватывать не только миграцию, но и аварийное восстановление, скрипты типа тестирования и разработки и т.д.\nAPI и автоматизация Я не говорил о возможности использовать API и автоматизировать некоторые из этих задач, но эти опции присутствуют, и во всем пользовательском интерфейсе есть хлебные крошки, которые предоставляют наборы команд для использования API для задач автоматизации.\nВажно отметить, что при развертывании Kasten K10 развертывается внутри кластера Kubernetes и затем может быть вызван через API Kubernetes.\nНа этом мы завершаем раздел о хранении и защите данных.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility Закрытие Заканчивая эту задачу, я хочу продолжить просить об обратной связи, чтобы убедиться, что информация всегда актуальна.\nЯ также ценю, что есть много тем, которые я не смог охватить или не смог глубже погрузиться в тему DevOps.\nЭто означает, что мы всегда можем предпринять еще одну попытку в следующем году и найти еще 90 дней контента и прохождений для работы.\nЧто дальше? Во-первых, немного отдохнем от писанины, я начал этот вызов 1 января 2022 года и закончил 31 марта 2022 года в 19:50 BST! Это был тяжелый труд. Но, как я говорю и говорил уже давно, если этот контент поможет одному человеку, то всегда стоит учиться публично! У меня есть несколько идей, куда двигаться дальше, и я надеюсь, что у него будет жизнь за пределами репозитория GitHub, и мы сможем рассмотреть возможность создания электронной книги и, возможно, даже физической книги.\nЯ также знаю, что нам нужно пересмотреть каждый пост и убедиться, что все грамматически правильно, прежде чем делать что-то подобное. Если кто-то знает о том, как использовать формат markdown для печати или создания электронной книги, я буду очень признателен за ответ.\nКак всегда, продолжайте обсуждать вопросы и PR.\nСпасибо!\n","description":"","title":"90. Мобильность данных и приложений","uri":"/ru/tracks/90daysofdevops/day90/"},{"content":"All examples\n","description":"Awesome app icons","title":"Awesome app icons","uri":"/ru/posts/photos/icons/"},{"content":"\nBrewMate is a macOS GUI application that makes it easy to search for, install, and uninstall Homebrew casks. You can also see the top downloaded casks for the last month.\nInstall Download the latest DMG file from the releases page or from sourceforge.net Double-click the DMG file to open it. Drag the BrewMate app to your Applications folder. Launch BrewMate from your Applications folder. or\nbrew install romankurnovskii/cask/brewmate --cask or\nbrew tap romankurnovskii/cask brew update brew install brewmate --cask FAQ Is this app free? Yes, the app is free to download and use.\nWhat operating systems does this app support? This app is designed for macOS, and it supports macOS 10.15 (Catalina) and newer versions.\n","description":"Homebrew GUI Apps Manager","title":"BrewMate","uri":"/ru/apps/brewmate/"},{"content":" https://chat.openai.com/chat/ https://russiannlp.github.io/rugpt-demo/ Краткий экскурс в ruGPT-3. Инструкция и демонстрация ","description":"ruGPT-3","title":"ChatGPT/ruGPT-3","uri":"/ru/posts/rugpt-3-notes/"},{"content":"Goal: Check if you are ready to pass the Cloud exam\nThe application calculates progress after each answered question. Ability to answer at least one question and get a comment at the same time. No need to pass all questions before. It is convenient to spend 20 min a day Works from web/tablet/mobile Link: https://www.cloud-exam-prepare.com\n","description":"Подготовка к сдаче экзамена AWS","title":"Cloud exam Quizz","uri":"/ru/apps/cloud-exam-quizz/"},{"content":"","description":"Отслеживает истечение срока действия access и id токенов Amazon Cognito. Обновляется по истечении срока действия.","title":"cognito-token-observer","uri":"/ru/apps/npm/cognito-token-observer/"},{"content":"Django - это высокоуровневый фреймворк для веб-приложений на языке Python. Он предоставляет множество инструментов для разработки сайтов, начиная от автоматического создания административного интерфейса до работы с базами данных. Основными принципами, которыми руководствуется Django, являются: быстрота разработки, возможность переиспользования кода и расширяемость.\nУстановим необходимые пакеты:\npip install django Для начала работы с Django нужно создать проект. Для этого в командной строке нужно ввести команду:\ndjango-admin startproject project_name После этого будет создан проект с именем “project_name”. Внутри проекта есть файлы настроек и приложения. Приложение - это часть проекта, которая отвечает за определенную функциональность.\nДля создания приложения нужно ввести команду:\npython manage.py startapp app_name Далее можно начинать разработку функциональности внутри приложения.\nПример реализации CRUD операций с использованием Django:\nfrom django.shortcuts import render, get_object_or_404 from django.http import HttpResponseRedirect from django.urls import reverse from .models import Book def index(request): books = Book.objects.all() return render(request, 'index.html', {'books': books}) def create(request): if request.method == 'POST': book = Book( title=request.POST.get('title'), author=request.POST.get('author'), published_date=request.POST.get('published_date') ) book.save() return HttpResponseRedirect(reverse('index')) return render(request, 'create.html') def update(request, book_id): book = get_object_or_404(Book, pk=book_id) if request.method == 'POST': book.title = request.POST.get('title') book.author = request.POST.get('author') book.published_date = request.POST.get('published_date') book.save() return HttpResponseRedirect(reverse('index')) return render(request, 'update.html', {'book': book}) def delete(request, book_id): book = get_object_or_404(Book, pk=book_id) book.delete() return HttpResponseRedirect(reverse('index')) В данном примере определены функции для отображения списка книг (index), создания новой книги (create), обновления существующей книги (update) и удаления книги (delete). Все эти функции используют модель Book, которая определена в файле models.py. Шаблоны (templates) для каждой из функций находятся в отдельных html-файлах.\nРесурсы:\nОфициальная документация Django ","description":"Python 101","title":"Django","uri":"/ru/tracks/python-101/frameworks/django/"},{"content":" Docs EN | RU Posts EN | RU ","description":"","title":"Docs","uri":"/ru/tracks/archive/"},{"content":"Amazon EC2 Документация Amazon EC2 - 1 Документация Amazon EC2 - 2 Amazon Elastic Compute Cloud (EC2) - одна из самых популярных служб AWS. EC2 позволяет запускать различные типы облачных экземпляров и оплачивать их по модели “оплата за использование”. EC2 позволяет контролировать вычислительные ресурсы на уровне операционной системы, работая в вычислительной среде Amazon.\nЦены Актуальный прайс\nПрактика Создание EC2 инстанса Заходим на страницу EC2 -\u003e Launch Instance\nОбраз EC2 Выбираем нужный нам образ Создание ключей Создадим ключ, чтобы использовать его для подключения к инстансу извне Вводим любое имя. Остальные параметры оставляю по умолчанию После создания ключа начнется автоматическое скачивание. Ключ понадобится далее для подключения к EC2 с локального терминала\nСетевые настройки В разделе Network Settings оставляю включенным Allow SSH traffic from Создание Нажимаем Launch Instance\nИнстанс создан и доступен для подключения\nПодключение к EC2 с терминала Подключимся к EC2 с локального терминала\nПеренесем созданный и скачанный ранее ключ mykey в папку home текущего пользователя и дадим права на файл CHMOD 400\ncd ~ cd Downloads/ mv mykey.pem $HOME cd .. chmod 400 mykey.pem Для подключения нам необходим публичный iPv4 адрес. Находим на странице с инстансом\nПодключаемся с помощью команды ssh\nssh -i mykey.pem ec2-user@52.24.109.78 Вопросы Вопрос 1 A company is migrating a legacy application to Amazon EC2. The application uses a username and password stored in the source code to connect to a MySQL database. The database will be migrated to an Amazon RDS for MySQL DB instance. As part of the migration, the company wants to implement a secure way to store and automatically rotate the database credentials.\nWhich approach meets these requirements?\nA) Store the database credentials in environment variables in an Amazon Machine Image (AMI). Rotate the credentials by replacing the AMI. B) Store the database credentials in AWS Systems Manager Parameter Store. Configure Parameter Store to automatically rotate the credentials. C) Store the database credentials in environment variables on the EC2 instances. Rotate the credentials by relaunching the EC2 instances. D) Store the database credentials in AWS Secrets Manager. Configure Secrets Manager to automatically rotate the credentials Ответ Правильный ответ: D D – AWS Secrets Manager helps to protect the credentialsneeded to access databases, applications,services, and other IT resources. The service enables users to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to the Secrets Manager APIs, eliminating the need to hardcode sensitive information in plaintext. Secrets Manager offers secret rotation with built-in integration for Amazon RDS, Amazon Redshift, and Amazon DocumentDB.\n","description":"Пошаговое руководство по Amazon EC2","title":"EC2","uri":"/ru/tracks/aws-certified-developer-associate/ec2/"},{"content":"AWS Elastic Beanstalk Документация AWS Elastic Beanstalk Документация AWS Elastic Beanstalk Цены Дополнительная плата за AWS Elastic Beanstalk не взимается. Оплате подлежат только ресурсы AWS, необходимые для хранения и работы приложений.\nПрактика Контролируемое развертывание с AWS Elastic Beanstalk Ссылка на лабораторную работу В этой лабораторной работе развернем несколько обновлений версий приложения в среде с балансировкой нагрузки и автоматическим масштабированием.\nПервое обновление развертывается с помощью простого развертывания. Второе обновление развертывается с помощью blue-green развертывания, когда создается отдельная среда для запуска новой версии приложения, а DNS свитчер переключает входящий трафик на новую среду.\nИтоговая архитектура развертывания будет выглядеть следующим образом Загрузка приложения В данном обзоре я использую код, который предоставил мне Cloudacademy, но у меня есть готовый скрипт для запуска, который вы можете загрузить в Elastic Beanstalk: скачать\nСоздание Заходим на страницу Elastic Beanstalk и нажимаем Create Application Название Указываем название нового приложения Выбор платформы В разделе Platform выбираем нужную платформу приложения. В нашем случае - Node.js Загрузка исходников В разделе Source code origin указываем версию приложения и загружаем архив с приложением. Пример\nКонфигурация приложения Изменяем предустановку Configuration на Custom configuration: Нажимаем Edit в разделе Rolling updates and deployments\nВ конфигурации по умолчанию обновления распространяются на все экземпляры одновременно. Это приводит к простою приложения, что неприемлемо для производственных сред.\nМы установим Rolling и Batch size 30% Сеть Вернувшись к основной форме приложения, нажмите Edit в конфигурации Network.\nНа форме Modify network настроим следующие значения, затем Save. VPC: Выберите VPC с блоком CIDR 10.0.0.0/16. Это не будет VPC по умолчанию. Load balancer settings: Load balancer subnets: Выберите подсети с блоками CIDR **10.0.100.0/24 **(us-west-2a)и 10.0.101.0/24 (us-west-2b). Это публичные подсети. Балансировщику нагрузки приложений требуется как минимум две подсети в разных зонах доступности Instance settings: Instance subnets: Выберите подсеть с блоком CIDR 10.0.1.0/24. Это частная подсеть. Подтверждение Нажимаем Create app\nПроцесс создания приложения занимает от 5 минут.\nДалее переходим в раздел Dasboard На этом этап загрузки приложения в Elastic Beanstalk закончен. Далее разберем как переключать загрузку новой версии приложения клиентам.\nЗагрузка 2-й версии приложения Загрузка версии 2.0 Нажимаем Upload and deploy и загружаем обновленный код. _Например, можно том же исходнике изменить текст для сравнения. Указываем новую версию и настройки публикации Сравнение версий Теперь можем сверить обе версии, пройдя по ссылкам. В моем случае приложения выглядят следующим образом Смена url у приложений Теперь поменяем приложения местами. Чтобы пользователь, который ранее заходил по одному адресу, теперь видел 2-ю версию приложения.\nВ разделе Actions нажимаем Swap environment URLs и далее выбираем приложение с которым происходит смена Удаление ресурсов Elastic Beanstalk Elastic Beanstalk для развертывания приложений запускает EC2 инстансы, а также прочие сервисы. Но удалить все сервисы можно из одного окна.\nИдем в раздел Applications Выбираем приложение Нажимаем Actions -\u003e Terminate environment Ресурсы https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/tutorials.html\n","description":"Пошаговое руководство по AWS Elastic Beanstalk. Разворачиваем приложение с AWS Elastic Beanstalk","title":"Elastic Beanstalk","uri":"/ru/tracks/aws-certified-developer-associate/elasticbeanstalk/"},{"content":"FastAPI - это фреймворк для создания веб-приложений на Python, использующий современный подход к созданию API и основанный на ASGI-серверах. Он разработан с упором на скорость и быстродействие, предоставляя возможности асинхронного выполнения запросов, автоматического документирования API и многие другие.\nДля установки FastAPI нужно выполнить команду pip install fastapi. Для запуска приложения можно использовать стандартный инструмент uvicorn, который также необходимо установить: pip install uvicorn.\nПример CRUD приложения на FastAPI:\nfrom fastapi import FastAPI, HTTPException from pydantic import BaseModel from typing import Dict app = FastAPI() # Имитация базы данных db = {} # Модель для создания/редактирования задачи class Task(BaseModel): title: str description: str # Модель для ответа со списком задач class TaskList(BaseModel): tasks: Dict[int, Task] # Получение списка задач @app.get(\"/tasks/\", response_model=TaskList) async def get_tasks(): return TaskList(tasks=db) # Получение одной задачи по id @app.get(\"/tasks/{task_id}\") async def get_task(task_id: int): if task_id not in db: raise HTTPException(status_code=404, detail=\"Task not found\") return db[task_id] # Создание новой задачи @app.post(\"/tasks/\") async def create_task(task: Task): task_id = max(db.keys(), default=0) + 1 db[task_id] = task return {\"id\": task_id} # Редактирование задачи @app.put(\"/tasks/{task_id}\") async def update_task(task_id: int, task: Task): if task_id not in db: raise HTTPException(status_code=404, detail=\"Task not found\") db[task_id] = task return {\"message\": \"Task has been updated\"} # Удаление задачи @app.delete(\"/tasks/{task_id}\") async def delete_task(task_id: int): if task_id not in db: raise HTTPException(status_code=404, detail=\"Task not found\") db.pop(task_id) return {\"message\": \"Task has been deleted\"} Этот код создает простое приложение с API для управления задачами. Он использует модели Pydantic для валидации данных, а также async/await синтаксис для асинхронной обработки запросов. Код использует декораторы FastAPI для определения конечных точек API (маршрутов), а также для указания моделей данных, которые используются для запросов и ответов.\nРесурсы:\nОфициальная документация FastAPI content/tracks/python-101/400_frameworks/403_fastapi.ru.md ","description":"Python 101","title":"FastAPI","uri":"/ru/tracks/python-101/frameworks/fastapi/"},{"content":"Flask - это легковесный фреймворк для создания веб-приложений на языке Python. Он подходит как для небольших проектов, так и для крупных веб-приложений.\nFlask не имеет встроенной базы данных или абстракции уровня модели, поэтому вам нужно будет выбрать библиотеку, которая лучше всего подходит для вашего проекта.\npip install flask pip install flask_sqlalchemy Пример CRUD-операций с использованием Flask:\nfrom flask import Flask, request, jsonify from flask_sqlalchemy import SQLAlchemy app = Flask(__name__) app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///example.db' db = SQLAlchemy(app) class Book(db.Model): id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String(100)) author = db.Column(db.String(100)) @app.route('/books', methods=['GET']) def get_all_books(): books = Book.query.all() result = [{'id': book.id, 'title': book.title, 'author': book.author} for book in books] return jsonify(result) @app.route('/books/\u003cint:book_id\u003e', methods=['GET']) def get_book(book_id): book = Book.query.get(book_id) if book is None: return jsonify({'error': 'Book not found'}), 404 result = {'id': book.id, 'title': book.title, 'author': book.author} return jsonify(result) @app.route('/books', methods=['POST']) def create_book(): book = Book(title=request.json['title'], author=request.json['author']) db.session.add(book) db.session.commit() result = {'id': book.id, 'title': book.title, 'author': book.author} return jsonify(result), 201 @app.route('/books/\u003cint:book_id\u003e', methods=['PUT']) def update_book(book_id): book = Book.query.get(book_id) if book is None: return jsonify({'error': 'Book not found'}), 404 book.title = request.json['title'] book.author = request.json['author'] db.session.commit() result = {'id': book.id, 'title': book.title, 'author': book.author} return jsonify(result) @app.route('/books/\u003cint:book_id\u003e', methods=['DELETE']) def delete_book(book_id): book = Book.query.get(book_id) if book is None: return jsonify({'error': 'Book not found'}), 404 db.session.delete(book) db.session.commit() return '', 204 Данный код использует Flask вместе с библиотекой SQLAlchemy для создания веб-приложения и взаимодействия с базой данных. Роуты приложения обрабатывают HTTP-запросы и возвращают соответствующий HTTP-ответ. В данном примере реализованы операции CRUD (Create, Read, Update, Delete) для модели Book.\nРесурсы:\nОфициальная документация Flask ","description":"Python 101","title":"Flask","uri":"/ru/tracks/python-101/frameworks/flask/"},{"content":"","description":"Создает индекс страниц Hugo для поиска lunr.js","title":"hugo-lunr-ml","uri":"/ru/apps/npm/hugo-lunr-ml/"},{"content":"AWS Identity and Access Management Документация AWS IAM Документация AWS IAM AWS Identity and Access Management (IAM) позволяет безопасно контролировать доступ пользователей к службам и ресурсам AWS. Эта услуга предназначена для организаций с множеством пользователей или систем, использующих такие продукты AWS, как Amazon EC2, Amazon RDS и AWS Management Console. С помощью IAM вы можете централизованно управлять пользователями, учетными данными безопасности, такими как ключи доступа, и разрешениями, контролирующими доступ пользователей к ресурсам AWS.\nПрактика Переходим на страницу IAM\nСоздание групп IAM На странице User Groups нажимаем Create group\nУказываем имя группы. Мое: DevOps Добавляем разрешение на просмотр EC2: AmazonEC2ReadOnlyAccess Create Группа создана\nСоздание пользователей IAM На странице Users нажимаем Create user Вводим имя пользователя(логин) Permissions Добавляем пользователя в созданную группу Tags Пропускаем раздел или ставим tags. Полезно и популярно устанавливать теги ресурсам в компаниях, где много подключено ресурсов AWS\nЛогин/Пароль На последнем этапе скачиваем .csv файл с логином, ключами и паролем. Пароль понадобится далее, чтобы войти в систему под данным пользователем. На данной странице имеется ссылка для входа. Ею воспользуемся на следующем шаге Вход новым пользователем Проверка прав У данного пользователя есть доступ на просмотр EC2 инстансов. Проверим наличие/отсутствие доступа к S3 корзинам.\nПопробуем создать S3 корзину После попытки создать корзину получаем окно с указанием на отсутствие прав ","description":"Пошаговое руководство по настройке AWS Identity and Access Management (IAM)","title":"IAM","uri":"/ru/tracks/aws-certified-developer-associate/iam/"},{"content":"Промежуточные метрики еще в процессе расчетов\nЗа 2020 год:\nЗатрачено времени на учебу/практику: ~5500 часов ","description":"Подтвержденные знания по IT за 2020 год","title":"IT курсы 2020","uri":"/ru/posts/diploma/"},{"content":"https://docs.aws.amazon.com/lambda/?id=docs_gateway\nhttps://aws.amazon.com/lambda/\nAWS Lambda – это сервис бессерверных вычислений, который запускает программный код в ответ на определенные события и отвечает за автоматическое выделение необходимых вычислительных ресурсов.\nAWS Lambda автоматически запускает программный код в ответ на различные события, такие как HTTP‑запросы через Amazon API Gateway, изменение объектов в корзинах Amazon Simple Storage Service (Amazon S3), обновление таблиц в Amazon DynamoDB или смена состояний в AWS Step Functions.\nПоддержка языков Java, Go, PowerShell, Node.js, C#, Python и Ruby\nЦены Актуальный прайс\nЦена x86\n0,0000166667 USD за каждую гигабайт-секунду 0,20 USD за 1 млн запросов Цена Arm\n0,0000133334 USD за каждую гигабайт-секунду 0,20 USD за 1 млн запросов Практика В строке поиска Консоли управления AWS введите Lambda и выбираем Lambda в разделе «Services»:\nhttps://us-west-2.console.aws.amazon.com/lambda/home?region=us-west-2#\nНа странице Functions нажимаем Create a function\nAuthor from scratch is selected and enter the following values in the bottom form:\nFunction name: MyCustomFunc Runtime: Node.js 16.X Я выбираю этот раздел, потому что использую аккаунт cloudacademy. Данная роль дает разрешение на создание функций\nPermissions: Change default execution role Execution Role: Select Use an existing role Existing role: Select the role beginning with cloudacademylabs-LambdaExecutionRole → Create function\nПишу функцию, чтобы просмотреть лог, добавлю печать в терминал. А также добавлю обработку получаемого сообщения (В следующем шаге в разделе тестирования)\nфункция принимает в качестве объекта event который содержит массив Records. На 1-й (0) позиции Объект Sns (название сервиса SNS Notifications).\nВ самом объекте будет 2 значения:\ncook_secs - время варки (микроволновки) req_secs - время приготовления console.log('Loading function'); exports.handler = function(event, context) { console.log(JSON.stringify(event, null, 2)); const message = JSON.parse(event.Records[0].Sns.Message); if (message.cook_secs \u003c message.req_secs) { if (message.pre) { context.succeed(\"User ended \" + message.pre + \" preset early\"); } else { context.succeed(\"User ended custom cook time early\"); } } context.succeed(); }; → Deploy\n→ Test\nДанная функциональность позволяет протестировать как функция реагирует на определенные события. Попробуем добавить событие от SNS Notifications.\nВыберем из списка\nПолучаем шаблон, в котором внесем правки, подправим поле Message - то самое, которое мы будем обрабатывать в нашей функции.\nПоле Message- строка, поэтому наш объект надо будет обернуть в кавычки\nЧтобы обработчик понимал, что мы ставим кавычки внутри кавычек, необходимо поставить специальный символ \\ перед кавычкой.\nВ итоге обновляем одну строку и сохраняем → Create\nТеперь нажимаем на кнопку Test\nТак как cook_secs в нашем евенте был меньше, чем req_secs, то функция распечатала первое условие, а ниже в разделе Function Logs видим сообщение, которые мы распечатываем при инициализации функции Loading function\n","description":"Пошаговое руководство по AWS Lambda","title":"Lambda","uri":"/ru/tracks/aws-certified-developer-associate/lambda/"},{"content":" Docs EN | RU Posts EN | RU ","description":"","title":"Posts Archive","uri":"/ru/posts/archive/"},{"content":"PyScript PyScript - средство запуска Python в браузере, встроенное в HTML, был анонсирован на мероприятии PyCon в Солт-Лейк-Сити, США. Кнопка Instl здесь для шутки, так как установка не требуется\nPyScript зависит от существующего проекта Pyodide, который является скомпилированным в WebAssembly интерпретатором CPython 3.8, позволяющим запускать Python в браузере, а также скомпилированных научных пакетов Python.\nСвязывание с файлами библиотеки CSS и JavaScript PyScript позволяет разработчикам встраивать код Python с помощью тега \u003cpy-script\u003e, а также компонент \u003cpy-repl\u003e (Read, Evaluate, Print, Loop), который позволяет Python печатать и выполняться динамически.\nPyScript является открытым исходным кодом с использованием лицензии Apache 2.0.\nСогласно сайту проекта, цели включают в себя включение Python в браузере без настройки на стороне сервера, запуск популярных пакетов Python, двунаправленную связь между JavaScript и Python и визуальную разработку с использованием «легкодоступных контролируемых компонентов пользовательского интерфейса, таких как кнопки, контейнеры, текстовые поля и многое другое».\nУпрощение использования в браузере порадует не только ученых, разрабатывающих аналитические приложения, но и программистов любого профиля, ищущих альтернативу JavaScript — хотя разработчики проекта предупреждают, что это «чрезвычайно экспериментальный проект» и что он только проверен в веб-браузере Google Chrome.\nPlease be advised that PyScript is very alpha and under heavy development. There are many known issues, from usability to loading times, and you should expect things to change often. We encourage people to play and explore with PyScript, but at this time we do not recommend using it for production.\nТуториал PyScript Попробуем скачать, настроить и запустить приложение PyScript в браузере.\nРабочая среда Разработчики PyScript пишут, что для работы не требуется никакой среды разработки, кроме веб-браузера. Попробуем запустить в Chrome.\nУстановка Можно скачать весь пакет с сайта, но будем использовать скрипт, с сервера pyscript.net\nHello World Создаем файл hello.html\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print('Hello, World!') \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег \u003cpy-script\u003e расположен внутри HTML body. Внутри этого тега будем пиcать Python код.\nОткроем файл в браузере Работает!\nТег py-script Тег \u003cpy-script\u003e позволяет писать многострочный код\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print(\"Let's compute π:\") def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) s = f\"π is approximately {pi:.3f}\" print(s) \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Важно соблюдать отступы в самом блоке Python. Но Начальную строку кода можно начинать и с начала строки\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print(\"Let's compute π:\") def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) s = f\"π is approximately {pi:.3f}\" print(s) \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Запись внутри HTML элементов В приведенном выше примере у нас был один тег \u003cpy-script\u003e, выводящий одну или несколько строк на страницу по порядку. Внутри \u003cpy-script\u003e есть доступ к модулю pyscript, который предоставляет метод .write() для отправки строк в помеченные элементы на странице.\nНапример, мы добавим некоторые элементы стиля и предоставим заполнители для тега \u003cpy-script\u003e для записи.\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003clink href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\" crossorigin=\"anonymous\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cb\u003e\u003cp\u003eToday is \u003cu\u003e\u003clabel id='today'\u003e\u003c/label\u003e\u003c/u\u003e\u003c/p\u003e\u003c/b\u003e \u003cbr\u003e \u003cdiv id=\"my-custom-pi\" class=\"alert alert-primary\"\u003e\u003c/div\u003e \u003cpy-script\u003e import datetime as dt pyscript.write('today', dt.date.today().strftime('%A %B %d, %Y')) def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) pyscript.write('my-custom-pi', f'π is approximately {pi:.3f}') \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег py-env В дополнение к стандартной библиотеке Python и модулю pyscript, многие сторонние пакеты работают с PyScript. Чтобы их использовать, нужно объявить зависимости с помощью тега \u003cpy-env\u003e в заголовке HTML. Вы также можете ссылаться на файлы .whl прямо на диске\n\u003cpy-env\u003e - './static/wheels/travertino-0.1.3-py3-none-any.whl' - './static/wheels/my-other-package-0.0.1-py3-none-any.whl' \u003c/py-env\u003e \u003cpy-script\u003e #my python code ... \u003c/py-script\u003e Пример с NumPy\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003cpy-env\u003e - numpy - matplotlib \u003c/py-env\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eLet's plot random numbers\u003c/h1\u003e \u003cdiv id=\"plot\"\u003e\u003c/div\u003e \u003cpy-script output=\"plot\"\u003e import matplotlib.pyplot as plt import numpy as np x = np.random.randn(1000) y = np.random.randn(1000) fig, ax = plt.subplots() ax.scatter(x, y) fig \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Импорт локальный модулей Мы также можем использовать собсвтенные модули, которые импортируем внутри тега \u003cpy-script\u003e\nНапример, создадим файл `data.py’ и запишем в него собственную функцию\n# data.py import numpy as np def make_x_and_y(n): x = np.random.randn(n) y = np.random.randn(n) return x, y Внутри тега \u003cpy-env\u003e добавим стандартные модули и путь до нашего локального модуля\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003cpy-env\u003e - numpy - matplotlib - paths: - /data.py \u003c/py-env\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eLet's plot random numbers\u003c/h1\u003e \u003cdiv id=\"plot\"\u003e\u003c/div\u003e \u003cpy-script output=\"plot\"\u003e import matplotlib.pyplot as plt from data import make_x_and_y x, y = make_x_and_y(n=1000) fig, ax = plt.subplots() ax.scatter(x, y) fig \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег py-repl Тег \u003cpy-repl\u003e создает компонент REPL(Read–eval–print loop), который отображается на странице как редактор кода, что позволяет писать исполняемый код в строке.\nТег py-config Тег \u003cpy-config\u003e используется для установки и настройки общих метаданных о вашем приложении PyScript в формате YAML.\n\u003cpy-config\u003e - autoclose_loader: false - runtimes: - src: \"https://cdn.jsdelivr.net/pyodide/v0.20.0/full/pyodide.js\" name: pyodide-0.20 lang: python \u003c/py-config\u003e Тег py-title Тег визуального отображения. Добавляет компонент заголовка статического текста, который стилизует текст внутри тега как заголовок страницы.\nТег py-box Создает объект-контейнер, который можно использовать для размещения одного или нескольких визуальных компонентов, определяющих, как элементы \u003cpy-box\u003e должны выравниваться и отображаться на странице.\nТег py-inputbox Позволяет вставить окно с текстовым полем\nТег py-button Добавляет кнопку, к которой авторы могут добавлять метки и обработчики событий для действий на кнопке, таких как on_focus или on_click.\nРесурсы Примеры использования PyScript Вопросы по PyScript ","description":"PyScript - Python, встроенный в HTML","title":"PyScript - Python, встроенный в HTML","uri":"/ru/posts/pyscript-python-embedded-in-html/"},{"content":"Tornado - это еще один быстрый веб-фреймворк, который разработан для обработки больших объемов трафика в режиме реального времени.\nДля начала работы с Tornado нам нужно установить его, используя команду pip:\npip install tornado import tornado.ioloop import tornado.web import tornado.escape class MainHandler(tornado.web.RequestHandler): def get(self): items = [{'id': 1, 'name': 'Item 1'}, {'id': 2, 'name': 'Item 2'}] self.write(tornado.escape.json_encode(items)) class ItemHandler(tornado.web.RequestHandler): def get(self, id): item = {'id': id, 'name': 'Item ' + id} self.write(tornado.escape.json_encode(item)) def post(self, id): item = {'id': id, 'name': self.get_argument('name')} self.write(tornado.escape.json_encode(item)) def put(self, id): item = {'id': id, 'name': self.get_argument('name')} self.write(tornado.escape.json_encode(item)) def delete(self, id): self.write('Item ' + id + ' deleted') def make_app(): return tornado.web.Application([ (r'/', MainHandler), (r'/item/(\\d+)', ItemHandler), ]) if __name__ == '__main__': app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() В этом примере мы создаем два класса-обработчика, один для главной страницы, другой для работы с конкретным элементом. Для тестирования мы создаем два элемента и возвращаем их в формате JSON при запросе к главной странице.\nКогда мы запрашиваем элемент, создается элемент соответствующий запрошенному и возвращается в формате JSON. Методы post, put и delete принимают данные из тела запроса и выполняют соответствующую операцию.\nЗапуск приложения осуществляется через командную строку:\npython tornado_app.py После запуска приложения, мы можем обращаться к нему через браузер по адресу http://localhost:8888/. При обращении к адресу http://localhost:8888/item/1, мы получим объект с идентификатором 1 в формате JSON.\nПри выполнении запроса post на тот же URL с параметрами, мы создадим новый элемент.\nПри запросе put мы обновим данные существующего элемента, а при выполнении delete - удалим элемент с указанным идентификатором.\nРесурсы:\nОфициальная документация Tornado ","description":"Python 101","title":"Tornado","uri":"/ru/tracks/python-101/frameworks/tornado/"},{"content":"Для работы большинства приложений WebRTC необходим сервер для ретрансляции трафика между узлами, поскольку прямой сокет часто невозможен между клиентами (если только они не находятся в одной локальной сети). Обычный способ решить эту проблему — использовать TURN-сервер (Traversal Using Relay NAT), который представляет собой протокол ретрансляции сетевого трафика.\nВ настоящее время существует несколько вариантов TURN-серверов, доступных в Интернете, как в виде самостоятельных приложений (например, проект COTURN с открытым исходным кодом), так и в виде облачных сервисов.\nЕсли у вас есть доступный онлайн TURN-сервер, то все, что вам нужно - это правильная RTCConfiguration для вашего клиентского приложения. Следующий фрагмент кода иллюстрирует пример конфигурации для RTCPeerConnection, где TURN-сервер hostname my-turn-server.mycompany.com работает на порту 19403.\nОбъект конфигурации также поддерживает свойства username и credentials для защиты доступа к серверу. Они необходимы при подключении к TURN-серверу.\nconst iceConfiguration = { iceServers: [ { urls: 'turn:my-turn-server.mycompany.com:19403', username: 'optional-username', credentials: 'auth-token' } ] } const peerConnection = new RTCPeerConnection(iceConfiguration); ","description":"Карманная книга по WebRTC","title":"TURN сервер","uri":"/ru/tracks/webrtc/turn-server/"},{"content":"В Python вы можете запросить у пользователя ввод данных во время выполнения программы. Для этого используется функция input(), которая приостанавливает выполнение программы, ожидает ввода от пользователя и возвращает введенные данные в виде строки.\nname = input(\"Введите ваше имя: \") print(\"Привет, \" + name + \"!\") При запуске этого кода пользователь увидит приглашение “Введите ваше имя:”, после чего он может ввести свое имя и нажать клавишу Enter. Затем программа поприветствует пользователя по имени.\nВы также можете использовать функцию int() для преобразования введенной строки в целое число. Например:\nage = int(input(\"Сколько вам лет? \")) print(\"В следующем году вам будет\", age + 1) Этот код запросит у пользователя возраст, преобразует его в целое число и выводит сообщение о том, сколько ему будет лет в следующем году.\nОбратите внимание, что функция input() всегда возвращает строку, поэтому необходимо преобразовывать введенные данные в нужный тип, если это необходимо.\n","description":"Python 101","title":"Ввод данных пользователем","uri":"/ru/tracks/python-101/basis/inputs/"},{"content":"Вы создали приложение для потоковой передачи видео в реальном времени и обмена данными!\nЧто вы узнали\nВ этой codelab вы узнали, как:\nПолучать видео с вашей веб-камеры. стримить видео с помощью RTCPeerConnection. Стримить данные с помощью RTCDataChannel. Настраивать сигналинг-службу для обмена сообщениями. Комбинировать одноранговое соединение и сигналинг. Сделать снимок и поделиться им через канал передачи данных. Следующие шаги\nПосмотрите на код и архитектуру канонического приложения AppRTC для чата WebRTC – приложение (https://appr.tc/), код (https://github.com/webrtc/apprtc) Попробуйте реальные примеры (http://webrtc.github.io/samples) из github.com/webrtc/samples. Узнать больше\nРяд ресурсов для начала работы с WebRTC доступен на https://webrtc.org/ ","description":"Карманная книга по WebRTC","title":"Выводы","uri":"/ru/tracks/webrtc/practice/practice-results/"},{"content":"В языке Python есть несколько методов создания списков и словарей, которые известны как генераторы.\nГенераторы списков Генератор списка - это выражение, которое генерирует список значений на основе каких-то правил. Вместо того, чтобы создавать список целиком и хранить его в памяти, генератор списка генерирует значения по мере их запроса.\nsquares = [x*x for x in range(10)] Эта строка создает генератор списка, который генерирует квадраты чисел от 0 до 9. Затем можно перебрать элементы этого генератора с помощью цикла:\nВ Python есть функция range, которая может возвращать список чисел. По умолчанию она возвращает целые числа, начиная с 0 и заканчивая числом, которое вы ей передали, но не включая его. В данном случае она возвращает список, содержащий целые числа 0-9.\nfor square in squares: print(square) Генераторы словарей Генератор словаря работает аналогично генератору списка, но вместо списка мы создаем словарь с помощью фигурных скобок и пары “ключ: значение”.\nmy_dict = {x: x**2 for x in range(5)} print(my_dict) # Вывод: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} Генератор множеств Генератор множества используется аналогично генератору списка, но вместо списка мы создаем множество с помощью фигурных скобок.\nmy_set = {x**2 for x in range(5)} print(my_set) # Вывод: {0, 1, 4, 9, 16} Здесь мы создаем множество my_set с элементами, равными квадратам чисел от 0 до 4.\nРесурсы:\nhttps://vegibit.com/python-comprehension-tutorial/ ","description":"Python 101","title":"Генераторы","uri":"/ru/tracks/python-101/basis/comprehensions/"},{"content":" Сгенерировать ","description":"Генерация краткого содержания текста","title":"Генерация аннотации","uri":"/ru/tracks/disser/utils/text_2_short/"},{"content":"Декораторы в Python позволяют изменять поведение функций и методов, оборачивая их в другую функцию. В этом разделе мы рассмотрим несколько встроенных декораторов и создание собственного декоратора.\n@classmethod Декоратор @classmethod используется для создания методов класса в Python. Методы класса имеют доступ к состоянию класса и могут использоваться без необходимости создания экземпляра класса. Методы класса можно вызывать как от самого класса, так и от его экземпляров.\nДекоратор @classmethod применяется к методам класса. Он принимает первым аргументом класс (cls) вместо экземпляра класса (self).\nclass MyClass: @classmethod def my_class_method(cls, arg1, arg2): print('Class:', cls, 'arg1:', arg1, 'arg2:', arg2) MyClass.my_class_method('a', 'b') @staticmethod Декоратор @staticmethod используется для создания статических методов в Python. Статические методы не имеют доступа к состоянию класса и могут использоваться без необходимости создания экземпляра класса. Статические методы можно вызывать как от самого класса, так и от его экземпляров.\nДекоратор @staticmethod также применяется к методам класса. Он не принимает первый аргумент, связанный с классом.\nclass MyClass: @staticmethod def my_static_method(arg1, arg2): print('arg1:', arg1, 'arg2:', arg2) MyClass.my_static_method('a', 'b') @property Декоратор @property используется для создания свойств класса в Python. Свойства класса обеспечивают доступ к закрытым переменным класса, так что они могут быть использованы без необходимости создания экземпляра класса. Доступ к свойствам можно получить как чтением, так и записью.\nДекоратор @property используется для превращения метода в атрибут объекта. Метод, декорированный @property, может быть вызван как атрибут объекта, а не как метод.\nclass MyClass: def __init__(self, x): self._x = x @property def x(self): return self._x my_obj = MyClass(10) print(my_obj.x) # 10 @contextmanager Декоратор @contextmanager используется для создания менеджера контекста в Python. Менеджеры контекста позволяют определять блоки кода, которые должны быть выполнены с определенными контекстными условиями, такими как открытие и закрытие файлов, установка и восстановление состояния объекта и т. д.\n@contextmanager позволяет использовать функцию как менеджер контекста с использованием ключевого слова with.\nfrom contextlib import contextmanager @contextmanager def my_context(): print('entering context') yield print('exiting context') with my_context(): print('inside context') @lru_cache Декоратор @lru_cache используется для кэширования результатов функции. Он сохраняет результаты вызовов функции в памяти, чтобы избежать повторных вычислений.\n@lru_cache использует алгоритм LRU (least recently used) для автоматического удаления наиболее неиспользуемых элементов из кэша.\nfrom functools import lru_cache @lru_cache(maxsize=128) def fibonacci(n): if n \u003c= 1: return n return fibonacci(n-1) + fibonacci(n-2) print(fibonacci(30)) Создание декоратора Для создания собственного декоратора в Python нужно определить функцию-обертку, которая будет принимать функцию в качестве аргумента и возвращать новую функцию, изменяющую поведение исходной функции.\nНапример, создадим декоратор, который будет выводить время выполнения функции:\nimport time def timer(func): def wrapper(*args, **kwargs): start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\"Function '{func.__name__}' executed in {end_time - start_time:.4f} seconds\") return result return wrapper @timer def my_func(): time.sleep(2) my_func() Здесь мы определили функцию-обертку wrapper, которая принимает любое количество позиционных и именованных аргументов и вызывает исходную функцию func с этими аргументами. Затем мы измеряем время выполнения функции, выводим результат и возвращаем его.\n","description":"Python 101","title":"Декораторы","uri":"/ru/tracks/python-101/enhance_python/decorators/"},{"content":"Для изучения темы “дерево отрезков” необходимо знать следующие понятия:\nмассивы циклы условные операторы битовые операции Дерево отрезков (Segment Tree) - это динамическая структура данных, используемая для выполнения операций над интервалами и их обновления. Оно поддерживает две операции: обновление элементов (update) в заданном диапазоне и запрос (query) на сумму элементов в заданном диапазоне.\nВыполним следующую задачу: у нас есть массив, и мы хотим находить сумму элементов в определенном диапазоне.\nДля этой задачи мы можем использовать дерево отрезков. Оно построено как бинарное дерево, где каждый узел представляет интервал, а значение узла - это сумма элементов в этом интервале.\nОсновы:\nОпределение элемента суммы в дереве отрезков: Элемент суммы в дереве отрезков является суммой всех элементов в диапазоне, который он представляет.\nКонструирование дерева отрезков: Дерево отрезков может быть построено на базе массива чисел. Каждый узел дерева представляет диапазон элементов в массиве и хранит сумму элементов в этом диапазоне.\nРеализация операций: Реализация различных операций в дереве отрезков по сути зависит от его структуры. Однако, существует несколько операций, которые часто используются в различных задачах:\nОбновление значения в массиве: Эта операция позволяет изменять значение элемента в массиве. Обычно она реализуется с помощью рекурсивного прохода по дереву.\nЗапрос на значение: Эта операция позволяет запрашивать значение элемента в массиве. Обычно она также реализуется с помощью рекурсивного прохода по дереву.\nЗапрос на сумму: Эта операция позволяет запрашивать сумму значений в массиве на заданном интервале. Она обычно реализуется с помощью рекурсивного прохода по дереву и подсчета суммы\nПостроение дерева отрезков Так как дерево бинарное, у каждой вершины будет до двух потомков.\nГрафически это выглядит следующим образом (для массива из 8 элементов):\nВ самой верхней вершине зафиксирован отрезок от начала массива до последнго элемента.\nСлева - лева половина от родителя ([0 1 2 3]). Справа - правая половина ()[4 5 6 7]). И так далее до последнего узла с отрезком из одного элемента.\nВозьмем массив a = [1, 3, -2, 8, -7]. На его базе построим дерево отрезкови запишем суммы этих отрезков в каждый узел.\nСтруктура такого дерево выглядит следующим образом:\n💡 Дерево содержит менее 2n вершин. 2*n-1\nЧисло вершин в худшем случае оценивается суммой $n + \\frac{n}{2} + \\frac{n}{4} + \\frac{n}{8} + \\ldots + 1 \u003c 2n$\nОтобразим такое дерево как массив:\nВ таком дереве 9 вершин. Массив будет состоять из 9 элементов. tree[0] = A[0:4] tree[1] = A[0:2] tree[2] = A[3:4] tree[3] = A[0:1] tree[4] = A[2:2] tree[5] = A[3:3] tree[6] = A[4:4] tree[7] = A[0:0] tree[8] = A[1:1] В данном дереве покрыты все вершины.\nИмея такую структуру, в значениях вершин можно хранить различные данные, например, сумму отрезка, наименьшее/наибольшее число или другие агрегированные данные на отрезках.\nРеализация дерева отрезков на Python Инициализация дерева\na = [1, 3, -2, 8, -7]\nТак как самыми последними вершинами являются отрезки длиной == 1. То процесс создания начинаем с них, постепенно поднимаясь на уровень выше.\n💡 Дерево содержит менее 2n вершин. 💡 Нижняя виршина - длина отрезка равна 1.\ndef build_tree(array): n = len(array) tree = [0] * 2 * n # Дерево содержит менее **2n** вершин. for i in range(n): tree[n + i] = a[i] # самые нижние вершины дерева # добавляем родителей for i in reversed(range(n)): tree[i] = tree[2 * i] + tree[2 * i + 1] print(i, tree) \u003e\u003e array = [1, 3, -2, 8, -7] \u003e\u003e build_tree(array) 4 [0, 0, 0, 0, 1, 1, 3, -2, 8, -7] 3 [0, 0, 0, 1, 1, 1, 3, -2, 8, -7] 2 [0, 0, 2, 1, 1, 1, 3, -2, 8, -7] 1 [0, 3, 2, 1, 1, 1, 3, -2, 8, -7] 0 [3, 3, 2, 1, 1, 1, 3, -2, 8, -7] Подсчет суммы на отрезке:\nФункция получает индексы исходного массива.\nПри создании дерева из изходного массива мы помещали каждый отдельный элемент на новый индекс [n + i].\n💡 Поэтому когда функция принимает индекс, сначала мы найдет самый нижний элемент в дереве. Он расположен в новом массиве по индексу [длина_исходного_массива + index]\n# подсчет суммы на отрезке def query_tree(l, r): global tree, n sum = 0 l += n # индекс текущего элемента r += n while l \u003c= r: if l % 2 == 1: # если индекс нечетный sum += tree[l] l += 1 if r % 2 == 0: sum += tree[r] r -= 1 l //= 2 # floor division. 8 // 3 = 2 r //= 2 return sum \u003e\u003e a = [1, 3, -2, 8, -7] \u003e\u003e n = len(a) \u003e\u003e tree = build_tree(a) \u003e\u003e query_tree(0, 4) # sum([1, 3, -2, 8, -7]) 3 \u003e\u003e query_tree(1, 3) # sum([3, -2, 8]) 9 \u003e\u003e query_tree(4, 4) -7 Получаем класс SegmentTree:\nФункцию суммирования или любую другую можно включить в момент генерации дерева\nclass SegmentTree: def __init__(self, a): self.n = len(a) self.tree = [0] * 2 * self.n for i in range(self.n): self.tree[self.n + i] = a[i] for i in range(self.n - 1, 0, -1): self.tree[i] = self.tree[2*i] + self.tree[2*i+1] def calculate_sum(self, l, r): sum = 0 l += self.n r += self.n while l \u003c= r: if l % 2 == 1: sum += self.tree[l] l += 1 if r % 2 == 0: sum += self.tree[r] r -= 1 l //= 2 r //= 2 return sum def find_value(self, l, r): l += self.n r += self.n while l \u003c r: if r % 2 == 0: r -= 1 else: r -= 1 l += 1 return l - self.n Шаблон класса Segment Tree class SegmentTree: def __init__(self, data, default=0, func=max): self._default = default self._func = func self._len = len(data) self._size = _size = 1 \u003c\u003c (self._len - 1).bit_length() self.data = [default] * (2 * _size) self.data[_size:_size + self._len] = data for i in reversed(range(_size)): self.data[i] = func(self.data[i + i], self.data[i + i + 1]) def __delitem__(self, idx): self[idx] = self._default def __getitem__(self, idx): return self.data[idx + self._size] def __setitem__(self, idx, value): idx += self._size self.data[idx] = value idx \u003e\u003e= 1 while idx: self.data[idx] = self._func(self.data[2 * idx], self.data[2 * idx + 1]) idx \u003e\u003e= 1 def __len__(self): return self._len def query(self, start, stop): \"\"\"func of data[start, stop)\"\"\" start += self._size stop += self._size if start==stop: return self._default res_left = res_right = self._default while start \u003c stop: if start \u0026 1: res_left = self._func(res_left, self.data[start]) start += 1 if stop \u0026 1: stop -= 1 res_right = self._func(self.data[stop], res_right) start \u003e\u003e= 1 stop \u003e\u003e= 1 return self._func(res_left, res_right) def __repr__(self): return \"SegmentTree({0})\".format(self.data) Метод build_tree строит дерево отрезков, а query позволяет выполнять операции запроса.\nРесурсы https://ru.algorithmica.org/cs/segment-tree/ ","description":"Дерево отрезков","title":"Дерево отрезков","uri":"/ru/tracks/algorithms-101/data-structures/segment-tree/"},{"content":"Дерево Фенвика, также известное как двоичное индексированное дерево (Binary Indexed Tree, BIT).\nТерминология:\na - исходный массив tree - массив дерева, полученный в результате преобразований массива 'a' i - индекс массива k - индекс массива F(i) - еще не определенный индекс, полученный в реузльтате преобразования индекса `i`. F(i) \u003c= i F(i) - функция, которую создадим позже. 0 1 2 3 4 5 6 7 a[ 5, 7, 9, 3, 8, 2, 4, 6] Сумма по текущему индексу содержит данные только с предыдущих индексов, не обязательно с нулевого.\nВ каждой ячейке реузльтируещего массива хранится сумма ячеек отрезка k. k- не константное число и может меняться.\nТ.е. в одной ячейке может храниться сумма за предудущий отрезок длинною 2 символа, а в другой ячейке за отрезок длиною 5 символов.\nПо вертикали — индексы массива a\nПо горизонтали — индексы массива tree\n($T_i$ является суммой элементов массива a, индексы которых заштрихованы), по вертикали — индексы массива a\nВ данном примере в tree[1] хранится сумма элементов на отрезве a[0:2] . 2 - потому что последний элемент по индексу не включается.\ntree[9] = sum(a[8:10]) tree[7] = sum(a[0:8]) На данном этапе получаем структуру дерева вида: tree[i] = sum(a[F(i):i+1]). Примечание: i+1 - чтобы захватить последний элемент по индексу.\nЕсли мы рассчитаем такое F(i) и умеем считать сумму на префиксе, то сможем находить сумму любого подотрезка за O(logn).\nКак формируется массив дерева | youtube\nПодсчет префиксных сумм:\ndef prefix_sum(k): result = 0 i = k while i \u003e= 0: result += tree[i] i = F(i) - 1 Ресурсы https://www.youtube.com/watch?v=BzFN9YwR-NM Дерево Фенвика | wiki ","description":"Дерево Фенвика","title":"Дерево Фенвика","uri":"/ru/tracks/algorithms-101/data-structures/fenwick-tree/"},{"content":"Загрузка кода Если вы знакомы с сайтом git, вы можете скачать код для данной codelab с GitHub, клонировав его: git clone https://github.com/googlecodelabs/webrtc-web\nМожно также нажать на ссылку ниже для загрузки zip-файла кода: https://github.com/googlecodelabs/webrtc-web/archive/master.zip\nОткройте загруженный zip-файл. Разархивируйте папку проекта (adaptive-web-media), в которой по одной папке на каждый шаг этой codelab, и есть все необходимые вам ресурсы. Вы будете выполнять все действия в папке work.\nПапки step-nn содержат финальную версию для каждого шага этой codelab. Они там для справки.\nУстановите и проверьте веб-сервер Несмотря на то, что вы можете использовать и свой собственный веб-сервер, эта codelab подразумевает работу с веб-сервером Chrome. Если у вас он еще не установлен, вы можете инсталлировать его из Chrome Web Store https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en\nПосле установки приложения Web Server для Chrome, нажмите на ярлык Chrome Apps на панели закладок, на странице новой вкладки или в панели запуска приложений:\nНажмите на значок Web Server\nДалее вы увидите это диалоговое окно, которое позволит настроить локальный веб-сервер:\nНажмите на кнопку «Choose Folder», и выберите папку work, которую вы только что создали. Это позволит вам просматривать текущую работу в Chrome по ссылке URL, подчеркнутой в диалоговом окне в разделе Web Server URL(s). Ниже, в Options, поставьте флажок в Automatically show index.html, как показано ниже:\nЗатем остановите и перезапустите сервер, сдвинув флажок с надписью «Web Server: STARTED» влево, а затем снова вправо.\nТеперь посетите свой рабочий сайт в браузере, кликнув на выделенный Web Server URL. Вы должны увидеть подобную страницу, которая соответствует пути work/index.html:\nОчевидно, что данное приложение пока еще не делает ничего интересного – пока это просто минимальный скелет, который нужен для того, чтоб убедиться, что веб-сервер работает, как надо. На следующих этапах мы добавим функциональности в этом приложение.\nС этого момента все тестирование и проверка должны выполняться с использованием этой настройки веб-сервера. Обычно достаточно просто обновить вкладку тестового браузера.\n","description":"Карманная книга по WebRTC","title":"Загрузка кода","uri":"/ru/tracks/webrtc/practice/practice-get-code/"},{"content":"Статистика - показатели по Израилю\n","description":"Заметки по Израилю","title":"Заметки по Израилю","uri":"/ru/tracks/disser/israel-notes/"},{"content":"Замыкание в Python - это функция, которая запоминает значения из внешней области видимости, даже если эта область видимости больше не существует. Таким образом, замыкание позволяет функции использовать переменные, которые были определены вне самой функции.\nПример:\ndef outer_func(x): def inner_func(y): return x + y return inner_func closure = outer_func(10) result = closure(5) print(result) # выводит 15 В этом примере outer_func возвращает inner_func, которая запоминает значение x. Затем outer_func вызывается, и возвращаемая функция сохраняется в closure. Затем closure вызывается с аргументом 5, и она использует сохраненное значение x (которое равно 10), чтобы вернуть результат 15.\nЗамыкания могут быть полезны для создания функций, которые сохраняют состояние между вызовами, а также для создания функций, которые могут быть адаптированы к различным сценариям использования, например для создания функций, которые возвращают другие функции в зависимости от переданных аргументов.\nНиже приведен другой пример замыкания, который возвращает функцию, которая будет умножать аргумент на заданное число:\ndef multiply_by(num): def multiplier(n): return n * num return multiplier double = multiply_by(2) triple = multiply_by(3) print(double(5)) # выводит 10 print(triple(5)) # выводит 15 В этом примере multiply_by возвращает функцию multiplier, которая запоминает значение num. Затем мы вызываем multiply_by два раза с аргументами 2 и 3 соответственно, и сохраняем возвращаемые функции в переменных double и triple.\nЗатем мы вызываем каждую из этих функций с аргументом 5, и каждая функция использует сохраненное значение num (которое равно 2 для double и 3 для triple) для умножения аргумента и возврата результата.\n","description":"Python 101","title":"Замыкания","uri":"/ru/tracks/python-101/enhance_python/closure/"},{"content":"Захват мультимедиа и ограничения Мультимедиа-часть WebRTC показывает, как получить доступ к оборудованию, способному записывать видео и аудио (например, камеры и микрофоны), а также как работают медиа-потоки. И помимо этого – средства отображения, которые позволяют делать захват экрана.\nМультимедиа-устройства Все камеры и микрофоны, поддерживаемые браузером, доступны и управляются через объект navigator.mediaDevices. Приложения могут получать текущий список подсоединенных устройств и отслеживать изменения, т.к. многие камеры и микрофоны подсоединены через USB, и могут подключаться/отключаться в течение работы приложения. Поскольку статус мультимедиа-устройства может меняться в любой момент времени, рекомендуем, чтоб приложения регистрировали все изменения в статусе устройства для правильной обработки статусов изменений.\nОграничения При получении доступа к мультимедиа-устройствам, хорошо бы обеспечить настолько подробные ограничения, насколько это возможно. И хотя можно открыть камеру и микрофон по умолчанию с простым ограничением, это может привести к тому, что медиапоток будет далеко не самым оптимальным для приложения.\nКонкретные ограничения определяются в объекте MediaTrackConstraint (одно для аудио, одно для видео). Атрибуты в этом объекте типа ConstraintLong, ConstraintBoolean, ConstraintDouble или ConstraintDOMString. Данные могут быть как конкретным значением (например, число, Boolean или String), диапазоном (LongRange или DoubleRange с минимальным и максимальным значением) или объектом c ideal или exact определением. Для конкретных значений браузер будет пытаться выбрать что-то наиболее близкое. Для диапазонных будет использоваться лучшее значение из диапазона. Для exact – будет передаваться только тот медиа-поток, который точно соответствует заданным ограничениям.\nNEAR // Camera with a resolution as close to 640x480 as possible { \"video\": { \"width\": 640, \"height\": 480 } } RANGE // Camera with a resolution in the range 640x480 to 1024x768 { \"video\": { \"width\": { \"min\": 640, \"max\": 1024 }, \"height\": { \"min\": 480, \"max\": 768 } } } EXACT // Camera with the exact resolution of 1024x768 { \"video\": { \"width\": { \"exact\": 1024 }, \"height\": { \"exact\": 768 } } } Чтобы определить актуальную конфигурацию конкретной дорожки медиа-потока, мы можем воспользоваться запросом MediaStreamTrack.getSettings(), который возвращает набор настроек MediaTrackSettings, используемых в данные момент.\nТакже можно обновить ограничения дорожки с мультимедиа-устройства, которое открываем через applyConstraints(). Это позволяет приложению перенастроить устройство без прерывания текущего потока.\nЗахват экрана Приложение, которое потенциально может выполнять захват и запись экрана, должно использовать Display Media API. Функция getDisplayMedia() (которая является частью navigator.mediaDevices), аналогична getUserMedia() и используется, чтобы открыть содержимое дисплея (или его части, например, окна). Возвращенный MediaStream работает также, как при использовании getUserMedia().\nОграничения для getDisplayMedia() отличаются от ограничений, используемых для обычных входящих видео- и аудио-потоков.\n{ video: { cursor: ‘always’ | ‘motion’ | ‘never’, displaySurface: ‘application’ | ‘browser’ | ‘monitor’ | ‘window’ } } Фрагмент кода выше показывает, как работают специальные ограничения для записи экрана. Обратите внимание, что они могут не поддерживаться некоторыми браузерами, поддерживающими отображение мультимедиа.\nПотоки и дорожки MediaStream представляет собой поток медиаконтента, который состоит из аудио- и видео- дорожек (MediaStreamTrack). Можно достать все дорожки из MediaStream, вызвав команду MediaStream.getTracks(), которая возвращает массив объектов из MediaStreamTrack.\nMediaStreamTrack MediaStreamTrack обладает свойством kind (audio или video, указывающий тип мультимедиа, который он воспроизводит). Каждую дорожку можно выключить, переключив ее свойство enabled. У дорожки есть логическое свойство remote, которое показывает, является ли она источником RTCPeerConnection и идет ли она от удаленного узла.\n","description":"Карманная книга по WebRTC","title":"Захват мультимедиа и ограничения","uri":"/ru/tracks/webrtc/media-capture-and-constraints/"},{"content":"Маршрут\n","description":"Израиль - Хайфа - Бахайские сады","title":"Израиль - Хайфа - Бахайские сады","uri":"/ru/posts/photos/22-07-02-israel-haifa-bahai-gardens/"},{"content":"Python поставляется с большим количеством готового кода. Эти части кода известны как модули и пакеты.\nМодуль - это один импортируемый файл Python, а пакет состоит из двух или более модулей. Пакет может быть импортирован так же, как и модуль.\nВ Python вы можете импортировать модули из других файлов, чтобы использовать функции и переменные, определенные в этих модулях.\nimport Python предоставляет ключевое слово import для импорта модулей.\nДопустим, у нас есть два файла:\nФайл dog.py, содержащий следующий код:\ndef bark(): print('Гав-гав!') Файл main.py, в котором мы хотим использовать функцию bark из dog.py:\nimport dog dog.bark() Мы импортируем модуль dog в main.py с помощью оператора import и затем можем вызывать функцию bark() через точку и имя модуля.\nfrom X import Y Мы также можем импортировать определенные функции или переменные из модуля с помощью оператора from.\nДопустим, у нас есть файл math.py, содержащий функцию square, которая возводит число в квадрат:\ndef square(x): return x ** 2 В файле main.py мы можем импортировать только функцию square из math.py:\nfrom math import square result = square(5) print(result) Мы можем использовать square, как будто она была определена в main.py, и не нужно вызывать ее через точку и имя модуля.\nОбратите внимание, что если мы попытаемся вызвать какую-то другую функцию из math.py, которая не была импортирована, мы получим ошибку:\nfrom math import square # Ошибка: name 'add' is not defined result = add(5, 6) import * В Python можно импортировать все функции из модуля одной командой. Для этого используется символ звездочки (*).\nВот пример:\nfrom math import * Эта команда импортирует все функции и константы из модуля math, и мы можем использовать их в нашем коде без префикса math.\nОднако, такой подход не рекомендуется, так как может привести к конфликту имен и ухудшить читаемость кода. Вместо этого, лучше явно указывать, какие функции и константы нужны для нашей программы.\nМодуль csv Модуль configparser Логирование Модуль sys Модуль os Модуль email / smtplib Модуль sqlite Модуль subprocess Модуль потоков Thread Модуль asyncio\n","description":"Python 101","title":"Импорт модулей","uri":"/ru/tracks/python-101/basis/imports/"},{"content":"Чему вы научитесь\nкак обмениваться данными между узлами WebRTC Полная версия этого шага находится в папке step-03.\nОбновите свой HTML\nНа этом шаге вы будете использовать WebRTC каналы данных для отправки текста между двумя textarea элементами на одной странице. Это опять не сильно применимо на практике, но зато демонстрирует, как WebRTC можно использовать для обмена данными, а также для потоковых видео.\nУдалите элементы video и button из index.html и замените их следующим HTML-кодом:\n\u003ctextarea id=\"dataChannelSend\" disabled placeholder=\"Press Start, enter some text, then press Send.\"\u003e\u003c/textarea\u003e \u003ctextarea id=\"dataChannelReceive\" disabled\u003e\u003c/textarea\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"sendButton\"\u003eSend\u003c/button\u003e \u003cbutton id=\"closeButton\"\u003eStop\u003c/button\u003e \u003c/div\u003e Одна текстовая область будет предназначена для ввода текста, другая будет отображать текст в потоковом режиме между узлами. Теперь index.html должен выглядеть так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003ctextarea id=\"dataChannelSend\" disabled placeholder=\"Press Start, enter some text, then press Send.\"\u003e\u003c/textarea\u003e \u003ctextarea id=\"dataChannelReceive\" disabled\u003e\u003c/textarea\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"sendButton\"\u003eSend\u003c/button\u003e \u003cbutton id=\"closeButton\"\u003eStop\u003c/button\u003e \u003c/div\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Обновите свой JavaScript\nЗамените main.js содержимым из step-03/js/main.js.\nКак и на предыдущем шаге, делать копи-паст на больших кусках кода – не идеальный вариант развития событий в codelab (как и с RTCPeerConnection). Но альтернатив у нас нет.\nПротестируйте потоковые данные между узлами: откройте index.html, нажмите Start для установки соединения между узлами, введите какой-то текст в textarea слева, затем нажмите на Send, чтобы передать текст через каналы данных WebRTC.\nКак это работает Этот код использует RTCPeerConnection и RTCDataChannel для обмена текстовыми сообщениями Большая часть кода на этом шаге такая же, как и в примере RTCPeerConnection. Функции sendData() и createConnection() содержат большую часть нового кода:\nfunction createConnection() { dataChannelSend.placeholder = ''; var servers = null; pcConstraint = null; dataConstraint = null; trace('Using SCTP based data channels'); // For SCTP, reliable and ordered delivery is true by default. // Add localConnection to global scope to make it visible // from the browser console. window.localConnection = localConnection = new RTCPeerConnection(servers, pcConstraint); trace('Created local peer connection object localConnection'); sendChannel = localConnection.createDataChannel('sendDataChannel', dataConstraint); trace('Created send data channel'); localConnection.onicecandidate = iceCallback1; sendChannel.onopen = onSendChannelStateChange; sendChannel.onclose = onSendChannelStateChange; // Add remoteConnection to global scope to make it visible // from the browser console. window.remoteConnection = remoteConnection = new RTCPeerConnection(servers, pcConstraint); trace('Created remote peer connection object remoteConnection'); remoteConnection.onicecandidate = iceCallback2; remoteConnection.ondatachannel = receiveChannelCallback; localConnection.createOffer().then( gotDescription1, onCreateSessionDescriptionError ); startButton.disabled = true; closeButton.disabled = false; } function sendData() { var data = dataChannelSend.value; sendChannel.send(data); trace('Sent Data: ' + data); } Синтаксис в RTCDataChannel намеренно похож на WebSocket, с методом send() событием message.\nОбратите внимание на использование dataConstraint. Каналы передачи данных могут быть настроены для обеспечения различных типов обмена данными — например, отправляемые данные могут быть в приоритете над над производительностью. Более подробную информацию о возможностях можно найти на https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/createDataChannel .\nТри типа ограничений Это сбивает с толку!\nРазличные типы параметров настройки вызовов WebRTC часто называются «ограничениями».\nУзнайте больше об ограничениях и возможностях:\nRTCPeerConnection https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/RTCPeerConnection RTCDataChannel https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/createDataChannel getUserMedia() https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia Бонусные задания\nс SCTP-протоколом, используемым каналами передачи данных WebRTC, надежная и упорядоченная доставка данных включена по умолчанию. Когда может понадобиться RTCDataChannel для обеспечения надежной доставки даных, а когда производительность может быть важнее – даже если это означает потерю каких-то данных? Используйте CSS для улучшения макета страницы и добавьте атрибут placeholder в текстовую область dataChannelReceive. Протестируйте страницу на мобильном устройстве. Что вы узнали? На этом шаге вы узнали, как\nустанавливать соединение между двумя узлами WebRTC обмениваться текстовыми данными между узлами Полная версия этого шага находится в папке step-03.\nУзнайте больше\nКаналы передачи данных WebRTC (написано пару лет назад, но все еще стоит прочитать) - http://www.html5rocks.com/en/tutorials/webrtc/datachannels/ Почему SCTP был выбран для канала передачи данных WebRTC? - https://bloggeek.me/sctp-data-channel/ Следующий шаг Вы узнали, как обмениваться данными между узлами на одной и той же странице, но как вы собираетесь это делать между разными устройствами? Сначала вам необходимо настроить сигналинг-канал для обмена сообщениями метаданных. Как – узнайте на следующем шаге!\n","description":"Карманная книга по WebRTC","title":"Использование RTCDataChannel для обмена данными","uri":"/ru/tracks/webrtc/practice/practice-rtcdatachannel-exchange-data/"},{"content":"os.rename Если имеется весь путь до пути файла:\nold_source = '/Users/r/Desktop/old_source.txt' new_source = '/Users/r/Desktop/new_source.txt' os.rename(\"old_source\", \"new_source\") Если имеется только имя файла, воспользуемся os.path.splitext(), который возвращает кортеж из имени файла и расширения:\nimport os for file in os.listdir(): name, ext = os.path.splitext(file) # return ('путь до файла без расщирения', '.txt') new_name = f\"{name}_new{ext}\" os.rename(file, new_name) pathlib С помощью встроенного модуля pathlib\nPath.rename(new_name) from pathlib import Path for file in os.listdir(): f = Path(file) new_name = f\"{f.stem}_new{f.suffix}\" f.rename(new_name) shutil.move Модуль Shutil предлагает ряд высокоуровневых операций с файлами и коллекциями файлов. В частности, предусмотрены функции, поддерживающие копирование и удаление файлов.\nimport shutil old_source = '/Users/r/Desktop/old_source.txt' new_source = '/Users/r/Desktop/new_source.txt' newFileName = shutil.move(old_source, new_source) print(\"Новый файл:\", newFileName) # Новый файл: /Users/r/Desktop/new_source.txt ","description":"Различные способы переименовывания файлов в Python","title":"Как переименовать файлы в Python","uri":"/ru/posts/howto-rename-files-in-python/"},{"content":"Hugo предлагает подключение различных JS библиотек в проект. Такие изменения влекут за собой полное обновление проекта. Сегодня мы подключим компонент react без внесения больших изменений.\nReact - это библиотека. Чтобы она заработала на сайте, необходимо ее подклчюить, а далее воспользоваться внутренними функциями.\nПодключить можно двумя способоами. С помощью подгрузки скрипта с CDN или загрузки пакета в package.json, чтопозволит использовать .jsx\npackage.json План:\nИмпорт пакета в package.json Создание .jsx скрипта Загрузка/build пакета в Hugo Импорт В корне проекта запускаем команду\nnpm i react react-dom Создание jsx скрипта В папке с темой assets создадим файл my-react-script.jsx import React from 'react'; import * as ReactDOM from 'react-dom'; import { createRoot } from 'react-dom/client'; const App = () =\u003e { function sayHello () { alert('Hello, World!') } return ( \u003cbutton onClick={sayHello}\u003eClick me!\u003c/button\u003e ) } ReactDOM.render( React.createElement(App, null), document.getElementById('root') ) const container = document.getElementById('my_render_block'); const root = createRoot(container); root.render(\u003cApp /\u003e); Добавим блок div в место в шаблоне для отрисовки react приложения \u003cdiv id=\"my_render_block\"\u003e\u003c/div\u003e Подключение в HUGO В файле head.html или другом файте шаблона Hugo импортируем скрипт\n{{ with resources.Get \"my-react-script.jsx\" }} {{ $options := dict \"defines\" (dict \"process.env.NODE_ENV\" \"\\\"development\\\"\" \"process.env.BaseURL\" (printf `\"%s\"` $.Site.BaseURL)) }} {{ $script := . | js.Build $options }} \u003cscript src=\"{{ $script.RelPermalink }}\" defer\u003e\u003c/script\u003e {{ end }} CDN Второй способ\nПодключение библиотеки React В проекте Hugo в шаблонах обновим файл head.html. В моем проекте это шаблон, который содержит основные теги html и head. Открываем layouts/partials/head.html и добавляем скрипт в раздел \u003chead\u003e:\n\u003c!-- ... \u003chead\u003e ... --\u003e \u003c!-- Примечание: при деплое на продакшен замените «development.js» на «production.min.js» --\u003e \u003cscript src=\"https://unpkg.com/react@17/umd/react.development.js\" crossorigin\u003e\u003c/script\u003e \u003cscript src=\"https://unpkg.com/react-dom@17/umd/react-dom.development.js\" crossorigin\u003e\u003c/script\u003e \u003c!-- ... \u003c/head\u003e ... --\u003e Выбор места для отрисовки компонента Создадим div блок в любом шаблоне Hugo, где будем отрисоывать React компонент. Например файл layouts/partials/footer.html\n\u003cdiv id=\"my_react_app\"\u003e\u003c/div\u003e React будет искать данный блок и отрисует внутри него компонент\nСоздание компонента Вынесем создание компонента в отдельный js файл. В Hugo есть директория static в корне проекта. Если нету, то можно создать. Подробнее о static folder\nСоздадим файл static/js/my_react_component.js и запишем код:\nВажно: сркипт должен подключиться в проекте после блока \u003cdiv id=\"my_react_app\"\u003e\u003c/div\u003e\nconst e = React.createElement; const MyCountButton = () =\u003e { const [count, setCount] = React.useState(100); return e( 'button', { onClick: () =\u003e setCount(count + 1) }, count ); } // Выведем на экран компонент // ищем блок my_react_app и отрисовываем внутри него компонент ReactDOM.render(React.createElement(MyCountButton), document.getElementById(\"my_react_app\")); Подключение скрипта с React компонентами Так как скрипт будет искать div “my_react_app”, данный div блок должен быть загружен до исполнения скрипта. Поэтому в файле layouts/partials/footer.html добавляем скрипт в конец раздела \u003cbody\u003e:\nПример Нажми на счетчик: 100\n","description":"Подключение react компонентов в hugo проект","title":"Как подключить React .jsx в проект на Hugo","uri":"/ru/posts/integrate-hugo-react/"},{"content":"В JavaScript объекты копируются по ссылке. Это означает, что фактически две(или более) ссылок ссылается на один объект Для глубокого клонирования мы можем воспользоваться рекурсией\nВоспользуемся методом Object.assign() и возьмем пустой объект ({}), чтобы создать клон оригинального объекта. Используем Object.keys() и Array.prototype.forEach() для определения ключей-значений, которые нужно полностью клонировать (не ссылаться на них).\nconst deepClone = obj =\u003e { let clone = Object.assign({}, obj); Object.keys(clone).forEach( key =\u003e (clone[key] = typeof obj[key] === 'object' ? deepClone(obj[key]) : obj[key]) ); return Array.isArray(obj) \u0026\u0026 obj.length ? (clone.length = obj.length) \u0026\u0026 Array.from(clone) : Array.isArray(obj) ? Array.from(obj) : clone; }; const a = { foo: 'bar', obj: { a: 1, b: 2 } }; const b = deepClone(a); // a !== b, a.obj !== b.obj ","description":"Как сделать глубокое клонирование объекта в JavaScript","title":"Как сделать глубокое клонирование объекта в JavaScript","uri":"/ru/posts/howto-create-deepclone-js/"},{"content":"Пользователя можно перенаправлять с одной веб-страницы на любую другую несколькими способами.\nс помощью обновления мета-данных HTML. Перенаправления на стороне сервера. Например, используя файл .htaccess, PHP с помощью перенаправления на стороне клиента через JavaScript. Для перенаправления на другой URL с помощью JavaScript используем window.location.href или window.location.replace(). Передать второй аргумент, чтобы произвести клик по ссылке (true - по умолчанию) или перенаправление по HTTP (false).\nJavaScript функции Логика const newUrl = 'https://www.google.com/'; window.location.href = newUrl; // 1 window.location.replace(newUrl); // 2 window.location.assign(newUrl) // 3 Пример функции const redirect = (url, asLink = true) =\u003e asLink ? (window.location.href = url) : window.location.replace(url); JavaScript в html \u003chtml\u003e \u003chead\u003e \u003cscript\u003e const newUrl = 'https://www.google.com/'; window.location.href = newUrl; \u003c/script\u003e \u003c!--...--\u003e redirect('https://google.com'); метатег HTML \u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"refresh\" content=\"0; url=https://example.com/newlocation\" /\u003e \u003c/head\u003e \u003c/html\u003e После того как загрузится ткущая страница, браузер перенаправит на новую страницу, ожидая при этом 0 content=\"0 секунд.\nЧтобы выполнялась отложенная переадресация, укажите нужное количество секунд в атрибуте content:\n\u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"refresh\" content=\"10; url=https://example.com/newlocation\" /\u003e \u003c/head\u003e \u003c/html\u003e ","description":"Как сделать редирект на другой URL в JavaScript","title":"Как сделать редирект на другой URL в JavaScript","uri":"/ru/posts/howto-redirect-to-url/"},{"content":"Стандарт WebRTC также охватывает API для отправки произвольных данных через RTCPeerConnection. Это происходит через запрос createDataChannel() для объекта RTCPeerConnection, который возвращает объект RTCDataChannel.\nconst peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel();\nУдаленный узел может получать каналы данных через отслеживание события datachannel в объекте RTCPeerConnection. Полученное событие имеет тип RTCDataChannelEvent и содержит свойство channel, которое представляет RTCDataChannel между двумя узлами.\nconst peerConnection = new RTCPeerConnection(configuration); peerConnection.addEventListener('datachannel', event =\u003e { const dataChannel = event.channel; }); События Open и Close Прежде чем канал данных можно будет использовать для отправки данных, клиент должен дождаться его открытия. Это происходит через прослушивание события open. Точно так же существует событие close, когда одна из сторон закрывает канал.\nconst messageBox = document.querySelector('#messageBox'); const sendButton = document.querySelector('#sendButton'); const peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel(); // Enable textarea and button when opened dataChannel.addEventListener('open', event =\u003e { messageBox.disabled = false; messageBox.focus(); sendButton.disabled = false; }); // Disable input when closed dataChannel.addEventListener('close', event =\u003e { messageBox.disabled = false; sendButton.disabled = false; }); Сообщения Отправка сообщения в RTCDataChannel выполняется через вызов функции send() с данными, которые мы хотим отправить. Параметр data для этой функции может быть типа String, Blob, ArrayBuffer или ArrayBufferView.\nconst messageBox = document.querySelector('#messageBox'); const sendButton = document.querySelector('#sendButton'); // Send a simple text message when we click the button sendButton.addEventListener('click', event =\u003e { const message = messageBox.textContent; dataChannel.send(message); }) Удаленный узел будет получать сообщения, отправленные на RTCDataChannel, через отслеживание события message.\nconst incomingMessages = document.querySelector('#incomingMessages'); const peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel(); // Append new messages to the box of incoming messages dataChannel.addEventListener('message', event =\u003e { const message = event.data; incomingMessages.textContent += message + '\\n'; }); ","description":"Карманная книга по WebRTC","title":"Каналы данных","uri":"/ru/tracks/webrtc/data-channels/"},{"content":"Все в Python является объектом. Это означает, что каждая сущность в Python имеет методы и значения. Причина в том, что в основе всего лежит класс.\n\u003e\u003e\u003e x = \"Some String\" \u003e\u003e\u003e dir(x) ['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] Здесь у нас есть строка, присвоенная переменной x. Может показаться, что это не так много, но у этой строки есть много методов. Если вы используете ключевое слово dir в Python, то сможете получить список всех методов, которые можно вызвать для вашей строки.\nТехнически мы не должны напрямую вызывать методы, начинающиеся с символов подчеркивания, но их можно вызвать.\nЭто значит, что строка основана на классе, а x- это экземпляр этого класса!\nВ Python мы можем создавать свои собственные классы.\nСоздание класса Создать класс в Python очень просто. Вот очень простой пример:\nclass MyClass: my_attribute = 42 def my_method(self): print(\"Hello, world!\") Здесь мы создали класс MyClass, который имеет атрибут my_attribute со значением 42 и метод my_method, который просто выводит сообщение в консоль.\nАтрибуты класса могут быть доступны как через экземпляр класса, так и напрямую через класс:\nprint(MyClass.my_attribute) # 42 my_object = MyClass() print(my_object.my_attribute) # 42 Методы класса принимают в качестве первого аргумента экземпляр класса (self) и могут иметь доступ к атрибутам класса и вызывать другие методы класса:\nclass MyClass: my_attribute = 42 def my_method(self): print(self.my_attribute) def my_other_method(self): self.my_method() Здесь мы добавили метод my_other_method, который просто вызывает метод my_method.\nВ Python существуют специальные методы, которые определяются с помощью двойного подчеркивания в начале и в конце названия метода. Например, метод __init__ используется для инициализации экземпляра класса при его создании (конструкторы):\nclass MyClass: def __init__(self, name): self.name = name def say_hello(self): print(\"Hello, \" + self.name + \"!\") Здесь мы определили метод __init__, который принимает аргумент name и сохраняет его в атрибуте name. Метод say_hello использует этот атрибут для вывода сообщения.\nКлассы могут наследовать друг от друга, позволяя переопределять и расширять функциональность базового класса. Для этого используется ключевое слово super:\nЧто такое self? Классы Python нуждаются в способе обращения к самим себе. Это не какое-то самовлюбленное созерцание класса. Напротив, это способ отличить один экземпляр от другого.\nСлово self - это способ самоописания любого объекта, в буквальном смысле.\nclass Person: def __init__(self, name, age): self.name = name self.age = age def introduce(self): print(\"My name is {} and I'm {} years old.\".format(self.name, self.age)) person1 = Person(\"Alice\", 25) person1.introduce() Здесь self.name и self.age представляют атрибуты объекта Person, который вызывает метод introduce. Без использования self мы не могли бы получить доступ к атрибутам объекта из метода.\nНаследование Наследование - это механизм, который позволяет создавать новый класс на основе уже существующего, наследуя его свойства и методы. Класс, от которого наследуется новый класс, называется родительским классом, а новый класс - дочерним классом.\nДочерний класс может использовать свойства и методы родительского класса, а также добавлять свои собственные свойства и методы. Это позволяет создавать более сложные иерархии классов, где дочерние классы наследуют общие свойства и методы от родительского класса, но могут быть уникальными в других отношениях.\nclass Animal: def __init__(self, name, species): self.name = name self.species = species def speak(self): print(\"I am an animal.\") class Dog(Animal): def __init__(self, name, breed): super().__init__(name, species=\"Canis\") self.breed = breed def speak(self): print(\"Woof!\") class Cat(Animal): def __init__(self, name, color): super().__init__(name, species=\"Felis\") self.color = color def speak(self): print(\"Meow!\") dog = Dog(\"Buddy\", \"Golden Retriever\") cat = Cat(\"Luna\", \"Black\") print(dog.name) # Output: Buddy print(dog.breed) # Output: Golden Retriever dog.speak() # Output: Woof! print(cat.name) # Output: Luna print(cat.color) # Output: Black cat.speak() # Output: Meow! В этом примере класс Animal является родительским классом для классов Dog и Cat.\nКласс Dog наследует свойства name и species от класса Animal и добавляет свой собственный атрибут breed.\nКласс Cat также наследует свойства name и species от класса Animal и добавляет свой собственный атрибут color.\nУ каждого класса есть свой метод speak, который переопределяет метод speak родительского класса Animal. Когда вызывается метод speak для экземпляра класса Dog, выводится строка “Woof!”, а когда вызывается для экземпляра класса Cat, выводится строка “Meow!”. (Полиморфизм)\nРесурсы:\nhttps://vegibit.com/python-abstract-base-classes/ ","description":"Python 101","title":"Классы","uri":"/ru/tracks/python-101/basis/classes/"},{"content":"Кортежи в Python - это неизменяемые последовательности элементов, очень похожие на списки.\nСоздание Создаются с использованием круглых скобок и могут содержать любые типы данных, в том числе и другие кортежи.\nСоздание кортежей очень похоже на создание списков, только используются круглые скобки вместо квадратных скобок. Например:\nt = (1, 2, 3) another_tuple = tuple() abc = tuple([4, 5, 6]) Мы создали кортеж t, содержащий три элемента. Теперь мы можем обратиться к каждому элементу этого кортежа по его индексу, так же как и в списках:\nprint(t[0]) # выведет 1 print(t[1]) # выведет 2 print(t[2]) # выведет 3 Кортежи также могут содержать элементы разных типов данных:\nt = (\"apple\", 42, True) Как и в списках, мы можем использовать отрицательные индексы для обращения к элементам кортежа с конца:\nprint(t[-1]) # выведет True Кортежи поддерживают срезы (slicing). Например, мы можем получить подкортеж, состоящий из элементов с индексами от 1 до 2:\nprint(t[1:3]) # выведет (42, True) Методы Кортежи имеют ряд методов, которые позволяют производить некоторые операции с ними. Однако, поскольку они неизменяемы, многие методы, доступные для списков, недоступны для кортежей. Вот несколько примеров доступных методов:\ncount(x) - возвращает количество элементов в кортеже, равных x. index(x) - возвращает индекс первого элемента в кортеже, равного x. Например, мы можем использовать метод count() для подсчета количества элементов “apple” в кортеже:\nt = (\"apple\", 42, True, \"apple\", \"banana\") print(t.count(\"apple\")) # выведет 2 Или мы можем использовать метод index() для поиска индекса первого вхождения элемента “banana” в кортеже:\nt = (\"apple\", 42, True, \"apple\", \"banana\") print(t.index(\"banana\")) # выведет 4 Применение Кортежи могут быть очень полезны, когда вам нужно создать неизменяемый набор данных. Они также могут быть использованы в качестве ключей словаря, потому что они неизменяемы.\n","description":"Python 101","title":"Кортежи","uri":"/ru/tracks/python-101/basis/tuples/"},{"content":"Лямбда-функции в Python - это безымянные функции, которые можно определить в одной строке и не требуют ключевого слова def. Они используются для написания коротких функций внутри других функций или выражений, где требуется функция в качестве аргумента.\nЛямбда-функция определяется ключевым словом lambda, за которым следуют параметры функции, после чего через двоеточие указывается выражение, которое нужно вернуть из функции.\nПример:\nadd = lambda x, y: x + y print(add(2, 3)) # Output: 5 Здесь мы определяем лямбда-функцию add, которая принимает два аргумента x и y и возвращает их сумму. Затем мы вызываем эту функцию, передав ей аргументы 2 и 3, и выводим результат, который равен 5.\nЛямбда-функции могут использоваться в качестве аргументов для функций высшего порядка, таких как map, filter или reduce. Например, следующий код использует лямбда-функцию для фильтрации списка:\nnumbers = [1, 2, 3, 4, 5, 6] even_numbers = list(filter(lambda x: x % 2 == 0, numbers)) print(even_numbers) # Output: [2, 4, 6] Здесь мы используем функцию filter, чтобы отфильтровать только четные числа из списка numbers. В качестве первого аргумента передаем лямбда-функцию, которая проверяет, является ли число четным. Результат фильтрации преобразуем в список и выводим на экран.\nЛямбда-функции также могут использоваться для создания простых обработчиков событий или для задания ключей сортировки. В целом, лямбда-функции могут быть удобным инструментом для написания коротких функций на лету.\n","description":"Python 101","title":"Лямбда","uri":"/ru/tracks/python-101/enhance_python/lambda/"},{"content":"Создание Множество можно создать, используя фигурные скобки {} или функцию set():\nmy_set = {1, 2, 3} print(my_set) # {1, 2, 3} my_set = set([1, 2, 3]) print(my_set) # {1, 2, 3} Методы add(): добавляет элемент в множество. remove(): удаляет элемент из множества. Если элемента нет в множестве, возбуждается исключение. discard(): удаляет элемент из множества. Если элемента нет в множестве, ничего не происходит. union(): возвращает объединение двух множеств. intersection(): возвращает пересечение двух множеств. difference(): возвращает разность двух множеств. symmetric_difference(): возвращает симметрическую разность двух множеств. Также: 'copy', 'difference', 'difference_update', 'discard', 'intersection', 'intersection_update', 'isdisjoint', 'issubset', 'issuperset', 'pop', 'remove', 'symmetric_difference', 'symmetric_difference_update', 'union', 'update'\nmy_set = {1, 2, 3} print(my_set) # {1, 2, 3} # Добавление элемента my_set.add(4) print(my_set) # {1, 2, 3, 4} # Удаление элемента my_set.remove(2) print(my_set) # {1, 3, 4} # Объединение множеств other_set = {3, 4, 5} union_set = my_set.union(other_set) print(union_set) # {1, 3, 4, 5} # Пересечение множеств intersection_set = my_set.intersection(other_set) print(intersection_set) # {3, 4} # Разность множеств difference_set = my_set.difference(other_set) print(difference_set) # {1} # Симметрическая разность множеств symmetric_difference_set = my_set.symmetric_difference(other_set) print(symmetric_difference_set) # {1, 5} Применение Множества могут использоваться для проверки наличия элемента или для удаления дубликатов из списка:\nmy_list = [1, 2, 2, 3, 4, 4, 5] my_set = set(my_list) print(my_set) # {1, 2, 3, 4, 5} # Проверка наличия элемента if 3 in my_set: print(\"3 есть в множестве\") # Удаление дубликатов из списка my_list = list(my_set) print(my_list) # [1, 2, 3, 4, 5] Ресурсы:\nМножества в Python ","description":"Python 101","title":"Множества","uri":"/ru/tracks/python-101/basis/sets/"},{"content":"Модуль argparse позволяет легко парсить аргументы командной строки.\nЭто может быть полезно для создания сценариев командной строки, которые должны принимать аргументы от пользователя, например, при написании утилит командной строки.\nПример:\n#script.py import argparse parser = argparse.ArgumentParser(description='Process some integers.') parser.add_argument('integers', metavar='N', type=int, nargs='+', help='an integer for the accumulator') parser.add_argument('--sum', dest='accumulate', action='store_const', const=sum, default=max, help='sum the integers (default: find the max)') args = parser.parse_args() print(args.accumulate(args.integers)) В этом примере мы создали парсер аргументов командной строки с помощью argparse, который принимает целочисленные значения и может вычислить их сумму или максимальное значение. При запуске скрипта мы можем указать значения, например:\npython script.py 1 2 3 4 --sum Resources:\nargparse tutorial | python.org ","description":"Python 101","title":"Модуль argparse","uri":"/ru/tracks/python-101/standard_library/argparse/"},{"content":" Асинхронное программирование — это концепция программирования, при применении которой запуск длительных операций происходит без ожидания их завершения и не блокирует дальнейшее выполнение программы.\nКорутина — это более общая форма подпрограмм. Подпрограммы имеют одну точку входа и одну точку выхода. А корутины поддерживают множество точек входа, выхода и возобновления их выполнения.\nPython модуль asyncio позволяет заниматься асинхронным программированием с применением конкурентного выполнения кода, основанного на корутинах.\nВот план использования модуля asyncio:\nimport asyncio # Определение асинхронной функции с помощью ключевого слова async. async def my_coroutine(): # code here # Создание цикла событий loop = asyncio.get_event_loop() # Запуск сопрограммы loop.run_until_complete(my_coroutine()) # обход асинхронного итератора async for item in async_iterator: print(item) Можно использовать функцию asyncio.gather() для выполнения нескольких сопрограмм параллельно:\nasync def coroutine1(): print(\"coroutine1 start\") await asyncio.sleep(1) print(\"coroutine1 end\") async def coroutine2(): print(\"coroutine2 start\") await asyncio.sleep(2) print(\"coroutine2 end\") async def main(): await asyncio.gather(coroutine1(), coroutine2()) loop.run_until_complete(main()) В этом примере две сопрограммы coroutine1() и coroutine2() запускаются параллельно с помощью функции asyncio.gather(), которая возвращает результаты выполнения всех сопрограмм.\nРесурсы:\nруководство по модулю asyncio в Python | habr ","description":"Python 101","title":"Модуль asyncio","uri":"/ru/tracks/python-101/standard_library/asyncio/"},{"content":"Модуль configparser позволяет работать с конфигурационными файлами в Python.\nДля использования модуля configparser нужно сначала импортировать его:\nimport configparser Для чтения конфигурационного файла используется метод configparser.ConfigParser() с методом read():\nconfig = configparser.ConfigParser() config.read('config.ini') Для записи в конфигурационный файл используется метод write():\nconfig.set('section', 'option', 'value') with open('config.ini', 'w') as f: config.write(f) Пример работы с конфигурационным файлом:\nimport configparser # Создаем объект ConfigParser config = configparser.ConfigParser() # Читаем конфигурационный файл config.read('config.ini') # Получаем значение параметра из секции db_name = config.get('database', 'db_name') # Меняем значение параметра и записываем изменения в файл config.set('database', 'db_name', 'new_db_name') with open('config.ini', 'w') as f: config.write(f) Конфигурационный файл может иметь несколько секций, каждая из которых может иметь набор параметров со значениями. Например:\n[database] db_name=my_db db_user=user_name db_password=secret_password [server] host=127.0.0.1 port=8080 В данном примере есть две секции: [database] и [server]. Каждая секция содержит набор параметров со значениями.\nМодуль configparser позволяет легко работать с этими параметрами, как с обычными переменными. Например, для получения значения параметра db_name из секции database нужно выполнить следующий код:\ndb_name = config.get('database', 'db_name') Параметры в файле могут быть определены без значения, только с именем параметра. В этом случае для получения значения параметра нужно использовать метод getboolean(), getint() или getfloat() в зависимости от типа значения параметра.\n","description":"Python 101","title":"Модуль configparser","uri":"/ru/tracks/python-101/standard_library/configparser/"},{"content":"datetime Модуль datetime в Python предоставляет классы для работы с датами и временем. Он позволяет создавать объекты даты, времени и даты-времени, а также выполнять операции с этими объектами.\nКласс datetime является основным классом модуля datetime и представляет дату и время в формате “ГГГГ-ММ-ДД ЧЧ:ММ:СС”. Класс date представляет только дату, а класс time - только время.\nФорматирование дат и времени может выполняться с помощью метода strftime, который позволяет создавать строку с заданным форматом даты и времени. Также существует метод strptime, который позволяет преобразовать строку в объект даты и времени.\nДля работы со временем и датами можно использовать методы класса datetime, такие как now для получения текущей даты и времени, date и time для получения объектов даты и времени соответственно, а также методы year, month, day, hour, minute, second для получения соответствующих значений.\nКласс timedelta позволяет выполнять арифметические операции над объектами дат и времени, такие как сложение и вычитание.\nimport datetime # Создание объекта datetime now = datetime.datetime.now() print(now) # Получение объекта date today = datetime.date.today() print(today) # Получение объекта time current_time = datetime.time(hour=12, minute=30, second=0) print(current_time) # Форматирование даты и времени formatted_date = now.strftime(\"%d-%m-%Y\") print(formatted_date) # Преобразование строки в объект datetime date_string = \"2022-02-15 18:00:00\" date_object = datetime.datetime.strptime(date_string, \"%Y-%m-%d %H:%M:%S\") print(date_object) # Использование timedelta one_day = datetime.timedelta(days=1) yesterday = today - one_day print(yesterday) # Перевод даты в строку и обратно date_string = today.strftime(\"%Y-%m-%d\") date_object = datetime.datetime.strptime(date_string, \"%Y-%m-%d\") print(date_object) time Модуль time в Python предоставляет доступ к системному времени и позволяет работать с временными значениями, такими как время в секундах, часах, минутах и т.д. Этот модуль также содержит функции для задержки выполнения программы, вычисления прошедшего времени и других операций, связанных со временем.\nВот некоторые из наиболее распространенных функций time:\ntime(): возвращает текущее время в секундах, начиная с начала эпохи Unix (1 января 1970 года 00:00:00 GMT). ctime(): принимает время в секундах в качестве аргумента и возвращает строку с форматированным временем в удобочитаемом формате. sleep(): приостанавливает выполнение программы на заданное количество секунд. gmtime(): принимает время в секундах в качестве аргумента и возвращает объект структурированного времени, представленного в UTC (координированное всемирное время). localtime(): принимает время в секундах в качестве аргумента и возвращает объект структурированного времени, представленного в локальной временной зоне. strftime(): преобразует объект структурированного времени в строку с заданным форматом. import time # Получение текущего времени в секундах current_time = time.time() print(current_time) # Отображение времени в удобочитаемом формате formatted_time = time.ctime(current_time) print(formatted_time) # Приостановка выполнения программы на 5 секунд time.sleep(5) # Получение объекта структурированного времени gm_time = time.gmtime(current_time) print(gm_time) # Преобразование объекта структурированного времени в строку formatted_gm_time = time.strftime('%Y-%m-%d %H:%M:%S', gm_time) print(formatted_gm_time) ","description":"Python 101","title":"Модуль datetime/time","uri":"/ru/tracks/python-101/standard_library/datetime_time/"},{"content":"Модуль smtplib в Python предоставляет возможность отправки электронных писем через Simple Mail Transfer Protocol (SMTP).\nОн предоставляет класс SMTP, который упрощает отправку электронной почты из Python-скрипта. Модуль smtplib позволяет отправлять электронные письма, как с аутентификацией, так и без, и можно отправлять как простые текстовые сообщения, так и письма с HTML-контентом.\nВот пример кода для отправки простого текстового сообщения:\nimport smtplib smtp_server = 'smtp.yandex.ru' port = 587 login = 'example@yandex.ru' password = 'password' from_addr = 'example@yandex.ru' to_addr = 'example2@yandex.ru' message = 'Hello, world!' with smtplib.SMTP(smtp_server, port) as server: server.starttls() server.login(login, password) server.sendmail(from_addr, to_addr, message) В этом примере мы создаем объект SMTP, указывая адрес сервера и номер порта. Затем мы используем starttls(), чтобы начать безопасное соединение и login(), чтобы авторизоваться на сервере. Затем мы отправляем электронное письмо с помощью метода sendmail().\n","description":"Python 101","title":"Модуль email / smtplib","uri":"/ru/tracks/python-101/standard_library/smtplib/"},{"content":"Модуль логирования logging является одним из стандартных модулей Python и предоставляет возможности для записи логов в приложении. Логирование используется для записи информации о работе приложения, которую можно использовать для отслеживания ошибок и диагностики проблем.\nВ модуле logging определены три основных компонента: логгеры (loggers), обработчики (handlers) и форматировщики (formatters). Логгеры представляют собой объекты, которые используются для записи сообщений лога. Обработчики определяют, куда будут записываться сообщения, а форматировщики определяют, как будут отформатированы эти сообщения.\nПример использования модуля logging:\nimport logging # Создание логгера logger = logging.getLogger('example') # Установка уровня логирования logger.setLevel(logging.INFO) # Создание обработчика handler = logging.FileHandler('example.log') # Установка уровня логирования для обработчика handler.setLevel(logging.INFO) # Создание форматировщика formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') # Установка форматировщика для обработчика handler.setFormatter(formatter) # Добавление обработчика к логгеру logger.addHandler(handler) # Запись сообщений лога logger.debug('Debug message') logger.info('Info message') logger.warning('Warning message') logger.error('Error message') logger.critical('Critical message') Этот пример создает логгер example, который записывает сообщения в файл example.log. Уровень логирования установлен на уровень INFO, что означает, что будут записаны сообщения с уровнем INFO и выше. Созданный обработчик определяет, что сообщения будут записываться в файл, а форматировщик определяет, как будут отформатированы сообщения.\nМетоды debug, info, warning, error и critical используются для записи сообщений лога разного уровня. В этом примере мы записываем сообщения всех уровней, поэтому в лог-файле будут отображены все эти сообщения.\nЭто только базовый пример использования модуля logging. В реальном приложении вы можете создать несколько логгеров с разными уровнями логирования и разными обработчиками для каждого из них, в зависимости от вашей конкретной задачи.\n","description":"Python 101","title":"Модуль logging","uri":"/ru/tracks/python-101/standard_library/logging/"},{"content":"Модуль os предоставляет функции для работы с операционной системой. Этот модуль позволяет получить доступ к файловой системе, управлять процессами, получать информацию об окружении и другие.\nos.listdir - получение списка файлов и директорий в указанной директории: os.mkdir() - создание директории os.system() - выполнение команды в командной строке os.getenv() os.putenv() os.remove() - удаление файла os.rename() os.startfile() os.walk() - дает способ итерации по пути корневого уровня pathlib.Path.walk() - похожий на os.walk(). (Добавлен в 3.12) os.environ: словарь, содержащий переменные окружения, доступные в текущем процессе. Можно использовать для получения значения переменной окружения или для установки ее значения. os.getcwd(): возвращает текущую рабочую директорию. os.chdir(path): изменяет текущую рабочую директорию на указанную. os.path.join(path1, path2, …): объединяет несколько путей в один, используя правильный разделитель для операционной системы. os.path.exists(path): возвращает True, если файл или директория по указанному пути существует. os.path.isfile(path): возвращает True, если путь указывает на существующий файл. os.path.isdir(path): возвращает True, если путь указывает на существующую директорию. os.makedirs(path): создает директории (в том числе вложенные), если они не существуют. os.rmdir(path): удаляет директорию, если она пуста. import os files = os.listdir(\".\") print(f\"Files in current directory: {files}\") #['file1.txt', 'file2.txt'] os.remove(\"file.txt\") os.system(\"ls -l\") # Получение значения переменной окружения home_dir = os.environ['HOME'] # Установка значения переменной окружения os.environ['MY_VAR'] = 'my_value' # Получение текущей рабочей директории current_dir = os.getcwd() # Смена рабочей директории os.chdir('/path/to/new/dir') # Объединение нескольких путей full_path = os.path.join('/path/to', 'file.txt') # Проверка наличия файла file_exists = os.path.exists('/path/to/file.txt') # Проверка наличия директории dir_exists = os.path.isdir('/path/to/dir') # Создание директории os.makedirs('/path/to/new/dir') # Удаление директории os.rmdir('/path/to/dir') # Итерация по каталогам for root, dirs, files in os.walk(path): print(root) for _dir in dirs: print(_dir) for _file in files: print(_file) ","description":"Python 101","title":"Модуль os","uri":"/ru/tracks/python-101/standard_library/os/"},{"content":"Модуль subprocess является одним из наиболее мощных и распространенных модулей Python для управления другими процессами в операционной системе.\nОсновная цель subprocess заключается в том, чтобы предоставить простой и удобный способ создания новых процессов, подключения к уже существующим процессам, их управления и взаимодействия с ними.\nОдним из основных классов в модуле subprocess является класс Popen, который представляет собой объект, связанный с запущенным в операционной системе процессом.\nНапример, чтобы запустить новый процесс с помощью Popen, мы можем использовать следующий код:\nimport subprocess process = subprocess.Popen(['ls', '-l'], stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr = process.communicate() print(stdout.decode()) В этом примере мы создаем новый процесс, который выполняет команду ls -l в командной строке операционной системы.\nЗатем мы отправляем строку в стандартный ввод процесса, используя метод communicate(), и получаем результат его работы в переменной output.\nНаконец, мы выводим содержимое переменной output на экран.\nКроме того, модуль subprocess также предоставляет удобный способ проверки состояния завершения процессов с помощью метода poll() и ожидания их завершения с помощью метода wait().\nВ целом, модуль subprocess является очень полезным инструментом для управления процессами в операционной системе и взаимодействия с ними из Python.\n","description":"Python 101","title":"Модуль subprocess","uri":"/ru/tracks/python-101/standard_library/subprocess/"},{"content":"Модуль sys предоставляет специфические для системы параметры и функции. Он содержит системную информацию и функции для взаимодействия со стандартными потоками ввода/вывода, аргументами командной строки и другими модулями Python.\nsys.argv - список аргументов командной строки, переданных в программу при ее запуске. Первым аргументом обычно является имя файла программы.\nsys.executable - путь к интерпретатору Python, который используется для запуска текущей программы.\nsys.exit([arg]) - завершает выполнение программы. Если задан аргумент, то он возвращается в качестве кода выхода.\nsys.modules - словарь, содержащий все загруженные модули Python, включая стандартные и сторонние модули.\nsys.path - список путей поиска модулей Python. Включает директории, содержащие стандартные модули, а также директории, перечисленные в переменной окружения PYTHONPATH.\nsys.platform - строка, содержащая название операционной системы, на которой запущен Python.\nsys.stdin, sys.stdout, sys.stderr - объекты для взаимодействия со стандартными потоками ввода/вывода.\nМы можем использовать sys.argv для получения доступа к аргументам командной строки:\nimport sys # Запуск: python my_program.py arg1 arg2 print(sys.argv) # ['my_program.py', 'arg1', 'arg2'] Атрибут sys.executable может быть полезен, если требуется запустить текущую программу с другим интерпретатором Python:\nimport sys import subprocess if 'win' in sys.platform: python_executable = 'python.exe' else: python_executable = 'python' subprocess.call([python_executable, 'my_program.py']) sys.exit() используется для выхода из программы. Можно передать ей код возврата в качестве аргумента, который будет использоваться для определения статуса выхода:\nimport sys if len(sys.argv) \u003c 2: print('Please specify a file to read') sys.exit(1) filename = sys.argv[1] # Чтение файла... Мы можем использовать sys.modules для получения списка всех загруженных модулей:\nimport sys for name, module in sys.modules.items(): print(name) Константы sys.stdin, sys.stdout и sys.stderr являются стандартными потоками ввода, вывода и ошибок соответственно.\nНапример, если мы хотим написать программу, которая запрашивает у пользователя ввод и выводит результат на экран, мы можем использовать sys.stdin и sys.stdout:\nimport sys name = input(\"What is your name? \") sys.stdout.write(f\"Hello, {name}!\\n\") Здесь мы запрашиваем у пользователя ввод с помощью функции input() и выводим результат на экран с помощью sys.stdout.write().\nАналогично, мы можем перенаправить вывод в файл, например:\nimport sys with open('output.txt', 'w') as f: sys.stdout = f print('Hello, world!') Здесь мы перенаправляем стандартный вывод в файл “output.txt” с помощью операции присваивания sys.stdout = f. Далее, когда мы вызываем функцию print(), результат будет записан в файл вместо вывода на экран.\n","description":"Python 101","title":"Модуль sys","uri":"/ru/tracks/python-101/standard_library/sys/"},{"content":"Модуль threading в Python предоставляет возможность создавать и управлять потоками выполнения. Потоки - это легковесные процессы, которые выполняются параллельно в пределах одного процесса, что позволяет лучше использовать ресурсы компьютера.\nДля создания нового потока необходимо создать объект Thread и передать в его конструктор функцию, которую вы хотите запустить в отдельном потоке. Затем вызовите метод start() у этого объекта, чтобы запустить поток. Если вы хотите дождаться завершения потока, вызовите метод join(), который блокирует текущий поток, пока поток, на который вы вызываете join(), не завершится.\nПример использования модуля threading:\nfrom time import sleep import threading def print_numbers(): for i in range(10): sleep(1) # задержка печати для примера print(i) def print_letters(): for letter in ['a', 'b', 'c', 'd', 'e']: print(letter) if __name__ == '__main__': t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) t1.start() t2.start() print(\"Done!\") t1.join() t2.join() print(\"Done!\") Здесь мы создали две функции print_numbers() и print_letters(), каждая из которых печатает набор символов в консоль. Затем мы создали два потока, один для каждой из этих функций, и запустили их, вызвав метод start(). Затем мы дождались завершения каждого потока, вызвав метод join(), и напечатали сообщение “Done!”.\nВ последнем примере кода мы увидим, что каждый поток будет печатать свою информацию в консоль, в произвольном порядке, так как потоки будут конкурировать за доступ к ресурсу (в данном случае, к выводу в консоль).\nРезультат может отличаться от запуска к запуску программы, так как порядок выполнения потоков не гарантирован и зависит от того, как ОС распределяет ресурсы между потоками.\nМодуль threading также предоставляет другие полезные классы, такие как Lock, Condition, Semaphore, которые помогают управлять доступом к ресурсам между несколькими потоками.\n","description":"Python 101","title":"Модуль потоков threading","uri":"/ru/tracks/python-101/standard_library/threading/"},{"content":"Мультимедиа-устройства Начало работы с мультимедийными устройствами При web-разработке WebRTC-стандарт предоставляет API для доступа к камерам и микрофонам, подключенным к компьютеру или смартфону. Эти устройства обычно называются мультимедийными устройствами, и к ним можно получить доступ с помощью Java-скрипта через объект navigator.mediaDevices, который реализует интерфейс MediaDevices. С помощью этого объекта мы можем просмотреть все подключенные устройства, отслеживать изменения статуса устройства (когда устройство подключается или отключается) и открывать устройство для извлечения мультимедийного потока (см. ниже). Чаще всего для этого используют функцию getUserMedia(), которая возвращает промис, который будет преобразован в MediaStream для соответствующих мультимедийных устройств. Эта функция принимает один объект MediaStreamConstraints, который определяет имеющиеся требования. Например, чтобы просто открыть микрофон и камеру по умолчанию, мы должны сделать следующее:\nЧерез промисы:\nconst constraints = { 'video': true, 'audio': true } navigator.mediaDevices.getUserMedia(constraints) .then(stream =\u003e { console.log('Got MediaStream:', stream); }) .catch(error =\u003e { console.error('Error accessing media devices.', error); }); Через async/await\nconst openMediaDevices = async (constraints) =\u003e { return await navigator.mediaDevices.getUserMedia(constraints); } try { const stream = openMediaDevices({'video':true,'audio':true}); console.log('Got MediaStream:', stream); } catch(error) { console.error('Error accessing media devices.', error); } Обращение к getUserMedia() запускает запрос на разрешение. Если пользователь одобряет запрос, промис разрешает MediaStream, содержащий одну видео и одну аудио дорожку. Если запрос отклонен, появляется PermissionDeniedError. Если же нет подключенных устройств, появляется NotFoundError. Полный список API для интерфейса MediaDevices доступен по ссылке https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices\nОбращение к мультимедиа-устройствам В более сложных приложениях, мы скорее всего захотим проверить все подключенные камеры и микрофоны и дать соответствующий отчет пользователю. Это можно сделать через запрос функции enumerateDevices(). Она возвращает промис, который преобразуется в массив MediaDevicesInfo, описывающий каждое известное мультимедиа-устройство. Через него мы можем предоставить пользовательский интерфейс пользователю, который позволит выбрать те или иные устройства. Каждый список MediaDevicesInfo содержит свойства, которые называются kind с значениями audioinput, audiooutput или videoinput, отражая, какой это тип мультимедиа-устройства.\nЧерез промисы\nfunction getConnectedDevices(type, callback) { navigator.mediaDevices.enumerateDevices() .then(devices =\u003e { const filtered = devices.filter(device =\u003e device.kind === type); callback(filtered); }); } getConnectedDevices('videoinput', cameras =\u003e console.log('Cameras found', cameras)); через async/await\nasync function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } const videoCameras = getConnectedDevices('videoinput'); console.log('Cameras found:', videoCameras); Отслеживание изменений в статусах устройств Большинство компьютеров поддерживают подключение различных устройств прямо во время работы. Это может быть веб-камера, подключенная через USB, Bluetooth-гарнитура или внешние динамики. Чтобы должным образом поддерживать все это, веб-приложение должно отслеживать изменения в статусах мультимедиа-устройств. Это можно сделать, добавив «отслеживатель» в navigator.mediaDevices для события devicechange.\n// Updates the select element with the provided set of cameras function updateCameraList(cameras) { const listElement = document.querySelector(‘select#availableCameras’); listElement.innerHTML = ‘’; cameras.map(camera =\u003e { const cameraOption = document.createElement(‘option’); cameraOption.label = camera.label; cameraOption.value = camera.deviceId; }).forEach(cameraOption =\u003e listElement.add(cameraOption)); } // Fetch an array of devices of a certain type async function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } // Get the initial set of cameras connected const videoCameras = getConnectedDevices(‘videoinput’); updateCameraList(videoCameras); // Listen for changes to media devices and update the list accordingly navigator.mediaDevices.addEventListener(‘devicechange’, event =\u003e { const newCameraList = getConnectedDevices(‘video’); updateCameraList(newCameraList); }); Ограничения для мультимедиа Объект ограничений, осуществляющий интерфейс MediaStreamConstraints и который мы отправляем в качестве параметра в getUserMedia(), позволяет нам открывать мультимедиа-устройство, которое отвечает определенным требованиям. Эти требования могут быть как очень расплывчатыми (аудио и/или видео), так и очень специфичными (минимальное разрешение камеры или точный ID устройства). Рекомендуем, чтобы приложения, использующие getUserMedia() API, сначала проверяли существующие устройства, а затем определяли ограничения, которые соответствуют точному устройству через deviceID-ограничение. Устройства, по возможности, будут настроены в соответствии с ограничениями. Мы можем включить эхоподавление на микрофоне, установить определенную или минимальную ширину и высоту видео с камеры.\nasync function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } // Open camera with at least minWidth and minHeight capabilities async function openCamera(cameraId, minWidth, minHeight) { const constraints = { 'audio': {'echoCancellation': true}, 'video': { 'deviceId': cameraId, 'width': {'min': minWidth}, 'height': {'min': minHeight} } } return await navigator.mediaDevices.getUserMedia(constraints); } const cameras = getConnectedDevices('videoinput'); if (cameras \u0026\u0026 cameras.length \u003e 0) { // Open first available video camera with a resolution of 1280x720 pixels const stream = openCamera(cameras[0].deviceId, 1280, 720); } Полную документацию для интерфейса MediaStreamConstraints можно найти по ссылке: https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints\nЛокальное воспроизведение Как только мультимедиа-устройство открыто и есть доступный MediaStream, мы можем назначить его для его видео- или аудио-элемента локальное воспроизведение потока.\nasync function playVideoFromCamera() { try { const constraints = {'video': true, 'audio': true}; const stream = await navigator.mediaDevices.getUserMedia(constraints); const videoElement = document.querySelector('video#localVideo'); videoElement.srcObject = stream; } catch(error) { console.error('Error opening video camera.', error); } } Обычно код HTML, необходимый для типичного видео-элемента с getUserMedia(), имеет атрибуты autoplay и playsinline. Атрибут autoplay запускает воспроизведение новых потоков, связанных с элементом, автоматически. Атрибут playsinline позволяет проигрывать встроенное видео вместо видео на весь экран, в некоторых мобильных браузерах. Также рекомендуем использовать controls = “false” для прямых эфиров, если у пользователя нет необходимости ставить их на паузу.\n\u003chtml\u003e \u003chead\u003e\u003ctitle\u003eLocal video playback\u003c/video\u003e\u003c/head\u003e \u003cbody\u003e \u003cvideo id=\"localVideo\" autoplay playsinline controls=\"false\"/\u003e \u003c/body\u003e \u003c/html\u003e ","description":"Карманная книга по WebRTC","title":"Мультимедиа-устройства","uri":"/ru/tracks/webrtc/media-devices/"},{"content":"Проверить журнал в диссернет\nВ аннотацию прописывать предложения, которые могут быть запрошены как поисковый запрос в поисковиках. Анотации индексируются поисковиками яндекс, гугл.\nhttps://www.semanticscholar.org/ https://www.researchgate.net/ После выхода в сборнике:\nДобавить на сайт pdf из журнала Добавить в ResearchGate IMF Report: September 16, 2022: West Bank and Gaza: Report to the AD HOC Liaison Committee\nКонференции https://sciencen.org/konferencii/grafik-konferencij/ https://na-konferencii.ru/ https://konferencii.ru/ https://www.kon-ferenc.ru/econom.html https://www.hse.ru/science/HSEconf ","description":"Заметки по написанию статей","title":"Написание статей","uri":"/ru/tracks/disser/articles-notes/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nИспользовать npm для установки взаимосвязей, как указано в package.json Запускать сервер Node.js и использовать node-static для обслуживания статических файлов. Настраивать службу обмена сообщениями на Node.js через Socket.IO . Использовать это для создания ‘комнат\" и обмена сообщениями. Полная версия этого шага находится в папке step-04.\nКонцепции\nЧтобы установить и поддерживать вызов WebRTC, клиенты WebRTC (узлы) должны обмениваться метаданными:\nИнформация о кандидате (сети). сообщения offer и answer, содержащие информацию о медиа, например, о разрешении и кодеках. Другими словами, обмен метаданными требуется до P2P потоковой передачи аудио, видео или данных. Этот процесс называется сигналингом. На предыдущих этапах объекты RTCPeerConnection отправителя и получателя находились на одной странице, поэтому “сигналинг” - это просто вопрос передачи метаданных между объектами.\nВ реальном приложении отправитель и получатель RTCPeerConnections запущены на веб-страницах на разных устройствах, и вам нужен способ для обмена метаданными.\nДля этого используется signaling-server: сервер, который может передавать сообщения между клиентами WebRTC (узлами). Фактически сообщения представляют собой обычный текст: строковые объекты JavaScript.\nОбязательное условие: установить Node.js\nДля выполнения следующих шагов этой codelab (папки step-04 до step-06) вам необходимо запустить сервер на локальном хосте с помощью Node.js . Вы можете скачать и установить Node.js по этой ссылке (https://nodejs.org/en/download/) или через предпочтительный для вас менеджер пакетов (https://nodejs.org/en/download/package-manager/). После установки вы сможете импортировать зависимости, необходимые для следующих шагов (запуск npm install), а также запустить небольшой локальный сервер для выполнения codelab (запуск node index.js). Эти команды будут указаны позже, когда они потребуются.\nО приложении\nWebRTC использует клиентский JavaScript API, но для использования в реальных приложениях также требуется сигналинг-сервер (обмена сообщениями), а также серверы STUN и TURN. Вы можете узнать больше здесь - https://www.html5rocks.com/en/tutorials/webrtc/infrastructure/. На этом шаге вы создадите простой Node.js сигналинг-сервер, использующий Socket.IO Node js модуль и библиотеку JavaScript для обмена сообщениями. Опыт работы с Node.js и Socket.IO будет полезным, но не решающим; компоненты обмена сообщениями очень просты.\nВыбор правильного сигналинг-сервера В этой кодовой лаборатории используется Socket.IO для сигналинг-сервера. Дизайн Socket.IO упрощает создание службы для обмена сообщениями. и Socket.IO подходит для изучения сигналинга WebRTC благодаря встроенной концепции ‘комнат\". Однако для производственного сервиса есть альтернативы получше. Смотрите, как выбрать сигналинг-протокол для вашего следующего проекта WebRTC - https://bloggeek.me/siganling-protocol-webrtc/\nВ этом примере сервер (Node.js приложение) реализовано в index.js, и клиент, который работает на нем (веб-приложение), реализован в index.html. Node.js приложение на этом этапе имеет две задачи. Во-первых, он действует как ретранслятор сообщений:\nsocket.on('message', function (message) { log('Got message: ', message); socket.broadcast.emit('message', message); }); Во-вторых, он управляет «комнатами» видеочата WebRTC:\nif (numClients === 0) { socket.join(room); socket.emit('created', room, socket.id); } else if (numClients === 1) { socket.join(room); socket.emit('joined', room, socket.id); io.sockets.in(room).emit('ready'); } else { // max two clients socket.emit('full', room); } Наше простое приложение WebRTC позволит максимум двум узлам совместно использовать комнату.\nHTML и JavaScript\nОбновите index.html. Теперь страница должна выглядеть примерно так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e На этом шаге вы ничего не увидите на странице: все протоколирование выполняется в консоли браузера. (Чтобы просмотреть консоль в Chrome, нажмите Ctrl-Shift-J или Command-Option-J, если работаете на Mac.) Заменить js/main.js следующим файлом:\n'use strict'; var isInitiator; window.room = prompt(\"Enter room name:\"); var socket = io.connect(); if (room !== \"\") { console.log('Message from client: Asking to join room ' + room); socket.emit('create or join', room); } socket.on('created', function(room, clientId) { isInitiator = true; }); socket.on('full', function(room) { console.log('Message from client: Room ' + room + ' is full :^('); }); socket.on('ipaddr', function(ipaddr) { console.log('Message from client: Server IP address is ' + ipaddr); }); socket.on('joined', function(room, clientId) { isInitiator = false; }); socket.on('log', function(array) { console.log.apply(console, array); }); Настройте Socket.IO для запуска Node.js В HTML-файле вы, возможно, видели, что используете Socket.IO файл:\n\u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e На верхнем уровне вашей папки work создайте файл с именем package.json со следующим содержимым:\n{ \"name\": \"webrtc-codelab\", \"version\": \"0.0.1\", \"description\": \"WebRTC codelab\", \"dependencies\": { \"node-static\": \"^0.7.10\", \"socket.io\": \"^1.2.0\" } } Это манифест приложения, который сообщает диспетчеру пакетов узлов (npm), какие зависимости проекта следует установить.\nЧтобы установить зависимости (например, /socket.io/socket.io.js), выполните следующие действия из терминала командной строки в вашей папке work: npm install\nВы должны увидеть журнал установки, который заканчивается примерно так:\nКак вы видите, npm установил зависимости, определенные в package.json.\nСоздайте новый файл index.js на верхнем уровне вашей папки work (не в папке js) и добавьте следующий код:\n'use strict'; var os = require('os'); var nodeStatic = require('node-static'); var http = require('http'); var socketIO = require('socket.io'); var fileServer = new(nodeStatic.Server)(); var app = http.createServer(function(req, res) { fileServer.serve(req, res); }).listen(8080); var io = socketIO.listen(app); io.sockets.on('connection', function(socket) { // convenience function to log server messages on the client function log() { var array = ['Message from server:']; array.push.apply(array, arguments); socket.emit('log', array); } socket.on('message', function(message) { log('Client said: ', message); // for a real app, would be room-only (not broadcast) socket.broadcast.emit('message', message); }); socket.on('create or join', function(room) { log('Received request to create or join room ' + room); var clientsInRoom = io.sockets.adapter.rooms[room]; var numClients = clientsInRoom ? Object.keys(clientsInRoom.sockets).length : 0; log('Room ' + room + ' now has ' + numClients + ' client(s)'); if (numClients === 0) { socket.join(room); log('Client ID ' + socket.id + ' created room ' + room); socket.emit('created', room, socket.id); } else if (numClients === 1) { log('Client ID ' + socket.id + ' joined room ' + room); io.sockets.in(room).emit('join', room); socket.join(room); socket.emit('joined', room, socket.id); io.sockets.in(room).emit('ready'); } else { // max two clients socket.emit('full', room); } }); socket.on('ipaddr', function() { var ifaces = os.networkInterfaces(); for (var dev in ifaces) { ifaces[dev].forEach(function(details) { if (details.family === 'IPv4' \u0026\u0026 details.address !== '127.0.0.1') { socket.emit('ipaddr', details.address); } }); } }); }); Из терминала командной строки выполните следующую команду в папке work: node index.js\nВ браузере откройте localhost:8080.\nКаждый раз, когда вы открываете этот URL-адрес, вам будет предложено ввести название комнаты. Чтобы присоединиться к одной и той же комнате, каждый раз выбирайте одно и то же имя комнаты, например, «foo».\nОткройте новую вкладку и снова откройте localhost: 8080. Выберите то же самое название комнаты.\nОткройте localhost:8080 в третьей вкладке или окне. Выберите то же название комнаты еще раз.\nПроверьте консоль на каждой из вкладок: вы должны увидеть логи из JavaScript выше.\nБонусные задания\nКакие альтернативные механизмы обмена сообщениями могут быть возможны? С какими проблемами вы можете столкнуться при использовании «чистого» WebSocket? Какие проблемы могут быть связаны с масштабированием этого приложения? Можете ли вы разработать метод для тестирования тысяч или миллионов одновременных запросов на номер? Это приложение использует запрос JavaScript для получения названия комнаты. Разработайте способ получения названия комнаты из URL. Например, localhost:8080/foo будет указывать имя комнаты foo. Что вы узнали\nНа этом шаге вы узнали, как:\nИспользовать npm для установки зависимостей проекта, как указано в package.json Запускать Node.js сервер для обмена системных файлов. Настраивать службу обмена сообщениями на Node.js через socket.io . Использовать это для создания ‘комнат\" и обмена сообщениями. Полная версия этого шага находится в папке step-04. Узнайте больше\nПример socket.io chat - https://github.com/rauchg/chat-example WebRTC в реальном мире: STUN, TURN и сигналинг - http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/ Термин “signaling” в WebRTC - https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html Следующий шаг Узнайте, как исполь зовать сигналинг, чтобы позволить двум пользователям установить одноранговое соединение.\n","description":"Карманная книга по WebRTC","title":"Настройка службы сигналинга для обмена сообщениями","uri":"/ru/tracks/webrtc/practice/practice-setup-signaling-service/"},{"content":"Создайте приложение для получения видео и снимков с веб-камеры, с возможностью делиться ими в P2P через WebRTC. В ходе codelab вы узнаете, как использовать основные API WebRTC и настроить сервер обмена сообщениями через Node.js.\nЧему вы научитесь\nполучать видео с вашей веб-камеры потоковое видео через RTCPeerConnection потоковая передача данных через RTCDataChannel настраивать сигналинг для обмена сообщениями комбинировать одноранговое соединение и сигналинг делать фото и передавать его через канал данных Что понадобится\nChrome версии 47 и выше веб-сервер для Chrome https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb , и ваш собственный веб-сервер по выбору пример кода текстовый редактор базовые знания HTML, CSS и Javaskript ","description":"Карманная книга по WebRTC","title":"Обзор","uri":"/ru/tracks/webrtc/practice/practice-overview/"},{"content":"Область видимости, или scope, определяет, где переменные могут быть использованы в программе. В Python есть две основные области видимости: глобальная и локальная.\nПеременные, определенные внутри функции, имеют локальную область видимости. Это означает, что они могут быть использованы только внутри этой функции. Если попытаться использовать их вне функции, будет вызвано исключение.\nПеременные, определенные вне функции, имеют глобальную область видимости. Они могут быть использованы в любом месте программы, в том числе и внутри функций. Если внутри функции определить переменную с тем же именем, что и глобальная переменная, то функция будет использовать локальную переменную.\nПример:\nx = 10 # глобальная переменная def my_func(): x = 5 # локальная переменная print(\"Значение x внутри функции:\", x) my_func() print(\"Значение x вне функции:\", x) Вывод:\nЗначение x внутри функции: 5 Значение x вне функции: 10 В этом примере мы создали глобальную переменную x со значением 10, а затем определили функцию my_func(), в которой мы создали локальную переменную x со значением 5. Внутри функции мы выводим значение локальной переменной x, а затем вызываем функцию и выводим значение глобальной переменной x.\n💡 Если мы попробуем изменить значение глобальной переменной x внутри функции, то мы получим ошибку:\nx = 10 # глобальная переменная def my_func(): x = x + 5 # ошибка: переменная x не определена print(\"Значение x внутри функции:\", x) my_func() print(\"Значение x вне функции:\", x) В этом примере мы пытаемся изменить значение глобальной переменной x внутри функции, но получаем ошибку, так как переменная x не определена внутри функции.\nЧтобы изменить значение глобальной переменной, нужно использовать оператор global.\nx = 10 # глобальная переменная def my_func(): global x x = x + 5 print(\"Значение x внутри функции:\", x) my_func() print(\"Значение x вне функции:\", x) В этом примере мы используем оператор global для того, чтобы указать, что мы хотим использовать глобальную переменную x.\n","description":"Python 101","title":"Область видимости","uri":"/ru/tracks/python-101/basis/scope/"},{"content":"Обработка исключений - это механизм, который позволяет обработать возможную ошибку, которая может возникнуть в процессе выполнения программы.\nВ Python эта конструкция исключений обычно обернута в так называемый try/except.\nОператор try-except - это основной инструмент для обработки исключений. Код, который может вызвать исключение, помещается в блок try. Если исключение возникает, то Python переходит в блок except, где вы можете обработать исключение и выполнить соответствующий код.\ntry: x = int(input(\"Введите число: \")) result = 100 / x except ZeroDivisionError: print(\"Деление на ноль!\") else: print(f\"Результат: {result}\") finally: print(\"Конец программы\") В этом примере программа просит пользователя ввести число, которое будет использоваться в делении на 100. Если пользователь вводит 0, то возникает исключение ZeroDivisionError, которое обрабатывается блоком except.\nВ случае, если исключение не возникает, программа выполняет блок else. Независимо от того, возникает исключение или нет, блок finally всегда будет выполнен.\nКроме того, вы можете использовать несколько блоков except для обработки разных типов исключений.\ntry: x = int(input(\"Введите число: \")) result = 100 / x except ZeroDivisionError: print(\"Деление на ноль!\") except ValueError: print(\"Неверный формат числа!\") else: print(f\"Результат: {result}\") finally: print(\"Конец программы\") Помимо этого, можно использовать операторы try-except внутри функций, чтобы обрабатывать исключения, возникающие во время их выполнения.\nВ Python используются операторы raise и assert, которые позволяют вызвать исключение в явном виде, когда это необходимо.\nПример использования оператора raise:\nx = -1 if x \u003c 0: raise ValueError(\"Число должно быть положительным!\") Пример использования оператора assert:\nx = 10 assert x \u003c 0, \"Число должно быть отрицательным!\" Оператор assert проверяет истинность заданного выражения, и если оно является ложным, вызывает исключение AssertionError.\n","description":"Python 101","title":"Обработка исключений","uri":"/ru/tracks/python-101/basis/exception_handling/"},{"content":"Начало работы с одноранговыми соединениями Одноранговые соединения – часть спецификации WebRTC, которая занимается связью двух приложений на различных компьютерах для коммуникации через P2P-протокол. Коммуникация между узлами может быть видео-, аудио- или произвольными двоичными данными (для клиентов, поддерживающих RTCDataChannel API). Чтобы выяснить, как два узла могут быть соединены, оба клиента должны предоставить конфигурацию ICE-Server. Это или STUN, или TURN-сервер, и их роль – обеспечить ICE-кандидатов для каждого клиента, который затем передается на удаленный узел. Эта «передача» ICE-кандидатов обычно называется «сигналинг».\nСигналинг Спецификации WebRTC включают API для коммуникации с ICE-сервером (ICE =Internet Connectivity Establishment, установление интерактивного подключения), но компонент сигналинга не является частью этого сервера. Сигналинг необходим, чтобы два узла могли использовать один и тот же способ подключения. Обычно это можно решить через обычный Web API на базе HTTP (то есть службу REST или другой механизм RPC), где веб-приложения могут передавать необходимую информацию до того, как будет установлено соединение. Следующий фрагмент кода показывает, как эту придуманную службу сигналинга можно использовать для отправки и получения асинхронных сообщений. Мы будем использовать по необходимости этот прием в оставшихся примерах в этом гайде.\n// Set up an asynchronous communication channel that will be // used during the peer connection setup const signalingChannel = new SignalingChannel(remoteClientId); signalingChannel.addEventListener('message', message =\u003e { // New message from remote client received }); // Send an asynchronous message to the remote client signalingChannel.send('Hello!'); Сигналинг может быть реализован разными способами, и спецификация WebRTC не отдает предпочтений какому-то определенному варианту.\nИнициирование одноранговых соединений Каждое одноранговое соединение управляется объектом RTCPeerConnection. Конструктор для этого класса берет в качестве параметра одиночный объект RTCConfiguration. Этот объект определяет, как одноранговое соединение устанавливается, и какую информацию должен содержать об используемых ICE-серверах.\nПосле того, как RTCPeerConnection установлено, мы должны задать SDP-запрос/ответ, в зависимости от того, являемся мы вызывающим или принимающим узлом. После того, как SDP-запрос/ответ создан, он должен быть отправлен на удаленный узел через другой канал. Передача SDP-объектов на удаленные узлы называется сигналингом и не рассматривается в WebRTC спецификации.\nДля установки однорангового соединения с вызывающей стороны, мы создаем объект RTCPeerConnection, и затем вызываем createOffer() для создания объекта RTCSessionDescription. Описание этого сеанса устанавливается как локальное описание с использованием setLocalDescription(), и затем отправляется через наш сигналинг-канал получающей стороне. Мы также устанавливаем «прослушиватель» для нашего сигналинг-канала, чтобы знать, когда получающей стороной будет получен ответ на описание нашего запрошенного сеанса.\nasync function makeCall() { const configuration = {'iceServers': [{'urls': 'stun:stun.l.google.com:19302'}]} const peerConnection = new RTCPeerConnection(configuration); signalingChannel.addEventListener('message', async message =\u003e { if (message.answer) { const remoteDesc = new RTCSessionDescription(message.answer); await peerConnection.setRemoteDescription(remoteDesc); } }); const offer = await peerConnection.createOffer(); await peerConnection.setLocalDescription(offer); signalingChannel.send({'offer': offer}); } На получающей стороне мы ждем входящий запрос до того, как мы создали пример RTCPeerConnection. После этого мы устанавливаем полученный запрос, используя setRemoteDescription().\nДалее, мы делаем запрос createAnswer() для создания ответа на полученный запрос. Этот ответ устанавливается как локальное описание через использование setLocalDescription() и затем отправляется набирающей стороне через наш сигналинг-сервер.\nconst peerConnection = new RTCPeerConnection(configuration); signalingChannel.addEventListener('message', async message =\u003e { if (message.offer) { peerConnection.setRemoteDescription(new RTCSessionDescription(message.offer)); const answer = await peerConnection.createAnswer(); await peerConnection.setLocalDescription(answer); signalingChannel.send({'answer': answer}); } }); Как только два узла установили описания и локального, и удаленного сеансов, становятся доступны возможности удаленного узла. Это еще не означает, что соединение между узлами готово. Для работы необходимо собрать ICE-кандидатов на каждом узле и передать (по сигналинг-каналу) другому узлу.\nICE-кандидаты До того, как два узла смогут коммуницировать через WebRTC, им необходимо обменяться информацией о подключении. Так как условия сети могут отличаться в зависимости от ряда факторов, для обнаружения возможных кандидатов на соединение с узлом обычно используется внешний сервис. Этот сервис называется ICE и использует серверы STUN или TURN. STUN – это аббревиатура от Session Traversal for NAT, и обычно косвенно используется в большинстве WebRTC приложениях.\nTURN (Traversal Using Relay NAT) более продвинутое решение, которое включает в себя протоколы STUN, и большинство коммерческих служб WebRTC используют TURN сервер для установки соединения между узлами.\nAPI WebRTC напрямую поддерживает как STUN, так и TURN, и объединяется под более полным термином ICE (Internet Connectivity Establishment - «Установление подключения к Интернету»). При установке WebRTC-соединения мы обычно предоставляем один или несколько ICE-серверов в конфигурации для объекта RTCPeerConnection.\nTrickle ICE После создания объекта RTCPeerConnection, исходный фреймворк использует предоставленные ICE-серверы для сбора кандидатов на установление соединения (кандидатов ICE).\nСобытие icegatheringstatechange на RTCPeerConnection передает информацию о том, в каком состоянии находится ICE-сбор (new, gathering или complete). Несмотря на то, что для узла возможно просто дождаться, пока ICE-сбор будет завершен, обычно гораздо эффективнее использовать метод «trickle ice» и передавать каждого вновь обнаруженного ICE-кандидата удаленному узлу. Это значительно сократит время настройки однорангового соединения и позволит начать видео-звонок с меньшими задержками.\nДля сбора ICE-кандидатов, просто добавьте «прослушиватель» в событие icecandidate. Объект RTCPeerConnectionIceEvent, созданный этим «прослушивателем», будет содержать свойство candidate, представляющее нового кандидата, которого нужно отправить удаленному узлу (см. Сигналинг)\n// Listen for local ICE candidates on the local RTCPeerConnection peerConnection.addEventListener(‘icecandidate’, event =\u003e { if (event.candidate) { signalingChannel.send({‘new-ice-candidate’: event.candidate}); } }); // Listen for remote ICE candidates and add them to the local RTCPeerConnection signalingChannel.addEventListener(‘message’, async message =\u003e { if (message.iceCandidate) { try { await peerConnection.addIceCandidate(message.iceCandidate); } catch € { console.error(‘Error adding received ice candidate’, e); } } }); Соединение установлено После того, как ICE-кандидаты получены, нужно дождаться, пока состояние нашего однорангового соединения изменится на подключенное состояние. Чтобы отследить это, добавим «прослушиватель» в наш RTCPeerConnection, где можно просматривать изменения события connectionstatechange.\n","description":"Карманная книга по WebRTC","title":"Одноранговые соединения","uri":"/ru/tracks/webrtc/peer-connections/"},{"content":"Оператор присваивания Оператор присваивания “=” используется для присвоения значения переменной. Например:\nx = 5 Арифметические операторы Арифметические операторы используются для выполнения математических операций над числами.\n+ # Сложение - # Вычитание * # Умножение / # Деление % # Остаток от деления ** # Возведение в степень // # Целочисленное деление Пример:\nx = 5 y = 2 print(x + y) # 7 print(x - y) # 3 print(x * y) # 10 print(x / y) # 2.5 print(x % y) # 1 print(x ** y) # 25 print(x // y) # 2 Операторы сравнения Операторы сравнения используются для сравнения значений.\n== # Равно != # Не равно \u003e # Больше \u003c # Меньше \u003e= # Больше или равно \u003c= # Меньше или равно x = 5 y = 2 print(x == y) # False print(x != y) # True print(x \u003e y) # True print(x \u003c y) # False print(x \u003e= y) # True print(x \u003c= y) # False Булевы операторы Булевы операторы используются для выполнения логических операций.\nand # Логическое И or # Логическое ИЛИ not # Логическое НЕ x = 5 y = 2 z = 0 print(x \u003e y and x \u003e z) # True print(x \u003e y or x \u003c z) # True print(not x \u003e y) # False Побитовые операторы Побитовые операторы используются для выполнения операций с двоичными числами.\n\u0026 # Побитовое И | # Побитовое ИЛИ ^ # Побитовое исключающее ИЛИ ~ # Побитовое НЕ \u003c\u003c # Сдвиг влево \u003e\u003e # Сдвиг вправо x = 5 # 0b101 y = 3 # 0b011 print(x \u0026 y) # 1 (0b001) print(x | y) # 7 Операторы “is” и “in” Оператор is используется для проверки, являются ли два объекта одним и тем же объектом в памяти.\nx = [1, 2, 3] y = [1, 2, 3] print(x is y) # False, потому что это два разных объекта в памяти print(x == y) # True, потому что содержание списков одинаковое Оператор in используется для проверки, находится ли элемент в последовательности.\nx = [1, 2, 3] print(2 in x) # True print(4 in x) # False Тернарный оператор Тернарный оператор - это оператор, который позволяет записать короткое условие в одну строку. Он имеет следующий синтаксис: value_if_true if condition else value_if_false.\nx = 10 y = 20 max_value = x if x \u003e y else y print(max_value) # 20 В этом примере, если x больше y, то max_value будет равен x, иначе y.\n","description":"Python 101","title":"Операторы","uri":"/ru/tracks/python-101/basis/operators/"},{"content":"Python поставляется с собственным модулем отладчика, который называется pdb. Этот модуль предоставляет интерактивный отладчик исходного кода для ваших программ на Python. Вы можете устанавливать брейкпоинты, просматривать код, изучать кадры стека и многое другое. Мы рассмотрим следующие аспекты этого модуля:\nНапример, чтобы установить точку останова в коде, можно вставить следующую строку в месте, где вы хотите остановить выполнение программы:\nimport pdb; pdb.set_trace() После запуска программы выполнение остановится на этой строке, и вы сможете использовать различные команды отладчика для изучения переменных и выполнения других операций.\nТакже можно запустить python модуль в режиме отладчика:\npython3 -m pdb myscript.py Кроме встроенного отладчика Python, есть также сторонние инструменты, такие как PyCharm, Visual Studio Code и Eclipse, которые предоставляют расширенные функции отладки, такие как автоматическое определение ошибок и возможность управления отладкой из пользовательского интерфейса.\nНекоторые из основных команд pdb:\nbreak: установить точку останова в коде continue: продолжить исполнение программы до следующей точки останова step: перейти к следующей строке в коде, вызванной из текущей строки next: перейти к следующей строке в коде, не вызывая функции, если таковые имеются return: выполнить оставшуюся часть текущей функции и вернуться к вызывающей функции list: отобразить несколько строк кода вокруг текущей строки print: напечатать значение переменной Ресурсы:\nThe Python Debugger ","description":"Python 101","title":"Отладка Python","uri":"/ru/tracks/python-101/enhance_python/debugging/"},{"content":"Задача Есть таблица google. Необходимо конвертировать ее в JSON и не делать каждый раз ручной экспорт.\nУсловия таблица закрыта для общего просмотра json отображение читать по ссылке План Использовать webapps от google. Парсить google таблицу и выдавать готовый url с json.\nПодготовка Открываем Таблицу Google Extensions → Apps Script Создаем скрипт Как работает endpoint. Документация\nКогда пользователь посещает приложение или программа отправляет приложению HTTP-запрос GET, Apps Script запускает функцию doGet(e).\nКогда отправляется приложению HTTP-запрос POST, вместо этого Apps Script запускает doPost(e).\nВ обоих случаях аргумент e представляет собой параметр события, который может содержать информацию о любых параметрах запроса.\nДополнительные условия в запрос сейчас посылать не буду.\nИтого функция с получением массива и функция с выдачей результата:\nconst sheetName = 's1' // название листа const sheetRange = 'A:J' // диапазон const sheet = SpreadsheetApp.getActive().getSheetByName(sheetName) function getData(){ const result = [] const values = sheet.getRange(sheetRange).getValues() const lastRow = parseInt(sheet.getLastRow()) for (let i = 1; i \u003c lastRow; i++) { result.push(values[i]) } return result } function doGet() { const data = getData() return ContentService.createTextOutput( JSON.stringify( {'result': data} ) ).setMimeType(ContentService.MimeType.JSON) } Публикуем приложение Результат ","description":"Экспорт google sheet в JSON, с моментальным обновлением данных","title":"Отображение таблицы Google Sheets в JSON","uri":"/ru/posts/google-sheets-2-json/"},{"content":"Модуль requests - это сторонняя библиотека Python для отправки HTTP-запросов. Он предоставляет удобный и простой API для отправки GET-, POST-, PUT-, DELETE- и других типов запросов.\nУстановить requests можно с помощью менеджера пакетов pip:\npip install requests Пример GET-запроса:\nimport requests response = requests.get(\"https://www.example.com\") print(response.status_code) print(response.text) Пример POST-запроса:\nimport requests payload = {'key1': 'value1', 'key2': 'value2'} response = requests.post(\"https://site.org/post\", data=payload) print(response.status_code) print(response.json()) Модуль requests также поддерживает отправку запросов с использованием сессий, установку заголовков, аутентификацию и другие полезные функции для работы с HTTP-запросами.\nРесурсы:\nhttps://www.w3schools.com/python/module_requests.asp ","description":"Python 101","title":"Пакет requests","uri":"/ru/tracks/python-101/external_packages/requests/"},{"content":" Печатные журналы / сборники Для цитирования:\nОсобенности региональной политики и экономические интеграции Израиля // Журнал ВАК: Наука и бизнес: пути развития // Курновский Р.М.// Номер: 1 (139) 2023 г. Страницы: 138-\nСтатья [pdf]\nПоддержка икт-экспорта как способ покрытия внутренних потребностей̆ рынка // XII международной научно-практической конференции «Трансформация экономики и управления: новые вызовы и перспективы» 15-16 декабря 2022г. // Курновский Р.М., Великородная Е. А. //\nСтатья [pdf]\nФакторы и условия, определяющие становления финансовой экосистемы в современных условиях // Экономика и предпринимательство // д.э.н., проф. Коновалова М.Е., Курновский Р.М., Ширяева Д.В. // Номер: 8 (145) 2022 г. Страницы: 928-931\nСтатья [pdf] / ResearchGate / academia.edu / SSRN\n«Ключевые подходы к разработке доступного, интуитивно понятного интерфейса статистического пакета» // Научный журнал // к.т.н., профессор Суханова Е. И., канд. физ.-мат., доцент Ширяева Л. К., Курновский Р. М. // 2014 г. //\n«Мобильность платформы 1С на базе приложения 1С:Монитор ERP» // Известия Института Систем Управления Самарского государственного экономического университета. // Курновский Р. М., Нечаев А. Н. // 2013 г. // Номер: 2 (8) // Страницы: 243-247 //\n«Современные инструменты моделирования архитектуры предприятия» // Известия Института Систем Управления Самарского государственного экономического университета. // 2012 г. // Номер: 3 (6) // Страницы: 256-260 //\n«Стволовая клетка — миф или реальность» // Тезисы 36-й Самарской областной студенческой научной конференции. // 2010 г. //\n«Права человека — миф или реальность» // Тезисы 4-й Международной научной конференции молодых ученых, аспирантов и студентов. // 2010 г. //\n«Хулиганство в Самаре 1920-1930-х гг.» // Тезисы 4-й Международной научной конференции молодых ученых, аспирантов и студентов. // 2010 г. //\n«Обеспечение прав человека — миф или реальность» // Сборник тезисов конкурсных работ, опубликованных Государственной Думой Федерального Собрания Российской Федерации во всероссийском конкурсе молодежи, образовательных учреждений и научных организаций на лучшую работу «Моя законотворческая инициатива». // 2008 г. //\n«Хулиганство в России в 20-30-е годы 20-го века на примере Самарской области» // Сборник тезисов 37-й городской научно-практической конференции. // 2008 г. //\n«Генетический паспорт гражданина Российской Федерации» // Сборник тезисов конкурсных работ, опубликованных Государственной Думой Федерального Собрания Российской Федерации во всероссийском конкурсе молодежи, образовательных учреждений и научных организаций на лучшую работу «Моя законотворческая инициатива». // 2007 г. //\nОжидают публикации Codes SCIENCE INDEX SPIN РИНЦ: 1657-2666 ORCID: 0000-0002-6040-3683 Web of Science ResearcherID: HLQ-2418-2023 Google Scholar SSRN academia.edu Links https://authors.repec.org/pro/pku734/ https://ideas.repec.org/ https://econpapers.repec.org/ Площадки medium.com dev.to vc.ru ","description":"Печатные журналы / сборники","title":"Печатные публикации","uri":"/ru/p/publications/"},{"content":"Список приложений: ФСФР - Базовый экзамен\nНастоящая Политика конфиденциальности персональных данных (далее – Политика конфиденциальности) действует в отношении всей информации, которую приложения из раздела: “Список приложений” могут получить о Пользователе во время использования.\nОбщие положения 1.1. Целью Политики конфиденциальности является реализация требований законодательства в области обработки и защиты персональных данных. 1.2. Настоящий Регламент разработан на основании Конституции Российской Федерации, Трудового кодекса Российской Федерации, Гражданского кодекса Российской Федерации, Уголовного кодекса Российской Федерации, Кодекса об административных правонарушениях Российской Федерации, Федерального закона Российской Федерации «О персональных данных» № 152-ФЗ от 27 июля 2006 года.\nОсновные понятия На основании законодательства Российской Федерации в целях настоящего Политики конфиденциальности используются следующие понятия 2.1. Администратор Приложений (далее – Администратор) – уполномоченные сотрудник, который организуют и (или) осуществляет обработку персональных данных, а также определяет цели обработки персональных данных, состав персональных данных, подлежащих обработке, действия (операции), совершаемые с персональными данными.\n2.2. Пользователь – лицо, являющееся субъектом персональных данных и сообщающее свои персональные данные посредством Приложений.\n2.3. «Персональные данные» - любая информация, относящаяся к прямо или косвенно к определяемому физическому лицу (субъекту персональных данных).\n2.4. «Обработка персональных данных» - любое действие (операция) или совокупность действий (операций), совершаемых с использованием средств автоматизации или без использования таких средств с персональными данными, включая сбор, запись, систематизацию, накопление, хранение, уточнение (обновление, изменение), извлечение, использование, передачу (распространение, предоставление, доступ), обезличивание, блокирование, удаление, уничтожение персональных данных.\nОбщие положения 3.1. Использование Пользователем Приложений означает согласие с настоящей Политикой конфиденциальности и условиями обработки персональных данных Пользователя. 3.2. В случае несогласия с условиями Политики конфиденциальности Пользователь должен прекратить использование Приложений.\n3.3. Настоящая Политика конфиденциальности применяется только к Приложениям.\nПредмет политики конфиденциальности 4.1. Настоящая Политика конфиденциальности устанавливает обязательства по неразглашению и обеспечению режима защиты конфиденциальности персональных данных, которые Пользователь. 4.2. Персональные данные, разрешённые к обработке в рамках настоящей Политики конфиденциальности, предоставляются Пользователем путём заполнения и включают в себя следующую информацию:\nфамилию, имя, отчество;\nконтактный телефон Пользователя;\ne-mail\n4.3. Любая иная персональная информация неоговоренная выше подлежит надежному хранению и нераспространению.\n4.4. Обработка персональных данных осуществляется с использованием интернет-сервисов сторонних организаций, в том числе с использованием интернет-сервиса Google Analitics. С порядком обработки данных с помощью интернет-сервиса Google Analitics можно ознакомиться, перейдя по ссылке https://www.google.ru/policies/privacy/partners/\nЦели сбора персональных данных 5.1. Запрещено обрабатывать персональные данные Пользователя о его политических, религиозных и иных убеждениях и частной жизни. 5.2. При передаче персональных данных Пользователя, Администратор предупреждает лиц, получающих персональные данные Пользователя, о том, что эти данные могут быть использованы лишь в целях, для которых они сообщены. Данная норма не распространяется на обмен персональными данными Пользователей в порядке, установленном федеральными законами.\n5.3. Защита персональных данных Пользователя от неправомерного их использования или утраты обеспечивается в порядке, установленном законодательством Российской Федерации.\n5.4. Пользователь вправе в любое время по своему усмотрению отозвать свое согласие на обработку своих персональных данных путем отправки сообщения об удалении персональных данных по следующему e-mail: r.kurnovskii@gmail.com.\nСпособы и сроки обработки персональных данных 6.1. Обработка персональных данных Пользователя осуществляется без ограничения срока, любым законным способом, в том числе в информационных системах персональных данных с использованием средств автоматизации или без использования таких средств. 6.2. При утрате или разглашении персональных данных Администрация сайта информирует Пользователя об утрате или разглашении персональных данных.\nОбязательства сторон 7.1. Администратор обязан: 7.1.1. Использовать полученную информацию исключительно для целей, указанных в п. 5 настоящей Политики конфиденциальности.\n7.1.2. Обеспечить хранение конфиденциальной информации в тайне.\n7.1.3. Принимать меры предосторожности для защиты конфиденциальности персональных данных Пользователя согласно порядку, обычно используемого для защиты такого рода информации в существующем деловом обороте.\n7.1.4. Осуществить блокирование, удаление персональных данных, относящихся к соответствующему Пользователю, с момента обращения или запроса Пользователя или его законного представителя либо уполномоченного органа по защите прав субъектов персональных данных на период проверки, в случае выявления недостоверных персональных данных или неправомерных действий\n7.2. Администратор не несет ответственности за возможное нецелевое использование персональных данных Пользователей, произошедшее из-за:\n7.2.1. технических неполадок в программном обеспечении, серверах или компьютерных сетях, находящихся вне контроля Администратора;\nДополнительные условия 8.1. Администратор вправе вносить изменения в настоящую Политику конфиденциальности без согласия Пользователя. 8.2. Новая Политика конфиденциальности вступает в силу с момента ее размещения на Сайте https://romankurnovskii.github.io/p/privacy_ru/, если иное не предусмотрено новой редакцией Политики конфиденциальности.\n","description":"","title":"Политика конфиденциальности","uri":"/ru/p/privacy_ru/"},{"content":"Web Создание заявки в IB Заходим на сайт https://www.interactivebrokers.co.uk/portal/#/ Нажимаем Deposit Нажимаем Use a new deposit method если ранее шаблон не был создан Bank Wire -\u003e Get instructions Account Number: Номер банковского счета.\nПолучаем инструкции с реквизитами для пополнения Bank Wire Instructions Эти данные Вам нужны для оплаты в Discount Bank\nОтправить деньги из Discount Bank Заходим в личный кабинет банка start.telebank.co.il Нажимаем: ביצוע העברה\nЗаполняем форму\nНажимаем המשך и жмем далее. Приходит смс с подверждением, вводим и жмем далее ","description":"Пополнение Interactive Brokers с Израильского счета банка Дисконт","title":"Пополнение Interactive Brokers с Израильского счета","uri":"/ru/posts/interactivebrokers-deposit/"},{"content":"Full in english\nТоп 10 комманд Docker docker ps — смотрим список запущенных контейнеров docker pull — загрузка образа docker build — собирает образ docker logs — смотрим логи docker run — запускаем контейнер docker stop — останавливает контейнер docker kill — «убивает» контейнер docker rm — удаляет контейнер docker rmi — удаляет образ docker volume ls — список томов docker build Документация Построить образ из Dockerfile.\ndocker build [DOCKERFILE PATH] Флаги\n--file -f Путь, где находится Dockerfile --force-rm Всегда удалять временные контейнеры. --no-cache Не использовать кэш при построении образа. --rm Удалить временные контейнеры после успешного построения. --tag -t Название и возможный тег в формате name:tag или просто тег my_tag (опционально) Примеры\nПостроить образ с меткой my-org/my-image, используя Dockerfile в /tmp/Dockerfile.\ndocker build -t my-org:my-image -f /tmp/Dockerfile docker run Документация\nСоздает и запускает контейнер за один операционный шаг\nПримеры\ndocker run -it ubuntu:latest /bin/bash Данная команда запустит контейнер ubuntu и при старте сразу запустит /bin/bash. Если образ ubuntu не был загружен ранее, он загрузится перед запуском.\nФлаги\n-it This will not make the container you started shut down immediately, as it will create a pseudo-TTY session (-t) and keep STDIN open (-i) --rm Automatically remove the container when it exit. Otherwise it will be stored and visible running docker ps -a. --detach -d Run container in background and print container ID --volume -v Bind mount a volume. Useful for accessing folders on your local disk inside your docker container, like configuration files or storage that should be persisted (database, logs etc.). docker exec Документация Выполнить команду внутри запущенного контейнера.\ndocker exec [CONTAINER ID] Флаги\n--detach -d Detached mode: запуск в фоновом режиме -it запуск в интерактивном режиме. запуск псевдотерминала pseudo-TTY (-t) и перенаправление ввода-вывода (STDIN) (-i). Даёт доступ к выполнению команд в терминале контейнера. Примеры\ndocker exec [CONTAINER ID] touch /tmp/exec_works docker images Документация Вывести список всех загруженных/созданных образов\ndocker images Флаги\n-q показать только ID образов docker inspect Документация\nПоказать всю информацию о контейнере.\ndocker inspect [CONTAINER ID] docker logs Документация\nВывести логи контейнера.\ndocker logs [CONTAINER ID] Флаги\n--details Показывает дополнительную информацию в логе. --follow -f Следить за выводом журнала --timestamps -t Показать журналы с меткой времени docker ps Документация\nПоказывает информацию о всех запущенных контейнерах.\ndocker ps Флаги\n--all -a Show all containers (default shows just running) --filter -f Filter output based on conditions provided, docker ps -f=\"name=\"example\" --quiet -q Only display numeric IDs docker rmi Документация\nУдалить один или несколько образов.\ndocker rmi [IMAGE ID] Флаги\n--force -f Force removal of the image Советы и рекомендации по докеру Сборник полезных советов по Docker.\nУдалить все контейнеры NOTE: Удалить ВСЕ контенеры.\ndocker container prune или\ndocker rm $(docker ps -a -q) Удалить все непомеченные контейнеры docker image prune Вывести сколько памяти занимает Docker docker system df Получить IP-адрес работающего контейнера docker inspect [CONTAINER ID] | grep -wm1 IPAddress | cut -d '\"' -f 4 Сгенерировать образ на основе файла Dockerfile и добавить этому образу имя и версию docker build -t new_image_name:v1 . . означает текущую директорию, где расположен файл Dockerfile.\nСгенерировать из запущенного контейнера новый образ docker commit [CONTAINER ID] [NEW IMAGE NAME] “Убить” все запущенные контейнеры docker kill $(docker ps -q) Ссылки docs.docker.com docker-cheat-sheet https://sourabhbajaj.com/mac-setup/Docker/ ","description":"Основные команды Docker, которыми пользуюсь в процессе разработки.","title":"Популярные команды Docker","uri":"/ru/posts/docker-commands/"},{"content":"Чему вы научитесь:\nНа этом шаге вы узнаете, как\nполучить видеопоток с вашей веб-камеры управлять воспроизведением потока использовать CSS и SVG для обработки видео Полная версия этого шага находится в папке step-01. Немного HTML\nДобавьте элемент video и элемент script в index.html в папку work.\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cvideo autoplay playsinline\u003e\u003c/video\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e И немного JavaScript\nДобавьте следующее в main.js в вашей папке js:\n'use strict'; // On this codelab, you will be streaming only video (video: true). const mediaStreamConstraints = { video: true, }; // Video element where stream will be placed. const localVideo = document.querySelector('video'); // Local stream that will be reproduced on the video. let localStream; // Handles success by adding the MediaStream to the video element. function gotLocalMediaStream(mediaStream) { localStream = mediaStream; localVideo.srcObject = mediaStream; } // Handles error by logging a message to the console with the error message. function handleLocalMediaStreamError(error) { console.log('navigator.getUserMedia error: ', error); } // Initializes media stream. navigator.mediaDevices.getUserMedia(mediaStreamConstraints) .then(gotLocalMediaStream).catch(handleLocalMediaStreamError); Все приведенные здесь примеры JavaScript используют ‘use strict’, для избежания частых ошибок в кодировании. Узнайте больше, что это означает в http://ejohn.org/blog/ecmascript-5-strict-mode-json-and-more/\nПопробуйте\nОткройте index.html в вашем браузере и вы должны увидеть что-то подобное (с видом из вашей камеры, конечно!):\nКак это работает\nСледуя запросу getUserMedia(), браузер запрашивает у пользователя разрешение на доступ к своей камере (если это впервые, когда запрашивается доступ к камере для текущего источника). В случае успеха возвращается MediaStream, который может быть использован элементов мультимедиа через атрибут srcObject:\nnavigator.mediaDevices.getUserMedia(mediaStreamConstraints) .then(gotLocalMediaStream).catch(handleLocalMediaStreamError); function gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; } Аргумент constraints позволяет указать, какой тип мультимедиа получать. В этом примере используется только видео, т.к. звук по умолчанию отключен:\nconst mediaStreamConstraints = { video: true, }; Вы можете использовать ограничения для дополнительных требований, таких как разрешение видео:\nconst hdConstraints = { video: { width: { min: 1280 }, height: { min: 720 } } } Спецификация MediaTrackConstraints перечисляет все возможные типы ограничений, хотя не все параметры поддерживаются во всех браузерах. Если запрошенное разрешение не поддерживается выбранной в данный момент камерой, getUserMedia() будет отклонен с ошибкой OverconstrainedError и пользователю даже не предложат предоставить разрешение на доступ к своей камере.\nДемо-версию, демонстрирующую, как использовать ограничения для запроса различных разрешений, можно посмотреть по ссылке https://simpl.info/getusermedia/constraints/, а демо-версию с использованием ограничений для выбора камеры и микрофона – по этой ссылке https://simpl.info/getusermedia/sources/.\nЕсли getUserMedia() сработал успешно, в качестве источника элемента video устанавливается видеопоток с веб-камеры:\nfunction gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; } Бонусные задания\nПереданный getUserMedia() объект localStream находится в глобальной области видимости, поэтому вы можете проверить его через консоль браузера: откройте консоль в Chrome, введите stream и нажмите Return (для просмотра консоли в Chrome, нажмите Ctrl+Shift+J, или command+Option+J, если вы работаете на Mac). что возвращает localStream.getVideoTracks()? попробуйте сделать запрос localStream.getVideoTracks()[0].stop() Посмотрите на объект constraints: что произойдет, когда вы меняете его на {audio: true, video: true)? Какой размер у элемента video? Как можно получить естественный размер из JavaScript, в отличие от размера экрана? Используйте Chrome Dev Tools для проверки Попробуйте добавить CSS фильтры в элемент video. Например: video { filter: blur(4px) invert(1) opacity(0.5); } Попробуйте добавить SVG-фильтры. Например: video { filter: hue-rotate(180deg) saturate(200%); } Что вы узнали\nНа этом шаге вы узнали, как\nполучать видео с вашей веб-камеры устанавливать ограничения для мультимедиа как навести хаос в элементе video Полная версия этого шага находится в папке step-01.\nСоветы\nне забывайте про атрибут autoplay в элемент video. Без него вы будете видеть только один кадр! есть гораздо больше ограничений для getUserMedia(). Посмотрите их по ссылке https://webrtc.github.io/samples/src/content/peerconnection/constraints/. Как видите, есть много интересных примеров c WebRTC на сайте. Лучшая практика\nубедитесь, что ваш элемент video не переполняет его контейнер. Мы добавили width и max-width для установки соответствующего размера и максимального размера видео. Браузер будет рассчитывать высоту автоматически. video { max-width: 100%; width: 320px; } Следующий шаг\nВы получили видео, но как его транслировать? Узнайте на следующем шаге!\n","description":"Карманная книга по WebRTC","title":"Потоковое видео с веб-камеры","uri":"/ru/tracks/webrtc/practice/practice-stream-to-cam/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nАбстрагироваться от различий браузера с помощью оболочки WebRTC, adapter.js. Использовать RTCPeerConnection API для потоковой передачи видео. Управлять захватом и потоковой передачей мультимедиа. Полная версия этого шага находится в папке step-2.\nЧто такое RTCPeerConnection?\nRTCPeerConnection - это API для выполнения WebRTC-запросов для потоковой передачи видео и аудио и обмена данными.\nВ этом примере устанавливается соединение между двумя объектами RTCPeerConnection (известными как узлы) на одной и той же странице.\nНе очень практично, но зато полезно для понимания того, как работает RTCPeerConnection.\nДобавление элементов video и кнопок управления\nВ index.html замените один видеоэлемент двумя видеоэлементами и тремя кнопками:\n\u003cvideo id=\"localVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cdiv\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"callButton\"\u003eCall\u003c/button\u003e \u003cbutton id=\"hangupButton\"\u003eHang Up\u003c/button\u003e \u003c/div\u003e Один видеоэлемент будет отображать поток из getUserMedia(), а другой будет показывать это же видео, но передаваемое через RTCPeerConnection (в реальном приложении один видеоэлемент будет отображать локальный поток, а другой – удаленный поток).\nДобавьте adapter.js Добавьте ссылку на текущую версию adapter.js выше ссылки на main.js:\n\u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e adapter.js - это оболочка для изоляции приложений от изменений спецификаций и различий в префиксах. (Хотя на самом деле стандарты и протоколы, используемые для реализации WebRTC, очень стабильны, и существует всего несколько имен с префиксами.)\nНа этом этапе мы используем самую последнюю версию adapter.js, что хорошо для codelab, но не всегда хорошо для приложений. Здесь https://github.com/webrtc/adapter мы объясняем, как сделать так, чтоб у вашего приложения всегда был доступ к самой последней версии.\nДля получения полной информации о взаимодействии сWebRTC, переходи по ссылке https://webrtc.github.io/webrtc-org/web-apis/interop/\nТеперь index.html должен выглядеть так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cvideo id=\"localVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cdiv\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"callButton\"\u003eCall\u003c/button\u003e \u003cbutton id=\"hangupButton\"\u003eHang Up\u003c/button\u003e \u003c/div\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Установите код RTCPeerConnection\nЗамените main.js в папке step-02.\nДелать копи-паст в больших кусках кода в codelab – это так себе вариант, конечно. Но чтобы получить и запустить RTCPeerConnection, у нас нет других альтернатив, как провести вас через весь этот путь. Вам нужно научиться, как код работает в каждый момент.\nСделайте звонок Откройте index.html, нажмите кнопку Start, чтоб получить видео с вашей веб-камеры, и затем нажмите Call, чтобы установить одноранговое соединение. Вы должны увидеть одно и то же видео (с вашей веб-камеры) в обоих видео-элементах. Посмотрите консоль браузера, чтоб увидеть логи WebRTC.\nКак это работает\nВ этом шаге будет много всего…\nЕсли вы хотите пропустить объяснение ниже - ок. Вы все еще можете продолжить работу с codelab!\nWebRTC использует API RTCPeerConnection для настройки соединения для потоковой передачи видео между клиентами WebRTC, известными как узлы. В этом примере два объекта RTCPeerConnection находятся на одной странице: pc1 и pc2. Это мало используется на практике, но зато хорошо демонстрирует, как работают API. Настройка вызова между WebRTC-узлами включает в себя три задачи:\nСоздать RTCPeerConnection для каждого конца вызова и на каждом конце добавить локальный поток из getUserMedia(). Получать и делиться сетевой информацией: потенциальные конечные точки подключения известны как ICE-кандидаты. Получать и делиться локальными и удаленными описаниями: метаданные о локальными мультимедиа в формате SDP. Представьте, что Алиса и Боб хотят использовать RTCPeerConnection для настройки видеочата. Сначала Алиса и Боб обмениваются информацией о сети. Выражение “finding candidates” относится к процессу поиска сетевых интерфейсов и портов с использованием ICE-фреймворк.\nАлиса создает объект RTCPeerConnection с обработчиком onicecandidate (addEventListener(‘icecandidate’)). Это соответствует следующему коду из main.js let localPeerConnection; localPeerConnection = new RTCPeerConnection(servers); localPeerConnection.addEventListener('icecandidate', handleConnection); localPeerConnection.addEventListener( 'iceconnectionstatechange', handleConnectionChange); Аргумент servers для RTCPeerConnection в этом примере не используется. Здесь вы можете указать STUN и TURN серверы. WebRTC разработан для работы с P2P, поэтому пользователи могут подключаться по самому прямому возможному маршруту. Однако WebRTC создан для работы в реальных сетях: клиентским приложениям необходимо проходить через шлюзы NAT (http://en.wikipedia.org/wiki/NAT_traversal) и брандмауэры, а P2P сеть нуждается в резервном варианте на случай сбоя прямого соединения. В рамках этого процесса, API WebRTC используют STUN-серверы для получения IP-адреса вашего компьютера и TURN-серверы для ретрансляции в случае сбоя P2P связи. Подробнее об этом - http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/\nАлиса вызывает getUserMedia() и добавляет переданные поток: navigator.mediaDevices.getUserMedia(mediaStreamConstraints). then(gotLocalMediaStream). catch(handleLocalMediaStreamError); function gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; localStream = mediaStream; trace('Received local stream.'); callButton.disabled = false; // Enable call button. } localPeerConnection.addStream(localStream); trace('Added local stream to localPeerConnection.'); Обработчик onicecandidate из шага 1 вызывается, когда становятся доступными сетевые кандидаты. Алиса отправляет Бобу данные кандидата. В реальном приложении этот процесс (известный как сигналинг) осуществляется через службу обмена сообщениями – вы узнаете, как это сделать, позднее. Конечно, на этом этапе два объекта RTCPeerConnection находятся на одной странице и могут взаимодействовать напрямую без необходимости во внешних сообщениях. Когда Боб получает сообщение о кандидате от Алисы, он вызывает addIceCandidate(), чтобы добавить кандидата в описание удаленного узла: function handleConnection(event) { const peerConnection = event.target; const iceCandidate = event.candidate; if (iceCandidate) { const newIceCandidate = new RTCIceCandidate(iceCandidate); const otherPeer = getOtherPeer(peerConnection); otherPeer.addIceCandidate(newIceCandidate) .then(() =\u003e { handleConnectionSuccess(peerConnection); }).catch((error) =\u003e { handleConnectionFailure(peerConnection, error); }); trace(`${getPeerName(peerConnection)} ICE candidate:\\n` + `${event.candidate.candidate}.`); } } Узлам WebRTC также необходимо узнавать и обмениваться информацией о локальных и удаленных аудио- и видеоматериалах, такими как разрешение и возможности кодеков, и обмениваться ими. Сигналинг для обмена информацией о конфигурации мультимедиа осуществляется путем обмена большими двоичными объектами метаданных, известными как offer и answer, с использованием формата Session Description Protocol, известного как SDP (http://en.wikipedia.org/wiki/Session_Description_Protocol):\nАлиса запускает метод RTCPeerConnectioncreateOffer(). Возвращенный промис обеспечивает RTCSessionDescription: Alice’s local session description: trace('localPeerConnection createOffer start.'); localPeerConnection.createOffer(offerOptions) .then(createdOffer).catch(setSessionDescriptionError); В случае успеха Алиса устанавливает локальное описание, используя setLocalDescription(), а затем отправляет это описание сеанса Бобу через сигналинг-канал. Боб принимает описание, отправленное ему Алисой, в качестве удаленного описания, используя setRemoteDescription(). Боб запускает метод RTCPeerConnection createAnswer(), передавая ему удаленное описание, которое он получил от Алисы, чтобы можно было создать локальный сеанс, совместимый с ее сеансом. Промис createAnswer() передает описание RTCSessionDescription: Боб устанавливает это как локальное описание и отправляет его Алисе. Когда Алиса получает описание сеанса Боба, она устанавливает его в качестве удаленного описания с помощью setRemoteDescription(). // Logs offer creation and sets peer connection session descriptions. function createdOffer(description) { trace(`Offer from localPeerConnection:\\n${description.sdp}`); trace('localPeerConnection setLocalDescription start.'); localPeerConnection.setLocalDescription(description) .then(() =\u003e { setLocalDescriptionSuccess(localPeerConnection); }).catch(setSessionDescriptionError); trace('remotePeerConnection setRemoteDescription start.'); remotePeerConnection.setRemoteDescription(description) .then(() =\u003e { setRemoteDescriptionSuccess(remotePeerConnection); }).catch(setSessionDescriptionError); trace('remotePeerConnection createAnswer start.'); remotePeerConnection.createAnswer() .then(createdAnswer) .catch(setSessionDescriptionError); } // Logs answer to offer creation and sets peer connection session descriptions. function createdAnswer(description) { trace(`Answer from remotePeerConnection:\\n${description.sdp}.`); trace('remotePeerConnection setLocalDescription start.'); remotePeerConnection.setLocalDescription(description) .then(() =\u003e { setLocalDescriptionSuccess(remotePeerConnection); }).catch(setSessionDescriptionError); trace('localPeerConnection setRemoteDescription start.'); localPeerConnection.setRemoteDescription(description) .then(() =\u003e { setRemoteDescriptionSuccess(localPeerConnection); }).catch(setSessionDescriptionError); } Пинг! Бонусные задания\nПосмотрите chrome://webrtc-internals. Там отражены статы WebRTC и отлаженные данные (Полный список ссылок в Chrome – chrome://about). Сделайте разметку страницы через CSS: Расположите видео друг за другом Сделайте кнопки такой же ширины, но с большим размером текста Убедитесь, что макет работает на мобильных устройствах В консоли Chrome Dev Tools посмотрите localStream, localPeerConnection и remotePeerConnection. Из консоли, посмотрите на localPeerConnecionpc1.localDescription. Как выглядит формат SDP? Что вы узнали?\nНа этом шаге вы узнали, как\nуйти от различий в браузерах через WebRTC оболочку adapter.js использовать RTCPeerConncetion API для потоковой передачи видео контролировать захват медиа и потоковую передачу данных делиться мультимедиа и сетевой информацией между узлами, чтоб разрешить вызов WebRTC. Полная версия этого шага находится в папке step-2. Советы\nна этом шаге вам нужно столько всего освоить! Чтобы найти другие ресурсы, объясняющие более детально RTCPeerConnection, загляните на webrtc.org. Эта страница включает решения для JavaScript фреймворков – если вы хотите использовать WebRTC, но не хотите конфликтовать с API. Узнайте больше про оболочку adapter.js из https://github.com/webrtc/adapter Хотите посмотреть, как выглядит лучшее в мире приложение для видеочата? Посмотрите на AppRTC, каноническое приложение для звонков WebRTC: приложение (https://appr.tc/) и код (https://github.com/webrtc/apprtc) . Время настройки вызова составляет менее 500 мс! Лучшая практика\nДля обеспечения надежности вашего кода в будущем используйте новые API-интерфейсы на основе промисов и включите совместимость с браузерами, которые их не поддерживают, используя adapter.js Следующий шаг\nЭтот шаг показывает, как использовать WebRTC для передачи видео между узлами – но эта codelab в том числе и о данных! В следующем шаге выясним, как передавать произвольные данные с помощью RTCDataChannel.\n","description":"Карманная книга по WebRTC","title":"Потоковое видео с помощью RTCPeerConnection","uri":"/ru/tracks/webrtc/practice/practice-stream-with-rtcpeerconnection/"},{"content":" Подсчет префиксных сумм Сумма в текущей ячейке равна сумме в предыдущей + значение текущей.\n0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 a[ 5, 7, 9, 3, 8, 2, 4, 6] =\u003e b[5, 12, 21, 24, 32, 34, 38, 44] 0 5 [5,] 1 5 + 7 = 12 [5,12,] 2 9 + 12 = 21 [5,12,21,] 3 3 + 21 = 24 [5,12,21,24,] ... Чтобы посчитать сумму на любом отрезок [L, R], достаточно вычесть сумму с предыдущего индекса от `L'\nL = 3, R = 5: [3, 8, 2] = 13\nАлгоритм:\nНаходим сумму (значение) в правой части отрезка: b[R] = 34 Вычитаем из значения b[R] значение b[L-1] В новом массиве:\nb[L - 1] = b[2] = 21 b[R] = 34 34 - 21 = 13 Ресурсы https://www.youtube.com/watch?v=BzFN9YwR-NM\u0026t=797s ","description":"Префиксные суммы","title":"Префиксные суммы","uri":"/ru/tracks/algorithms-101/data-structures/prefix-sum/"},{"content":"Подготовка коммит все предыдущего состояния на случай вынужденного отката\nДля того чтобы Actions имели доступ к репозиторию нужно подключить ключи шифрования\nНастройка репозитория Создаю ключи\nssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" Создалось 2 файла с ключами:\ngh-pages - приватный gh-pages.pub - публичный в Репозитории (не профиле)\nhttps://github.com/romankurnovskii/notion-project/settings/keys\nSettings → Deploy keys →Add new\nиз файла gh-pages.pub вставляю текст публичного ключа\nSettings → Secrets\nИмя: ACTIONS_DEPLOY_KEY\nВставляю приватный ключ из приватного файла gh-pages\nhttps://github.com/romankurnovskii/notion-project/settings/secrets/actions/new\nУдаляю ключи файлы чтобы случайно не закоммитить\nна гитхабе создаю экшн\nhttps://github.com/romankurnovskii/notion-project/new/main?filename=.github%2Fworkflows%2Fmain.yml\u0026workflow_template=blank\nActions → Create\nСоздание Actions Выбираю стандартный action (Deploy…)\nРедактирую нижнюю часть кода\n- name: Build run: | npm i npm run build npm run export - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./out npm run export - для создания статических файлов (добавлю позже)\nACTIONS_DEPLOY_KEY - название ключа, что создал ранее\npeaceiris/actions-gh-pages@v3 - action из другого популярного репозитория. Ссылаюсь на него.\nИтого код:\nname: Deploy to Github Pages on: push: branches: - main workflow_dispatch: jobs: deployment: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup Node uses: actions/setup-node@v3 with: node-version: \"lts/*\" cache: \"npm\" - name: Build run: | npm i npm run build npm run export - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./out открыть package.json\nнайти поле scripts, если нет создать:\n{ ..., \"scripts\": { \"dev\": \"next dev\", \"build\": \"next build\", \"start\": \"next start\", \"deploy\": \"vercel --prod\", \"export\": \"next export\" }, ... } Если npm run build \u0026\u0026 npm run export отработала, то хорошо\nОтладка Не отработала, ошибка:\ninfo - Copying \"static build\" directory info - No \"exportPathMap\" found in \"next.config.js\". Generating map from \"./pages\" Error: Image Optimization using Next.js' default loader is not compatible with `next export`. Possible solutions: - Use `next start` to run a server, which includes the Image Optimization API. - Use any provider which supports Image Optimization (like Vercel). - Configure a third-party loader in `next.config.js`. - Use the `loader` prop for `next/image`. Read more: https://nextjs.org/docs/messages/export-image-api https://nextjs.org/docs/api-reference/next.config.js/exportPathMap\nпример кода из документации\nmodule.exports = { exportPathMap: async function ( defaultPathMap, { dev, dir, outDir, distDir, buildId } ) { return { \"/\": { page: \"/\" }, \"/about\": { page: \"/about\" }, \"/p/hello-nextjs\": { page: \"/post\", query: { title: \"hello-nextjs\" } }, \"/p/learn-nextjs\": { page: \"/post\", query: { title: \"learn-nextjs\" } }, \"/p/deploy-nextjs\": { page: \"/post\", query: { title: \"deploy-nextjs\" } }, }; }, }; мой:\nmodule.exports = withBundleAnalyzer({ images: { domains: [\"pbs.twimg.com\"], }, }); Редактирую **next.config.js**\nДобавляю:\nconst repoName = '/notion-project' module.exports = { basePath: repoName, assetPrefix: repoName, ... https://github.com/romankurnovskii/notion-project/blob/main/next.config.js\nПроблема с установкой зависимости вовремя использованя npm установщика. Буду использовать yarn потому что он пропускает минорные уведомления для меня кажется более стабильным.\nПока разбирался с проблемы запуска экшенов и настройками нашёл новые экшены и без использования ключа. Обновлю код\nПосле того как я редактирую данные нужен они не меняются на сайте. Не меняются потому что гитхаб создаёт статические файлы, то есть нужно заново сделать новый билд. Для меня моментальные изменения не критичны поэтому я поставлю задачу билда повторяться каждый день в 7:00 утра\nДобавляю код в yaml файл\non: push: branches: [main] schedule: - cron: \"0 7 * * *\" ## every day 7 am Итоговый результат\nhttps://github.com/romankurnovskii/notion-project/blob/main/.github/workflows/main.yml\nlines (32 sloc) 867 Bytes name: Deploy to GitHub Pages on: push: branches: [main] schedule: - cron: \"0 7 * * *\" ## every day 7 am jobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x] steps: - name: Get files uses: actions/checkout@v2 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v2 with: node-version: ${{ matrix.node-version }} - name: Install packages run: yarn install - name: Build project run: yarn run build - name: Export static files run: yarn run export - name: Add .nojekyll file run: touch ./out/.nojekyll - name: Deploy uses: JamesIves/github-pages-deploy-action@4.1.1 #third party github actions / ok to use with: branch: gh-pages folder: out После тестового комитета и билда получаю 2 проблемы:\nСтилей нет, картинки не подгружены Ссылки не работают Next.js ожидает адрес вида https://username.github.io/\nА у меня в конце ещё добавляется репозиторий. Т.е. добавился ещё один уровень в пути\n- name: Deploy uses: JamesIves/github-pages-deploy-action@4.1.1 #third party github actions / ok to use with: branch: gh-pages folder: out - name: Add .nojekyll file run: touch ./out/.nojekyll Источники https://wallis.dev/blog/deploying-a-next-js-app-to-github-pages https://gregrickaby.blog/article/nextjs-github-pages https://medium.com/@anotherplanet/git-tips-next-js-github-pages-2dbc9a819cb8 https://www.linkedin.com/pulse/deploy-nextjs-app-github-pages-federico-antu%C3%B1a ","description":"Сайт на next.js использует данные из Notion. Сделать публикацию на github pages с помощью github actions","title":"Публикация next.js приложения на github pages","uri":"/ru/posts/nextjs-to-github-pages-ations/"},{"content":"Чтение файла Чтобы прочитать файл в Python, вам нужно сначала открыть файл. Вы можете сделать это, используя функцию open(). Эта функция принимает два аргумента: имя файла и режим открытия файла.\nРежим открытия файла может быть “r” (чтение), “w” (запись) или “a” (добавление).\nПример, который читает файл “example.txt” в режиме чтения и выводит его содержимое на экран:\nwith open(\"example.txt\", \"r\") as f: content = f.read() print(content) Мы используем оператор with, который автоматически закрывает файл после его использования. Функция read() читает содержимое файла и возвращает его в виде строки.\nКак читать файлы по частям Если файл очень большой, то может быть более эффективным читать его по частям.\nСамый простой способ читать файл по частям - использовать цикл. Для первого примера мы будем использовать цикл for:\nhandle = open(\"test.txt\", \"r\") for line in handle: print(line) handle.close() Здесь мы открываем файл в дескрипторе в режиме “только чтение”, а затем используем цикл for для итерации по нему.\nВот пример, который читает файл по 100 байтов за раз:\nwith open(\"example.txt\", \"r\") as f: while True: chunk = f.read(100) if not chunk: break print(chunk) Здесь мы используем цикл while для чтения файла по частям. Функция read() читает 100 байтов за раз и возвращает их в виде строки. Если возвращаемая строка пустая, значит, мы достигли конца файла, и мы выходим из цикла.\nЗапись файлов Чтобы записать данные в файл в Python, вам также нужно открыть файл с помощью функции open(), но в режиме записи (“w”) или добавления (“a”). Затем вы можете записать данные в файл, используя функцию write().\nВот пример, который записывает строку в файл “example.txt”:\nwith open(\"example.txt\", \"w\") as f: f.write(\"Hello, world!\") Здесь мы используем функцию write(), чтобы записать строку в файл.\nИспользование оператора with В Python есть небольшой встроенный оператор with, который можно использовать для упрощения чтения и записи файлов. Оператор with создает то, что в Python известно как менеджер контекста, который автоматически закроет файл, когда вы закончите его обработку. Давайте посмотрим, как это работает:\nwith open(\"test.txt\") as file_handler: for line in file_handler: print(line) ","description":"Python 101","title":"Работа с файлами","uri":"/ru/tracks/python-101/basis/file_io/"},{"content":" (ВОЛГИНА НАТАЛЬЯ АНАТОЛЬЕВНА)\nМеркантилизм как внешнеторговая теория и политика. «Игра с нулевой суммой» в торговле. Адам Смит: теория абсолютного преимущества в торговле. Давид Рикардо: теория сравнительного преимущества в торговле. Теорема Хекшера-Олина и выравнивание относительных цен на торгуемые товары. Меркантилизм как внешнеторговая теория и политика. «Игра с нулевой суммой» в торговле. Меркантилизм (15-17 вв) - это экономическая политика, цель которой — накопление в стране драгоценных металлов, средство достижения цели – активный торговый баланс, то есть превышение экспорта над импортом.\nНеобходимость активного вмешательства государства в хозяйственную деятельность, в основном в форме протекционизма: установления высоких импортных пошлин, выдачи субсидий национальным производителям и так далее. 1. Ранний меркантилизм (конец XV — середина XVI века).\nПредставители: У. Стаффорд, Де Сантис, Г. Скаруффи. В этот период в учении преобладает теория денежного баланса, в рамках которой было закреплено увеличение национального благосостояния законодательным путем: устанавливался запрет на вывоз золота и серебра за границу. Деньги выполняли только функцию средства накопления.\n2. Поздний меркантилизм (вторая половина XVI — начало XVII века).\nПредставители: Т. Ман, А. Серра, А. де Монкретьен.\nИми была создана теория торгового баланса, который обеспечивался путем активной внешней торговли. Главенствовал принцип: покупать дешевле в одной стране и продавать дороже в другой. Вывоз денежных средств за границу был разрешен. Деньгам отводились функции средства накопления и средства обращения — поздний меркантилизм трактовал деньги как капитал и признавал их товаром.\nПоздний меркантилизм был прогрессивным. Он содействовал развитию торговли, судостроения, экспортной промышленности, международного разделения труда.\nОсновные принципы:\n— регулирование внешней торговли с целью притока в страну золота и серебра; — поддержка промышленности путем импорта дешевого сырья; — протекционизм; — поощрение экспорта готовой продукции; — рост населения для поддержания низкого уровня зарплаты; — рассмотрение проблем сферы обращения в отрыве от сферы производства; — достижение экономического роста путем приумножения денежного богатства страны через государственное регулирование внешней торговли и достижение положительного сальдо торгового баланса.\nПреобладал в странах Западной Европы (преимущественно Франции, Италии и Англии). В России одним из приверженцев идей меркантилизма был выдающийся государственный деятель А. Л. Ордын-Нащекин (1605—1680).\nИгра с нулевой суммой — это противоположность беспроигрышным ситуациям — таким как торговое соглашение, которое значительно увеличивает торговлю между двумя странами — или проигрышным ситуациям, таким как война, например. В реальной жизни, однако, не всегда все так очевидно, и зачастую сложно измерить прибыли и убытки.\nИгра с нулевой суммой — это ситуация, когда, если одна сторона проигрывает, другая сторона выигрывает, а чистое изменение богатства равно нулю.\nИсточники:\nhttps://www.banki.ru/wikibank/merkantilizm/ Меркантелизм / годы /страны Адам Смит: теория абсолютного преимущества в торговле. Исследование о природе и причинах богатства народов (1776 г.) - основная работа шотландского экономиста Адама Смита.\nА. Смит (1723—1790) распространил и на мирохозяйственную сферу, впервые теоретически обосновав принцип абсолютных преимуществ (или абсолютных издержек)\n«Основное правило каждого благоразумного главы семьи состоит в том, чтобы не пытаться изготовить дома такие предметы, изготовление которых обойдется дороже, чем при покупке их на стороне… То, что представляется разумным в образе действия любой частной семьи, вряд ли может оказаться неразумным для всего королевства. Если какая-либо чужая страна может снабдить нас каким-нибудь товаром по более дешевой цене, чем мы в состоянии изготовить его, гораздо лучше покупать его у нее на некоторую часть продукта нашего собственного промышленного труда, прилагаемого в той области, в которой мы обладаем некоторым преимуществом»\nОсновой развития международной торговли служит различие в абсолютных издержках. Торговля будет приносить экономический эффект, если товары будут ввозиться из страны, где издержки абсолютно меньше, а вывозиться те товары, издержки которых в данной стране ниже, чем за рубежом.\nБлагосостояние наций зависит не столько от количества накопленного ими золота, сколько от их способностей производить конечные товары и услуги.\nОсновные положения А.Смита в теории международной торговли:\nправительствам не следует вмешиваться во внешнюю торговлю, поддерживая режим открытых рынков и свободы торговли; нации, так же как и частные лица, должны специализироваться на изготовлении товаров, в производстве которых у них есть абсолютные преимущества, и торговать ими в обмен на товары, абсолютным преимуществом в производстве которых обладают другие нации; концентрация усилий (ресурсов) стран на производстве товаров, по которым страны имеют абсолютное преимущество, приводит к увеличению общих объемов производства, росту обмена между странами продуктами своего труда; свободная торговля между странами обусловливает эффективное распределение мировых ресурсов, обеспечивая прибыль любой и каждой торгующей стране. Давид Рикардо: теория сравнительного преимущества в торговле. Теория сформулированна Давидом Рикардо (1772-1823) (классик политической экономии, последователь и одновременно оппонент Адама Смита) в начале XIX века.\nДавид Рикардо развил теорию абсолютных преимуществ Адама Смита и показал, что торговля выгодна каждой из двух стран, даже если одна из них не обладает абсолютным преимуществом в производстве любых конкретных товаров. Специализация на производстве товара, имеющего максимальные сравнительные преимущества, выгодна, даже если нет абсолютных преимуществ.\nТеория сравнительных преимуществ на примере двух стран и двух товаров\nВременные затраты на производство единицы товара:\nСыр (в ед. Вина) Вино (в ед. Сыра) Франция 2 1 Испания 4 3 В данном случае во Франции затраты времени в производстве обоих товаров меньше (она обладает абсолютным преимуществом). Согласно А. Смиту, торговля между странами принесёт выгоды только Франции. Однако, с точки зрения теории сравнительных преимуществ Д. Рикардо, при определённом соотношении цен между товарами, торговля может приводить к взаимной выгоде обеих стран даже при абсолютном преимуществе только одной из них.\nРассчитаем альтернативные цены производства каждого из товаров в каждой стране:\nАльтернативная цена производства единицы товара:\nСыр (в ед. Вина) Вино (в ед. Сыра) Франция 2 / 1 1 / 2 Испания 4 / 3 3 / 4 В данном случае одна единица сыра (например, килограмм) во Франции стоит 2 единицы вина (2 бутылки), а в Испании единица сыра стоит дешевле (4 / 3 единицы вина). В то же время единица вина в Испании стоит 3 / 4 единицы сыра, что дороже чем во Франции. Таким образом, если Франция будет производить вино для Испании, а Испания — сыр для Франции, то обе страны выиграют трудовые ресурсы. На каждой закупленной единице сыра Франция будет экономить 2 - 4 /3 = 2/3 единицы вина, а Испания 3/4-1/2=1/4 единицы сыра на каждой закупленной единице вина.\nТеорема Хекшера-Олина и выравнивание относительных цен на торгуемые товары. Теория Хекшера — Олина (теория соотношения факторов производства) - каждая страна экспортирует товары, для производства которых она обладает относительно избыточными факторами производства, и импортирует товары, для производства которых она испытывает относительный недостаток факторов производства.\nВыравнивание относительных цен на торгуемые товары - это процесс, который происходит когда цены на торгуемые товары становятся ближе к ценам на неторгуемые товары. Это может происходить из-за снижения транспортных расходов, изменения в налоговой политике или снижения тарифов на товары. Это может повлиять на решения потребителей и производителей и в конечном итоге повлиять на развитие экономики.\nИсточники:\nТеория выравнивания цен на факторы производства (теория Хекшера-Олина-Самуэльсона) ","description":"Кандидатский минимум 08.00.14 «Мировая экономика» - Тезисы ответов","title":"Раздел 1. Экономическая теория","uri":"/ru/tracks/disser/canditate-minimum/01-economic-theory/"},{"content":" БЕЛОВА ИРИНА НИКОЛАЕВНА\nПонятие и критерии «открытости» национальной экономики. Показатели открытости экономик США, стран Европы, России. Особенности развития мировой торговли товарами в 2000-2010-е годы: стоимостная динамика и товарно-географическая структура. Крупнейшие страны-экспортеры и страны-импортеры. Сущность и причины структурных сдвигов в мировой торговле промышленными товарами, сырьем, топливом и продовольствием. Место и роль России в международной торговле. Конкурентные преимущества России. Стоимостная динамика, структура и география международной торговли услугами. Крупнейшие страны-экспортеры и страны-импортеры. Международный трансферт технологий: современные каналы, формы и показатели технологического обмена между странами. Понятие и критерии «открытости» национальной экономики. Показатели открытости экономик США, стран Европы, России. Статья макроэкономика. Вопрос 3 Статистика по нешней торговле РФ 2021 Открытая национальная экономика (полностью открытое хозяйство) характеризуется полностью открытыми внутренними рынками природных ресурсов, товаров, услуг, капиталов, рабочей силы, идей, информации. Такая экономика способна обеспечить углубление специализации и кооперации в национальной экономике, рост ее конкурентоспособности за счет постоянного соперничества с иностранными фирмами на внутреннем рынке, использование позитивного мирового опыта через систему международных экономических отношений, эффективное использование принципа сравнительных преимуществ в международном разделении труда.\nКритерии:\nКритерии, которыми можно оценивать открытость экономики, включают в себя уровень торговой интеграции, уровень иностранной наличности, и уровень иностранных инвестиций.\nфакт наличия влияния внешней среды на динамику основных показателей национального экономического развития, а именно: на объем и темпы роста производства, состояние внутренних товарных рынков, занятости населения. В настоящее время стремление к открытости национальных экономик в большей степени обусловливается объективными процессами интернационализации и глобализации производства, обмена, капиталов, потребления, чем экспансией американских корпораций.\nСтепень открытости экономики\nРассчитывается как показатель экспортной квоты, который понимается как отношение объема экспорта (за год) к ВВП в следующей формуле: $Эк = Экспорт / ВВП * 100%$. Чем больше показатель Эк, тем более высока степень открытости экономики. показатель импортной квоты. Рассчитывается как отношение объема импорта (за год) к ВВП. $Ик = Импорт / ВВП * 100%$ Наиболее точный показатель - внешнеторговой квоты. Отношение суммы объемов экспорта и импорта страны (за год) к ее ВВП: $ВТк = (Экспорт+Импорт) / ВВП * 100%$. Чем больше ВТК, тем более открытой является экономика страны Показатели Экспорт+Импорт по странам\nОсобенности развития мировой торговли товарами в 2000-2010-е годы: стоимостная динамика и товарно-географическая структура. Крупнейшие страны-экспортеры и страны-импортеры. Развитие мировой торговли товарами в 2000-2010 годах было связано с несколькими особенностями, включая стоимостную динамику и товарно-географическую структуру.\nСтоимостная динамика в этот период была определена преимущественно повышением цен на энергоносители и металлы. Это привело к росту средней цены на экспортируемые товары и повышению доходов стран-экспортеров.\nТоварно-географическая структура мировой торговли также изменилась в этот период. Страны Азии, в частности Китай, значительно увеличили свою долю в мировой торговле, став самыми крупными экспортерами и импортерами. Страны Европы и Северной Америки также оставались важными участниками мировой торговли, но их доля снизилась.\nКрупнейшие страны-экспортеры в этот период были Китай, США, Германия и Япония. Они составляли более трети мирового экспорта. Китай был крупнейшим экспортером, а США и Германия занимали второе и третье место соответственно.\nКрупнейшими странами-импортерами были США, Китай, Япония и Германия. Они также составляли более трети мирового импорта. США был крупнейшим импортером, а Китай и Япония занимали второе и третье место соответственно.\nВ целом, развитие мировой торговли в 2000-2010 годах было связано с ростом цен на энергоносители и металлы, что привело к существенному увеличению стоимости товаров и усилило конкуренцию на мировом рынке. Это также привело к смещению товарно-географической структуры торговли, с ростом торговли между развитыми странами и развивающимися странами, в частности Китаем и другими странами Азии.\nОдним из важных факторов, который способствовал росту мировой торговли в этот период, был рост инвестиций в инфраструктуру и технологии в развивающихся странах, что позволило увеличить их производительность и способствовало росту экспорта. Также рост интеграции развивающихся стран в мировую экономику, в частности Китая в мировой торговле и производстве, сыграл важную роль в развитии мировой торговли.\nКрупнейшими экспортерами в 2000-2010 годах были США, Китай, Германия, Япония и Нидерланды. Эти страны вносили значительный вклад в мировой экспорт, особенно в такие отрасли как автомобилестроение, машиностроение, электроника и текстильная промышленность. США также были крупнейшим импортером, а Китай занимал второе место. Россия и другие страны СНГ также имели значительный уровень экспорта нефти и газа, но их роль в мировой торговле все еще была несущественной.\nВ целом, мирововая торговля товарами в 2000-2010 годах была существенно обусловлена стоимостной динамикой и товарно-географической структурой. Крупнейшие экспортеры и импортеры были США, Китай, Европейский союз и Япония. Эти страны имели значительное влияние на мировой рынок товаров, и их роль в торговле была ключевой в этот период. Китай и Европейский союз были особенно важными игроками, так как они стали одними из крупнейших импортеров и экспортеров товаров в мире. Россия и другие страны СНГ также имели значительный уровень экспорта нефти и газа, но их роль в мировой торговле все еще была несущественной.\nСущность и причины структурных сдвигов в мировой торговле промышленными товарами, сырьем, топливом и продовольствием. Структурные сдвигы в мировой торговле - это изменения в распределении торговли между различными группами товаров и странами. Это может быть вызвано различными факторами, включая экономические и политические изменения, технологические инновации и изменения в потребительском спросе.\nОдной из главных причин структурных сдвигов является изменение технологий и инноваций. Например, развитие информационных технологий и интернета привело к сокращению торговли физическими товарами и росту торговли цифровыми товарами и услугами. Также, развитие новых технологий в области энергетики, таких как солнечная и ветроэнергетика, может привести к сдвигу в торговле топливом и энергоресурсами.\nДругой важной причиной является изменение в мировой экономике и политике. Например, рост новых индустрий и развитие стран в Азии может привести к сдвигу в торговле с участием этих стран. Также, изменения в международной политике, такие как тарифы или ограничения на торговлю, могут привести к сдвигам в торговле между странами.\nВ целом, структурные сдвигы в мировой торговле промышленными товарами, сырьем, топливом и продовольствием являются необходимой частью эволюции мировой экономики. Они отражают изменения в технологиях, инновациях, демографии и мировой политике, которые в свою очередь оказывают влияние на развитие и эволюцию различных отраслей и рынков. Однако, необходимо учитывать, что эти сдвиги могут иметь как положительные, так и отрицательные последствия для развития стран и общества в целом. Поэтому важно проводить мониторинг и анализ сдвигов, а также разрабатывать международные инициативы и политики, которые способствуют сохранению стабильности и равновесия в мировой торговле.\nМесто и роль России в международной торговле. Конкурентные преимущества России. Россия является одной из крупнейших икономик мира, и ее место и роль в международной торговле имеет значительное значение. Россия является крупным производителем нефти, газа, металлургической продукции и других промышленных товаров, которые являются важными экспортными товарами.\nКонкурентными преимуществами России являются ее богатые природные ресурсы, как нефть, газ и металлы, а также высокоразвитая инфраструктура и квалифицированная рабочая сила. Россия также имеет развитую систему образования и науки, что позволяет ей развивать инновационные технологии и новые продукты.\nОднако, Россия также сталкивается с некоторыми проблемами в международной торговле, такими как сложности с доступом к западным рынкам и ограничения на экспорт некоторых товаров. Россия также сталкивается с конкуренцией на мировом рынке от других крупных икономик, таких как Китай и США.\nВ целом, Россия имеет значителелое место и роль в международной торговле из-за ее богатых природных ресурсов и высокоразвитой инфраструктуры. Ее конкурентные преимущества включают в себя нефть, газ, металлы, а также развитое сельское хозяйство и развитую систему образования и науки. Однако, Россия должна справиться с некоторыми проблемами в международной торговле, такими как сложности с доступом к западным рынкам и ограничения на экспорт некоторых товаров, а также с конкуренцией с другими крупными икономиками.\nВ целом, Россия имеет значительный потенциал для роста и развития в международной торговле, но для этого необходимо сделать существенные усилия.\nСтоимостная динамика, структура и география международной торговли услугами. Крупнейшие страны-экспортеры и страны-импортеры. Международная торговля услугами является важной составляющей мировой экономики, и ее стоимостная динамика, структура и география имеют значительное влияние на мировой рынок торговли.\nСтоимостная динамика международной торговли услугами зависит от множества факторов, включая экономическое развитие стран, изменения в ценах на товары и услуги, изменения в общей ситуации на рынке, а также изменения в тарифах и торговых барьерах. В последние годы международная торговля услугами стала расти быстрее, чем торговля товарами, что свидетельствует о росте значимости услуг в мировой экономике.\nСтруктура международной торговли услугами также имеет свои особенности. Крупнейшими секторами являются туризм, транспортные услуги, коммуникационные услуги и профессиональные услуги. Кроме того, международная торговля услугами часто ассоциируется с интеллектуальной собственностью и лицензиями.\nГеография международной торговли услугами также имеет свои особенности. Крупнейшими странами-экспортерами являются США, Германия и Великобритания, а странами-импортерами - Китай, Япония и Индия. Одна из важных особенностей международной торговли услугами является то, что она часто происходит между развитыми странами и развивающимися странами. Это может быть связано с тем, что развитые страны имеют более высокий уровень технологического развития и более высокий уровень образования, которые позволяют им предлагать более высококачественные услуги.\nМеждународный трансферт технологий: современные каналы, формы и показатели технологического обмена между странами. Международный трансфер технологий - это процесс передачи знаний, инноваций и технологий между странами. Современные каналы трансфера технологий включают множество форм, таких как инвестиции в исследование и разработку, лицензирование, совместное производство и совместное исследование.\nИнвестиции в исследование и разработку являются одним из наиболее эффективных способов трансфера технологий. Они позволяют компаниям и организациям приобретать новые знания и технологии, которые могут быть использованы для улучшения их продуктов и услуг.\nЛицензировование также является важным каналом трансфера технологий. Это позволяет компаниям и организациям использовать запатентованные технологии и инновации других сторон в обмен на определенную плату. Лицензирование может быть как на использование технологии, так и на ее дальнейшую разработку.\nСовместное производство и совместное сотрудничество также являются важными формами международного трансфера технологий. Это позволяет компаниям и организациям сотрудничать на месте, чтобы создавать и использовать новые технологии. Совместное производство может включать в себя совместное исследование и разработку, а также производство и маркетинг продуктов и услуг, использующих новые технологии.\nМеждународный трансферт технологий является важным фактором экономического роста и развития стран. Он позволяет странам получить доступ к новым технологиям и знаниям, которые помогают улучшить конкурентносспособность и снизить затраты. Одним из главных каналов технологического обмена является инвестиция, которая позволяет фирмам иностранного капитала инвестировать в развитие новых технологий в стране-партнере. Другими каналами являются сотрудничество в области науки и исследований, обмен специалистами и студентами, а также лицензирование и франшизинг.\nКрупнейшими странами-экспортерами технологий являются США, Япония и Германия, а крупнейшими странами-импортерами - Китай, Индия и Россия.\nОсновными формами технологического обмена между странами являются лицензирование, франчайзинг, контрактное производство, совместное исследование и разработка, партнерство и инвестиции.\nОсновные показатели технологического обмена между странами включают:\nОбъем инвестиций в исследования и разработки; Число патентов, зарегистрированных в международных организациях; Число международных стандартов, которым следуют страны; Число международных контрактов на лицензирование технологий; Число студентов, обучающихся за границей, и число иностранных студентов, обучающихся в стране; Число международных научных сотрудничеств и конференций. ","description":"Кандидатский минимум 08.00.14 «Мировая экономика» - Тезисы ответов","title":"Раздел 2. Международная торговля","uri":"/ru/tracks/disser/canditate-minimum/02-international-trade/"},{"content":" Политика «свободной торговли» и политика протекционизма в исторической перспективе. Цели и инструменты внешнеторговой политики. Таможенно-тарифное регулирование: характеристика основных институтов и их экономическое значение. Нетарифные барьеры в международной торговле. Всемирная торговая организация (ВТО): функции, задачи, система соглашений, новые направления многосторонних торговых переговоров. Россия в ВТО: сложности вступления, принятые обязательства, экономические последствия. Характеристика современного участия РФ в ВТО. Система внешнеторгового регулирования в ЕАЭС и в России. Политика «свободной торговли» и политика протекционизма в исторической перспективе. Цели и инструменты внешнеторговой политики. Политика “свободной торговли” и политика протекционизма - это две различные стратегии, которые используются государствами для регулирования их экономики.\nПолитика “свободной торговли” опирается на идею, что открытость торговли поможет создать большую эффективность и рост экономики. В то же время, политика протекционизма стремится защитить отечественное производство и рабочие места с помощью таможенных пошлин, квот и других форм регулирования.\nПолитика протекционизма в исторической перспективе - это политика, которая направлена на защиту отечественной промышленности и торговли от иностранной конкуренции. Это может быть достигнуто с помощью таких мер, как таможенные пошлины, квоты, субсидии и иные ограничения на импорт.\nИнструменты внешнеторговой политики, используемые в протекционизме, могут включать:\nТаможенные пошлины: таможенные сборы, которые увеличивают цену на импортные товары, защищая отечественное производство.\nКвоты и ограничения на импорт: ограничения на количество импортируемых товаров или специальные требования, которые делают импорт менее конкурентным.\nСубсидии для отечественного производства: государственная поддержка для отечественных производителей, чтобы сделать их более конкурентными на местном рынке.\nНационализация или контроль над ключевыми отраслями: государство объединяет контроль над ключевыми отраслями экономики, чтобы обеспечить их сохранность и развитие.\nПолитика свободной торговли:\nОсновная идея заключается в отсутствии тарифных и нетарифных барьеров на импорт и экспорт товаров и услуг между странами; Приводит к экономическому росту за счет увеличения объемов торговли и специализации производства; Основана на принципах компаративных преимуществ и абсолютной выгоды. Политика протекционизма:\nПредусматривает введение тарифов и нетарифных барьеров для защиты от импорта и поддержки отечественных производителей; Может привести к снижению объемов торговли, росту цен, нарушению конкуренции и инфляции; Используется государствами для достижения своих экономических и политических целей, например, защиты отечественной промышленности, увеличения экспорта или сокращения импорта. Цели внешнеторговой политики:\nРасширение рынков сбыта для национальной экономики; Увеличение объемов экспорта; Защита отечественной промышленности от конкуренции; Повышение уровня занятости и доходов населения; Решение политических задач, например, улучшение отношений с другими странами. Инструменты внешнеторговой политики:\nТарифы и квоты на импорт и экспорт товаров; Субсидирование отечественных производителей; Различные виды лицензирования и контроля за импортом и экспортом; Валютные манипуляции; Соглашения о свободной торговле. Таможенно-тарифное регулирование: характеристика основных институтов и их экономическое значение. Таможенно-тарифное регулирование внешнеторговой деятельности:\nСовокупность методов государственного регулирования внешнеторговой деятельности, основанных на применении пошлин, таможенных процедур, правил. Осуществляется путем установления таможенных пошлин, налогов и других ограничений на импорт и экспорт товаров. Основные институты таможенно-тарифного регулирования включают в себя:\nтарифы квоты лицензирование инспекционные и контрольные меры санкции и международное сотрудничество в области таможенного регулирования. Тарифы:\nТаможенные пошлины, которые устанавливаются на импорт и экспорт товаров для регулирования объемов торговли и защиты национальных производителей; Имеются два типа тарифов: специфические (фиксированная сумма на единицу товара) и адвалорные (процент от стоимости товара). Тарифы - это пошлины, которые налагаются на импортируемые товары, в то время как квоты ограничивают количество импортируемых товаров. Цели и задачи таможенно-тарифного регулирования:\nТаможенно-тарифное регулирование является основным методом регулирования государством сферы внешней торговли.\nЦелями могут быть:\nПротекционистская функция — защита национальных товаропроизводителей от иностранной конкуренции. Фискальная функция — обеспечение поступления средств в бюджет Институты таможенно-тарифного регулирования:\nТаможенная служба - осуществляет контроль за перемещением товаров через таможенную границу и взимает таможенные пошлины; Таможенные брокеры - предоставляют услуги по таможенному оформлению товаров и оказанию консультационной помощи по таможенному регулированию Международные организации - например, ВТО, которые регулируют правила международной торговли и снижают уровень протекционизма. Экономическое значение таможенно-тарифного регулирования:\nПозволяет государствам защитить отечественных производителей от конкуренции; Способствует повышению доходов государственного бюджета за счет сбора таможенных пошлин; Снижает уровень импорта некоторых товаров, что может способствовать развитию отечественной промышленности; Может ограничивать объемы торговли и вызывать рост цен для потребителей. Ресурсы:\nВикипедия - Таможенно-тарифное регулирование внешнеторговой деятельности Вики - Таможенный тариф Нетарифные барьеры в международной торговле. Нетарифные барьеры - при­ни­мае­мые го­су­дар­ст­вен­ны­ми и му­ни­ци­паль­ны­ми ор­га­на­ми не­та­мо­жен­но-та­риф­ные ме­ры по ре­гу­ли­ро­ва­нию внеш­ней тор­гов­ли, ко­то­рые спо­соб­ны пря­мо или кос­вен­но воз­дей­ст­во­вать на им­порт и экс­порт то­ва­ров – на их объ­ё­мы, струк­ту­ру и це­ны. Не­та­риф­ное ре­гу­ли­ро­ва­ние на­прав­ле­но на соз­да­ние для отеч. то­ва­ров бо­лее бла­го­при­ят­ных ус­ло­вий, чем для то­ва­ров ино­стр. про­ис­хо­ж­де­ния. Оно мо­жет ис­поль­зо­вать­ся так­же для диф­фе­рен­циа­ции тор­го­во­го ре­жи­ма для то­ва­ров, про­ис­хо­дя­щих из разл. стран.\nНетарифные барьеры (НБ): Это меры, которые не являются таможенными пошлинами, но ограничивают объемы торговли и влияют на конкуренцию на рынке; НБ могут быть установлены для защиты национальных производителей, обеспечения безопасности и здоровья населения, охраны окружающей среды и других целей. Виды НБ: Технические преграды - например, стандарты качества, упаковки и маркировки, которые могут ограничивать ввоз товаров; Санитарные и фитосанитарные меры - контроль за качеством и безопасностью продуктов питания, животных и растений; Антидемпинговые меры - установление дополнительных пошлин на импорт товаров, которые продаются на международном рынке ниже рыночной стоимости; Субсидирование отечественных производителей; Лицензирование импорта товаров; Дискриминационные меры, направленные против конкретных стран или регионов. Экономические последствия НБ: Могут приводить к снижению объемов торговли и сокращению выгоды от международной специализации; Увеличивают издержки для потребителей и ограничивают доступ к более качественным и дешевым товарам; Могут приводить к возникновению торговых споров и противодействию со стороны других государств; Использование НБ ограничивает конкуренцию на рынке, что может привести к росту цен и снижению инновационной активности. На­ря­ду с по­ня­ти­ем «Н. б.» (non-tariff barriers) в лит-ре ис­поль­зу­ют­ся и иные, близ­кие ему по смыс­лу – «не­та­риф­ные ог­ра­ни­че­ния» (non-tariff restraints), «не­та­риф­ные пре­пят­ст­вия» (non-tariff obstacles), «не­та­риф­ные ис­ка­же­ния» (non-tariff distortions) и др. В офи­ци­аль­ной и нор­ма­тив­но-пра­во­вой лит-ре ис­поль­зу­ет­ся по­ня­тие «не­та­риф­ные ме­ры» (non-tariff measures). Ис­то­ри­че­ски фор­ми­рова­ние ин­ст­ру­мен­та­рия ре­гу­ли­ро­ва­ния ме­ж­ду­нар. тор­гов­ли шло по пу­ти вы­де­ле­ния (раз­ли­че­ния) мер та­мо­жен­но-та­риф­но­го ре­гу­ли­ро­ва­ния (та­мо­жен­ных по­шлин) и всех иных спо­со­бов, с по­мо­щью ко­то­рых мож­но бы­ло воз­дей­ст­во­вать на неё. Про­ти­во­пос­тав­ле­ние с са­мо­го на­ча­ла Н. б. та­мо­жен­но­му та­ри­фу вы­ра­зи­лось в их на­зва­нии.\nВ до­ку­мен­тах Все­мир­ной тор­го­вой ор­га­ни­за­ции уточ­ня­ет­ся, что Н. б. мо­гут при­ме­нять­ся на ос­но­ве дос­тиг­ну­тых в рам­ках этой ор­га­ни­за­ции спец. со­гла­ше­ний (в т. ч. по ли­цен­зи­ро­ва­нию им­пор­та, за­щит­ным ме­рам, ан­ти­дем­пин­го­вым про­це­ду­рам, та­мо­жен­ной оцен­ке, стра­не про­ис­хо­ж­де­ния, с. х-ву, ин­фор­мац. тех­но­ло­ги­ям, тек­сти­лю, тех­нич. барь­е­рам в тор­гов­ле, са­ни­тар­ным и фи­то­са­ни­тар­ным ме­рам).\nНаиболее распространенные в настоящее время нетарифные меры, воздействующие на международную торговлю, охватывают следующие категории:\nколичественные ограничения и сходные административные меры (импортные и экспортные квоты, лицензии, меры валютного контроля, запреты и др.); нетарифные сборы, финансовые меры, скользящие налоги, антидемпинговые и компенсационные пошлины, защитные меры; ограничительная практика правительственных органов; субсидии и другие дотации экспортерам или импортозамещающим отраслям, предпочтительная для национальных предприятий система размещения правительственных заказов, транспортные мероприятия, дискриминирующие иностранные грузы и предприятия, региональная политика развития, устанавливающая льготы отдельным регионам, дискриминационная политика в отношении иностранных инвестиций, дискриминационная налоговая, финансовая и валютная политика; таможенные и другие пограничные формальности в том случае, когда они превышают нормальные общепринятые нормы, что превращает их в дополнительный барьер в торговле, в частности: методы таможенной оценки, система тарифной классификации, завышенные и произвольные требования к документам, необходимым для таможенного оформления, недостаточная правовая и судебная защита в спорах, возникающих по этому кругу вопросов; технические барьеры в торговле и стандарты в тех случаях, когда они затрудняют экспорт или импорт товаров или прямо дискриминируют иностранные товары; санитарные и фитосанитарные нормы. Практика последних десятилетий показывает, что применение этих норм постепенно становится все более заметным направлением их использования не столько по прямому назначению, а в качестве нетарифных мер. Анализ деятельности системы разрешения споров ВТО за последние 15 лет – яркое тому подтверждение. Влияние наиболее распространенных видов нетарифных барьеров на международную торговлю:\nЛицензия. Страны могут использовать лицензии для ограничения импорта товаров определенными предприятиями. Если компании выдана торговая лицензия, ей разрешается импортировать товары, которые в противном случае были бы ограничены для торговли в стране. Использование лицензионных систем в качестве инструмента регулирования внешней торговли основано на многих международных стандартах. В частности, эти соглашения включают некоторые положения генерального соглашения по тарифам и торговле, а также соглашения о процедурах лицензирования импорта, заключенные в рамках ГАТТ(Генеральное соглашение по тарифам и торговле). Квоты. Страны часто выдают квоты на экспорт и импорт товаров и услуг. При помощи этих квот страны договариваются об определенных лимитах на товары и услуги, разрешенные к ввозу в ту или иную страну. В большинстве случаев нет никаких ограничений на импорт этих товаров и услуг до тех пор, пока страна не достигнет своей квоты, которую она может установить на определенный период времени. Кроме того, квоты часто используются в международных торговых лицензионных соглашениях. Эмбарго. Это когда одна или несколько стран официально запрещают торговлю определенными товарами и услугами с другой страной. Правительства могут принимать такие меры в поддержку своих конкретных политических или экономических целей. Стандарты. Одним из наиболее распространенных видов нетарифных барьеров являются стандарты. Страны вводят определенный стандарт маркировки, классификации и тестирования продуктов для обеспечения соответствия отечественных и иностранных продуктов внутренним стандартам. В случае несоответствия этим стандартам идет ограничение продаж соответствующего продукта. Валютный контроль и валютные ограничения. Данные ограничения занимают важное место среди методов нетарифного регулирования внешнеэкономической деятельности. Валютные ограничения представляют собой управление операциями между национальными и иностранными операторами либо с помощью ограничения предложения иностранной валюты, тем самым ограничивая импорт, либо путем государственного манипулирования обменными курсами (в целях стимулирования экспорта и ограничения импорта). Санкции. Страны вводят санкции против других стран, чтобы ограничить их торговую деятельность. Санкции могут включать усиленные административные меры или дополнительные таможенные и торговые процедуры, которые ограничивают или замедляют способность страны вести торговлю. Основные каналы воздействия на торговлю:\nнетарифные барьеры могут ограничить полный доступ к рынкам (как в случае квот). они могут увеличить стоимость ведения бизнеса. Нетарифные барьеры, которые увеличивают издержки бизнеса, могут быть специфическими – например, соблюдение определенных стандартов на продукцию- или более общими, такими как более строгие документальные и таможенные процедуры. Ресурсы:\nНетарифные меры в современной международной торговле: некоторые вопросы теории, практика и правила ВТО, интересы России НЕТАРИФНЫЕ БАРЬЕРЫ И ИХ ВЛИЯНИЕ НА МЕЖДУНАРОДНУЮ ТОРГОВЛЮ Всемирная торговая организация (ВТО): функции, задачи, система соглашений, новые направления многосторонних торговых переговоров. Функции Всемирной торговой организации (ВТО): Регулирование международной торговли, обеспечение свободной и честной конкуренции; Разрешение торговых споров между государствами-членами; Предоставление форума для переговоров по вопросам международной торговли; Обе спечение развития экономических связей между государствами. Задачи ВТО: Создание условий для расширения международной торговли и увеличения объемов экспорта; Снижение тарифных и нетарифных барьеров на международную торговлю; Предотвращение использования протекционистских мер в торговле; Защита прав интеллектуальной собственности. Система соглашений ВТО: Соглашение о создании ВТО, основной документ, определяющий задачи и функции организации; Соглашение по тарифам и торговле (ГАТТ), устанавливающее правила торговли и ограничивающее уровень тарифов; Соглашение по аспектам прав интеллектуальной собственности, которое регулирует защиту интеллектуальной собственности, включая патенты, авторские - права и товарные знаки. Новые направления многосторонних торговых переговоров: Расширение сферы деятельности ВТО на новые секторы экономики, включая услуги и интеллектуальную собственность; Разработка новых мер по регулированию международной торговли, таких как решение проблем, связанных с электронной коммерцией; Поиск более эффективных механизмов разрешения торговых споров; Развитие взаимодействия между ВТО и другими международными организациями. Россия в ВТО: сложности вступления, принятые обязательства, экономические последствия. Характеристика современного участия РФ в ВТО. Сложности вступления России в ВТО: Вступление России в ВТО заняло более 18 лет и было связано с различными сложностями, такими как переговоры с другими государствами, в том числе с США, Евросоюзом и Китаем, а также с противодействием со стороны отдельных отраслей российской экономики. Принятые обязательства России при вступлении в ВТО: Снижение таможенных пошлин на большинство товаров и услуг; Согласование правил и процедур импорта и экспорта товаров; Разрешение торговых споров в соответствии с правилами ВТО; Подписание многосторонних соглашений и протоколов с другими государствами. Экономические последствия вступления России в ВТО: Рост объемов международной торговли; Увеличение конкуренции на внутреннем рынке; Снижение тарифных барьеров и других препятствий для въезда и выезда товаров и услуг; Развитие экспортной ориентации российской экономики. Характеристика современного участия России в ВТО: Россия активно участвует в работе организации, принимает участие в переговорах и разрешении торговых споров; Однако российские экспортеры продолжают сталкиваться с рядом препятствий при экспорте товаров, таких как технические преграды и санитарные нормы; Россия выступает за сохранение правил многосторонней торговой системы, однако также разрабатывает свою более протекционистскую торговую политику. Система внешнеторгового регулирования в ЕАЭС и в России. Система внешнеторгового регулирования в ЕАЭС: ЕАЭС (Евразийский экономический союз) - таможенный союз, созданный Россией, Беларусью, Казахстаном, Арменией и Киргизией; Члены ЕАЭС осуществляют единую внешнеторговую политику, включая согласование ставок таможенных пошлин, проведение внешнеторговых переговоров и координацию мер по борьбе с контрабандой и незаконной торговлей; ЕАЭС имеет единую систему таможенного регулирования и таможенного контроля. Система внешнеторгового регулирования в России: Россия имеет свою систему внешнеторгового регулирования, включая правила и процедуры импорта и экспорта товаров, включая таможенное оформление и таможенную очистку; Россия также регулирует ввоз и вывоз отдельных товаров, включая продукты питания, лекарства и товары, связанные с национальной безопасностью; Россия может устанавливать тарифы на импорт и экспорт товаров, а также другие нетарифные меры регулирования внешней торговли. Различия в системах внешнеторгового регулирования: В России и в ЕАЭС имеются различные правила и процедуры внешнеторгового регулирования; В рамках ЕАЭС действуют общие правила таможенного регулирования и контроля, а также единые ставки таможенных пошлин; Россия имеет больше свободы в установлении собственных тарифов и нетарифных мер регулирования внешней торговли. Сотрудничество России и ЕАЭС: Россия активно сотрудничает с государствами-членами ЕАЭС в области внешнеторгового регулирования; Россия и другие государства-члены ЕАЭС стремятся к согласованию тарифных ставок и прочих мер регулирования торговли; Россия поддерживает развитие ","description":"Кандидатский минимум 08.00.14 «Мировая экономика» - Тезисы ответов","title":"Раздел 3. Международная торговая политика","uri":"/ru/tracks/disser/canditate-minimum/03-international-policy/"},{"content":" Формы, структура и масштабы международного движения капитала. Масштабы, динамика и география прямых иностранных инвестиций. Основные инвестирующие и принимающие страны. Международная инвестиционная позиция России: динамика и состав иностранных активов и обязательств. Условия для масштабного привлечения в Россию иностранных инвестиций. Международное движение капитала - это процесс переноса финансовых ресурсов из одной страны в другую в целях получения прибыли или увеличения доходности инвестиций. Международное движение капитала имеет важное значение для экономического развития и роста стран, позволяя привлекать капитал для инвестирования в различные отрасли экономики.\nОднако, международное движение капитала также может приводить к некоторым рискам, таким как волатильность финансовых рынков, кризисы и паники, а также экономическую зависимость различных стран друг от друга. В условиях глобализации и ускоренного развития технологий международное движение капитала становится все более интенсивным, а страны развивающегося мира становятся все более зависимыми от притока иностранных инвестиций.\nОдним из важных инструментов регулирования международного движения капитала является налоговая политика, тарифное регулирование, контроль капитальных операций, международное сотрудничество и координация мер макроэкономической политики.\nФормы, структура и масштабы международного движения капитала. Формы международного движения капитала: Прямые иностранные инвестиции (ПИИ), когда иностранные компании инвестируют в зарубежные предприятия; Портфельные инвестиции, когда инвесторы покупают ценные бумаги зарубежных компаний; Кредитование и заемы, когда банки и другие финансовые институты предоставляют заемные средства зарубежным компаниям и правительствам; Инвестиции в недвижимость и другие активы. Структура международного движения капитала: Большая часть международного движения капитала сосредоточена в развитых странах, таких как США, Великобритания, Германия и Япония; Страны с развивающимися экономиками также получают значительные инвестиции, но общий объем этих инвестиций ниже, чем в развитых странах; Инвестиции в различные отрасли экономики распределены неравномерно: наибольшие объемы инвестиций приходятся на финансовый сектор, производство и добычу полезных ископаемых, а также на недвижимость. Масштабы международного движения капитала: Общий объем международного движения капитала достигает нескольких триллионов долларов ежегодно; Портфельные инвестиции составляют значительную долю международного движения капитала, особенно в развитых странах; Прямые иностранные инвестиции являются важным источником капитала для многих развивающихся стран, особенно для стран с низким уровнем инвестиционной активности. Масштабы, динамика и география прямых иностранных инвестиций. Основные инвестирующие и принимающие страны. Масштабы и динамика ПИИ: Объем ПИИ составляет многие миллиарды долларов ежегодно; Общий объем ПИИ постепенно растет на протяжении последних десятилетий; Развитые страны являются наиболее активными инвесторами в ПИИ, однако страны с развивающимися экономиками также увеличивают свою долю в общем - объеме ПИИ. География ПИИ: Европа, Северная Америка и Азия являются наиболее активными регионами по привлечению ПИИ; Крупнейшими принимающими странами являются США, Китай, Великобритания, Германия, Франция, Индия, Бразилия, Россия и др.; Основными инвестирующими странами являются США, Япония, Германия, Великобритания, Франция, Нидерланды и др. Основные направления ПИИ: Основные - это производство, добыча полезных ископаемых, финансовый сектор, телекоммуникации, информационные технологии и другие - секторы экономики; Отрасли с высокой доходностью и быстрым ростом обычно привлекают большую часть инвестиций. Россия и ПИИ: Россия привлекает значительные объемы ПИИ, особенно в нефтегазовом секторе, добыче полезных ископаемых, транспортной инфраструктуре, финансовом - секторе и других секторах экономики; Россия также активно инвестирует в другие страны, в том числе в страны СНГ, Европу, Азию и Африку; Однако, политическая нестабильность, низкая инвестиционная активность в отдельных секторах экономики и низкий уровень инновационности могут - снижать привлекательность России для иностранных инвесторов. Международная инвестиционная позиция России: динамика и состав иностранных активов и обязательств. Условия для масштабного привлечения в Россию иностранных инвестиций. Международная инвестиционная позиция России: Международная инвестиционная позиция России включает в себя иностранные активы и обязательства; В 2021 году иностранные активы России составили около $520 млрд, а обязательства - около $535 млрд; Состав иностранных активов России включает преимущественно прямые иностранные инвестиции, портфельные инвестиции и резервы Центрального банка. Динамика международной инвестиционной позиции России: С 2014 года международная инвестиционная позиция России снижается, главным образом из-за сокращения объемов внешней торговли и падения цен на нефть и газ; Однако в последнее время инвестиционная активность в России начала постепенно восстанавливаться. Условия для масштабного привлечения иностранных инвестиций в Россию: Устойчивость макроэкономической ситуации и рост экономики; Политическая стабильность и предсказуемость; Улучшение инвестиционного климата и снижение административных барьеров; Развитие инфраструктуры и увеличение эффективности бизнес-процессов; Разработка и реализация национальных программ по развитию ключевых отраслей экономики; Сотрудничество с международными организациями и инвесторами. Особенности инвестирования в Россию: Высокий уровень риска, связанный с политической цнестабильностью, санкциями и неопределенностью законодательной базы; Высокие инвестиционные риски, связанные с изменением экономической ситуации и колебаниями цен на нефть и газ; Высокий уровень коррупции и бюрократии, который может затруднять реализацию инвестиционных проектов; Высокий потенциал доходности, особенно в некоторых отраслях экономики, таких как нефтегазовая, транспортная. Ресурсы:\nКонференция ООН по торговле и развитию (ЮНКТАД/UNCTAD - United Nations Conference on Trade and Development):\nДоклады о мировых инвестициях Организация экономического сотрудничества и развития (ОЭСР/Organisation for Economic Co-operation and Development, OECD)):\nОтчеты по РФ ","description":"Кандидатский минимум 08.00.14 «Мировая экономика» - Тезисы ответов","title":"Раздел 4. Международное движение капитала","uri":"/ru/tracks/disser/canditate-minimum/04-international-capital-movement/"},{"content":" Понятие иностранной валюты. Валютный курс и паритет покупательной способности валюты. Мировой валютный рынок: понятие, функции, размер, институциональная структура, тенденции развития. Виды операций на валютном рынке. Хеджирование валютных рисков. Факторы, влияющие на формирование валютного курса. Понятие иностранной валюты. Валютный курс и паритет покупательной способности валюты. Понятие иностранной валюты: Иностранная валюта - это денежные единицы других стран, которые используются в международных финансовых - операциях; Иностранная валюта может быть использована для оплаты товаров и услуг, инвестирования, торговли на - международном валютном рынке и других целей. Валютный курс: Валютный курс - это отношение стоимости одной валюты к другой; Курс валют может изменяться в зависимости от спроса и предложения на международном валютном рынке, а - также от макроэкономической ситуации в странах-участниках; Некоторые факторы, которые могут влиять на курс валют, включают в себя инфляцию, процентные ставки, - политическую стабильность, торговый баланс и т.д. Паритет покупательной способности валюты: Паритет покупательной способности (PPP) - это теоретический концепт, который описывает ситуацию, когда - две разные валюты имеют одинаковую стоимость в разных странах; В рамках PPP цена товаров и услуг должна быть одинаковой в разных странах при использовании курса - валют, который учитывает стоимость товаров в каждой стране; PPP может использоваться для оценки действительного курса валюты и прогнозирования изменений курса в - долгосрочной перспективе. Инструменты на международном валютном рынке: Операции на межбанковском валютном рынке; Валютные фьючерсы и опционы; Спот-рынок валют, т.е. операции на продажу и покупку валюты с моментальным исполнением; Кредиты в иностранной валюте; Инвестирование в ценные бумаги и фонды, выраженные в иностранной валюте; Конверсионные операции и др. Мировой валютный рынок: понятие, функции, размер, институциональная структура, тенденции развития. Понятие мирового валютного рынка: Мировой валютный рынок - это рынок, на котором торгуются валюты разных стран; Рынок включает в себя банки, биржи, фондовые рынки, государственные резервы и другие участники. Функции мирового валютного рынка: Обеспечение доступности иностранной валюты для международных торговых операций; Обеспечение ликвидности на международном уровне; Определение валютных курсов; Формирование цен на различные активы, связанные с валютами, такие как ценные бумаги и фьючерсы. Размер мирового валютного рынка: Размер мирового валютного рынка включает в себя все валюты мира и может быть оценен в несколько триллионов долларов; Основными валютами на мировом валютном рынке являются доллар США, евро, японская йена, британский фунт стерлингов и швейцарский франк. Институциональная структура мирового валютного рынка: Мировой валютный рынок не имеет централизованной структуры и состоит из множества финансовых институтов и участников; Основные участники рынка включают в себя центральные банки, коммерческие банки, инвестиционные фонды, хедж-фонды, фондовые биржи, брокерские фирмы и другие финансовые институты. Тенденции развития мирового валютного рынка: Глобализация и расширение международной торговли; Развитие электронной торговли на международном валютном рынке; Изменение роли национальных валют на мировом уровне; Усиление регулирования и надзора на мировом валютном рынке; Развитие новых финансовых инструментов на мировом валютном рынке; Изменение конкурентной среды и структуры рынка на мировом уровне. Ресурсы:\nДанные Банка международных расчетов (BIS) предоставляют информацию о международном валютном рынке, его размере и участниках: https://www.bis.org/statistics/rpfx19.htm Виды операций на валютном рынке. Хеджирование валютных рисков. Виды операций на валютном рынке: Операции на спот-рынке валют, включая операции покупки/продажи валюты на моментальной основе; Форвардные операции, которые позволяют сторонам договориться о покупке/продаже валюты в будущем по фиксированной цене; Валютные фьючерсы, которые позволяют инвесторам купить/продать валюту по заранее установленной цене в будущем; Опционы на валюту, которые позволяют покупателю опции купить/продать валюту по определенной цене в определенный момент времени; Свопы, которые являются договоренностью между двумя сторонами на обмен валютами с последующим возвратом валют. Хеджирование валютных рисков: Хеджирование - это стратегия защиты инвесторов от потенциальных убытков, связанных с колебаниями валютных курсов; Хеджирование валютных рисков - это использование финансовых инструментов для снижения рисков, связанных с изменениями валютных курсов; Примеры инструментов хеджирования валютных рисков включают форвардные контракты, опционы, свопы и другие финансовые инструменты; Хеджирование валютных рисков широко используется на международном уровне, особенно в бизнесе, где компании имеют множество обязательств и активов, выраженных в различных валютах; Хеджирование валютных рисков может помочь компаниям снизить потенциальные риски, связанные с изменением валютных курсов, и защитить свои прибыли и активы. Одним из примеров компаний, использующих хеджирование валютных рисков, является международная сеть ресторанов McDonald’s. Компания использует свою программу хеджирования для защиты себя от колебаний курсов валют, которые могут значительно влиять на ее операционную прибыль, в частности, на закупку продуктов и услуг в разных странах.\nКонкретнее, McDonald’s использует финансовые деривативы, такие как валютные форварды и опционы, чтобы зафиксировать определенный курс обмена валют на будущее время. Это позволяет компании избежать возможных потерь при колебаниях курсов валют и защитить свою операционную прибыль. Например, если компания заключила сделку на закупку продуктов из другой страны на будущее время, она может использовать финансовые деривативы, чтобы защитить себя от валютных рисков, связанных с колебаниями курсов обмена валют.\nФакторы, влияющие на формирование валютного курса. Экономические факторы: Инфляция - рост инфляции может привести к понижению стоимости валюты; Процентные ставки - высокие процентные ставки могут привлечь иностранных инвесторов и увеличить спрос на валюту; Баланс платежей - неравновесие между экспортом и импортом может привести к изменению валютного курса; Экономический рост - высокий экономический рост может привести к увеличению спроса на валюту. Политические факторы: Стабильность правительства - нестабильность политической ситуации может привести к понижению стоимости валюты; Геополитические события - например, военные конфликты или террористические акты могут привести к понижению стоимости валюты; Регулирование валютного рынка - правительственные органы могут вводить различные меры, такие как интевенции на валютном рынке, которые могут повлиять на валютный курс. Факторы спроса и предложения: Изменения в спросе на валюту и предложении валюты могут привести к изменению валютного курса; Наличие большого спроса на валюту может привести к повышению ее стоимости, тогда как избыток валюты на рынке может привести к ее понижению. Технические факторы: Технические анализы - основанные на данных о прошлых изменениях валютного курса, а также на технических показателях, могут помочь предсказать будущие изменения валютного курса; Наличие больших игроков на рынке - таких как крупные банки или хедж-фонды, может оказывать значительное влияние на валютный курс. ","description":"Кандидатский минимум 08.00.14 «Мировая экономика» - Тезисы ответов","title":"Раздел 5. Международный валютный рынок","uri":"/ru/tracks/disser/canditate-minimum/05-international-foreign-exchange-market/"},{"content":"Валютные форварды (forward contracts) - это договоры, в рамках которых две стороны соглашаются на обмен активами (обычно это валюты, сырьевые товары или финансовые инструменты) на определенную дату в будущем по заранее оговоренной цене. Это финансовый инструмент, который используется компаниями и инвесторами для защиты от рисков колебаний курсов валют. Например, если компания знает, что ей нужно купить определенную сумму валюты на будущее время для оплаты поставок, она может заключить валютный форвард, чтобы зафиксировать курс обмена на определенный период времени. Таким образом, она может избежать потерь от колебаний курса валют и защитить свою операционную прибыль.\nФорварды являются одним из инструментов хеджирования рисков и используются для защиты от потенциальных потерь, связанных с колебаниями цен на активы. Например, компания, занимающаяся импортом товаров, может заключить форвардный контракт на покупку валюты по фиксированной цене, чтобы защитить себя от возможного увеличения стоимости валюты в будущем.\nФорварды и фьючерсы относятся к группе финансовых инструментов, но они имеют некоторые отличия.\nФьючерсы - это стандартизованные контракты на покупку или продажу определенного актива, например, валюты, акций, сырья, в определенное время в будущем по заранее оговоренной цене. Фьючерсы торгуются на биржах и обычно имеют строгие правила в отношении размера контракта, срока исполнения, стоимости и способа расчета.\nФьючерсы имеют ряд особенностей:\nСтандартизация: все фьючерсы имеют одинаковый размер, срок действия, тип и спецификацию актива, на который они ссылаются. Кредитный риск: каждая сторона должна обеспечить свои обязательства по фьючерсному контракту, что означает, что обе стороны могут быть подвержены кредитному риску, если одна из них не исполнит свои обязательства. Маржинальное финансирование: для уменьшения кредитного риска стороны должны вносить маржу (внесение определенного денежного залога) в течение срока действия контракта. Ликвидность: фьючерсы торгуются на биржах, что обеспечивает высокую ликвидность контрактов и возможность быстрой покупки или продажи актива по рыночной цене. Спекулятивные операции: фьючерсы могут использоваться не только для защиты от рисков, но и для спекулятивных операций с целью получения прибыли от изменения цен активов. Форварды - это договоренности о покупке или продаже определенного актива в будущем по заранее оговоренной цене. Они не стандартизованы и заключаются напрямую между двумя контрагентами. Форварды обычно не торгуются на биржах и могут иметь различные условия, например, размер контракта, дата исполнения и расчета.\nФорвардные контракты могут быть настроены индивидуально для каждой стороны, в отличие от фьючерсов, которые стандартизированы и торгуются на биржах. Также, в отличие от фьючерсов, форварды не имеют стандартных условий исполнения и могут быть заключены на любой актив и на любой период времени.\nТаким образом, форварды и фьючерсы имеют некоторые сходства, но их различия заключаются в степени стандартизации, регулирования и доступности для обычных инвесторов.\n","description":"Сравнение Валютных форвардов и Фьючерсов","title":"Разница Валютные форварды и Фьючерсы","uri":"/ru/posts/economics/diff-forward-contracts-futures/"},{"content":"Маржинализм и меркантилизм - это два разных термина, которые описывают различные экономические концепции.\nМаржинализм - (Неоклассическое направление) - середина XIX в, это экономическая теория, которая основана на идее, что цена товара или услуги определяется его маржой, то есть разницей между продажной ценой и затратами на его производство. В рамках маржинализма обычно считается, что рост маржи является показателем эффективности экономики.\nМаржинализм использует такие величины, как предельная полезность, предельная производительность, предельные издержки\nОдним из главных аспектов является «субъективизм» - подход, при котором все явления в экономике оцениваются, а также исследуются с точки зрения определенного субъекта.\nОсновные элементы маржинализма:\nИспользование предельных (т.е. приростных) величин. Само слово «маржинализм» происходит от латинского margo, что означает край, предел. Маржиналистов интересует то, насколько изменится та или иная величина при изменении другой величины на единицу. В этом смысле весьма удобным оказывается использование дифференциального исчисления, в котором все построено на соотношении приростов разных величин. Субъективизм, т.е. подход, при котором все экономические явления исследуются и оцениваются с точки зрения отдельного хозяйствующего субъекта. Недаром маржинализм иногда называют субъективной школой экономики. Гедонизм хозяйствующих субъектов. Человек рассматривался маржиналистами как рациональное существо, целью которого является максимизация собственного удовлетворения. После Маржиналистской революции экономическая теория из науки о материальном богатстве превратилась в науку о рациональном поведении людей.\nМетодологический индивидуализм. Согласно этому методологическому принципу, закономерности функционирования хозяйства в целом выводятся из поведения отдельно взятого хозяйствующего субъекта. Как писал один из творцов Маржиналистской революции К. Менгер, «то наблюдение, которое мы сперва сделали над изолированным индивидом, а затем над маленьким обществом, временно отделенным от остальных людей, равным образом относится и к более сложным отношениям народа и человеческого общества вообще»[1][1].\nСтатичность. Маржиналисты потеряли интерес к «законам движения» капитализма, которыми занимались классики. Акцент экономических исследований после Маржиналистской революции сместился к изучению использования редких ресурсов для удовлетворения потребностей людей в данный момент времени.\nЗамена причинно-следственного анализа функциональным. Это также стимулировало применение в экономической науке математических методов.\nЛиквидация приоритета сферы производства, характерного для экономического анализа классиков. Вместо этого на ранней стадии своего развития маржинализма акцент был перенесен на сферу потребления.\nАкцент на применении дедуктивных методов исследования в противоположность историзму и индукции.\nВосприятие рыночной экономики как равновесной системы (хотя последнее было не характерно для австрийской школы маржинализма). Эта равновесность неразрывна связана с рациональным оптимизирующим поведением, поскольку неравновесные состояния экономики - т. е. те состояния, которые не удовлетворяют рациональных хозяйствующих субъектов - корректируются их действиями и приводятся к равновесию.\nМеркантилизм - это экономическая теория, которая основана на идее, что основной движущей силой экономики является спрос. Меркантилисты считают, что рост спроса способствует росту экономики и снижению безработицы.\nМеркантилизм (Англия) - первая школа экономической науки. Представители: Томас Ман, Джон Лоу, Ричард Кантильон. Главным источником богатства представители этой школы считали торговлю, а богатство отождествляли с золотом.\nОсновные принципы меркантилизма:\nзолото и другие сокровища являются главным богатством общества; главный источник получения богатства – внешняя торговля и денежный оборот для обеспечения притока в страну золота и серебра; государство должно активно вмешиваться в экономику страны; внутри страны производство развивается за счет импорта дешевого сырья; поощряется экспорт; низкий уровень поддержания заработной платы за счет роста населения. Необходимым условием для развития экономики меркантилисты считали превышение экспорта над импортом (активный торговый баланс).\n«ранний» меркантилизм (до середины XVI в.); «поздний» меркантилизм (середина XVI – середина XVII в.); начало установления торговых связей между странами за счет предложения относительно дешевых товаров; использование золота и серебра чаще в посреднических сделках. В общем маржинализм сосредоточен на стоимости производства и продаже товара, в то время как меркантилизм сосредоточен на спросе и потребностях потребителей. Они оба имеют разные подходы к управлению экономикой и оба имеют свои достоинства и недостатки.\nРесурсы Этапы развития экономической теории: меркантилизм, физиократы, классическая теория, марксизм, маржинализм, кейнсианство, институционализм, монетаризм Маржинализм и неоклассика ","description":"Сравнение Меркантилизма и Маржинализма","title":"Разница между Маржинализмом и Меркантилизмом","uri":"/ru/posts/economics/raznica-mezhdu-marzhinalizmom-i-nerkantilizmom/"},{"content":"Эта статья предлагает пример базового синтаксиса Markdown, который можно использовать в файлах содержимого Hugo, а также показывает, украшаются ли основные элементы HTML с помощью CSS в теме Hugo.\nРекомендации по оформления статьи\nЗаголовки Заголовки первого и второго уровней, выполненные с помощью подчеркивания, выглядят следующим образом:\nЗаголовок первого уровня ======================== Заголовок второго уровня ------------------------- Заголовок первого уровня Заголовок второго уровня Заголовки всех шести уровней можно обозначать и с помощью символа («#»)\n# H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 H1 H2 H3 H4 H5 H6 Параграфы Для оформления абзацев в html используются теги \u003cp\u003e\u003c/p\u003e, но в Markdown блок текста автоматически преобразуется в параграф.\nДля вставки пустой строки необходимо два раза поставить символ переноса строки (нажать на Enter)\nLorem ipsum dolor sit amet, consectetur adipisicing elit. Consequuntur eius in labore quidem, sequi suscipit! Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aliquam aut commodi debitis ipsam nobis perspiciatis sequi, sint unde vitae. Цитаты Элемент blockquote представляет содержимое, которое цитируется из другого источника, по желанию с цитатой, которая должна находиться в элементе footer или cite, и по желанию с изменениями в строке, такими как аннотации и сокращения.\nБлок-цитата без указания авторства Tiam, ad mint andaepu dandae nostion secatur sequo quae. Обратите внимание, что вы можете использовать синтаксис Markdown внутри блочной цитаты.\nБлок-цитата с указанием авторства Don’t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n\u003eЭто пример цитаты, \u003eв которой перед каждой строкой \u003eставится угловая скобка. \u003eЭто пример цитаты, в которой угловая скобка ставится только перед началом нового параграфа. \u003eВторой параграф. Это пример цитаты, в которой перед каждой строкой ставится угловая скобка.\nЭто пример цитаты, в которой угловая скобка ставится только перед началом нового параграфа. Второй параграф.\n\u003e Первый уровень цитирования \u003e\u003e Второй уровень цитирования \u003e\u003e\u003e Третий уровень цитирования \u003e \u003eПервый уровень цитирования Первый уровень цитирования\nВторой уровень цитирования\nТретий уровень цитирования\nПервый уровень цитирования\nТаблицы Таблицы не являются частью основной спецификации Markdown, но Hugo поддерживает их из коробки.\n| Name | Age | | ----- | --- | | Bob | 27 | | Alice | 23 | Name Age Bob 27 Alice 23 В ячейках разделительной строки используются только символы - и :. Символ : ставится в начале, в конце или с обеих сторон содержимого ячейки разделительной строки, чтобы обозначить выравнивание текста в соответствующем столбце по левой стороне, по правой стороне или по центру.\nКолонка по левому краю | Колонка по правому краю | Колонка по центру :--- | ---: | :---: Текст | Текст | Текст Колонка по левому краю Колонка по правому краю Колонка по центру Текст Текст Текст Markdown внутри таблицы | Italics | Bold | Code | | --------- | -------- | ------ | | *italics* | **bold** | `code` | Italics Bold Code italics bold code Блоки кода Блок кода с обратными кавычками \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Блок кода с отступом в четыре пробела \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Блок кода с внутренним шорткодом подсветки Hugo \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Списки Оформляйте заголовки единообразно. В конце заголовка точку не ставьте.\nПравильно Неправильно Получение сертификата Создание кластера Получить сертификат Создание кластера Получить сертификат Создать кластер Если требуется описать последовательность действий, используйте нумерованный список. В конце строк ставьте точку.\nЕсли порядок пунктов неважен, используйте маркированный список. Оформляйте его одним из способов:\nЕсли элементы списка — отдельные предложения, начинайте их с заглавной буквы и ставьте точку в конце. Если вводная фраза и список составляют одно предложение, то элементы списка должны начинаться со строчной буквы и завершаться точкой с запятой. Последний элемент списка завершается точкой. Если список состоит из названий или значений параметров (без пояснений), знаки в конце строк не ставьте. Упорядоченный список First item Second item Third item Чтобы оформить упорядоченный нумерованный список, используйте цифры с символом . или ). Рекомендованный формат разметки: цифра 1 и символ ..\n1. Первый пункт 1. Второй пункт 1. Третий пункт будет отображаться как:\nПервый пункт Второй пункт Третий пункт Чтобы оформить вложенный упорядоченный список, добавьте отступ для элементов дочернего списка. Допустимый размер отступа — от двух до пяти пробелов. Рекомендуемый размер отступа — четыре пробела.\nНапример, разметка:\n1. Первый пункт 1. Вложенный пункт 1. Вложенный пункт 1. Второй пункт будет отображаться как:\nПервый пункт Вложенный пункт Вложенный пункт Второй пункт Неупорядоченный список List item Another item And another item Вложенный список Fruit Apple Orange Banana Dairy Milk Cheese Другие элементы - abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n💡 Структура данных — это контейнер, который хранит данные в определённом формате. Этот контейнер решает, каким образом внешний мир может эти данные считать или изменить.\nПриведенная выше цитата взята из книги Роба Пайка talk during Gopherfest, November 18, 2015. ↩︎\n","description":"Руководство по оформлению Markdown файлов","title":"Руководство по оформлению Markdown файлов","uri":"/ru/posts/markdown-syntax/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nДелать снимок и получать из него данные, используя элемент canvas. Обмениваться изображениями с удаленным пользователем. Полная версия этого шага находится в папке step-06.\nКак это работает\nРанее вы узнали, как обмениваться текстовыми сообщениями с помощью RTCDataChannel.\nЭтот шаг позволяет обмениваться целыми файлами: в этом примере - фотографиями, снятыми с помощью getUserMedia().\nОсновные части этого шага заключаются в следующем:\nУстановите канал передачи данных. Обратите внимание, что на этом шаге вы не добавляете никаких медиапотоков к одноранговому соединению. Захватите видеопоток пользователя с веб-камеры с помощью getUserMedia(): var video = document.getElementById('video'); function grabWebCamVideo() { console.log('Getting user media (video) ...'); navigator.mediaDevices.getUserMedia({ video: true }) .then(gotStream) .catch(function(e) { alert('getUserMedia() error: ' + e.name); }); } Когда пользователь нажимает кнопку Snap, получает снимок (видеокадр) из видеопотока и отображает его в элементе canvas: var photo = document.getElementById('photo'); var photoContext = photo.getContext('2d'); function snapPhoto() { photoContext.drawImage(video, 0, 0, photo.width, photo.height); show(photo, sendBtn); } Когда пользователь нажимает кнопку Send, преобразуйте изображение в байты и отправьте их по каналу передачи данных: function sendPhoto() { // Split data channel message in chunks of this byte length. var CHUNK_LEN = 64000; var img = photoContext.getImageData(0, 0, photoContextW, photoContextH), len = img.data.byteLength, n = len / CHUNK_LEN | 0; console.log('Sending a total of ' + len + ' byte(s)'); dataChannel.send(len); // split the photo and send in chunks of about 64KB for (var i = 0; i \u003c n; i++) { var start = i * CHUNK_LEN, end = (i + 1) * CHUNK_LEN; console.log(start + ' - ' + (end - 1)); dataChannel.send(img.data.subarray(start, end)); } // send the reminder, if any if (len % CHUNK_LEN) { console.log('last ' + len % CHUNK_LEN + ' byte(s)'); dataChannel.send(img.data.subarray(n * CHUNK_LEN)); } } Принимающая сторона преобразует байты сообщений канала передачи данных обратно в изображение и отображает изображение пользователю: function receiveDataChromeFactory() { var buf, count; return function onmessage(event) { if (typeof event.data === 'string') { buf = window.buf = new Uint8ClampedArray(parseInt(event.data)); count = 0; console.log('Expecting a total of ' + buf.byteLength + ' bytes'); return; } var data = new Uint8ClampedArray(event.data); buf.set(data, count); count += data.byteLength; console.log('count: ' + count); if (count === buf.byteLength) { // we're done: all data chunks have been received console.log('Done. Rendering photo.'); renderPhoto(buf); } }; } function renderPhoto(data) { var canvas = document.createElement('canvas'); canvas.width = photoContextW; canvas.height = photoContextH; canvas.classList.add('incomingPhoto'); // trail is the element holding the incoming images trail.insertBefore(canvas, trail.firstChild); var context = canvas.getContext('2d'); var img = context.createImageData(photoContextW, photoContextH); img.data.set(data); context.putImageData(img, 0, 0); } Получите код\nЗамените содержимое вашей папки work содержимым из step-06. Ваш файл index.html в папке work теперь должен выглядеть следующим образом :\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003ch2\u003e \u003cspan\u003eRoom URL: \u003c/span\u003e\u003cspan id=\"url\"\u003e...\u003c/span\u003e \u003c/h2\u003e \u003cdiv id=\"videoCanvas\"\u003e \u003cvideo id=\"camera\" autoplay\u003e\u003c/video\u003e \u003ccanvas id=\"photo\"\u003e\u003c/canvas\u003e \u003c/div\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"snap\"\u003eSnap\u003c/button\u003e\u003cspan\u003e then \u003c/span\u003e\u003cbutton id=\"send\"\u003eSend\u003c/button\u003e \u003cspan\u003e or \u003c/span\u003e \u003cbutton id=\"snapAndSend\"\u003eSnap \u0026amp; Send\u003c/button\u003e \u003c/div\u003e \u003cdiv id=\"incoming\"\u003e \u003ch2\u003eIncoming photos\u003c/h2\u003e \u003cdiv id=\"trail\"\u003e\u003c/div\u003e \u003c/div\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Если вы не отслеживаете эту codelab из своей папки work, вам может потребоваться установить зависимости для папки step-06 или вашей текущей рабочей папки. Просто запустите следующую команду из своей рабочей папки:\nnpm install После установки, если ваш Node.js сервер не запущен, запустите его, вызвав следующую команду из вашей папки work: node index.js\nУбедитесь, что вы используете версию index.js, который реализует Socket.IO, и не забудьте перезапустить ваш сервер Node.js, если вы собираетесь что-то менять. Для большей информации на Node и Socket.IO, загляните в раздел «Set up a signaling service to exchange messages».\nПри необходимости нажмите на кнопку Allow, чтобы разрешить приложению использовать вашу веб-камеру.\nПриложение создаст случайный ID комнаты, и добавьте этот ID в URL. Откройте URL из адресной стройки в новой вкладке или окне браузера.\nНажмите кнопку Snap\u0026Send и затем посмотрите входящую область в другой вкладке внизу страницы. Приложение переносит фотографии между вкладками.\nВы должны увидеть что-то типа этого:\nБонусные задания:\nКак вы можете изменить код, чтобы сделать возможным совместное использование файлов любого типа? Узнайте больше\nThe MediaStream Image Capture API (https://www.chromestatus.com/features/4843864737185792): API для фотосъемки и управления камерами — скоро появится в браузере! API MediaRecorder для записи аудио и видео: демо-примеры (https://webrtc.github.io/samples/src/content/getusermedia/record/) и документация (https://www.chromestatus.com/features/5929649028726784) Что вы узнали\nКак делать фото и получать из нее данные с помощью элемента canvas. Как обмениваться этими данными с удаленным пользователем. Полная версия этого шага находится в папке step-06.\n","description":"Карманная книга по WebRTC","title":"Сделайте фото и отправьте его через канал данных","uri":"/ru/tracks/webrtc/practice/practice-take-photo/"},{"content":"Словарь - это коллекция, которая позволяет хранить пары ключ-значение. В отличие от списков, словари не имеют порядка, и доступ к элементам словаря осуществляется по ключу, а не по индексу.\nСоздание Для создания словаря используется фигурная скобка {} с ключами и значениями, разделенными двоеточием. Можно также использовать функцию dict() для создания словаря.\nПример создания словаря:\nmy_dict = {'name': 'John', 'age': 25, 'city': 'New York'} my_dict_2 = dict(name='Mary', age=30, city='London') Для доступа к элементам словаря используется ключ. Например, чтобы получить значение, связанное с ключом “name”, можно использовать следующий синтаксис:\nname = my_dict['name'] name = my_dict.get('name', None) # вернет None если такого ключа нету Чтобы добавить новый элемент в словарь, просто создайте новую пару ключ-значение:\nmy_dict['occupation'] = 'engineer' Методы keys(): возвращает все ключи словаря values(): возвращает все значения словаря items(): возвращает все пары ключ-значение словаря в виде кортежей А также: 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values'\nkeys = my_dict.keys() # Получение всех ключей словаря values = my_dict.values() # Получение всех значений словаря items = my_dict.items() # Получение всех пар ключ-значение словаря Применение Словари - это очень мощный инструмент, который часто используется в программировании для хранения и управления данными.\n","description":"Python 101","title":"Словари","uri":"/ru/tracks/python-101/basis/dict/"},{"content":"Дата Текущая import datetime x = datetime.datetime.now() # 2022-08-04 21:41:24.871910 Формат YYYY-MM-DD import datetime x = datetime.datetime.now().strftime(\"%Y-%m-%d\") # 2022-08-04 Создать папку import os if not os.path.exists(name): os.makedirs(name) Самое часто встречаемое значение в списке import collections x = [1, 2, 7, 4, 5, 6, 7, 10] print(collections.Counter(x).most_common(1)[0][0]) # 7 def most_freq(list): return max(set(list), key=list.count) test = [10, 10, 20, 20, 10, 30, 30, 30, 20, 10] print(most_freq(test)) # 10 Случайное целое число import random x = random.randint(1, 10) # 9 Одновременная проверка нескольких флагов в Python x, y, z = 0, 1, 0 if x == 1 or y == 1 or z == 1: print('passed') if 1 in (x, y, z): print('passed') # These only test for truthiness: if x or y or z: print('passed') if any((x, y, z)): print('passed') Pdf -\u003e Audio import PyPDF2, pyttsx3 # PDF file path = open('clcoding.pdf', 'rb') # creating a PdfFileReader object pdfReader = PyPDF2.PdfFileReader(path) # Get an engine instance for the speech synthesis speak = pyttsx3.init() for pages in range(pdfReader.numPages): text = pdfReader.getPage(pages).extractText() speak.say(text) speak.runAndWait() speak.stop() Полный обзор # Однострочные комментарии начинаются с символа решётки. \"\"\" Многострочный текст может быть записан, используя 3 знака \" и обычно используется в качестве встроенной документации \"\"\" #################################################### ## 1. Примитивные типы данных и операторы #################################################### # У вас есть числа 3 # =\u003e 3 # Математика работает вполне ожидаемо 1 + 1 # =\u003e 2 8 - 1 # =\u003e 7 10 * 2 # =\u003e 20 35 / 5 # =\u003e 7.0 # Результат целочисленного деления округляется в меньшую сторону # как для положительных, так и для отрицательных чисел. 5 // 3 # =\u003e 1 -5 // 3 # =\u003e -2 5.0 // 3.0 # =\u003e 1.0 # работает и для чисел с плавающей запятой -5.0 // 3.0 # =\u003e -2.0 # # Результат деления возвращает число с плавающей запятой 10.0 / 3 # =\u003e 3.3333333333333335 # Остаток от деления 7 % 3 # =\u003e 1 # Возведение в степень 2**3 # =\u003e 8 # Приоритет операций указывается скобками 1 + 3 * 2 # =\u003e 7 (1 + 3) * 2 # =\u003e 8 # Булевы значения - примитивы (Обратите внимание на заглавную букву) True # =\u003e True False # =\u003e False # Для отрицания используется ключевое слово not not True # =\u003e False not False # =\u003e True # Булевы операторы # Обратите внимание: ключевые слова \"and\" и \"or\" чувствительны к регистру букв True and False # =\u003e False False or True # =\u003e True # True и False на самом деле 1 и 0, но с разными ключевыми словами True + True # =\u003e 2 True * 8 # =\u003e 8 False - 5 # =\u003e -5 # Операторы сравнения обращают внимание на числовое значение True и False 0 == False # =\u003e True 1 == True # =\u003e True 2 == True # =\u003e False -5 != False # =\u003e True # Использование булевых логических операторов на типах int превращает их в булевы значения, но возвращаются оригинальные значения # Не путайте с bool(ints) и bitwise and/or (\u0026,|) bool(0) # =\u003e False bool(4) # =\u003e True bool(-6) # =\u003e True 0 and 2 # =\u003e 0 -5 or 0 # =\u003e -5 # Равенство — это == 1 == 1 # =\u003e True 2 == 1 # =\u003e False # Неравенство — это != 1 != 1 # =\u003e False 2 != 1 # =\u003e True # Ещё немного сравнений 1 \u003c 10 # =\u003e True 1 \u003e 10 # =\u003e False 2 \u003c= 2 # =\u003e True 2 \u003e= 2 # =\u003e True # Проверка, находится ли значение в диапазоне 1 \u003c 2 and 2 \u003c 3 # =\u003e True 2 \u003c 3 and 3 \u003c 2 # =\u003e False # Сравнения могут быть записаны цепочкой 1 \u003c 2 \u003c 3 # =\u003e True 2 \u003c 3 \u003c 2 # =\u003e False # (is vs. ==) ключевое слово is проверяет, относятся ли две переменные к одному и тому же объекту, но == проверяет если указанные объекты имеют одинаковые значения. a = [1, 2, 3, 4] # a указывает на новый список, [1, 2, 3, 4] b = a # b указывает на то, что указывает a b is a # =\u003e True, a и b относятся к одному и тому же объекту b == a # =\u003e True, Объекты a и b равны b = [1, 2, 3, 4] # b указывает на новый список, [1, 2, 3, 4] b is a # =\u003e False, a и b не относятся к одному и тому же объекту b == a # =\u003e True, Объекты a и b равны # Строки определяются символом \" или ' \"Это строка.\" 'Это тоже строка.' # И строки тоже могут складываться! Хотя лучше не злоупотребляйте этим. \"Привет \" + \"мир!\" # =\u003e \"Привет мир!\" # Строки (но не переменные) могут быть объединены без использования '+' \"Привет \" \"мир!\" # =\u003e \"Привет мир!\" # Со строкой можно работать, как со списком символов \"Привет мир!\"[0] # =\u003e 'П' # Вы можете найти длину строки len(\"Это строка\") # =\u003e 10 # Вы также можете форматировать, используя f-строки (в Python 3.6+) name = \"Рейко\" f\"Она сказала, что ее зовут {name}.\" # =\u003e \"Она сказала, что ее зовут Рейко\" # Вы можете поместить любой оператор Python в фигурные скобки, и он будет выведен в строке. f\"{name} состоит из {len(name)} символов.\" # =\u003e \"Рэйко состоит из 5 символов.\" # None является объектом None # =\u003e None # Не используйте оператор равенства \"==\" для сравнения # объектов с None. Используйте для этого \"is\" \"etc\" is None # =\u003e False None is None # =\u003e True # None, 0 и пустые строки/списки/словари/кортежи приводятся к False. # Все остальные значения равны True bool(0) # =\u003e False bool(\"\") # =\u003e False bool([]) # =\u003e False bool({}) # =\u003e False bool(()) # =\u003e False #################################################### ## 2. Переменные и Коллекции #################################################### # В Python есть функция Print print(\"Я Python. Приятно познакомиться!\") # =\u003e Я Python. Приятно познакомиться! # По умолчанию функция, print() также выводит новую строку в конце. # Используйте необязательный аргумент end, чтобы изменить последнюю строку. print(\"Привет мир\", end=\"!\") # =\u003e Привет мир! # Простой способ получить входные данные из консоли input_string_var = input(\"Введите данные: \") # Возвращает данные в виде строки # Примечание: в более ранних версиях Python метод input() назывался raw_input() # Объявлять переменные перед инициализацией не нужно. # По соглашению используется нижний_регистр_с_подчёркиваниями some_var = 5 some_var # =\u003e 5 # При попытке доступа к неинициализированной переменной выбрасывается исключение. # Об исключениях см. раздел \"Поток управления и итерируемые объекты\". some_unknown_var # Выбрасывает ошибку NameError # if можно использовать как выражение # Эквивалент тернарного оператора '?:' в C \"да!\" if 0 \u003e 1 else \"нет!\" # =\u003e \"нет!\" # Списки хранят последовательности li = [] # Можно сразу начать с заполненного списка other_li = [4, 5, 6] # Объекты добавляются в конец списка методом append() li.append(1) # [1] li.append(2) # [1, 2] li.append(4) # [1, 2, 4] li.append(3) # [1, 2, 4, 3] # И удаляются с конца методом pop() li.pop() # =\u003e возвращает 3 и li становится равен [1, 2, 4] # Положим элемент обратно li.append(3) # [1, 2, 4, 3]. # Обращайтесь со списком, как с обычным массивом li[0] # =\u003e 1 # Обратимся к последнему элементу li[-1] # =\u003e 3 # Попытка выйти за границы массива приведёт к ошибке индекса li[4] # Выбрасывает ошибку IndexError # Можно обращаться к диапазону, используя так называемые срезы # (Для тех, кто любит математику, это называется замкнуто-открытый интервал). li[1:3] # Вернуть список из индекса с 1 по 3 =\u003e [2, 4] li[2:] # Вернуть список, начиная с индекса 2 =\u003e [4, 3] li[:3] # Вернуть список с начала до индекса 3 =\u003e [1, 2, 4] li[::2] # Вернуть список, выбирая каждую вторую запись =\u003e [1, 4] li[::-1] # Вернуть список в обратном порядке =\u003e [3, 4, 2, 1] # Используйте сочетания всего вышеназванного для выделения более сложных срезов # li[начало:конец:шаг] # Сделать однослойную глубокую копию, используя срезы li2 = li[:] # =\u003e li2 = [1, 2, 4, 3], но (li2 is li) вернет False. # Удаляем произвольные элементы из списка оператором del del li[2] # [1, 2, 3] # Удалить первое вхождение значения li.remove(2) # [1, 3] li.remove(2) # Выбрасывает ошибку ValueError поскольку 2 нет в списке # Вставить элемент по определенному индексу li.insert(1, 2) # [1, 2, 3] # Получить индекс первого найденного элемента, соответствующего аргументу li.index(2) # =\u003e 1 li.index(4) # Выбрасывает ошибку ValueError поскольку 4 нет в списке # Вы можете складывать, или, как ещё говорят, конкатенировать списки # Обратите внимание: значения li и other_li при этом не изменились. li + other_li # =\u003e [1, 2, 3, 4, 5, 6] # Объединять списки можно методом extend() li.extend(other_li) # Теперь li содержит [1, 2, 3, 4, 5, 6] # Проверить элемент на наличие в списке можно оператором in 1 in li # =\u003e True # Длина списка вычисляется функцией len len(li) # =\u003e 6 # Кортежи похожи на списки, только неизменяемые tup = (1, 2, 3) tup[0] # =\u003e 1 tup[0] = 3 # Выбрасывает ошибку TypeError # Обратите внимание, что кортеж длины 1 должен иметь запятую после последнего элемента, но кортежи другой длины, даже 0, не должны. type((1)) # =\u003e \u003cclass 'int'\u003e type((1,)) # =\u003e \u003cclass 'tuple'\u003e type(()) # =\u003e \u003cclass 'tuple'\u003e # Всё то же самое можно делать и с кортежами len(tup) # =\u003e 3 tup + (4, 5, 6) # =\u003e (1, 2, 3, 4, 5, 6) tup[:2] # =\u003e (1, 2) 2 in tup # =\u003e True # Вы можете распаковывать кортежи (или списки) в переменные a, b, c = (1, 2, 3) # a == 1, b == 2 и c == 3 # Вы также можете сделать расширенную распаковку a, *b, c = (1, 2, 3, 4) # a теперь 1, b теперь [2, 3] и c теперь 4 # Кортежи создаются по умолчанию, если опущены скобки d, e, f = 4, 5, 6 # кортеж 4, 5, 6 распаковывается в переменные d, e и f # соответственно, d = 4, e = 5 и f = 6 # Обратите внимание, как легко поменять местами значения двух переменных e, d = d, e # теперь d == 5, а e == 4 # Словари содержат ассоциативные массивы empty_dict = {} # Вот так описывается предзаполненный словарь filled_dict = {\"one\": 1, \"two\": 2, \"three\": 3} # Обратите внимание, что ключи для словарей должны быть неизменяемыми типами. Это # сделано для того, чтобы ключ может быть преобразован в хеш для быстрого поиска. # Неизменяемые типы включают целые числа, числа с плавающей запятой, строки, кортежи. invalid_dict = {[1,2,3]: \"123\"} # =\u003e Выбрасывает ошибку TypeError: unhashable type: 'list' valid_dict = {(1,2,3):[1,2,3]} # Однако значения могут быть любого типа. # Поиск значений с помощью [] filled_dict[\"one\"] # =\u003e 1 # Все ключи в виде списка получаются с помощью метода keys(). # Его вызов нужно обернуть в list(), так как обратно мы получаем # итерируемый объект, о которых поговорим позднее. Примечание - для Python # версии \u003c3.7, порядок словарных ключей не гарантируется. Ваши результаты могут # не точно соответствовать приведенному ниже примеру. Однако, начиная с Python 3.7 # элементы в словаре сохраняют порядок, в котором они вставляются в словарь. list(filled_dict.keys()) # =\u003e [\"three\", \"two\", \"one\"] в Python \u003c3.7 list(filled_dict.keys()) # =\u003e [\"one\", \"two\", \"three\"] в Python 3.7+ # Все значения в виде списка можно получить с помощью values(). # И снова нам нужно обернуть вызов в list(), чтобы превратить # итерируемый объект в список. # То же самое замечание насчёт порядка ключей справедливо и здесь list(filled_dict.values()) # =\u003e [3, 2, 1] в Python \u003c3.7 list(filled_dict.values()) # =\u003e [1, 2, 3] в Python 3.7+ # При помощи ключевого слова in можно проверять наличие ключей в словаре \"one\" in filled_dict # =\u003e True 1 in filled_dict # =\u003e False # Попытка получить значение по несуществующему ключу выбросит ошибку KeyError filled_dict[\"four\"] # Выбрасывает ошибку KeyError # Чтобы избежать этого, используйте метод get() filled_dict.get(\"one\") # =\u003e 1 filled_dict.get(\"four\") # =\u003e None # Метод get поддерживает аргумент по умолчанию, когда значение отсутствует filled_dict.get(\"one\", 4) # =\u003e 1 filled_dict.get(\"four\", 4) # =\u003e 4 # Метод setdefault() вставляет пару ключ-значение, только если такого ключа нет filled_dict.setdefault(\"five\", 5) # filled_dict[\"five\"] возвращает 5 filled_dict.setdefault(\"five\", 6) # filled_dict[\"five\"] по-прежнему возвращает 5 # Добавление элементов в словарь filled_dict.update({\"four\":4}) # =\u003e {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4} filled_dict[\"four\"] = 4 # Другой способ добавления элементов # Удаляйте ключи из словаря с помощью ключевого слова del del filled_dict[\"one\"] # Удаляет ключ \"one\" из словаря # После Python 3.5 вы также можете использовать дополнительные параметры распаковки {'a': 1, **{'b': 2}} # =\u003e {'a': 1, 'b': 2} {'a': 1, **{'a': 2}} # =\u003e {'a': 2} # Множества содержат... ну, в общем, множества empty_set = set() # Инициализация множества набором значений. # Да, оно выглядит примерно как словарь. Ну извините, так уж вышло. filled_set = {1, 2, 2, 3, 4} # =\u003e {1, 2, 3, 4} # Similar to keys of a dictionary, elements of a set have to be immutable. # Как и ключи словаря, элементы множества должны быть неизменяемыми. invalid_set = {[1], 1} # =\u003e Выбрасывает ошибку TypeError: unhashable type: 'list' valid_set = {(1,), 1} # Множеству можно назначать новую переменную filled_set = some_set filled_set.add(5) # {1, 2, 3, 4, 5} # В множествах нет повторяющихся элементов filled_set.add(5) # {1, 2, 3, 4, 5} # Пересечение множеств: \u0026 other_set = {3, 4, 5, 6} filled_set \u0026 other_set # =\u003e {3, 4, 5} # Объединение множеств: | filled_set | other_set # =\u003e {1, 2, 3, 4, 5, 6} # Разность множеств: - {1, 2, 3, 4} - {2, 3, 5} # =\u003e {1, 4} # Симметричная разница: ^ {1, 2, 3, 4} ^ {2, 3, 5} # =\u003e {1, 4, 5} # Проверить, является ли множество слева надмножеством множества справа {1, 2} \u003e= {1, 2, 3} # =\u003e False # Проверить, является ли множество слева подмножеством множества справа {1, 2} \u003c= {1, 2, 3} # =\u003e True # Проверка на наличие в множестве: in 2 in filled_set # =\u003e True 10 in filled_set # =\u003e False # Сделать однослойную глубокую копию filled_set = some_set.copy() # {1, 2, 3, 4, 5} filled_set is some_set # =\u003e False #################################################### ## 3. Поток управления и итерируемые объекты #################################################### # Для начала создадим переменную some_var = 5 # Так выглядит выражение if. Отступы в python очень важны! # Конвенция заключается в использовании четырех пробелов, а не табуляции. # Pезультат: \"some_var меньше, чем 10\" if some_var \u003e 10: print(\"some_var точно больше, чем 10.\") elif some_var \u003c 10: # Выражение elif необязательно. print(\"some_var меньше, чем 10.\") else: # Это тоже необязательно. print(\"some_var равно 10.\") \"\"\" Циклы For проходят по спискам. Выводит: собака — это млекопитающее кошка — это млекопитающее мышь — это млекопитающее \"\"\" for animal in [\"собака\", \"кошка\", \"мышь\"]: # Можете использовать format() для интерполяции форматированных строк print(\"{} — это млекопитающее\".format(animal)) \"\"\" \"range(число)\" возвращает список чисел от нуля до заданного числа Выводит: 0 1 2 3 \"\"\" for i in range(4): print(i) \"\"\" \"range(нижнее, верхнее)\" возвращает список чисел от нижнего числа к верхнему Выводит: 4 5 6 7 \"\"\" for i in range(4, 8): print(i) \"\"\" \"range(нижнее, верхнее, шаг)\" возвращает список чисел от нижнего числа к верхнему, от нижнего числа к верхнему, увеличивая шаг за шагом. Если шаг не указан, значение по умолчанию - 1. Выводит: 4 6 \"\"\" for i in range(4, 8, 2): print(i) \"\"\" Чтобы перебрать список и получить индекс и значение каждого элемента в списке Выводит: 0 собака 1 кошка 2 мышь \"\"\" animals = [\"собака\", \"кошка\", \"мышь\"] for i, value in enumerate(animals): print(i, value) \"\"\" Циклы while продолжаются до тех пор, пока указанное условие не станет ложным. Выводит: 0 1 2 3 \"\"\" x = 0 while x \u003c 4: print(x) x += 1 # Краткая запись для x = x + 1 # Обрабатывайте исключения блоками try/except try: # Чтобы выбросить ошибку, используется raise raise IndexError(\"Это ошибка индекса\") except IndexError as e: pass # pass — это просто отсутствие оператора. Обычно здесь происходит восстановление после ошибки. except (TypeError, NameError): pass # Несколько исключений можно обработать вместе, если нужно. else: # Необязательное выражение. Должно следовать за последним блоком except print(\"Всё хорошо!\") # Выполнится, только если не было никаких исключений finally: # Выполнить при любых обстоятельствах print(\"Мы можем очистить ресурсы здесь\") # Вместо try/finally чтобы очистить ресурсы, можно использовать оператор with with open(\"myfile.txt\") as f: for line in f: print(line) # Запись в файл contents = {\"aa\": 12, \"bb\": 21} with open(\"myfile1.txt\", \"w+\") as file: file.write(str(contents)) # Записывает строку в файл with open(\"myfile2.txt\", \"w+\") as file: file.write(json.dumps(contents)) # Записывает объект в файл # Чтение из файла with open('myfile1.txt', \"r+\") as file: contents = file.read() # Читает строку из файла print(contents) # print: {\"aa\": 12, \"bb\": 21} with open('myfile2.txt', \"r+\") as file: contents = json.load(file) # Читает объект json из файла print(contents) # print: {\"aa\": 12, \"bb\": 21} # Python предоставляет фундаментальную абстракцию, # которая называется итерируемым объектом (Iterable). # Итерируемый объект — это объект, который воспринимается как последовательность. # Объект, который возвратила функция range(), итерируемый. filled_dict = {\"one\": 1, \"two\": 2, \"three\": 3} our_iterable = filled_dict.keys() print(our_iterable) # =\u003e dict_keys(['one', 'two', 'three']). Это объект, реализующий интерфейс Iterable # Мы можем проходить по нему циклом. for i in our_iterable: print(i) # Выводит one, two, three # Но мы не можем обращаться к элементу по индексу. our_iterable[1] # Выбрасывает ошибку TypeError # Итерируемый объект знает, как создавать итератор. our_iterator = iter(our_iterable) # Итератор может запоминать состояние при проходе по объекту. # Мы получаем следующий объект, вызывая функцию next(). next(our_iterator) # =\u003e \"one\" # Он сохраняет состояние при вызове next(). next(our_iterator) # =\u003e \"two\" next(our_iterator) # =\u003e \"three\" # Возвратив все данные, итератор выбрасывает исключение StopIterator next(our_iterator) # Выбрасывает исключение StopIteration # Мы можем проходить по нему циклом. our_iterator = iter(our_iterable) for i in our_iterator: print(i) # Выводит one, two, three # Вы можете получить сразу все элементы итератора, вызвав на нём функцию list(). list(our_iterable) # =\u003e Возвращает [\"one\", \"two\", \"three\"] list(our_iterator) # =\u003e Возвращает [] потому что состояние сохраняется #################################################### ## 4. Функции #################################################### # Используйте def для создания новых функций def add(x, y): print(\"x равен %s, а y равен %s\" % (x, y)) return x + y # Возвращайте результат с помощью ключевого слова return # Вызов функции с аргументами add(5, 6) # =\u003e Выводит \"x равен 5, а y равен 6\" и возвращает 11 # Другой способ вызова функции — вызов с именованными аргументами add(y=6, x=5) # Именованные аргументы можно указывать в любом порядке. # Вы можете определить функцию, принимающую переменное число аргументов def varargs(*args): return args varargs(1, 2, 3) # =\u003e (1,2,3) # А также можете определить функцию, принимающую переменное число # именованных аргументов def keyword_args(**kwargs): return kwargs # Вызовем эту функцию и посмотрим, что из этого получится keyword_args(big=\"foot\", loch=\"ness\") # =\u003e {\"big\": \"foot\", \"loch\": \"ness\"} # Если хотите, можете использовать оба способа одновременно def all_the_args(*args, **kwargs): print(args) print(kwargs) \"\"\" all_the_args(1, 2, a=3, b=4) выводит: (1, 2) {\"a\": 3, \"b\": 4} \"\"\" # Вызывая функции, можете сделать наоборот! # Используйте символ * для распаковки кортежей и ** для распаковки словарей args = (1, 2, 3, 4) kwargs = {\"a\": 3, \"b\": 4} all_the_args(*args) # эквивалентно all_the_args(1, 2, 3, 4) all_the_args(**kwargs) # эквивалентно all_the_args(a=3, b=4) all_the_args(*args, **kwargs) # эквивалентно all_the_args(1, 2, 3, 4, a=3, b=4) # Возврат нескольких значений (с назначением кортежей) def swap(x, y): return y, x # Возвращает несколько значений в виде кортежа без скобок. # (Примечание: скобки исключены, но могут быть включены) x = 1 y = 2 x, y = swap(x, y) # =\u003e x = 2, y = 1 # (x, y) = swap(x,y) # Снова, скобки были исключены, но могут быть включены. # Область определения функций x = 5 def set_x(num): # Локальная переменная x — это не то же самое, что глобальная переменная x x = num # =\u003e 43 print(x) # =\u003e 43 def set_global_x(num): global x print(x) # =\u003e 5 x = num # Глобальная переменная x теперь равна 6 print(x) # =\u003e 6 set_x(43) set_global_x(6) # Python имеет функции первого класса def create_adder(x): def adder(y): return x + y return adder add_10 = create_adder(10) add_10(3) # =\u003e 13 # Также есть и анонимные функции (lambda x: x \u003e 2)(3) # =\u003e True (lambda x, y: x ** 2 + y ** 2)(2, 1) # =\u003e 5 # Есть встроенные функции высшего порядка list(map(add_10, [1, 2, 3])) # =\u003e [11, 12, 13] list(map(max, [1, 2, 3], [4, 2, 1])) # =\u003e [4, 2, 3] list(filter(lambda x: x \u003e 5, [3, 4, 5, 6, 7])) # =\u003e [6, 7] # Для удобного отображения и фильтрации можно использовать списочные интерпретации # Интерпретация списка сохраняет вывод в виде списка, который сам может быть вложенным списком [add_10(i) for i in [1, 2, 3]] # =\u003e [11, 12, 13] [x for x in [3, 4, 5, 6, 7] if x \u003e 5] # =\u003e [6, 7] # Вы также можете создавать интерпретации множеств и словарей. {x for x in 'abcddeef' if x not in 'abc'} # =\u003e {'d', 'e', 'f'} {x: x**2 for x in range(5)} # =\u003e {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} #################################################### ## 5. Модули #################################################### # Вы можете импортировать модули import math print(math.sqrt(16)) # =\u003e 4.0 # Вы можете получить определенные функции из модуля from math import ceil, floor print(ceil(3.7)) # =\u003e 4.0 print(floor(3.7)) # =\u003e 3.0 # Вы можете импортировать все функции из модуля. # Предупреждение: это не рекомендуется from math import * # Вы можете сократить имена модулей import math as m math.sqrt(16) == m.sqrt(16) # =\u003e True # Модули Python - это обычные файлы Python. Вы # можете писать свои собственные и импортировать их. Имя # модуля совпадает с именем файла. # Вы можете узнать, какие функции и атрибуты # определены в модуле. import math dir(math) # Если у вас есть скрипт Python с именем math.py в той же папке, # что и ваш текущий скрипт, файл math.py будет # будет загружен вместо встроенного модуля Python. # Это происходит потому, что локальная папка имеет приоритет # над встроенными библиотеками Python. #################################################### ## 6. Классы #################################################### # Мы используем оператор class для создания класса class Human: # Атрибут класса. Он используется всеми экземплярами этого класса species = \"Гомосапиенс\" # Обычный конструктор, вызывается при инициализации экземпляра класса # Обратите внимание, что двойное подчёркивание в начале и в конце имени # означает объекты и атрибуты, которые используются Python, но находятся # в пространствах имён, управляемых пользователем. # Методы (или объекты или атрибуты), например: # __init__, __str__, __repr__ и т. д. называются специальными методами. # Не придумывайте им имена самостоятельно. def __init__(self, name): # Присваивание значения аргумента атрибуту self.name = name # Инициализация свойства self._age = 0 # Метод экземпляра. Все методы принимают self в качестве первого аргумента def say(self, msg): return \"{name}: {message}\".format(name=self.name, message=msg) # Другой метод экземпляра def sing(self): return 'йо... йо... проверка микрофона... раз, два... раз, два...' # Метод класса разделяется между всеми экземплярами # Они вызываются с указыванием вызывающего класса в качестве первого аргумента @classmethod def get_species(cls): return cls.species # Статический метод вызывается без ссылки на класс или экземпляр @staticmethod def grunt(): return \"*grunt*\" # property похоже на геттер. # Оно превращает метод age() в одноименный атрибут только для чтения. # Однако нет необходимости писать тривиальные геттеры и сеттеры в Python. @property def age(self): return self._age # Это позволяет установить свойство @age.setter def age(self, age): self._age = age # Это позволяет удалить свойство @age.deleter def age(self): del self._age # Когда интерпретатор Python читает исходный файл, он выполняет весь его код. # Проверка __name__ гарантирует, что этот блок кода выполняется только тогда, когда # этот модуль - это основная программа. if __name__ == '__main__': # Инициализация экземпляра класса i = Human(name=\"Иван\") i.say(\"привет\") # Выводит: \"Иван: привет\" j = Human(\"Пётр\") j.say(\"привет\") # Выводит: \"Пётр: привет\" # i и j являются экземплярами типа Human, или другими словами: они являются объектами Human # Вызов метода класса i.say(i.get_species()) # \"Иван: Гомосапиенс\" # Изменение разделяемого атрибута Human.species = \"Неандертальец\" i.say(i.get_species()) # =\u003e \"Иван: Неандертальец\" j.say(j.get_species()) # =\u003e \"Пётр: Неандертальец\" # Вызов статического метода print(Human.grunt()) # =\u003e \"*grunt*\" # Невозможно вызвать статический метод с экземпляром объекта # потому что i.grunt() автоматически поместит \"self\" (объект i) в качестве аргумента print(i.grunt()) # =\u003e TypeError: grunt() takes 0 positional arguments but 1 was given # Обновить свойство для этого экземпляра i.age = 42 # Получить свойство i.say(i.age) # =\u003e \"Иван: 42\" j.say(j.age) # =\u003e \"Пётр: 0\" # Удалить свойство del i.age # i.age # =\u003e это выбрасило бы ошибку AttributeError #################################################### ## 6.1 Наследование #################################################### # Наследование позволяет определять новые дочерние классы, которые наследуют методы и # переменные от своего родительского класса. # Используя класс Human, определенный выше как базовый или родительский класс, мы можем # определить дочерний класс Superhero, который наследует переменные класса, такие как # \"species\", \"name\" и \"age\", а также методы, такие как \"sing\" и \"grunt\" из класса Human, # но также может иметь свои уникальные свойства. # Чтобы воспользоваться преимуществами модульности по файлам, вы можете поместить # вышеперечисленные классы в их собственные файлы, например, human.py # Чтобы импортировать функции из других файлов, используйте следующий формат # from \"имя-файла-без-расширения\" import \"функция-или-класс\" from human import Human # Укажите родительский класс(ы) как параметры определения класса class Superhero(Human): # Если дочерний класс должен наследовать все определения родителя без каких-либо # изменений, вы можете просто использовать ключевое слово pass (и ничего больше), # но в этом случае оно закомментировано, чтобы разрешить уникальный дочерний класс: # pass # Дочерние классы могут переопределять атрибуты своих родителей species = 'Сверхчеловек' # Дочерние классы автоматически наследуют конструктор родительского класса, включая # его аргументы, но также могут определять дополнительные аргументы или определения # и переопределять его методы, такие как конструктор класса. # Этот конструктор наследует аргумент \"name\" от класса \"Human\" # и добавляет аргументы \"superpower\" и \"movie\": def __init__(self, name, movie=False, superpowers=[\"сверхсила\", \"пуленепробиваемость\"]): # добавить дополнительные атрибуты класса: self.fictional = True self.movie = movie # помните об изменяемых значениях по умолчанию, # поскольку значения по умолчанию являются общими self.superpowers = superpowers # Функция \"super\" позволяет вам получить доступ к методам родительского класса, # которые переопределяются дочерним, в данном случае, методом __init__. # Это вызывает конструктор родительского класса: super().__init__(name) # переопределить метод sing def sing(self): return 'Бам, бам, БАМ!' # добавить дополнительный метод экземпляра def boast(self): for power in self.superpowers: print(\"Я обладаю силой '{pow}'!\".format(pow=power)) if __name__ == '__main__': sup = Superhero(name=\"Тик\") # Проверка типа экземпляра if isinstance(sup, Human): print('Я человек') if type(sup) is Superhero: print('Я супергерой') # Получить порядок поиска разрешения метода (MRO), # используемый как getattr(), так и super() # Этот атрибут является динамическим и может быть обновлен print(Superhero.__mro__) # =\u003e (\u003cclass '__main__.Superhero'\u003e, # =\u003e \u003cclass 'human.Human'\u003e, \u003cclass 'object'\u003e) # Вызывает родительский метод, но использует свой собственный атрибут класса print(sup.get_species()) # =\u003e Сверхчеловек # Вызов переопределенного метода print(sup.sing()) # =\u003e Бам, бам, БАМ! # Вызывает метод из Human sup.say('Ложка') # =\u003e Тик: Ложка # Метод вызова, существующий только в Superhero sup.boast() # =\u003e Я обладаю силой 'сверхсила'! # =\u003e Я обладаю силой 'пуленепробиваемость'! # Атрибут унаследованного класса sup.age = 31 print(sup.age) # =\u003e 31 # Атрибут, который существует только в Superhero print('Достоин ли я Оскара? ' + str(sup.movie)) #################################################### ## 6.2 Множественное наследование #################################################### # Eще одно определение класса # bat.py class Bat: species = 'Летучая мышь' def __init__(self, can_fly=True): self.fly = can_fly # В этом классе также есть метод say def say(self, msg): msg = '... ... ...' return msg # И свой метод тоже def sonar(self): return '))) ... (((' if __name__ == '__main__': b = Bat() print(b.say('привет')) print(b.fly) # И еще одно определение класса, унаследованное от Superhero и Bat # superhero.py from superhero import Superhero from bat import Bat # Определите Batman как дочерний класс, унаследованный от Superhero и Bat class Batman(Superhero, Bat): def __init__(self, *args, **kwargs): # Обычно для наследования атрибутов необходимо вызывать super: # super(Batman, self).__init__(*args, **kwargs) # Однако здесь мы имеем дело с множественным наследованием, а super() # работает только со следующим базовым классом в списке MRO. # Поэтому вместо этого мы вызываем __init__ для всех родителей. # Использование *args и **kwargs обеспечивает чистый способ передачи # аргументов, когда каждый родитель \"очищает слой луковицы\". Superhero.__init__(self, 'анонимный', movie=True, superpowers=['Богатый'], *args, **kwargs) Bat.__init__(self, *args, can_fly=False, **kwargs) # переопределить значение атрибута name self.name = 'Грустный Бен Аффлек' def sing(self): return 'на на на на на бэтмен!' if __name__ == '__main__': sup = Batman() # Получить порядок поиска разрешения метода (MRO), # используемый как getattr(), так и super() # Этот атрибут является динамическим и может быть обновлен print(Batman.__mro__) # =\u003e (\u003cclass '__main__.Batman'\u003e, # =\u003e \u003cclass 'superhero.Superhero'\u003e, # =\u003e \u003cclass 'human.Human'\u003e, # =\u003e \u003cclass 'bat.Bat'\u003e, \u003cclass 'object'\u003e) # Вызывает родительский метод, но использует свой собственный атрибут класса print(sup.get_species()) # =\u003e Сверхчеловек # Вызов переопределенного метода print(sup.sing()) # =\u003e на на на на на бэтмен! # Вызывает метод из Human, потому что порядок наследования имеет значение sup.say('Я согласен') # =\u003e Грустный Бен Аффлек: Я согласен # Вызов метода, существующий только во втором родителе print(sup.sonar()) # =\u003e ))) ... ((( # Атрибут унаследованного класса sup.age = 100 print(sup.age) # =\u003e 100 # Унаследованный атрибут от второго родителя, # значение по умолчанию которого было переопределено. print('Могу ли я летать? ' + str(sup.fly)) # =\u003e Могу ли я летать? False #################################################### ## 7. Дополнительно #################################################### # Генераторы помогут выполнить ленивые вычисления def double_numbers(iterable): for i in iterable: yield i + i # Генераторы эффективны с точки зрения памяти, потому что они загружают только данные, # необходимые для обработки следующего значения в итерации. # Это позволяет им выполнять операции с недопустимо большими диапазонами значений. # ПРИМЕЧАНИЕ: \"range\" заменяет \"xrange\" в Python 3. for i in double_numbers(range(1, 900000000)): # \"range\" - генератор. print(i) if i \u003e= 30: break # Так же, как вы можете создать интерпретации списков, вы можете создать и # интерпретации генераторов. values = (-x for x in [1,2,3,4,5]) for x in values: print(x) # Выводит -1 -2 -3 -4 -5 # Вы также можете преобразовать интерпретацию генератора непосредственно в список. values = (-x for x in [1,2,3,4,5]) gen_to_list = list(values) print(gen_to_list) # =\u003e [-1, -2, -3, -4, -5] # Декораторы # В этом примере \"beg\" оборачивает \"say\". # Если say_please равно True, он изменит возвращаемое сообщение. from functools import wraps def beg(target_function): @wraps(target_function) def wrapper(*args, **kwargs): msg, say_please = target_function(*args, **kwargs) if say_please: return \"{} {}\".format(msg, \"Пожалуйста! Спасибо :)\") return msg return wrapper @beg def say(say_please=False): msg = \"Вы не купите мне сока?\" return msg, say_please print(say()) # Вы не купите мне сока? print(say(say_please=True)) # Вы не купите мне сока? Пожалуйста! Спасибо :) ","description":"Сниппеты Python","title":"Сниппеты Python","uri":"/ru/posts/python-snippets/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nЗапускать службу сигнализации WebRTC с помощью Socket.IO на Node.js Использовать эту службу для обмена метаданными WebRTC между узлами. Полная версия этого шага находится в папке step-05. Поменяйте HTML и JavaScript\nЗамените содержимое index.html следующим:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cdiv id=\"videos\"\u003e \u003cvideo id=\"localVideo\" autoplay muted\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay\u003e\u003c/video\u003e \u003c/div\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Замените js/main.js содержимым из step-05/js/main.js.\nЗапустите Node.js сервер\nЕсли вы не отслеживаете эту codelab из своей папки work, вам может потребоваться установить зависимости для папки step-05 или вашей текущей рабочей папки. Выполните следующую команду из своей рабочей папки: npm install\nПосле установки, если ваш Node.js сервер не запущен, запустите его, вызвав следующую команду в папке work: node index.js\nУбедитесь, что вы используете версию index.js из предыдущего шага, который реализует Socket.IO. Для получения дополнительной информации о Node и Socket.IO, посмотрите раздел “Set up a signaling service to exchange messages”. В вашем браузере откройте localhost:8080.\nСнова откройте localhost: 8080 в новой вкладке или окне. Один видеоэлемент будет отображать локальный поток из getUserMedia(), а другой будет показывать “удаленное” видео, передаваемое через RTCPeerConnection.\nВам необходимо перезапускать Node.js сервер каждый раз, когда вы закрываете клиентскую вкладку или окно. Посмотрите логи в консоли браузера.\nБонусные задания\nЭто приложение поддерживает только видеочат один на один. Как вы можете изменить дизайн, чтобы несколько человек могли посещать одну и ту же комнату видеочата? В примере строго задано имя комнаты foo. Каков наилучший способ включить другие имена комнат? Как пользователям обмениваться названием комнаты? Попробуйте создать альтернативу для обмена именами комнат. Как вы могли бы изменить приложение Что вы узнали\nНа этом шаге вы узнали, как:\nЗапускать сигналинг-службу WebRTC с помощью Socket.IO через Node.js . Использовать эту службу для обмена метаданными WebRTC между узлами. Полная версия этого шага находится в папке step-05. Советы\nСтатистика WebRTC и данные отладки доступны в chrome:// webrtc-internals. test.webrtc.org может использоваться для проверки ваших локальных настроек и тестирования камеры и микрофона. Если у вас возникли странные проблемы с кэшированием, попробуйте следующее: Выполните принудительную перезагрузку обновление, удерживая нажатой клавишу ctrl и нажав кнопку Reload Перезапустите браузер Запустите npm cache clean из командной строки. Далее\nУзнайте, как делать снимки, получать изображения и делиться ими между удаленными узлами.\n","description":"Карманная книга по WebRTC","title":"Соединение однорангового соединения и сигналинга","uri":"/ru/tracks/webrtc/practice/practice-peer-signaling-combine/"},{"content":"Список в Python похож на массив в других языках.\nСоздание В Python пустой список может быть создан следующими способами.\nmy_list = [] \u003e\u003e\u003e my_list = list() Можно обращаться к элементам списка и кортежа по индексу, начиная с нуля. Например, чтобы получить доступ к первому элементу списка, можно использовать индекс 0:\nmy_list = [1, 2, 3, \"four\", 5.0] print(my_list[0]) # выводит 1 Можно также использовать срезы (slices) для получения подмножества элементов списка или кортежа. Например, чтобы получить первые три элемента списка, можно использовать срез [0:3]:\nmy_list = [1, 2, 3, \"four\", 5.0] print(my_list[0:3]) # выводит [1, 2, 3] Вы также можете создавать списки списков следующим образом:\n\u003e\u003e\u003e my_nested_list = [my_list, my_list2] \u003e\u003e\u003e my_nested_list [[1, 2, 3], ['a', 'b', 'c']] Иногда возникает необходимость объединить два списка вместе. Первый способ - использовать метод extend:\n\u003e\u003e\u003e combo_list = [] \u003e\u003e\u003e one_list = [4, 5] \u003e\u003e\u003e combo_list.extend(one_list) \u003e\u003e\u003e combo_list [4, 5] Можно просто сложить два списка вместе:\n\u003e\u003e\u003e my_list = [1, 2, 3] \u003e\u003e\u003e my_list2 = [\"a\", \"b\", \"c\"] \u003e\u003e\u003e combo_list = my_list + my_list2 \u003e\u003e\u003e combo_list [1, 2, 3, 'a', 'b', 'c'] Методы Методы списков - это функции, которые могут быть применены к спискам. Некоторые из наиболее распространенных методов:\nappend(): добавляет элемент в конец списка. insert(): добавляет элемент в указанное место списка. pop(): удаляет последний элемент списка и возвращает его. remove(): удаляет первый элемент списка с указанным значением. sort(): сортирует элементы списка по возрастанию. reverse(): переворачивает порядок элементов списка. Примеры использования методов:\nfruits = ['apple', 'banana', 'cherry'] fruits.append('orange') # ['apple', 'banana', 'cherry', 'orange'] fruits.insert(1, 'grape') # добавить по индексу 1: ['apple', 'grape', 'banana', 'cherry', 'orange'] fruits.pop() # ['apple', 'grape', 'banana', 'cherry'] fruits.remove('banana') fruits.sort() #['apple', 'cherry', 'grape'] ","description":"Python 101","title":"Списки","uri":"/ru/tracks/python-101/basis/lists/"},{"content":"Для удобной работы с Python требуется хорошо настроенная рабочая среда. Я предпочитаю использовать Visual Studio Code - бесплатный редактор кода, разработанный Microsoft.\nДля начала, нужно установить Visual Studio Code на свой компьютер. Это можно сделать с помощью официального сайта https://code.visualstudio.com/.\nУстановка Python на MacOS и Linux очень проста. Для MacOS можно использовать менеджер пакетов brew, который позволяет установить последнюю версию Python одной командой:\nbrew install --cask visual-studio-code Для Linux, в зависимости от дистрибутива, используется свой менеджер пакетов. Например, для Ubuntu это можно сделать командой:\nsudo apt-get install code После установки необходимо установить расширение Python. Для этого необходимо перейти во вкладку “Extensions”, найти “Python” и нажать кнопку “Install”.\nСоздайте файл для проекта, например, example_1.py.\nНапишите код print(\"Hello, world!\") и запустите его, нажав на кнопку с треугольником справа вверху:\nVSCode запустит код и в нижнем окне программы в терминале вы увидите результат:\n","description":"Python 101","title":"Среда разработки","uri":"/ru/tracks/python-101/basis/ide/"},{"content":"В Python существует несколько типов данных. Основные типы данных, с которыми вы, вероятно, будете чаще всего встречаться, - это строка, целое число, плавающая цифра, список, словарь и кортеж. В этой главе мы рассмотрим строковый тип данных. Вы удивитесь, как много вещей можно делать со строками в Python прямо из коробки. Существует также модуль string, который можно импортировать для получения доступа к еще большей функциональности, но мы не будем рассматривать его в этой главе. Вместо этого мы рассмотрим следующие темы:\nКак создавать строки Конкатенация строк Методы работы со строками Нарезка строк Подстановка строк Создание Строки обычно создаются одним из трех способов. Вы можете использовать одинарные, двойные или тройные кавычки. Давайте посмотрим!\n\u003e\u003e\u003e text1 = 'Привет, мир!' \u003e\u003e\u003e text2 = \"Python - это замечательный язык программирования\" \u003e\u003e\u003e text3 = '''Строка с тройными кавычками может быть выполнена с помощью трех одинарных или трех двойных кавычек. При выводе сохраняются разрывы строк.''' Существует еще один способ создания строки - это использование метода str:\n\u003e\u003e\u003e my_number = 123 \u003e\u003e\u003e my_string = str(my_number) \u003e\u003e\u003e \u003e\u003e\u003e my_string '123' Методы Строка - это объект в Python. Фактически, все в Python является объектом.\nСтроки в Python поддерживают множество операций, включая конкатенацию (объединение строк), повторение, индексацию, извлечение срезов и многое другое.\nstring1 = 'Привет, ' string2 = 'мир!' string3 = string1 + string2 # конкатенация строк print(string3) # выведет 'Привет, мир!' string4 = 'Python ' string5 = string4 * 3 # повторение строки print(string5) # выведет 'Python Python Python' string6 = 'Hello, world!' print(string6[7]) # индексация символов, выведет 'w' string7 = 'Python is awesome' print(string7[0:6]) # извлечение среза, выведет 'Python' Существует множество других методов работы со строками. Например, если бы вы хотели, чтобы все было в нижнем регистре, вы бы использовали метод lower(). Если бы вы хотели удалить все пробелы в начале и в конце строки, вы бы использовали метод strip(). Чтобы получить список всех методов работы со строками, введите в интерпретатор следующую команду:\n\u003e\u003e\u003e dir(my_string) В итоге вы должны увидеть нечто похожее на это:\n['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] Вы можете смело игнорировать методы, начинающиеся и заканчивающиеся двойными знаками, такие как add. Они не используются в повседневном кодировании на Python. Вместо этого сосредоточьтесь на других методах.\nЕсли вы хотите узнать, что делает один из них, просто попросите помощи. Например, вы хотите узнать, для чего нужна capitalize. Чтобы узнать это, введите\n\u003e\u003e\u003e help(my_string.capitalize) Это вернет следующую информацию:\nHelp on built-in function capitalize: capitalize() method of builtins.str instance Return a capitalized version of the string. More specifically, make the first character have upper case and the rest lower case. Возвращает копию строки S, в которой заглавным является только первый символ.\nВы только что узнали немного о теме, называемой интроспекцией. Python позволяет легко проводить интроспекцию всех своих объектов, что делает его очень удобным в использовании. По сути, интроспекция позволяет вам спрашивать Python о самом себе. В одном из предыдущих разделов вы узнали о преобразовании. Возможно, вы задавались вопросом, как определить тип переменной (например, int или string). Вы можете попросить Python рассказать вам об этом!\n\u003e\u003e\u003e type(my_string) \u003ctype 'str'\u003e Переменная my_string имеет тип str.\nРазделение строки на подстроки Одной из задач с которой вы будете часто заниматься в реальном мире, - это разделение строк. Давайте посмотрим, как работает нарезка на примере следующей строки:\n\u003e\u003e\u003e my_string = \"I like Python!\" Каждый символ в строке может быть доступен с помощью нарезки. Например, если я хочу получить только первый символ, я могу сделать следующее:\n\u003e\u003e\u003e my_string[0:4] 'I li' Это захватит первый символ в строке до 4-го символа, но не включая его. Да, Python основан на нулях. Это будет немного проще понять, если мы обозначим позицию каждого символа в таблице:\n0 |\t1 |\t2 |\t3 |\t4 |\t5 |\t6 |\t7 |\t8 |\t9 |\t10 | 11 |\t12 | 13 I |\t|\tl |\ti |\tk |\te |\t|\tP |\ty |\tt |\th |\to |\tn |\t! Таким образом, у нас есть строка длиной 14 символов, начинающаяся с нуля и заканчивающаяся тринадцатью. Давайте рассмотрим еще несколько примеров, чтобы лучше закрепить эти понятия в голове.\n\u003e\u003e\u003e my_string[:1] 'I' \u003e\u003e\u003e my_string[0:12] 'I like Pytho' \u003e\u003e\u003e my_string[0:13] 'I like Python' \u003e\u003e\u003e my_string[0:14] 'I like Python!' \u003e\u003e\u003e my_string[0:-5] 'I like Py' \u003e\u003e\u003e my_string[:] 'I like Python!' \u003e\u003e\u003e my_string[2:] 'like Python!' Форматирование строк Для форматирования строк в Python есть несколько способов, но одним из наиболее распространенных является метод format(). Он позволяет объединять строки и значения переменных, заданных в скобках {}. Например:\nname = \"Alice\" age = 30 print(\"Меня зовут {}, и мне {} лет\".format(name, age)) В этом примере мы использовали фигурные скобки для обозначения места, где нужно вставить переменные name и age. Метод format() позволяет использовать несколько переменных, их значения будут подставлены в порядке следования внутри скобок.\nКроме того, можно задать формат вывода для каждой переменной. Например, чтобы вывести значение переменной age в шестнадцатеричном формате, можно использовать следующий код:\nage = 30 print(\"Мне {} лет, что в шестнадцатеричной системе счисления равно {}\".format(age, hex(age))) В результате мы получим вывод: ‘Мне 30 лет, что в шестнадцатеричной системе счисления равно 0x1e’.\nТакже в Python 3.6 и выше есть более удобный способ форматирования строк, называемый “f-strings” (форматированные строки). В этом случае мы используем символ f перед открывающей кавычкой, а переменные вставляем прямо внутрь фигурных скобок. Например:\nname = \"Alice\" age = 30 print(f\"Меня зовут {name}, и мне {age} лет\") Этот код даст тот же результат, что и предыдущий.\nРесурсы:\nОфициальная документация Python по типу str Форматирование строк Подробнее о форматировании строк ","description":"Python 101","title":"Строки","uri":"/ru/tracks/python-101/basis/strings/"},{"content":"unittest Python поставляется со встроенным модулем для тестирования - unittest.\nПример теста:\nimport unittest def square(x): return x * x class TestSquare(unittest.TestCase): def test_positive(self): self.assertEqual(square(2), 4) self.assertEqual(square(3), 9) self.assertEqual(square(4), 16) def test_negative(self): self.assertEqual(square(-2), 4) self.assertEqual(square(-3), 9) self.assertEqual(square(-4), 16) if __name__ == '__main__': unittest.main() В этом примере мы создаем тестовый класс TestSquare, который наследуется от unittest.TestCase. В этом классе мы определяем два метода: test_positive и test_negative. Эти методы используют метод assertEqual для проверки ожидаемых результатов.\nМетод assertEqual сравнивает два значения и генерирует исключение, если они не равны. Если тест проходит успешно, то мы не получаем никаких сообщений.\nЗапуск тестов можно выполнить из командной строки с помощью следующей команды:\npython test_square.py Да, в модуле unittest есть возможность делать моки с помощью встроенного класса unittest.mock.Mock. Это позволяет заменить реальный объект на имитацию, чтобы упростить тестирование и избежать внешних зависимостей.\nВот пример, который демонстрирует, как можно использовать моки в unittest для тестирования функции, которая зависит от внешнего сервиса:\nfrom unittest import TestCase, mock def get_external_data(): # Это внешний сервис, который может вернуть много данных # Но для тестирования нас интересует только первый элемент return ['data1', 'data2', 'data3'] def process_data(): data = get_external_data() return data[0] class TestProcessData(TestCase): @mock.patch('__main__.get_external_data') def test_process_data(self, mock_get_external_data): mock_get_external_data.return_value = ['test_data1', 'test_data2', 'test_data3'] result = process_data() self.assertEqual(result, 'test_data1') Здесь мы используем декоратор @mock.patch для замены реального get_external_data на имитацию. В тесте мы устанавливаем возвращаемое значение имитации и проверяем, что функция process_data вернула ожидаемый результат.\nРесурсы:\nДокументация по unittest ","description":"Python 101","title":"Тестирование","uri":"/ru/tracks/python-101/enhance_python/testing/"},{"content":"При написании автоматических тестов для приложений WebRTC, существуют полезные конфигурации, которые можно включить для браузеров, и которые упростят разработку и тестирование.\nChrome При запуске автоматических тестов в Chrome полезны следующие функции:\n–allow-file-access-from-files — дает API-доступ для file://URLs –disable-translate — отключает всплывающие окна –use-fake-ui-for-media-stream — Представляет поддельные медиапотоки. Полезно при работе на CI-серверах. –use-file-for-fake-audio-capture= — дает возможность использовать файл при захвате звука. –use-file-for-fake-video-capture= — дает возможность использовать файл при захвате видео. –headless - Запустить в автономном режиме. Полезно при работе на CI-серверах. –mute-audio - Отключить аудио. Firefox При запуске автоматических тестов в Firefox, необходимо указать набор ключей предпочтений, которые будут использоваться в запущенном соединении. Ниже приведена конфигурация, используемая для автоматических тестов образцов WebRTC:\n\"prefs\": { \"browser.cache.disk.enable\": false, \"browser.cache.disk.capacity\": 0, \"browser.cache.disk.smart_size.enabled\": false, \"browser.cache.disk.smart_size.first_run\": false, \"browser.sessionstore.resume_from_crash\": false, \"browser.startup.page\": 0, \"media.navigator.streams.fake\": true, \"media.navigator.permission.disabled\": true, \"device.storage.enabled\": false, \"media.gstreamer.enabled\": false, \"browser.startup.homepage\": \"about:blank\", \"browser.startup.firstrunSkipsHomepage\": false, \"extensions.update.enabled\": false, \"app.update.enabled\": false, \"network.http.use-cache\": false, \"browser.shell.checkDefaultBrowser\": false } ","description":"Карманная книга по WebRTC","title":"Тестирование приложений WebRTC","uri":"/ru/tracks/webrtc/testing/"},{"content":"Python - это язык программирования, который обладает динамической типизацией, что означает, что тип переменной может меняться в процессе выполнения программы.\nВ Python есть несколько основных типов данных:\nСтроковые типы (string)\nЧисловые типы (целые числа, числа с плавающей запятой, комплексные числа)\nЛогический тип (True/False)\nСписки (list) - это упорядоченная коллекция элементов, которые могут быть различных типов данных.\nСписки создаются при помощи квадратных скобок [ ] и элементы списка разделяются запятыми.\nКортежи (tuple) - это упорядоченная коллекция элементов, которые могут быть различных типов данных.\nКортежи создаются при помощи круглых скобок ( ) и элементы кортежа разделяются запятыми.\nСловари (dictionary) - это неупорядоченная коллекция пар “ключ-значение”, где каждый ключ связан со значением.\nСловари создаются при помощи фигурных скобок { } и пары “ключ-значение” разделяются двоеточием, а элементы словаря разделяются запятыми.\nМножества (set) - это неупорядоченная коллекция уникальных элементов.\nМножества создаются при помощи фигурных скобок { } и элементы множества разделяются запятыми.\nНапример, вот как можно создать списки, кортежи, словари и множества в Python:\nmy_list = [1, 2, 3, \"four\", 5.0] my_tuple = (1, \"two\", 3.0, \"four\", 5) my_dict = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"} my_set = {1, 2, 3, 4, 5} ","description":"Python 101","title":"Типы данных","uri":"/ru/tracks/python-101/basis/types/"},{"content":" В процессе заполнения\nСкачать | PDF обновление 2023/02/17\nJunior 1. Что такое Python? Какие преимущества использования Python? Python - это высокоуровневый интерпретируемый язык программирования общего назначения. Будучи языком общего назначения, он может быть использован для создания практически любого типа приложений при наличии соответствующих инструментов/библиотек.\nКроме того, python поддерживает объекты, модули, потоки, обработку исключений и автоматическое управление памятью, что помогает моделировать реальные проблемы и создавать приложения для решения этих проблем.\nПреимущества использования Python:\nPython - это язык программирования общего назначения, который имеет простой, легко изучаемый синтаксис, подчеркивающий удобочитаемость и, следовательно, снижающий затраты на сопровождение программ. Более того, язык способен выполнять сценарии, является полностью открытым и поддерживает пакеты сторонних разработчиков, что способствует модульности и повторному использованию кода.\nЕго высокоуровневые структуры данных в сочетании с динамической типизацией и динамическим связыванием привлекают огромное сообщество разработчиков для быстрой разработки и развертывания приложений.\n2. Что такое динамически типизированный язык? Прежде чем понять, что такое динамически типизированный язык, мы должны узнать, что такое типизация. Типизация относится к проверке типов в языках программирования. В языке с сильной типизацией, таком как Python, “1” + 2 приведет к ошибке типа, поскольку эти языки не допускают “приведения типов” (неявного преобразования типов данных). С другой стороны, слабо типизированный язык, такой как JavaScript, просто выведет “12” в качестве результата.\nПроверка типов может быть выполнена на двух этапах:\nСтатический - типы данных проверяются перед выполнением. Динамический - типы данных проверяются во время выполнения. Python - интерпретируемый язык, каждый оператор выполняется построчно, поэтому проверка типов выполняется на лету, во время выполнения. Следовательно, Python является динамически типизированным языком.\n3. Что такое интерпретируемый язык? Интерпретированный язык выполняет свои утверждения построчно. Такие языки, как Python, JavaScript, R, PHP и Ruby, являются яркими примерами интерпретируемых языков. Программы, написанные на интерпретируемом языке, выполняются непосредственно из исходного кода, без промежуточного этапа компиляции.\n4. Что такое PEP 8 и почему он важен? PEP расшифровывается как Python Enhancement Proposal. PEP - это официальный проектный документ, предоставляющий информацию сообществу Python или описывающий новую функцию для Python или его процессов.\nPEP 8 особенно важен, поскольку в нем документированы руководящие принципы стиля для кода Python. Очевидно, что вклад в сообщество разработчиков открытого кода Python требует от вас искреннего и строгого следования этим руководящим принципам стиля.\n5. Что такое область видимости в Python? Каждый объект в Python функционирует в пределах области видимости. Область видимости - это блок кода, в котором объект в Python остается актуальным. Пространства имен однозначно идентифицируют все объекты внутри программы.\nВ Python существует 3 области видимости:\nЛокальная Глобальная Нелокальная Однако эти пространства имен также имеют область видимости, определенную для них, где вы можете использовать их объекты без префикса. Ниже приведено несколько примеров областей видимости, создаваемых во время выполнения кода в Python:\nЛокальная область видимости относится к локальным объектам, доступным в текущей функции.\nЛокальная область видимости - определенная внутри функции, метода или выражения. Переменные, определенные внутри этой области, недоступны за ее пределами.\nx = 10 def my_func(a, b): print(x) print(z) \u003e\u003e\u003emy_func(1, 2) 10 Traceback (most recent call last): File \"\u003cpyshell#19\u003e\", line 1, in \u003cmodule\u003e my_func(1, 2) File \"\u003cpyshell#18\u003e\", line 3, in my_func print(z) NameError: name 'z' is not defined Глобальная область видимости относится к объектам, доступным во время выполнения кода с момента их создания.\nГлобальная область видимости - определенная вне функций, методов и выражений. Переменные, определенные в глобальной области видимости, доступны везде в коде.\nОбласть видимости на уровне модуля относится к глобальным объектам текущего модуля, доступным в программе.\nГлобальная область видимости относится ко всем встроенным именам, вызываемым в программе. Объекты в этой области видимости ищутся в последнюю очередь, чтобы найти имя, на которое ссылаются.\ndef my_func(a, b): global x print(x) x = 5 print(x) if __name__ == '__main__': x = 10 my_func(1, 2) print(x) 10 5 5 🎾 Примечание: Объекты локальной области видимости могут быть синхронизированы с объектами глобальной области видимости с помощью таких ключевых слов, как global.\nВ Python 3 было добавлено новое ключевое слово под названием nonlocal. С его помощью мы можем добавлять переопределение области во внутреннюю область. Вы можете ознакомиться со всей необходимой на данный счет информацией в PEP 3104. Это наглядно демонстрируется в нескольких примерах. Один из самых простых – это создание функции, которая может увеличиваться:\ndef counter(): num = 0 def incrementer(): num += 1 return num return incrementer Если вы попробуете запустить этот код, вы получите ошибку UnboundLocalError, так как переменная num ссылается прежде, чем она будет назначена в самой внутренней функции. Давайте добавим nonlocal в наш код:\ndef counter(): num = 0 def incrementer(): nonlocal num num += 1 return num return incrementer c = counter() print(c) # \u003cfunction counter.\u003clocals\u003e.incrementer at 0x7f45caf44048\u003e c() # 1 c() # 2 c() # 3 6. Что такое списки и кортежи? В чем ключевое различие между ними? Списки и кортежи - это типы данных последовательности, которые могут хранить коллекцию объектов в Python. Объекты, хранящиеся в обеих последовательностях, могут иметь различные типы данных. Списки представлены квадратными скобками ['sara', 6, 0.19], а кортежи - круглыми ('ansh', 5, 0.97).\nНо в чем реальная разница между ними? Ключевое различие между ними заключается в том, что списки являются изменяемыми, а кортежи, напротив, неизменяемыми объектами. Это означает, что списки можно изменять, добавлять или нарезать на ходу, а кортежи остаются неизменными и не могут быть изменены никаким образом. Вы можете выполнить следующий пример, чтобы убедиться в разнице:\nmy_tuple = ('sara', 6, 5, 0.97) my_list = ['sara', 6, 5, 0.97] print(my_tuple[0]) # output =\u003e 'sara' print(my_list[0]) # output =\u003e 'sara' my_tuple[0] = 'ansh' # modifying tuple =\u003e throws an error my_list[0] = 'ansh' # modifying list =\u003e list modified print(my_tuple[0]) # output =\u003e 'sara' print(my_list[0]) # output =\u003e 'ansh' 7. Каковы общие встроенные типы данных в Python? В Python существует несколько встроенных типов данных. Хотя Python не требует явного определения типов данных при объявлении переменных, ошибки могут возникнуть, если пренебречь знанием типов данных и их совместимости друг с другом. Python предоставляет функции type() и isinstance() для проверки типа этих переменных. Эти типы данных можно сгруппировать в следующие категории-\nТип None:\nКлючевое слово None представляет нулевые значения в Python. Операция булева равенства может быть выполнена с использованием этих объектов NoneType.\nNoneType Представляет значения NULL в Python.\nЧисловые типы:\nСуществует три различных числовых типа - целые числа (integers), числа с плавающей точкой (floating-point) и комплексные числа(complex numbers). Кроме того, булевы числа являются подтипом целых чисел.\nint Хранит целочисленные литералы, включая шестнадцатеричные, восьмеричные и двоичные числа, как целые числа float Хранит литералы, содержащие десятичные значения и/или знаки экспоненты, как числа с плавающей точкой complex Хранит комплексные числа в виде (A + Bj) и имеет атрибуты: real и imag bool Хранит булево значение (True или False). Типы последовательностей:\nСогласно Python Docs, существует три основных типа последовательностей - списки (lists), кортежи (tuples) и объекты диапазона (range objects). Типы последовательностей имеют операторы in и not in, определенные для обхода их элементов. Эти операторы имеют тот же приоритет, что и операции сравнения.\nlist Неизменяемая последовательность, используемая для хранения коллекции элементов. tuple Неизменяемая последовательность, используемая для хранения коллекции элементов. range Представляет собой неизменяемую последовательность чисел, генерируемую во время выполнения. str Неизменяемая последовательность кодовых точек Unicode для хранения текстовых данных. Стандартная библиотека также включает дополнительные типы для обработки:\nДвоичные данные Текстовые строки, такие как str. Тип словарь (dict):\nОбъект отображения может отображать хэшируемые значения на произвольные объекты в Python. Объекты отображения являются изменяемыми, и в настоящее время существует только один стандартный тип отображения - dict.\ndict Хранит список пар ключ: значение, разделенных запятыми. Типы множеств:\nВ настоящее время в Python есть два встроенных типа множеств - set и frozenset.\nТип set является изменяемым и поддерживает такие методы, как add() и remove().\nТип frozenset является неизменяемым и не может быть изменен после создания.\nset Мутабельная неупорядоченная коллекция отдельных хэшируемых объектов. frozenset Неизменяемая коллекция отдельных хэшируемых объектов. set является изменяемым и поэтому не может быть использован в качестве ключа словаря. С другой стороны, frozenset является неизменяемым и, следовательно, хэшируемым, и может использоваться как ключ словаря или как элемент другого множества.\nМодули:\nModule - это дополнительный встроенный тип, поддерживаемый интерпретатором Python. Он поддерживает одну специальную операцию, т.е. доступ к атрибуту: mymod.myobj, где mymod - модуль, а myobj ссылается на имя, определенное в модуле.\nТаблица символов модуля находится в специальном атрибуте модуля dict, но прямое присвоение этому модулю невозможно и не рекомендуется.\nТипы Callable:\nCallable типы - это типы, к которым может быть применен вызов функции. Это могут быть определяемые пользователем функции, методы экземпляра, функции генератора и некоторые другие встроенные функции, методы и классы.\n8. Что такое pass в Python? Ключевое слово pass представляет собой нулевую операцию в Python. Обычно оно используется для заполнения пустых блоков кода, который может выполняться во время исполнения, но еще не написан. Без оператора pass в следующем коде мы можем столкнуться с некоторыми ошибками во время выполнения кода.\ndef myEmptyFunc(): # do nothing pass myEmptyFunc() # nothing happens ## Without the pass keyword # File \"\u003cstdin\u003e\", line 3 # IndentationError: expected an indented block 9. Что такое модули и пакеты в Python? Пакеты Python и модули Python - это два механизма, которые позволяют осуществлять модульное программирование в Python. Модулирование имеет несколько преимуществ:\nПростота: Работа над одним модулем помогает сосредоточиться на относительно небольшой части решаемой задачи. Это делает разработку более простой и менее подверженной ошибкам. Удобство обслуживания: Модули предназначены для обеспечения логических границ между различными проблемными областями. Если они написаны таким образом, что уменьшают взаимозависимость, то меньше вероятность того, что изменения в модуле могут повлиять на другие части программы. Возможность повторного использования: Функции, определенные в модуле, могут быть легко использованы повторно в других частях приложения. Разметка: Модули обычно определяют отдельное пространство имен, что помогает избежать путаницы между идентификаторами из других частей программы. Модули, в общем случае, это просто файлы Python с расширением .py, в которых может быть определен и реализован набор функций, классов или переменных. Они могут быть импортированы и инициализированы один раз с помощью оператора import. Если требуется частичная функциональность, импортируйте необходимые классы или функции с помощью оператора import: from foo import bar.\nПакеты позволяют иерархически структурировать пространство имен модуля с помощью точечной нотации. Как модули помогают избежать столкновений между именами глобальных переменных, так и пакеты помогают избежать столкновений между именами модулей.\nСоздать пакет очень просто, поскольку он использует присущую системе файловую структуру. Просто поместите модули в папку, и вот оно, имя папки как имя пакета. Для импорта модуля или его содержимого из этого пакета требуется, чтобы имя пакета было префиксом к имени модуля, соединенным точкой.\nПримечание: технически вы можете импортировать и пакет, но, увы, это не импортирует модули внутри пакета в локальное пространство имен.\n10. Что такое глобальные, защищенные и приватные атрибуты в Python? Глобальные переменные- это общедоступные переменные, которые определены в глобальной области видимости. Чтобы использовать переменную в глобальной области видимости внутри функции, мы используем ключевое слово global.\nЗащищенные атрибуты (Protected attributes) - это атрибуты, определенные с префиксом подчеркивания к их идентификатору, например, _sara. К ним все еще можно получить доступ и изменить их извне класса, в котором они определены, но ответственный разработчик должен воздержаться от этого.\nПриватные атрибуты (Private attributes) - это атрибуты с двойным подчеркиванием в префиксе к их идентификатору, например __ansh. Они не могут быть доступны или изменены извне напрямую, и при такой попытке будет выдана ошибка AttributeError.\n11. Как используется self в Python? self используется для представления экземпляра класса. С помощью этого ключевого слова вы можете получить доступ к атрибутам и методам класса в python.\nself связывает атрибуты с заданными аргументами. self используется в разных местах и часто считается ключевым словом. Но в отличие от C++, self не является ключевым словом в Python.\n12. Что такое init? init - это метод-конструктор в Python, который автоматически вызывается для выделения памяти при создании нового объекта/экземпляра. Все классы имеют метод init, связанный с ними. Он помогает отличить методы и атрибуты класса от локальных переменных.\n# class definition class Student: def __init__(self, fname, lname, age, section): self.firstname = fname self.lastname = lname self.age = age self.section = section # creating a new object stu1 = Student(\"Sara\", \"Ansh\", 22, \"A2\") 13. Что такое break, continue и pass в Python? Оператор break немедленно завершает цикл, а управление переходит к оператору после тела цикла.\nОператор continue завершает текущую итерацию оператора, пропускает остальной код в текущей итерации, а управление переходит к следующей итерации цикла.\nКлючевое слово pass в Python обычно используется для заполнения пустых блоков и аналогично пустому утверждению, представленному точкой с запятой в таких языках, как Java, C++, Javascript и т.д.\n14. Что такое модульные тесты в Python? Юнит-тесты - это структура модульного тестирования в Python.\nЮнит-тестирование означает тестирование различных компонентов программного обеспечения по отдельности. Можете ли вы подумать о том, почему модульное тестирование важно? Представьте себе сценарий: вы создаете программное обеспечение, которое использует три компонента, а именно A, B и C. Теперь предположим, что в какой-то момент ваше программное обеспечение ломается. Как вы определите, какой компонент был ответственен за поломку программы? Может быть, это компонент A вышел из строя, который, в свою очередь, вышел из строя компонент B, что и привело к поломке программного обеспечения. Таких комбинаций может быть множество.\nВот почему необходимо должным образом протестировать каждый компонент, чтобы знать, какой компонент может быть ответственен за сбой программного обеспечения.\n15. Что такое docstring в Python? docstring - это многострочная строка, используемая для документирования определенного участка кода.\nВ docstring должно быть описано, что делает функция или метод.\n16. Что такое срез в Python? Как следует из названия, “срез” - это взятие частей.\nСинтаксис следующий [start : stop : step].\nstart - начальный индекс, с которого производится нарезка списка или кортежа stop - конечный индекс или место нарезки. step - количество шагов для перехода. Значение по умолчанию для start - 0, stop - количество элементов, step - 1.\nСрезы можно выполнять для строк, массивов, списков и кортежей.\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] print(numbers[1 : : 2]) #output : [2, 4, 6, 8, 10] 17. Объясните, как можно сделать Python Script исполняемым на Unix? Файл сценария должен начинаться с #!/usr/bin/env python\n18. В чем разница между массивами и списками в Python? Массивы в python могут содержать элементы только одного типа данных, т.е. тип данных массива должен быть однородным. Это тонкая обертка вокруг массивов языка C, и они потребляют гораздо меньше памяти, чем списки.\nСписки в python могут содержать элементы разных типов данных, то есть тип данных списков может быть неоднородным. Их недостатком является потребление большого объема памяти.\nimport array a = array.array('i', [1, 2, 3]) for i in a: print(i, end=' ') #OUTPUT: 1 2 3 a = array.array('i', [1, 2, 'string']) #OUTPUT: TypeError: an integer is required (got type str) a = [1, 2, 'string'] for i in a: print(i, end=' ') #OUTPUT: 1 2 string Middle / Senior 19. Как осуществляется управление памятью в Python? Управление памятью в Python осуществляется менеджером памяти Python. Память, выделяемая менеджером, представляет собой частное пространство кучи, предназначенное для Python. Все объекты Python хранятся в этой куче, и, будучи частной, она недоступна программисту. Тем не менее, Python предоставляет некоторые основные функции API для работы с частным пространством кучи.\nКроме того, Python имеет встроенную сборку мусора для утилизации неиспользуемой памяти для частного пространства кучи.\n20. Что такое пространства имен Python? Зачем они используются? Пространство имен в Python гарантирует, что имена объектов в программе уникальны и могут использоваться без каких-либо конфликтов. Python реализует эти пространства имен в виде словарей, в которых “имя как ключ” сопоставлено с соответствующим “объектом как значением”. Это позволяет нескольким пространствам имен использовать одно и то же имя и сопоставлять его с отдельным объектом. Ниже приведены несколько примеров пространств имен:\nЛокальное пространство имен включает локальные имена внутри функции. Пространство имен временно создается для вызова функции и очищается после возвращения функции.\nГлобальное пространство имен включает имена из различных импортированных пакетов/модулей, которые используются в текущем проекте. Это пространство имен создается при импорте пакета в скрипт и сохраняется до выполнения скрипта.\nВстроенное пространство имен включает встроенные функции ядра Python и встроенные имена для различных типов исключений.\nЖизненный цикл пространства имен зависит от области видимости объектов, с которыми они сопоставлены. Если область видимости объекта заканчивается, жизненный цикл этого пространства имен завершается. Следовательно, невозможно получить доступ к объектам внутреннего пространства имен из внешнего пространства имен.\n21. Что такое разрешение области видимости в Python? Иногда объекты в одной области видимости имеют одинаковые имена, но функционируют по-разному. В таких случаях разрешение области видимости в Python происходит автоматически. Вот несколько примеров такого поведения:\nМодули Python ‘math’ и ‘cmath’ имеют множество функций, общих для обоих - log10(), acos(), exp() и т.д. Чтобы разрешить эту двусмысленность, необходимо снабдить их префиксом соответствующего модуля, например, math.exp() и cmath.exp().\nРассмотрим приведенный ниже код, объект temp был инициализирован на 10 глобально и затем на 20 при вызове функции. Однако вызов функции не изменил значение temp глобально. Здесь мы можем заметить, что Python проводит четкую границу между глобальными и локальными переменными, рассматривая их пространства имен как отдельные личности.\ntemp = 10 # global-scope variable def func(): temp = 20 # local-scope variable print(temp) print(temp) # output =\u003e 10 func() # output =\u003e 20 print(temp) # output =\u003e 10 Это поведение может быть переопределено с помощью ключевого слова global внутри функции, как показано в следующем примере:\ntemp = 10 # global-scope variable def func(): global temp temp = 20 # local-scope variable print(temp) print(temp) # output =\u003e 10 func() # output =\u003e 20 print(temp) # output =\u003e 20 22. Что такое декораторы в Python? Декораторы в Python - это, по сути, функции, которые добавляют функциональность к существующей функции в Python без изменения структуры самой функции. В Python они обозначаются @decorator_name и вызываются по принципу “снизу вверх”. Например:\n# decorator function to convert to lowercase def lowercase_decorator(function): def wrapper(): func = function() string_lowercase = func.lower() return string_lowercase return wrapper # decorator function to split words def splitter_decorator(function): def wrapper(): func = function() string_split = func.split() return string_split return wrapper @splitter_decorator # this is executed next @lowercase_decorator # this is executed first def hello(): return 'Hello World' hello() # output =\u003e [ 'hello' , 'world' ] Прелесть декораторов заключается в том, что помимо добавления функциональности к выходу метода, они могут даже принимать аргументы для функций и дополнительно модифицировать эти аргументы перед передачей в саму функцию. Внутренняя вложенная функция, то есть функция-“обертка”, играет здесь важную роль. Она реализуется для обеспечения инкапсуляции и, таким образом, скрывает себя от глобальной области видимости.\n# decorator function to capitalize names def names_decorator(function): def wrapper(arg1, arg2): arg1 = arg1.capitalize() arg2 = arg2.capitalize() string_hello = function(arg1, arg2) return string_hello return wrapper @names_decorator def say_hello(name1, name2): return 'Hello ' + name1 + '! Hello ' + name2 + '!' say_hello('sara', 'ansh') # output =\u003e 'Hello Sara! Hello Ansh!' 23. Что такое comprehensions Dict и List? Python comprehensions, как и декораторы, - это синтаксический сахар, который помогает строить измененные и отфильтрованные списки, словари или множества из заданного списка, словаря или множества. Использование понятий позволяет сэкономить много времени и сэкономить код, который мог бы быть значительно более многословным (содержать больше строк кода). Давайте рассмотрим несколько примеров, в которых понимания могут быть действительно полезны:\nСловарные (Dict) comprehension используют фигурные скобки и позволяют создавать новые словари на основе уже существующих.\nnew_dict = {key: value for key, value in old_dict.items() if value \u003e 2} Выполнение математических операций над всем списком\nmy_list = [2, 3, 5, 7, 11] squared_list = [x**2 for x in my_list] # list comprehension # output =\u003e [4 , 9 , 25 , 49 , 121] squared_dict = {x:x**2 for x in my_list} # dict comprehension # output =\u003e {11: 121, 2: 4 , 3: 9 , 5: 25 , 7: 49} Выполнение операций условной фильтрации для всего списка\nmy_list = [2, 3, 5, 7, 11] squared_list = [x**2 for x in my_list if x%2 != 0] # list comprehension # output =\u003e [9 , 25 , 49 , 121] squared_dict = {x:x**2 for x in my_list if x%2 != 0} # dict comprehension # output =\u003e {11: 121, 3: 9 , 5: 25 , 7: 49} Объединение нескольких списков в один\na = [1, 2, 3] b = [7, 8, 9] [(x + y) for (x,y) in zip(a,b)] # parallel iterators # output =\u003e [8, 10, 12] [(x,y) for x in a for y in b] # nested iterators # output =\u003e [(1, 7), (1, 8), (1, 9), (2, 7), (2, 8), (2, 9), (3, 7), (3, 8), (3, 9)] Преобразование многомерного массива в одномерный\nАналогичный подход вложенных итераторов (как описано выше) может быть применен для сглаживания многомерного списка или работы с его внутренними элементами.\nmy_list = [[10,20,30],[40,50,60],[70,80,90]] flattened = [x for temp in my_list for x in temp] # output =\u003e [10, 20, 30, 40, 50, 60, 70, 80, 90] Примечание: генератор списков имеет тот же эффект, что и метод map в других языках. Они используют математическую нотацию построителя множеств, а не функции map и filter в Python.\n24. Что такое лямбда в Python? Почему это используется? Лямбда - это анонимная функция в Python, которая может принимать любое количество аргументов, но может иметь только одно выражение. Обычно она используется в ситуациях, когда требуется анонимная функция на короткий промежуток времени. Лямбда-функции можно использовать одним из двух способов:\nПрисвоение лямбда-функций переменной:\nmul = lambda a, b : a * b print(mul(2, 5)) # output =\u003e 10 Обертывание лямбда-функций внутри другой функции:\ndef myWrapper(n): return lambda a : a * n mulFive = myWrapper(5) print(mulFive(2)) # output =\u003e 10 25. Как скопировать объект в Python? В Python оператор присваивания (=) не копирует объекты. Вместо этого он создает связь(ссылку) между существующим объектом и именем целевой переменной. Чтобы создать копии объекта в Python, необходимо использовать модуль copy. Существует два способа создания копий для данного объекта с помощью модуля copy.\nShallow Copy - это побитовая копия объекта. Созданный скопированный объект имеет точную копию значений в исходном объекте. Если одно из значений является ссылкой на другие объекты, копируются только адреса ссылок на них.\nГлубокое копирование рекурсивно копирует все значения от исходного объекта к целевому, т.е. дублирует даже объекты, на которые ссылается исходный объект.\nfrom copy import copy, deepcopy list_1 = [1, 2, [3, 5], 4] ## shallow copy list_2 = copy(list_1) list_2[3] = 7 list_2[2].append(6) list_2 # output =\u003e [1, 2, [3, 5, 6], 7] list_1 # output =\u003e [1, 2, [3, 5, 6], 4] ## deep copy list_3 = deepcopy(list_1) list_3[3] = 8 list_3[2].append(7) list_3 # output =\u003e [1, 2, [3, 5, 6, 7], 8] list_1 # output =\u003e [1, 2, [3, 5, 6], 4] 26. В чем разница между xrange и range в Python? xrange() и range() довольно похожи по функциональности. Они оба генерируют последовательность целых чисел, с той лишь разницей, что range() возвращает список Python, тогда как xrange() возвращает объект xrange.\nВ отличие от range(), xrange() не генерирует статический список, а создает значение на ходу. Эта техника обычно используется с генератором объектного типа и называется “yielding”.\nВыдача очень важна в приложениях, где память ограничена. Создание статического списка, как в range(), может привести к ошибке памяти в таких условиях, в то время как xrange() может справиться с этим оптимально, используя только достаточное количество памяти для генератора (значительно меньше по сравнению с другими).\nfor i in xrange(10): # numbers from o to 9 print i # output =\u003e 0 1 2 3 4 5 6 7 8 9 for i in xrange(1,10): # numbers from 1 to 9 print i # output =\u003e 1 2 3 4 5 6 7 8 9 for i in xrange(1, 10, 2): # skip by two for next print i # output =\u003e 1 3 5 7 9 Примечание: xrange была устаревшей начиная с Python 3.x. Теперь range делает то же самое, что делала xrange в Python 2.x, поскольку в Python 2.x было гораздо лучше использовать xrange(), чем оригинальную функцию range().\n27. Что такое pickling и unpickling? Библиотека Python предлагает функцию сериализации из коробки. Сериализация объекта означает преобразование его в формат, который можно хранить, чтобы впоследствии можно было десериализовать его и получить исходный объект.\nPickling - это название процесса сериализации в Python. Любой объект в Python может быть сериализован в поток байтов и выгружен в память в виде файла. Процесс pickling компактен, но объекты pickle могут быть сжаты еще больше. pickle отслеживает объекты, которые он сериализовал, и сериализация переносима между версиями.\nДля этого процесса используется функция pickle.dump().\nРаспаковка (Unpickling) - является полной противоположностью pickle. Он десериализует поток байтов для воссоздания объектов, хранящихся в файле, и загружает объект в память.\nДля этого используется функция pickle.load().\n28. Что такое генераторы в Python? Генераторы - это функции, которые возвращают итерируемую коллекцию элементов, по одному за раз, заданным образом. Генераторы, в общем случае, используются для создания итераторов с другим подходом. Они используют ключевое слово yield, а не return для возврата объекта генератора.\nПостроим генератор для чисел Фибоначчи:\n## generate fibonacci numbers upto n def fib(n): p, q = 0, 1 while(p \u003c n): yield p p, q = q, p + q x = fib(10) # create generator object ## iterating using __next__(), for Python2, use next() x.__next__() # output =\u003e 0 x.__next__() # output =\u003e 1 x.__next__() # output =\u003e 1 x.__next__() # output =\u003e 2 x.__next__() # output =\u003e 3 x.__next__() # output =\u003e 5 x.__next__() # output =\u003e 8 x.__next__() # error ## iterating using loop for i in fib(10): print(i) # output =\u003e 0 1 1 2 3 5 8 29. Что такое PYTHONPATH в Python? PYTHONPATH - это переменная окружения, которую можно установить, чтобы добавить дополнительные каталоги, в которых Python будет искать модули и пакеты.\nЭто особенно полезно при работе с библиотеками Python, которые вы не хотите устанавливать в глобальном месте по умолчанию.\n30. Как используются функции help() и dir()? Функция help() в Python используется для отображения документации по модулям, классам, функциям, ключевым словам и т.д. Если функции help() не передан ни один параметр, то на консоли запускается интерактивная справочная утилита.\nФункция dir() пытается вернуть правильный список атрибутов и методов объекта, к которому она обращается. Она ведет себя по-разному с разными объектами, поскольку стремится выдать наиболее релевантные данные, а не полную информацию.\nДля объектов Modules/Library он возвращает список всех атрибутов, содержащихся в данном модуле. Для объектов класса возвращает список всех допустимых атрибутов и базовых атрибутов. При отсутствии аргументов возвращает список атрибутов в текущей области видимости. 31. В чем разница между файлами .py и .pyc? Файлы .py содержат исходный код программы. В то время как файл .pyc содержит байткод программы. Мы получаем байткод после компиляции файла .py (исходного кода). Файлы .pyc создаются не для всех файлов, которые вы запускаете. Они создаются только для тех файлов, которые вы импортируете.\nПеред выполнением программы python интерпретатор python проверяет наличие скомпилированных файлов. Если файл присутствует, виртуальная машина выполняет его. Если файл не найден, он проверяет наличие файла .py. Если он найден, то компилирует его в файл .pyc, а затем виртуальная машина python выполняет его.\nНаличие файла .pyc экономит время компиляции.\n32. Как интерпретируется язык Python? Python как язык не интерпретируется и не компилируется. Интерпретация или компиляция - это свойство реализации. Python - это байткод (набор инструкций, читаемых интерпретатором), интерпретируемый в общем случае.\nИсходный код - это файл с расширением .py.\nPython компилирует исходный код в набор инструкций для виртуальной машины. Интерпретатор Python является реализацией этой виртуальной машины. Этот промежуточный формат называется “байткод”.\nИсходный код .py сначала компилируется, чтобы получить .pyc, который является байткодом. Затем этот байткод может быть интерпретирован официальным CPython или JIT (Just in Time compiler) компилятором PyPy.\n33. Как в python аргументы передаются по значению или по ссылке? Передача по значению: Передается копия реального объекта. Изменение значения копии объекта не приведет к изменению значения исходного объекта.\nПередача по ссылке: Передается ссылка на реальный объект. Изменение значения нового объекта изменит значение исходного объекта.\nВ Python аргументы передаются по ссылке, т.е. передается ссылка на реальный объект.\ndef appendNumber(arr): arr.append(4) arr = [1, 2, 3]. print(arr) #Вывод: =\u003e [1, 2, 3] appendNumber(arr) print(arr) #Вывод: =\u003e [1, 2, 3, 4] 34. Что такое итераторы в Python? Итератор - это объект. Он запоминает свое состояние, т.е. где он находится во время итерации (см. код ниже, чтобы увидеть, как это делается). Метод iter() инициализирует итератор. У него есть метод next(), который возвращает следующий элемент в итерации и указывает на следующий элемент. При достижении конца итерируемого объекта next() должен возвращать исключение StopIteration. Он также является самоитерируемым. Итераторы - это объекты, с помощью которых мы можем выполнять итерации над итерируемыми объектами, такими как списки, строки и т.д. class ArrayList: def __init__(self, number_list): self.numbers = number_list def __iter__(self): self.pos = 0 возвращать себя def __next__(self): if(self.pos \u003c len(self.numbers)): self.pos += 1 return self.numbers[self.pos - 1] else: raise StopIteration array_obj = ArrayList([1, 2, 3]) it = iter(array_obj) print(next(it)) #вывод: 2 print(next(it)) #вывод: 3 print(next(it)) #Throws Exception #Traceback (последний последний вызов): #... #StopIteration 35. Объясните, как удалить файл в Python? Используйте команду os.remove(file_name)\nimport os os.remove(\"ChangedFile.csv\") print(\"File Removed!\") 36. Объясните функции split() и join() в Python? Вы можете использовать функцию split() для разбиения строки на основе разделителя на список строк.\nС помощью функции join() можно объединить список строк на основе разделителя, чтобы получить одну строку.\nstring = \"Текст строки\". string_list = string.split(' ') #разделителем является символ \"пробел\" или ' ' print(string_list) #вывод: ['This', 'is', 'a', 'string.']. print(' '.join(string_list)) #вывод: Это строка. 37. Что означают *args и **kwargs? *args\n*args - это специальный синтаксис, используемый в определении функции для передачи аргументов переменной длины. \"*\" означает переменную длину, а “args” - это имя, используемое по соглашению. Вы можете использовать любое другое. def multiply(a, b, *argv): mul = a * b for num in argv: mul *= num возвращать mul print(multiply(1, 2, 3, 4, 5)) #вывод: 120 **kwargs\n**kwargs - это специальный синтаксис, используемый в определении функции для передачи аргументов переменной длины с ключевыми словами.\nЗдесь также kwargs используется просто по соглашению. Вы можете использовать любое другое имя. Аргумент с ключевым словом означает переменную, которая имеет имя при передаче в функцию. На самом деле это словарь имен переменных и их значений. def tellArguments(**kwargs): for key, value in kwargs.items(): print(key + \": \" + value) tellArguments(arg1 = \"аргумент 1\", arg2 = \"аргумент 2\", arg3 = \"аргумент 3\") #вывод: # arg1: аргумент 1 # arg2: аргумент 2 # arg3: аргумент 3 38. Что такое отрицательные индексы и зачем они используются? Отрицательные индексы - это индексы с конца списка, кортежа или строки.\narr = [1, 2, 3, 4, 5, 6] arr[-1] означает последний элемент массива arr[] #получить последний элемент print(arr[-1]) #вывод 6 #получить второй последний элемент print(arr[-2]) #вывод 5 Junior/Middle+ / ООП 39. Как создать класс в Python? Чтобы создать класс в python, используем ключевое слово class, как показано в примере ниже:\nclass Employee: def __init__(self, emp_name): self.emp_name = emp_name Чтобы инстанцировать или создать объект из класса, созданного выше, мы делаем следующее:\nemp_1 = Employee(\"Mr. Employee\"). Чтобы получить доступ к атрибуту name, мы просто вызываем атрибут с помощью точки:\nprint(emp_1.emp_name) # Mr. Employee Чтобы создать методы внутри класса, мы включаем их в область видимости класса:\nclass Employee: def __init__(self, emp_name): self.emp_name = emp_name def introduce(self): print(\"Hello I am \" + self.emp_name) Параметр self в функциях init и introduce представляет собой ссылку на текущий экземпляр класса, которая используется для доступа к атрибутам и методам этого класса. Параметр self должен быть первым параметром любого метода, определенного внутри класса.\nДоступ к методу класса Employee можно получить:\nemp_1.introduce() Общая программа будет выглядеть следующим образом:\nclass InterviewbitEmployee: def __init__(self, emp_name): self.emp_name = emp_name def introduce(self): print(\"Hello I am \" + self.emp_name) # create an object of InterviewbitEmployee class emp_1 = InterviewbitEmployee(\"Mr Employee\") print(emp_1.emp_name) #print employee name emp_1.introduce() #introduce the employee 40. Как работает наследование в python? Наследование дает классу право доступа ко всем атрибутам и методам другого класса. Это способствует повторному использованию кода и помогает разработчику поддерживать приложения без лишнего кода. Класс, наследующий от другого класса, является дочерним классом или также называется производным классом. Класс, от которого дочерний класс получает свои члены, называется родительским классом или суперклассом.\nPython поддерживает различные виды наследования, а именно:\nОдиночное наследование Многоуровневое наследование Множественное наследование Иерархическое наследование Одиночное наследование: Дочерний класс получает члены от одного родительского класса.\n# Parent class class ParentClass: def par_func(self): print(\"I am parent class function\") # Child class class ChildClass(ParentClass): def child_func(self): print(\"I am child class function\") # Driver code obj1 = ChildClass() obj1.par_func() obj1.child_func() Многоуровневое наследование: Члены родительского класса A наследуются дочерним классом, который затем наследуется другим дочерним классом B. Характеристики базового и производного классов далее наследуются в новом производном классе C.\nЗдесь A является дедушкой класса C.\n# Parent class class A: def __init__(self, a_name): self.a_name = a_name # Intermediate class class B(A): def __init__(self, b_name, a_name): self.b_name = b_name # invoke constructor of class A A.__init__(self, a_name) # Child class class C(B): def __init__(self,c_name, b_name, a_name): self.c_name = c_name # invoke constructor of class B B.__init__(self, b_name, a_name) def display_names(self): print(\"A name : \", self.a_name) print(\"B name : \", self.b_name) print(\"C name : \", self.c_name) # Driver code obj1 = C('child', 'intermediate', 'parent') print(obj1.a_name) obj1.display_names() Множественное наследование: Это достигается, когда один дочерний класс получает свойста от более чем одного родительского класса. Все свойства родительских классов наследуются в дочернем классе.\n# Parent class1 class Parent1: def parent1_func(self): print(\"Hi I am first Parent\") # Parent class2 class Parent2: def parent2_func(self): print(\"Hi I am second Parent\") # Child class class Child(Parent1, Parent2): def child_func(self): self.parent1_func() self.parent2_func() # Driver's code obj1 = Child() obj1.child_func() Иерархическое наследование: Когда от родительского класса происходит более одного дочернего класса.\n# Base class class A: def a_func(self): print(\"I am from the parent class.\") # 1st Derived class class B(A): def b_func(self): print(\"I am from the first child.\") # 2nd Derived class class C(A): def c_func(self): print(\"I am from the second child.\") # Driver's code obj1 = B() obj2 = C() obj1.a_func() obj1.b_func() #child 1 method obj2.a_func() obj2.c_func() #child 2 method 41. Как получить доступ к членам родительского класса в дочернем классе? Ниже перечислены способы, с помощью которых вы можете получить доступ к членам родительского класса в дочернем классе:\nС помощью имени родительского класса: Вы можете использовать имя родительского класса для доступа к атрибутам, как показано в примере ниже:\nclass Parent(object): # Constructor def __init__(self, name): self.name = name class Child(Parent): # Constructor def __init__(self, name, age): Parent.name = name self.age = age def display(self): print(Parent.name, self.age) # Driver Code obj = Child(\"ParentName\", 6) obj.display() С помощью метода super(): Члены родительского класса могут быть доступны в дочернем классе с помощью ключевого слова super.\nclass Parent(object): # Constructor def __init__(self, name): self.name = name class Child(Parent): # Constructor def __init__(self, name, age): ''' In Python 3.x, we can also use super().__init__(name) ''' super(Child, self).__init__(name) self.age = age def display(self): # Note that Parent.name cant be used # here since super() is used in the constructor print(self.name, self.age) # Driver Code obj = Child(\"Interviewbit\", 6) obj.display() 42. Используются ли спецификаторы доступа в python? Да, в Python есть спецификаторы доступа, но они не являются строгими и не работают так же, как в других языках, таких как C++ или Java.\nВ Python есть три уровня спецификаторов доступа:\nPublic - открытый доступ. Переменные и методы, объявленные без какого-либо спецификатора доступа, считаются общедоступными и могут быть использованы в любом месте программы. Protected - защищенный доступ. Переменные и методы, которые начинаются с символа подчеркивания (_), считаются защищенными и должны использоваться только внутри класса и его потомков. Private - закрытый доступ. Переменные и методы, которые начинаются с двух символов подчеркивания (__), считаются закрытыми и не могут быть использованы за пределами класса, даже его потомками. Однако в Python все переменные и методы на самом деле являются общедоступными и могут быть доступны вне класса, даже если они были объявлены с использованием защищенного или закрытого спецификатора доступа. Но общепринятым правилом считается использование подчеркиваний в начале имен переменных и методов, чтобы показать, что они не предназначены для использования вне класса.\nТакже существует соглашение, что имена методов и переменных, начинающихся с двух символов подчеркивания, должны использоваться только внутри класса.\nПример использования спецификаторов доступа в Python:\nclass Example: def __init__(self): self.public_variable = \"Public variable\" # публичная переменная self._protected_variable = \"Protected variable\" # защищенная переменная self.__private_variable = \"Private variable\" # приватная переменная def public_method(self): print(\"Public method\") def _protected_method(self): print(\"Protected method\") def __private_method(self): print(\"Private method\") example = Example() # Доступ к публичной переменной и методу print(example.public_variable) # выведет \"Public variable\" example.public_method() # выведет \"Public method\" # Доступ к защищенной переменной и методу print(example._protected_variable) # выведет \"Protected variable\" example._protected_method() # выведет \"Protected method\" # Доступ к приватной переменной и методу # Возникнет ошибка AttributeError, потому что переменная и метод приватные print(example.__private_variable) example.__private_method() В этом примере мы создали класс Example с тремя переменными и методами, которые имеют разные уровни спецификаторов доступа. Затем мы создали объект example и использовали различные спецификаторы доступа, чтобы получить доступ к его переменным и методам.\n43. Можно ли вызвать родительский класс без создания его экземпляра? Да, это возможно, если базовый класс инстанцируется другими дочерними классами или если базовый класс является статическим методом.\n44. Как в python создается пустой класс? Пустой класс не имеет определенных свойств/методов, определенных внутри. Он создается с помощью ключевого слова pass (команда pass ничего не делает в python). Мы можем создавать объекты для этого класса вне класса.\nclass MyClass: pass 45. Проведите различие между модификаторами new и override. new используется для создания новой реализации метода в классе-наследнике, которая заменяет реализацию метода в базовом классе. Это означает, что когда метод вызывается на объекте класса-наследника, будет использоваться новая реализация метода из класса-наследника, а не из базового класса.\noverride используется для переопределения реализации метода, унаследованного от базового класса. Это означает, что когда метод вызывается на объекте класса-наследника, будет использоваться новая реализация метода из класса-наследника, а не реализация метода из базового класса.\nЕсли в классе-наследнике не определен метод с тем же именем, что и метод в базовом классе, то метод базового класса будет унаследован.\nclass BaseClass: def method(self): print(\"BaseClass.method\") class DerivedClass1(BaseClass): def method(self): print(\"DerivedClass1.method\") class DerivedClass2(BaseClass): def new_method(self): print(\"DerivedClass2.new_method\") class DerivedClass3(BaseClass): def method(self): super().method() print(\"DerivedClass3.method\") base_object = BaseClass() derived_object1 = DerivedClass1() derived_object2 = DerivedClass2() derived_object3 = DerivedClass3() base_object.method() # выведет \"BaseClass.method\" derived_object1.method() # выведет \"DerivedClass1.method\" derived_object2.new_method() # выведет \"DerivedClass2.new_method\" derived_object3.method() # выведет \"BaseClass.method\" и \"DerivedClass3.method\" 46. Как использовать декораторы для определения свойств (property) в Python? В Python свойства (property) позволяют использовать методы геттера (getter) и сеттера (setter) для доступа к данным объекта, скрывая реализацию от пользователя.\nДля определения свойства (property) в Python используются декораторы @property, @property_name.setter и @property_name.deleter. Декоратор @property указывается перед методом геттера, который должен возвращать значение свойства. Декоратор @property_name.setter указывается перед методом сеттера, который должен устанавливать значение свойства. Декоратор @property_name.deleter указывается перед методом удаления, который должен удалить свойство.\nПример определения свойства (property) с помощью декораторов в Python:\nclass Rectangle: def __init__(self, width, height): self.width = width self.height = height @property def area(self): return self.width * self.height @property def perimeter(self): return 2 * (self.width + self.height) @property def width(self): return self._width @width.setter def width(self, value): if value \u003c= 0: raise ValueError(\"Width must be positive.\") self._width = value @property def height(self): return self._height @height.setter def height(self, value): if value \u003c= 0: raise ValueError(\"Height must be positive.\") self._height = value @property def dimensions(self): return (self.width, self.height) @dimensions.setter def dimensions(self, values): self.width, self.height = values def __str__(self): return f\"Rectangle({self.width}, {self.height})\" В этом примере мы создали класс Rectangle, который определяет прямоугольник с шириной и высотой. Мы определили свойства (property) area, perimeter, width, height и dimensions с помощью декораторов.\nСвойства area и perimeter используют методы геттера для вычисления площади и периметра.\nСвойства width и height используют методы геттера и сеттера для доступа к ширине и высоте.\nСвойство dimensions использует методы геттера и сеттера для доступа к ширине и высоте в виде кортежа.\nТеперь мы можем создать объект класса Rectangle и использовать свойства для доступа к данным:\nrect = Rectangle(3, 4) print(rect.width) # выведет 3 print(rect.height) # выведет 4 print(rect.area) # выведет 12 print(rect.perimeter) # 47. Что такое метод init в python? В Python метод __init__ является конструктором класса, который вызывается при создании нового объекта класса. Он используется для инициализации свойств объекта и может принимать параметры, которые передаются при создании объекта.\nclass MyClass: def __init__(self, name): self.name = name my_object = MyClass(\"John\") print(my_object.name) # выведет \"John\" В этом примере мы создали класс MyClass с методом __init__, который инициализирует свойство name объекта класса. При создании объекта my_object мы передали ему параметр “John”, который был использован для инициализации свойства name.\n48. Как проверить, является ли класс дочерним по отношению к другому классу? В Python можно проверить, является ли класс дочерним по отношению к другому классу с помощью функции issubclass. Функция issubclass принимает два аргумента: класс-потомок и класс-родитель, и возвращает True, если класс-потомок является подклассом класса-родителя, и False в противном случае.\nВот пример использования функции issubclass в Python:\nclass BaseClass: pass class DerivedClass(BaseClass): pass print(issubclass(DerivedClass, BaseClass)) # выведет True print(issubclass(BaseClass, DerivedClass)) # выведет False В этом примере мы создали два класса, BaseClass и DerivedClass, где DerivedClass наследует BaseClass. Мы затем использовали функцию issubclass, чтобы проверить, является ли DerivedClass дочерним по отношению к BaseClass, и вывели результат на экран.\nВ этом примере функция issubclass(DerivedClass, BaseClass) возвращает True, потому что DerivedClass является дочерним по отношению к BaseClass.\nА функция issubclass(BaseClass, DerivedClass) возвращает False, потому что BaseClass не является дочерним по отношению к DerivedClass.\nБиблиотеки 49. Различия между пакетом и модулем в python. Различия между пакетами и модулями в Python: модуль - это файл с расширением .py, который содержит определение функций, классов и других объектов, которые могут быть использованы в других модулях. Пакет - это каталог, который содержит один или несколько файлов модулей и может содержать другие подкаталоги.\n50. Каковы некоторые из наиболее часто используемых встроенных модулей в Python? Некоторые из наиболее часто используемых встроенных модулей в Python включают os, sys, math, random, datetime, re, json, csv, urllib, socket и многие другие.\n51. Что такое лямбда-функции? Лямбда-функции в Python - это функции, которые определяются без использования ключевого слова def. Они используются для определения функции в одной строке кода.\n52. Как можно генерировать случайные числа? В Python можно генерировать случайные числа с помощью модуля random. Например, для генерации случайного числа в диапазоне от 1 до 10 можно использовать функцию random.randint(1, 10).\n53. Можете ли вы проверить, все ли символы в заданной строке являются буквенно-цифровыми? Для проверки, являются ли все символы в заданной строке буквенно-цифровыми, можно использовать метод isalnum(). Например, \"Abc123\".isalnum() вернет True, а \"Abc 123\".isalnum() вернет False.\n54. Дайте определение понятию GIL. GIL (Global Interpreter Lock) - это механизм блокировки интерпретатора Python, который ограничивает выполнение только одного потока Python в любой момент времени. Это ограничение делает невозможным многопоточное выполнение Python-кода на нескольких ядрах процессора.\n55. Существуют ли инструменты для выявления ошибок и выполнения статического анализа в python? В Python существует множество инструментов для идентификации ошибок и проведения статического анализа кода, таких как pylint, pyflakes, pycodestyle и другие.\n","description":"55 вопросов по Python для Junior, Middle и Senior в 2023","title":"Топ 55 вопросов по Python","uri":"/ru/tracks/python-101/top-questions/"},{"content":"Необходимые документы:\nЗаявление на имя заведующего кафедрой. В з-и указать название и шифр специальности Монография на иностранном языке. Реферат на русском языке (объем 21-8 стр) по прочитанной лит-ре объемом 300 стр. Реферат, подписанный автором, должен иметь заключения, а также библиографию (список использованной литературы). Глосарий (словарь специальных терминов) - ен менее 300 единиц. Отзыв от научного руководителя или специалиста по данной дисциплине. Содержание экзамена:\nВышеуказанные документы сдаются н а кафедру иностраных яызков за 10 дней до экзамена. Чтение, перевод со (словарем) на руский язык оп специальности оригинального текста. Объем 2500 печ знаков. Время на подготовку 45 мин. Форма проверки - чтение части текста вслух, выборочная проверка подготовленного перевода (Если не выполнен минимум 2тыс знаков - экзамен не продолжается). Чтение (просмотровое без словаря) оригинального газетного публицистического текста по специальности. Объем 2500 печ знаков. Время на подготовку - 5 мин. Форма проверки - передача содержания текста на русском языке (реферирование). Чтение оригинального газетно-публицистического текста без словаря. Объем - 2500 печатных знаков. Время н а подготовку - 15-20 мин. Форма проверки - передача содержания текста на иностранном языке и беседа на иностранном языке по прочитанному тексту. Беседа на иностранном по вопросам, связынным со специальностью и научной работой аспиранта (защита реферата по теме исследования; требования к реферату см. выше) Примечание: вышеуказанные документы иностранных языков за 14 дней до экзамена тексту.\n","description":"Основные требования к кандидатскому экзамену по иностранным языкам","title":"Требования по иностранным языкам","uri":"/ru/tracks/disser/canditate-minimum/languages-requirements/"},{"content":"Введение В Hugo по умолчанию используется парсинг markdown файлов. Т.е. мы получаем html код в том виде, как он написан в markdown.\nДля того, чтобы нам понимать какие именно изображения мы можем увеличивать, добавим к этим изображениям отдельный тег/ключ/id\nИнструменты Для реализации функционала нам необходимо:\nнаписать/подключить скрипт/обработчик, который будет выполнять эффект zoomin к нужным нам изображениям Добавить необходимые метаданные к изображениям, чтобы скрипт их смог найти Скрипт zoomin Для добавления возможности увеличивать картинку при нажатии воспользуемся пакетом medium-zoom.\nДанный покет реализовывает данную функциональность в ненагруженном удобном стиле.\nДемо сайт\nЛогика скрипта Скрипт находит изображения с id и так понимает, что нужно применить свойство zoomin к этим изображениям\nВозможные id:\nzoom-default zoom-margin zoom-background zoom-scrollOffset zoom-trigger zoom-detach zoom-center Подключение скриптов Для работы скрипта, нам необходимо подключить логику, а также обработчик.\nВ Hugo в корне проекта есть папка static, которую можно использовать для хранения статических файлов (стиле, скриптов) и использовать для подключения на сайте. Если такой папки нет, то можно создать.\nВ папке static создадим папку zoom-image и добавим в нее 2 скрипта\nstatic/js/zoom-image/index.js const zoomDefault = mediumZoom('#zoom-default') const zoomMargin = mediumZoom('#zoom-margin', { margin: 48 }) const zoomBackground = mediumZoom('#zoom-background', { background: '#212530' }) const zoomScrollOffset = mediumZoom('#zoom-scrollOffset', { scrollOffset: 0, background: 'rgba(25, 18, 25, .9)', }) // Trigger the zoom when the button is clicked const zoomToTrigger = mediumZoom('#zoom-trigger') const button = document.querySelector('#button-trigger') button.addEventListener('click', () =\u003e zoomToTrigger.open()) // Detach the zoom after having been zoomed once const zoomToDetach = mediumZoom('#zoom-detach') zoomToDetach.on('closed', () =\u003e zoomToDetach.detach()) // Observe zooms to write the history const observedZooms = [ zoomDefault, zoomMargin, zoomBackground, zoomScrollOffset, zoomToTrigger, zoomToDetach, ] // Log all interactions in the history const history = document.querySelector('#history') observedZooms.forEach(zoom =\u003e { zoom.on('open', event =\u003e { const time = new Date().toLocaleTimeString() history.innerHTML += `\u003cli\u003eImage \"\u003cem\u003e${event.target.alt }\u003c/em\u003e\" was zoomed at ${time}\u003c/li\u003e` }) zoom.on('detach', event =\u003e { const time = new Date().toLocaleTimeString() history.innerHTML += `\u003cli\u003eImage \u003cem\u003e\"${event.target.alt }\"\u003c/em\u003e was detached at ${time}\u003c/li\u003e` }) }) static/js/zoom-image/placeholders.js // Show placeholders for paragraphs const paragraphs = [].slice.call(document.querySelectorAll('p.placeholder')) paragraphs.forEach(paragraph =\u003e { // eslint-disable-next-line no-param-reassign paragraph.innerHTML = paragraph.textContent .split(' ') .filter(text =\u003e text.length \u003e 4) .map(text =\u003e `\u003cspan class=\"placeholder__word\"\u003e${text}\u003c/span\u003e`) .join(' ') }) CDN скрипт Скрипт можно скачать, а можно подгружать\nСсылка на скрипт\nДобавление в шаблон Для того, чтобы данные скрипты работали в шаблоне сайта, их необходимо подключить.\nЯ использую для этого шаблон baseof.html. Просто добавляю ссылки на скрипта в body шаблона.\n# baseof.html ... \u003c/footer\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js\" defer\u003e\u003c/script\u003e \u003cscript src=\"/js/zoom-image/placeholders.js\" defer\u003e\u003c/script\u003e \u003cscript src=\"/js/zoom-image/index.js\" defer\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ID изображения Hugo позволяет изменить поведение при парсинге markdown файлов с помощью хуков. Подробнее о рендер-хуках можно прочитать на сайте.\nВ папке *layouts\nДобавим файл render-image.html по следующему пути layouts -\u003e _default -\u003e _markup код файла:\n\u003cp class=\"md__image\"\u003e \u003cimg src=\"{{ .Destination | safeURL }}\" id=\"zoom-default\" alt=\"{{ .Text }}\" {{ with .Title}} title=\"{{ . }}\" {{ end }} /\u003e \u003c/p\u003e Мы добавили только id=\"zoom-default\" в код по умолчанию\nИтоги Your browser does not support the video tag. Процесс ","description":"Добавляем скрипт, который будет увеличивать картинку в статье при нажатии","title":"Увеличение картинки по нажатию в Hugo","uri":"/ru/posts/hugo-add-image-zoomin/"},{"content":"Начало работы с удаленными потоками Как только RTCPeerConnection подключился к удаленному узлу, между ними можно передавать аудио- и видео-потоки. Это точка, в которой мы подключаем поток, полученный от getUserMedia(), к RTCPeerConnection. Медиаопоток состоит как минимум из одной дорожки мультимедиа, и они по отдельности добавляются в RTCPeerConnection, когда мы хотим передать данные удаленному узлу.\nconst localStream = await getUserMedia({vide: true, audio: true}); const peerConnection = new RTCPeerConnection(iceConfig); localStream.getTracks().forEach(track =\u003e { peerConnection.addTrack(track, localStream); }); Дорожки можно добавлять в RTCPeerConnection до подключения к удаленному узлу, поэтому имеет смысл выполнить эту настройку как можно раньше, а не ждать завершения соединения.\nДобавление удаленных дорожек Для получения удаленных дорожек, которые были добавлены другим узлом, мы регистрируем «прослушиватель» на локальном RTCPeerConnection, отслеживая изменения в событии track. RTCTrackEvent содержит массив объектов MediaStream, которые имеют те же значения MediaStream.id, что и соответствующие локальные потоки узла. В нашем примере каждая дорожка связана только с одним потоком.\nОбратите внимание, что, хотя ID из MediaStream совпадают на обеих сторонах однорангового соединения, в общем случае это не работает для ID MediaStreamTrack.\nconst remoteVideo = document.querySelector('#remoteVideo'); peerConnection.addEventListener('track', async (event) =\u003e { const [remoteStream] = event.streams; remoteVideo.srcObject = remoteStream; }); ","description":"Карманная книга по WebRTC","title":"Удаленные потоки","uri":"/ru/tracks/webrtc/remote-streams/"},{"content":"В каждом компьютерном языке есть хотя бы один условный оператор. Чаще всего этот оператор представляет собой структуру if/elif/else.\nВ Python 3.10 добавилась структура match/case\nОператор if Позволяет выполнить блок кода, если определенное условие истинно\nx = 5 if x \u003e 0: print(\"x is positive\") elif x \u003c 0: print(\"x is negative\") else: print(\"x is zero\") match/case def get_day_name(day): match day: case 1: return \"Monday\" case 2: return \"Tuesday\" case 3: return \"Wednesday\" case 4: return \"Thursday\" case 5: return \"Friday\" case 6: return \"Saturday\" case 7: return \"Sunday\" case _: return \"Invalid day\" match command.split(): case [\"quit\"]: print(\"Goodbye!\") quit_game() case [\"look\"]: current_room.describe() case [\"get\", obj]: character.get(obj, current_room) case [\"go\", direction]: current_room = current_room.neighbor(direction) or/and/not or означает, что если любое условие, которое “перечислено” вместе, равно True, то выполняется следующее утверждение and означает, что для выполнения следующего утверждения все утверждения должны быть True not означает, что если условие оценивается как False, то оно является True. На мой взгляд, это самый запутанный вариант. x = 5 y = 10 if x \u003e 0 and y \u003e 0: print(\"Both x and y are positive\") if x \u003e 0 or y \u003e 0: print(\"At least one of x and y is positive\") if not x \u003c 0: print(\"x is not negative\") my_list = [1, 2, 3, 4] x = 10 if x not in my_list: print(\"'x' is not in the list, so this is True!\") Проверка на ничто (None) В Python None используется, чтобы обозначить отсутствие значения. Это можно использовать в условных операторах, чтобы проверить, имеет ли переменная значение None.\nНапример, если мы хотим проверить, имеет ли переменная x значение None, мы можем написать:\nif x is None: print(\"x is None\") Мы также можем использовать оператор is not для проверки, имеет ли переменная значение, отличное от None:\nif x is not None: print(\"x is not None\") Здесь мы используем условный оператор if, чтобы проверить, имеет ли переменная x значение None. Если это так, мы выводим сообщение “x is None”. Если переменная x имеет какое-то другое значение, мы ничего не выводим.\nЭто может быть полезно, если мы не знаем, какое значение будет иметь переменная, или если переменная может быть пустой.\nif name == “main” Оператор if name == “main” используется для определения, запущен ли файл напрямую или импортирован как модуль. Если файл запущен напрямую, блок кода внутри этого условия будет выполнен, если же файл импортирован как модуль, этот блок кода не будет выполнен:\nif __name__ == \"__main__\": # код, который будет выполнен только при запуске файла напрямую Располагается в конце файла. Это говорит Python, что вы хотите выполнить следующий код, только если эта программа будет выполнена как отдельный файл.\n","description":"Python 101","title":"Условия","uri":"/ru/tracks/python-101/basis/conditionals/"},{"content":"Red Hat Enterprise Linux 9 (RHEL 9) под кодовым названием Plow стал общедоступным (GA). Компания Red Hat объявила об этом 18 мая 2022 года. Она сменила бета-версию, которая существовала с 3 ноября 2021 года.\nRHEL 9 - это несколько первых релизов в семействе Red Hat. Это первый крупный релиз после приобретения Red Hat компанией IBM в июле 2019 года, а также первая крупная версия после отказа от проекта CentOS в пользу CentOS Stream, который теперь является предшественником RHEL.\nRHEL 9 является последней основной версией RHEL и поставляется с ядром 5.14, множеством новых пакетов программного обеспечения и массой усовершенствований. В ней особое внимание уделяется безопасности, стабильности, гибкости и надежности.\nОписание RHEL 9 поставляется с новыми версиями программного обеспечения, включая Python 3.9. Node.JS 16, GCC 11, Perl 5.32, Ruby 3.0, PHP 8.0 и многие другие.\nПодготовка к установке Регистрация на портале Red Hat Подписка Red Hat Developer Subscription - это бесплатное предложение программы Red Hat Developer, предназначенное для индивидуальных разработчиков, которые хотят воспользоваться всеми преимуществами Red Hat Enterprise Linux.\nОна дает разработчикам доступ ко всем версиям Red Hat Enterprise Linux, а также к другим продуктам Red Hat, таким как дополнения, обновления программного обеспечения и ошибки безопасности.\nПрежде всего, убедитесь, что у вас есть активная учетная запись Red Hat. Если у вас еще нет учетной записи, перейдите на портал Red Hat Customer Portal, нажмите на кнопку “Регистрация” и заполните свои данные для создания учетной записи Red Hat. Загрузка установочного образа После создания учетной записи Red Hat вы можете приступать к загрузке RHEL 9. Чтобы загрузить Red Hat Enterprise Linux 9 абсолютно бесплатно, зайдите на Red Hat Developer Portal и войдите в систему, используя учетные данные своей учетной записи. Затем перейдите на страницу загрузки RHEL 9 и нажмите на кнопку загрузки, показанную ниже.\nЯ использую MacBook M1, поэтому скачиваю образ RHEL 9 для M1 процессора aarch64 Виртуальная машина В качестве вирутальной машины для установки RHEL 9 использую бесплатную виртуальную машину UTM. Установить можно с помощью Homebrew, выполнив команду brew install --cask utm.\nУстановка Red Hat Enterprise Linux 9 Настройка виртуальной машины UTM В UTM нажимаем Create a New Virtual Machine -\u003e Virtualize Выбираем скачанный образ RHEL 9 и нажимаем Continue Главное меню Помеченные поля необходимо заполнить\nСоздаем Root Password User Creation. Создаем пользователя, под которым будет осуществляться вход в систему. Connect to Red Hat. Здесь используем учетную запись, созданную выше.\nВводим данные аккаунта, нажимаем Register Нажимаем Done\nВ разделе Installation Destination выбираем диск по умолчанию\nТеперь можем продолижть установку. На главном экране появилась кнопка Begin installation\nПосле завершения установки перезагружаем систему. Иногда после перезагрузки запускается загрузка с установочного образа опять. Неоьбходимо либо отключить диск в настройка вирутальной машины либо перезагрузить UTM.\nЗапуск Red Hat Enterprise Linux 9 Вводим пароль и видим рабочий стол RHEL 9 Для доступа к приложениям нажимаем кнопку Activities в верхнем левом углу\nНастройка Red Hat Enterprise Linux 9 Проверка пользователя ROOT В системе Linux пользователи относятся к разным группам, у которых есть определенные права. Если в процессе установки мы не поставили галку сделать пользователя администратором, то по умолчанию он не сможет устанавливать некоторые системные программы.\nВыходим из системы и заходим в систему под пользователем root (тем самым, которого создавали ранее на главном экране). Нажимаем Log out Теперь входим под root. Пользователя может не быть в списке. Жмем Not listed и вводим данные аккаунта. Открываем терминал и проверяем Настройка параметров системы Кнопки сворачивания приложения Первое, что кажется непривычным при использовании GUI, отсутствие кнопок сворачивания окон Устанавливаем необходимый пакет\nyum install gnome-tweaks -y После установки появится приложение Tweaks. Найдем его через поиск. В приложении множество и других настроек. Мы отобразим кнопки сворачивания приложений.\nИдем в раздел Windows titlebars и включаем параметры Maximize, Minimize Доступ пользователю на установку приложений Чтобы постоянно не переключаться на root пользователя для устновки приложений, мы можем предоставить обычному пользвоателю доступ к установке приложений. Действия продолжаем делать под пользователем root. Открываем файл /etc/sudoers и добавляем пользователя\nsudo vi /etc/sudoers Добавляем в конец файла данные пользователя. Имя моего пользователя: rhel-user\nrhel-user ALL= NOPASSWD: /usr/sbin/synaptic, /usr/bin/software-center, /usr/bin/apt-get, /usr/bin/dnf Установим Visual Studio Code под обычным пользователем Установка состоит из следующих шагов:\nдобавление нужного репозитория. Права на добавление репозитория (изменение файлов в директории по прежнему только у root пользователя) загрузка и Установка Первый шаг делаем под пользователем root Идем на сайт https://code.visualstudio.com/docs/setup/linux\nКопируем код и запускаем в терминале\nsudo rpm --import https://packages.microsoft.com/keys/microsoft.asc sudo sh -c 'echo -e \"[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\" \u003e /etc/yum.repos.d/vscode.repo' Переключаемся на пользователя rhel-user. Это можно сделать и в терминале. Обновим репозитории Установим VSCode su rhel-user dnf check-update sudo dnf install code Ссылки https://developers.redhat.com/products/rhel/getting-started https://www.redhat.com/sysadmin/install-linux-rhel-9 ","description":"Скачать и установить Linux RHEL 9 бесплатно","title":"Установка Linux RHEL 9","uri":"/ru/posts/howto-install-rhel-9-free/"},{"content":"Для установки Python на MacOS можно использовать менеджер пакетов brew. Для этого необходимо выполнить команду:\nbrew install python Для операционных систем на базе Linux также существуют менеджеры пакетов, которые можно использовать для установки Python. Например, для Ubuntu можно использовать команду:\nsudo apt-get install python Для Windows можно загрузить установочный пакет с официального сайта https://www.python.org/downloads/.\nПосле установки Python необходимо убедиться, что версия Python, установленная на компьютере, соответствует требованиям для запуска необходимых библиотек и инструментов, которые будут использоваться в процессе разработки.\nПроверить версию можно в терминале или командной строке набрав команду python.\nКак только мы запутили Python, можно писать код в терминале.\n","description":"Python 101","title":"Установка Python","uri":"/ru/tracks/python-101/basis/install/"},{"content":"Ubuntu - одна из популярных Linux систем и достаточно много обзоров по установке Ubuntu. В этой статье мы будем устанавливать образ Ubuntu для ARM процессора на виртуальную машину UTM. Вся установка будет проходить на Mac OS.\nЗагрузка установочного образа На сайте Ubuntu доступен для скачивания только образ Ubuntu Server ARM версии 22.04 - без графического интерфейса. Но можно скачать обновленный релиз Ubuntu Desktop для ARM - Daily Build по ссылке.\nНаходим 64-bit ARM (ARMv8/AArch64) desktop image и скачиваем Виртуальная машина В качестве виртуальной машины для установки RHEL 9 использую бесплатную виртуальную машину UTM. Установить можно с помощью Homebrew, выполнив команду brew install --cask utm.\nУстановка Ubuntu Desktop Настройка виртуальной машины UTM В UTM нажимаем Create a New Virtual Machine -\u003e Virtualize Выбираем скачанный образ и нажимаем Continue, далее оставляем опции по умолчанию Запуск Live версии Выбираем Try or Install Ubuntu. Запустится live образ Ubuntu. Такой образ не сохраняет свое состояние после перезагрузки. Входим под пользователем ubuntu:\nВидим рабочий стол и можем пользоваться.\nУстановка Внизу справа есть ярлык для стандартной установки Ubuntu. Нажимаем и запускаем обычную установку на диск. Выбираем нужный язык Я выбираю минимальную установку, т.к. мне не нужны будут предустановленные игры и прочие приложения. Графический интерфейс, браузер, терминал остается со всеми базовыми настройками. Оставляем по умолчанию стирание виртуального диска перед установкой Создаем пользователя, под которым будем входить в систему. Как только установка закончится, нажимаем Restart. У меня после перезагрузки черный экран. Поэтому я просто закрываю и снова запускаю вирутальную машину.\nВход в систему После запуска системы выбираем *Boot from next volume. Первым по умолчанию будет запуск с вирутального образа, но у нас уже есть система на диске, поэтому выбираем запуск со следующего по очереди диска. Входим под своим пользователем Система предлагает скачать обновления для системы. Нажимаю установить. Теперь можно пользоваться системой и все данные будут сохраняться после перезагрузки. Ссылки Kinetic Kudu Release Schedule Daily Builds ","description":"Быстрая базовая установка Ubuntu Desktop 22.10 на виртуальную машину UTM с процессором ARM M1","title":"Установка Ubuntu Desktop 22.10 (Kinetic Kudu) на ARM CPU","uri":"/ru/posts/howto-install-ubuntu-desktop-on-arm/"},{"content":"Python-пакеты можно искать на официальном репозитории PyPI (Python Package Index) по адресу https://pypi.org/. В PyPI представлены большинство сторонних пакетов для Python, их можно устанавливать с помощью менеджера пакетов pip.\nТакже существуют другие источники для поиска и установки Python-пакетов, например, Anaconda, Conda-forge и т.д.\nДля установки пакетов в Python существует несколько способов. Рассмотрим наиболее распространенные из них:\nУстановка с помощью pip pip - это менеджер пакетов для Python, который упрощает установку, удаление и обновление пакетов. Чтобы установить пакет с помощью pip, необходимо выполнить команду в терминале:\npip install package_name Здесь package_name - название пакета, который вы хотите установить. Можно также указать конкретную версию пакета:\npip install package_name==version_number Кроме того, можно установить пакет из файла, используя команду:\npip install path/to/package.whl Установка с помощью Anaconda Anaconda - это дистрибутив Python, который включает в себя множество научных пакетов и библиотек. Установка пакетов в Anaconda происходит с помощью менеджера пакетов conda. Для установки пакета необходимо выполнить команду:\nconda install package_name Установка из исходников При установке пакета из исходников необходимо скачать исходный код пакета, распаковать его, перейти в папку с исходниками и выполнить команду:\npython setup.py install Эта команда выполнит установку пакета.\nВажно отметить, что при установке пакетов необходимо убедиться в том, что используется правильная версия Python и что пакеты совместимы с используемой версией Python.\n","description":"Python 101","title":"Установка пакетов","uri":"/ru/tracks/python-101/external_packages/install_packages/"},{"content":"Google планирует перевести реализацию WebRTC в Chrome с текущего SDP-формата (называемого «Plan B») на формат соответствующих стандартов («Unified Plan», draft-ietf-rtcweb-jsep) в течение следующих нескольких кварталов. План включает 5 этапов и одну временную функцию API.\nКто будет затронут? Людям, которые используют несколько аудиодорожек или несколько видеодорожек в одном PeerConnection, придется протестировать свой продукт в рамках Унифицированного Плана и, соответственно, адаптироваться. В случае, когда вызов инициируется с конечной точки не из Chrome, и на него отвечают в Chrome, форма запросов может измениться.\nЛюдям, выполняющим детальный анализ SDP и заботящимся о msid атрибутах, придется убедиться, что их код синтаксического анализа поддерживает новый формат (a=msid). Подробная информация о том, потребуются ли изменения и как должны измениться приложения, будет зависеть от приложения. Мы думаем, что почти все приложения, которые используют только одну аудио- и одну видеодорожку для каждого RTCPeerConnection, - их эти изменения не коснутся.\nФункция API Мы добавляем новую функцию в RTCConfiguration RTCPeerConnection:\nenum SdpSemantics { \"plan-b\", \"unified-plan\" }; partial dictionary RTCConfiguration { SdpSemantics sdpSemantics; } RTCConfiguration может быть передана конструктору из RTCPeerConnection, и все запросы и ответы будут в формате Унифицированного Плана. Запросы в setLocalDescription и setRemoteDescription также будут ожидать, что SDP будет в формате Унифицированного Плана; если он в устаревшем формате Chrome, то все, кроме первой звуковой дорожки и первой видеодорожки, будут игнорироваться.\nТакже есть флаг командной строки (–enable-features=RTCUnifiedPlanByDefault в версии Chrome M71 и выше, –enable-blink-features=RTCUnifiedPlanByDefault в более ранних версиях), который позволяет установить для этого флага значение по умолчанию в «Unified-plan».\nЭтапы Этап 1. Внедрение Унифицированного Плана На этом этапе Унифицированный План разрабатывался под флагом экспериментов, доступным с версии M65. До этапа 2 разумнее всего было тестировать Chrome Canary, используя «–enable-blink-features=RTCUnifiedPlan».\nЭтап 2. Сделать функцию API общедоступной Представлено в версии M69 (бета-август 2018 г., стабильная версия в сентябре 2018 г.)\nНа этом этапе значением по умолчанию флага sdpSemantics было «plan-b». На этапе 2 люди, у которых были реализации, зависящие от формата SDP, должны были протестировать, работают ли их приложения при использовании Унифицированного Плана. Для приложений, поддерживающих Firefox, это очень простое упражнение: просто делайте то же, что делали до этого в Firefox. Значение по умолчанию флага sdpSemantics можно изменить в «chrome://flags»; найдите функцию «WebRTC: Use Unified Plan SDP Semantics by default».\nЭтап 3 Переключите значение по умолчанию Датой перехода была версия M72 (бета-декабрь 2018 г., стабильная версия — январь 2019 г.). На этом этапе было изменено значение флага sdpSemantics по умолчанию на «unified plan». Приложения, которые обнаружили, что стали работать медленнее, переустановили флаг sdpSemantics в «plan-b», чтобы вернуться к предыдущему поведению.\nЭтап 4: бросьте «План Б» На этом этапе установка флага sdpSemantics в значение «plan-b» приводит к возникновению исключения. Это было сделано при переходе от версии Canary к M93. Что касается M96, исключение работает как в Canary, так и на Beta. План состоит в том, чтобы добавить его и в стабильную версию. Мы следим за использованием Plan B. На этом этапе доступна пробная версия, которая позволяет использовать план Б без создания исключений. Эта пробная версия перестала работать 29 декабря 2021 г.\nЭтап 5: Уберите «План Б» После окончания пробного периода Plan B будет удален из Chrome. На этом этапе флаг sdpSemantics будет удален. Попытка установить его на «plan-b» не вызовет исключение, и перестанет работать.\n","description":"Карманная книга по WebRTC","title":"Формат SDP унифицированного плана – план перехода","uri":"/ru/tracks/webrtc/unified-plan-transition-guide/"},{"content":"Функция - это структура, которую вы определяете. Вы можете решать, есть ли у них аргументы или нет. Вы можете добавить аргументы в виде ключевых слов и аргументы по умолчанию.\nФункция - это блок кода, который начинается с ключевого слова def, имени функции и двоеточия. Вот простой пример:\ndef a_function(): print(\"You just created a function!\") Эта функция ничего не делает, кроме вывода какого-то текста.\ndef add(a, b): result = a + b return result В этом примере мы создали функцию add, которая принимает два аргумента a и b и возвращает их сумму.\nВызов функции происходит путем указания имени функции, за которым следуют аргументы в скобках.\nПример:\nresult = add(2, 3) print(result) # выводит 5 Пустая функция (заглушка) Иногда, когда вы пишете код, вы просто хотите написать определения функций, не вставляя в них никакого кода.\ndef empty_function(): pass Все функции что-то возвращают. Если не указать ей, что она должна что-то вернуть, то она вернет None.\nАргументы с ключевыми словами Функции также могут принимать аргументы в виде ключевых слов! На самом деле они могут принимать как обычные аргументы, так и аргументы с ключевыми словами. Значит, вы можете указать, какие ключевые слова какими являются, и передать их. Вы видели такое поведение в предыдущем примере.\ndef keyword_function(a=1, b=2): return a+b keyword_function(b=4, a=5) # 9 Вы также могли бы вызвать эту функцию без указания ключевых слов. Эта функция также демонстрирует концепцию аргументов по умолчанию. Каким образом? Ну, попробуйте вызвать функцию вообще без аргументов!\nkeyword_function() # 3 *args и **kwargs Также функции могут принимать переменное число аргументов или аргументы с произвольными именами (как в словарях). Это делается с помощью операторов * и **.\ndef myfunc(*args): for arg in args: print(arg) Эта функция принимает переменное число аргументов и выводит их все на экран.\nФункции в Python также могут иметь аргументы со значениями по умолчанию. Если аргумент не передан при вызове функции, то будет использовано значение по умолчанию. Например:\ndef myfunc(a, b=10): result = a + b return result В этом примере мы создали функцию myfunc, которая принимает два аргумента: a и b (по умолчанию равный 10). Если при вызове функции не указан второй аргумент, то он будет равен 10.\nФункции также могут принимать аргументы с ключевыми словами, которые представляют собой пары “ключ-значение”. Эти аргументы позволяют явно указать, какое значение должно быть использовано для каждого параметра функции. Для определения аргументов с ключевыми словами используются двойные звездочки (**).\ndef print_values(**kwargs): for key, value in kwargs.items(): print(key, value) print_values(name='John', age=25, city='New York') В этом примере функция print_values() принимает произвольное количество аргументов с ключевыми словами и выводит их на экран. При вызове функции передаются аргументы с ключевыми словами name, age, и city, и функция выводит их значения.\nАргументы с ключевыми словами особенно полезны, когда у функции есть множество параметров, и вы хотите явно указать, какое значение должно быть использовано для каждого параметра. Это также может быть полезно, если вы используете библиотеку, которая принимает множество аргументов, и вы хотите быть уверены, что вы передаете значения правильно.\nРесурсы:\nhttps://vegibit.com/python-function-tutorial/ ","description":"Python 101","title":"Функции","uri":"/ru/tracks/python-101/basis/functions/"},{"content":"Цикл while Цикл while повторяет набор инструкций, пока заданное условие истинно. Каждый раз, когда выполняется набор инструкций, условие проверяется снова, и если оно продолжает быть истинным, то набор инструкций выполняется снова.\ni = 1 while i \u003c 6: print(i) i += 1 1 2 3 4 5 Цикл for Цикл for используется для прохождения через элементы в последовательности, такой как список или строка. В отличие от цикла while, в цикле for не нужно определять начальное условие или шаг увеличения.\nfruits = [\"apple\", \"banana\", \"cherry\"] for x in fruits: print(x) apple banana cherry Операторы break и continue Оператор break позволяет выйти из цикла, когда выполнено определенное условие, даже если условие продолжает оставаться истинным. Оператор continue позволяет пропустить определенные итерации цикла, когда выполняется определенное условие, и продолжить следующую итерацию.\nПример:\ni = 0 while i \u003c 6: i += 1 if i == 3: continue print(i) if i == 5: break 1 2 4 5 else в циклах Конструкция else в циклах в Python выполняется, когда цикл завершается нормально, то есть без использования оператора break. Если оператор break используется в цикле, то блок кода, указанный после else, не будет выполняться.\nВ цикле while, конструкция else будет выполнена, когда условие цикла станет ложным, и все итерации будут выполнены.\nВ цикле for, конструкция else будет выполнена после последней итерации, когда больше нет элементов для итерации.\nnumbers = [1, 2, 3, 4, 5] for num in numbers: if num == 3: print(\"Found 3\") break else: print(\"3 not found\") В этом примере, если число 3 найдено в списке numbers, то будет выведено “Found 3”. Если число 3 не найдено в списке, то после окончания цикла будет выведено “3 not found”.\n","description":"Python 101","title":"Циклы","uri":"/ru/tracks/python-101/basis/loops/"},{"content":"Инфа СОХНУТ - Еврейское агентство для Израиля, — международная сионистская организация с центром в государстве Израиль, которая занимается репатриацией в Израиль и помощью репатриантам.\nhttps://www.jewishagency.org/ru/\nМинистерства алии и интеграции тел. *2994 или 03-9733333\nСсылки Чаты, где спрашивать:\nhttps://t.me/OlimHadashim https://t.me/olehadash_com_chat https://t.me/forum_israel Няни, частные учителя, частные школы и садики в Израиле. https://www.facebook.com/groups/Nyani.Uchitelya.Shkoli.Israel\nASD в Израиле. Все о детях в спектре и их родителях https://www.facebook.com/groups/asdisraelrus\nМамочки Израиля https://www.facebook.com/groups/1524467887858435\nРепатрианты в Израиле: здесь помогают и делятся опытом https://www.facebook.com/groups/1511311149184796\nОТДАМ ДАРОМ В ИЗРАИЛЕ https://www.facebook.com/groups/1601685156757272\nДругие инструкции\nhttps://olehadash.com/\nВторичка:\nhttps://t.me/BROOTTO\nРассчет налога по зарплате\nПервая неделя Сначала получить симкарту, все уведомления на нее. Брать любую, тариф в среднем около 30-40 шек мес\nБанк\nоткрыть счет (леуми или дисконт)\nсразу запросить чеки (нужны для аренды квартиры и мало ли на что еще, стоят около 10шек)\nсамую дешевую карту, без всяких плат попросить.\nБольничаная касса\nвзял маккаби, вроде все примерно одинаковые но у маккаби больше покрытия, может чуть подороже она\nПодработки Форма для добавления в базу резюме или на поиск работы: https://forms.gle/NFB2JXs1fHrCJn5Q7\nРасчет налога на зарплату: https://investomatica.com/income-tax-calculator/israel\nЧто спрашивают и какие документы нужны, и как с оплатой\nhttps://t.me/joinchat/DlAMLxN_S-XCXgJ8MQxslg https://t.me/Rus_Work_Israel https://t.me/izrail_rabota https://t.me/sidejobisrael https://t.me/rabotadlyadruzei https://t.me/rabotaisraeli ","description":"репатриация в Израиль","title":"Чеклист репатриация в Израиль","uri":"/ru/p/%D1%80%D0%B5%D0%BF%D0%B0%D1%82%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D1%8F/"},{"content":"Числовые типы данных в Python могут быть целыми числами (int), числами с плавающей запятой (float) и комплексными числами (complex).\nЦелые числа - это числа без дробной части, а числа с плавающей запятой - это числа с дробной частью.\nКомплексные числа представляются парой вещественных чисел и используются в математических расчетах.\na = 5 # целое число b = 3.14 # вещественное число c = 2 + 3j # комплексное число print(type(a)) # выведет \u003cclass 'int'\u003e print(type(b)) # выведет \u003cclass 'float'\u003e print(type(c)) # выведет \u003cclass 'complex'\u003e Python поддерживает все стандартные арифметические операции: сложение, вычитание, умножение, деление, возведение в степень, целочисленное деление и остаток от деления.\na = 10 b = 3 print(a + b) # сложение, выведет 13 print(a - b) # вычитание, выведет 7 print(a * b) # умножение, выведет 30 print(a / b) # деление, выведет 3.3333333333333335 print(a ** b) # возведение в степень, выведет 1000 print(a // b) # целочисленное деление, выведет 3 print(a % b) # остаток от деления, выведет 1 ","description":"Python 101","title":"Числа","uri":"/ru/tracks/python-101/basis/numbers/"},{"content":"Кратко Создать:\ntar cf archive.tar directory Распаковать:\ntar xf archive.tar Создание mkdir my_dir # Создаем папку tar cf dir_archive.tar my_dir # Создаем архив с папкой ll # Проверяем содержимое текущего каталога # -rw-r--r-- 1 r staff 1.5K Jun 4 14:42 dir_archive.tar # drwxr-xr-x 2 r staff 64B Jun 4 14:42 my_dir Распаковка tar xf dir_archive.tar Сжатие tar czf dir_archive.tar.gz dir_archive.tar Распаковка сжатого файла tar xzf dir_archive.tar.gz Сжатие с помощью bzip2 tar cjf dir_archive.tar.bz2 my_dir Распаковка с помощью bzip2 tar xjf dir_archive.tar.bz2 Просмотр содержимого архива tar -tvf dir_archive.tar ","description":"Необходимые команды для работы с архиватором tar","title":"Шпаргалка tar архиватор","uri":"/ru/posts/cheat-sheet-command-tar/"}]