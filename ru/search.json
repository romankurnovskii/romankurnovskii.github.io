[{"content":"Введение - День 1 Первый день из 90, чтобы получить хорошее базовое понимание DevOps и инструментов.\nЭтот путь обучения начался для меня несколько лет назад, но тогда я сосредоточился на платформах виртуализации и облачных технологиях. В основном я изучал инфраструктуру как код и управление конфигурацией приложений с помощью Terraform и Chef.\nПеренесемся в март 2021 года. Мне представилась прекрасная возможность сосредоточить свои усилия на стратегии Cloud Native в Kasten by Veeam. Это должно было стать огромным фокусом на Kubernetes и DevOps, а также на сообществе, окружающем эти технологии. Я начал свое обучение и быстро понял, что помимо изучения основ Kubernetes и контейнеризации существует очень широкий мир, и именно тогда я начал общаться с сообществом и узнавать все больше и больше о культуре, инструментах и ​​​​процессах DevOps, поэтому я начал публично документировать некоторые области, которые я хотел изучить.\nНачнем наше путешествие Если вы прочитаете приведенный выше блог, вы увидите, что это содержание высокого уровня для моего учебного пути, и я скажу, что на данный момент я не являюсь экспертом ни в одном из этих разделов, но я хотел поделиться некоторыми БЕСПЛАТНЫМИ ресурсами. а некоторые платные, но вариант для обоих, так как у всех разные обстоятельства.\nВ течение следующих 90 дней я хочу задокументировать эти ресурсы и охватить эти основополагающие области. Я бы хотел, чтобы сообщество также приняло участие, поделилось своим путешествием и ресурсами, чтобы мы могли учиться публично и помогать друг другу.\nИз начального файла readme в репозитории проекта вы увидите, что я разделил все на разделы, и в основном это 12 недель плюс 6 дней. Первые 6 дней мы будем изучать основы DevOps в целом, прежде чем погрузиться в некоторые конкретные области, этот список ни в коем случае не является исчерпывающим, и мы снова будем рады, если сообщество поможет сделать этот ресурс полезным.\nЕще один ресурс, которым я поделюсь на этом этапе, который, я думаю, каждый должен внимательно изучить и, возможно, создать свою собственную карту ума для себя, своих интересов и позиции:\nDevOps Roadmap\nЯ нашел это отличным ресурсом, когда создавал свой первоначальный список и сообщение в блоге по этой теме. Вы также можете заметить, что помимо 12 тем, которые я перечислил здесь, в этом репозитории, есть и другие разделы, требующие более подробного рассмотрения.\nПервые шаги - или что такое DevOps? Есть так много статей в блогах и видео на YouTube, которые можно перечислить здесь, но поскольку мы начинаем 90-дневное испытание и сосредоточиваемся на том, чтобы тратить около часа в день на изучение чего-то нового или о DevOps, я подумал, что было бы хорошо получить некоторые из высокого уровня «что такое DevOps» для начала.\nВо-первых, DevOps — это не инструмент. Вы не можете купить его, это не номер программного обеспечения или репозиторий GitHub с открытым исходным кодом, который вы можете скачать. Это также не язык программирования, это также не какая-то магия темного искусства.\nDevOps — это способ делать более разумные вещи в разработке программного обеспечения. - Подождите… Но если вы не разработчик программного обеспечения, вы должны отвернуться прямо сейчас и не погрузиться в этот проект??? Нет, совсем нет, оставайтесь… Потому что DevOps объединяет разработку программного обеспечения и эксплуатацию. Ранее я упоминал, что больше занимаюсь виртуальными машинами, и это, как правило, относится к сфере эксплуатации, но в сообществе есть люди с самым разным опытом, и DevOps на 100 % принесет пользу отдельным лицам, разработчикам, специалистам по эксплуатации и Все инженеры по контролю качества могут в равной степени изучить эти передовые методы, лучше разбираясь в DevOps.\nDevOps — это набор практик, которые помогают достичь цели этого движения: сократить время между фазой создания идеи продукта и его выпуском в производство для конечного пользователя или кого бы то ни было, внутренней команды или клиента.\nЕще одна область, в которую мы углубимся в первую неделю, касается Методологии Agile. DevOps и Agile широко применяются вместе для обеспечения непрерывной доставки вашего Приложения.\nГлавный вывод заключается в том, что образ мышления или культура DevOps позволяют сократить затянувшийся процесс выпуска программного обеспечения с потенциально многих лет до возможности более частого выпуска небольших выпусков. Другой ключевой принцип, который следует здесь усвоить, заключается в том, что речь идет о разрушении разрозненности между командами, о которых я упоминал ранее, разработчиками, эксплуатацией и контролем качества.\nС точки зрения DevOps, разработка, тестирование и развертывание выполняются командой DevOps.\nПоследнее, что я хотел бы сделать, чтобы сделать это максимально эффективным и действенным, мы должны использовать автоматизацию\nИсточники Я всегда открыт для добавления дополнительных ресурсов в эти файлы readme, поскольку они здесь в качестве учебного пособия.\nМой совет — посмотрите все ссылки ниже, и, надеюсь, вы тоже что-то почерпнули из текста и объяснений выше.\nDevOps in 5 Minutes What is DevOps? Easy Way DevOps roadmap 2022 | Success Roadmap 2022 ","description":"DevOps - общее представление","title":"1. DevOps - общее представление","uri":"/ru/docs/90daysofdevops/day01/"},{"content":"Глава 1 - Программирование IDLE Использование IDLE Python поставляется с собственным редактором кода: IDLE (Integrated Development and Learning Environment). Существует предание, что название IDLE происходит от имени Эрика Айдла, актера из “Монти Пайтона”. IDE - это редактор для программистов, который обеспечивает цветную подсветку ключевых слов языка, автозаполнение, “экспериментальный” отладчик и множество других интересных вещей. Вы можете найти IDE к большинству популярных языков, а некоторые IDE работают с несколькими языками.\nIDLE - это своего рода легкая IDE, но в ней есть все перечисленные элементы. Она позволяет программисту писать на Python и отлаживать свой код довольно просто. Причина, по которой я называю её “легким”, заключается в том, что отладчик очень базовый. В нем отсутствуют другие функции, которые программисты, имеющие опыт работы с такими продуктами, как Visual Studio, пропустят. Вам также будет интересно узнать, что IDLE был создан с помощью Tkinter, набора инструментов графического интерфейса Python, который поставляется вместе с Python.\nЧтобы открыть IDLE, вам нужно найти его, и вы увидите что-то вроде этого:\nДа, это оболочка Python, в которой вы можете набирать короткие сценарии и сразу же видеть их вывод, и даже взаимодействовать с кодом в реальном времени. Компиляция кода не требуется, так как Python является интерпретируемым языком и выполняется в интерпретаторе Python. Давайте сейчас напишем вашу первую программу. Введите следующее после командной строки (»\u003e) в IDLE:\nprint(\"Hello from Python!\") Вы только что написали свою первую программу! Все, что делает ваша программа, это записывает строку на экран, но позже вы увидите как это полезно.\nВ Python 3 оператор print превратился в функцию print, поэтому скобки необходимы. Что такое функции, вы узнаете в главе 10.\nЕсли вы хотите сохранить свой код в файл, зайдите в меню Файл и выберите Новое окно (или нажмите CTRL+N). Теперь вы можете набрать свою программу и сохранить ее здесь. Главное преимущество использования оболочки Python заключается в том, что вы можете экспериментировать с небольшими фрагментами кода, сразу видеть как он себя поведёт, прежде чем поместите его в реальную программу. Экран редактора кода выглядит немного иначе, чем на скриншоте IDLE выше:\nТеперь мы уделим немного времени рассмотрению других полезных возможностей IDLE.\nPython поставляется с большим количеством модулей и пакетов, которые можно импортировать для добавления новых возможностей. Например, вы можете импортировать модуль math для всех видов хороших математических функций, таких как квадратные корни, косинусы и т.д. В меню File вы найдете Path Browser, который пригодится для того, чтобы понять, где Python ищет импорт модулей. Python сначала ищет в том же каталоге, что и запущенный скрипт, чтобы узнать, есть ли там файл, который нужно импортировать. Затем он проверяет предопределенный список других мест. Вы можете добавлять и удалять эти места. Браузер путей покажет вам, где эти файлы находятся на вашем жестком диске, если вы что-то импортировали. Мой Path Browser выглядит следующим образом:\nДалее находится Class Browser, который поможет вам ориентироваться в коде. Честно говоря, было бы логичнее назвать этот пункт меню “Браузер модулей”, так как это гораздо ближе к тому, что вы будете делать на самом деле. В действительности это то, что не очень полезно для вас сейчас, но будет полезно в будущем. Когда у вас много строк кода в одном файле это очень поможет, дав “древовидный” интерфейс. Обратите внимание, что вы не сможете загрузить Class Browser, пока не сохраните свою программу.\nМеню Edit содержит типичные функции, такие как Копировать, Вырезать, Вставить, Отменить, Повторить и Выбрать все. Оно также содержит различные способы поиска кода и поиска и замены. Наконец, в меню Правка есть несколько пунктов, которые показывают вам различные вещи, такие как выделение круглых скобок или отображение списка автозаполнения.\nМеню Format содержит множество полезных функций. В нем есть несколько полезных пунктов, позволяющих делать отступы и вычеты * в коде, а также комментировать код. Это довольно полезно при тестировании кода. Комментирование кода может быть очень полезным, когда у вас много кода и вам нужно выяснить, почему он работает неправильно. Комментирование части кода и повторный запуск скрипта могут помочь вам понять, где вы ошиблись. Вы просто медленно продвигаетесь по пути, не комментируя ничего, пока не найдете ошибку. Это напомнило мне о том, что вы, возможно, заметили, что на главном экране IDLE есть меню Debugger.\nЭто удобно для отладки, но только в окне Shell. К сожалению, вы не можете использовать отладчик в главном меню редактирования. Однако вы можете запустить модуль с включенной отладкой так, чтобы иметь возможность взаимодействовать с объектами вашей программы. Это будет полезно, например, в циклах, где вы пытаетесь определить текущее значение элемента внутри цикла. Если вы используете tkinter для создания пользовательского интерфейса (UI), вы можете не включать вызов mainloop() (который может блокировать UI), чтобы иметь возможность отлаживать пользовательский интерфейс. Наконец, если при запущенном отладчике возникает исключение, вы можете дважды щелкнуть по нему, чтобы перейти непосредственно к коду, в котором произошло исключение.\nЕсли вам нужен более универсальный отладчик, вам следует либо найти другую IDE, либо попробовать отладчик Python, находящийся в библиотеке pdb.\nЧто такое комментарии? Комментарий - это способ оставить неисполняемый код, который документирует то, что вы делаете в своем коде. Каждый язык программирования использует различные символы для обозначения начала и конца комментария. Как выглядят комментарии в Python? Комментарий - это все, что начинается с восьмеричного символа (т.е. знака хеша или фунта). Ниже приведен пример некоторых комментариев в действии:\n# This is a comment before some code print(\"Hello from Python!\") print(\"Winter is coming\") # this is an in-line comment Комментарии можно писать в строке сами по себе или после оператора, как, например, во втором операторе print выше. Интерпретатор Python игнорирует комментарии, поэтому вы можете писать в них все, что захотите. Большинство программистов, с которыми я встречался, не очень часто используют комментарии. Однако я настоятельно рекомендую использовать комментарии не только для себя, но и для всех остальных, кому в будущем придется поддерживать или улучшать ваш код. Я понял, что собственные комментарии полезны, когда вернулся к сценарию, который я написал 6 месяцев назад. Обнаружив, что работаю с не закомментированным кодом, я жалел, что не написал комментариев раньше, чтобы быстрее разобраться в коде сейчас.\nПримерами хороших комментариев могут быть пояснения к сложным утверждениям кода или добавление пояснений к аббревиатурам в коде. Иногда вам нужно оставить комментарий, чтобы объяснить, почему вы сделали что-то определенным образом, потому что это просто не очевидно*.\nТеперь нам нужно вернуться к рассмотрению опций меню IDLE:\nВ меню Run есть несколько удобных опций. С его помощью можно вызвать оболочку Python Shell, проверить код на наличие ошибок или запустить его. В меню Options не так много пунктов. В нем есть пункт Настроить, который позволяет изменить цвет подсветки кода, шрифт и сочетания клавиш. Кроме того, есть опция Code Context, которая полезна тем, что помещает в окно редактирования накладку, показывающую, в каком классе или функции вы сейчас находитесь. Мы будем объяснять функции и классы в конце первой части. Вы увидите как эта функция полезна, когда у в функции много кода, а название прокручивается за пределы верхней части экрана. При включенной опции этого не произойдет. Конечно, если функция слишком велика, чтобы поместиться на одном экране, то, возможно, она стала слишком длинной и пора разбить её на несколько функций. Еще один интересный пункт в диалоге настроек находится на вкладке General, где вы можете добавить другую документацию. Это означает, что вы можете добавить URL-адреса к документации сторонних разработчиков, например, SQLAlchemy или pillow, и получить ее в IDLE. Чтобы получить доступ к новой документации, просто перейдите в меню Help.\nМеню Windows показывает список открытых в данный момент окон и позволяет переключаться между ними.\nПоследнее, но не менее важное меню - это меню Help, где вы можете узнать об IDLE, получить помощь по работе с самой IDLE или загрузить локальную копию документации по Python. Документация объясняет, как работает каждый элемент Python, и является довольно исчерпывающей в своем охвате. Меню Help, вероятно, наиболее полезно тем, что вы можете получить доступ к документации, даже если вы не подключены к Интернету. Вы можете искать в документации, находить HOWTO, читать о любой из встроенных библиотек и узнавать столько нового, что у вас голова начнет кружиться.\nДругие советы Когда вы увидите примеры кода в следующих главах, вы можете написать и запустить их в IDLE. Я писал все свои программы в IDLE первые пару лет своей жизни программиста на Python и был вполне доволен этим. Однако существует множество бесплатных IDE для Python и несколько IDE, за которые нужно платить. Если вы хотите обойтись дешевой, вам стоит обратить внимание на Eclipse+PyDev, VSCode, Atom, Sublime Text или даже Notepad++. Из платных - PyCharm, но есть и ознакомительная версия. Они имеют гораздо больше возможностей, таких как интеграция с репозиториями кода, лучшие отладчики, помощь в рефакторинге и т.д.\nVisual Studio Code с набором отличных плагинов - самый универсальный и бесплатный инструмент.\nВ этой книге мы будем использовать IDLE в наших примерах, потому что она поставляется вместе с Python и обеспечивает общий тестовый стенд. Я по-прежнему считаю, что IDLE имеет лучшую, наиболее последовательную подсветку кода из всех IDE, которые я использовал. Подсветка кода важна, на мой взгляд, потому что она помогает избежать использования одного из ключевых слов Python (или встроенных модулей) для имени переменной. Если вам интересно, вот список этих ключевых слов:\nand del from not while as elif global or with assert else if pass yield break except import print class exec in raise continue finally is return def for lambda try Давайте посмотрим, что произойдет, когда мы напечатаем несколько вещей на языке Python:\nКак вы можете видеть, IDLE все кодирует цветом. Ключевое слово имеет пурпурный цвет, строка текста - зеленый, комментарий - красный, а вывод функции печати - синий.\nПодведение итогов В этой главе мы узнали, как использовать интегрированную среду разработки Python, IDLE. Мы также узнали, что такое комментарии и как их использовать. На данном этапе вы должны быть достаточно знакомы с IDLE, чтобы использовать ее в остальных частях этой книги. Существует множество других интегрированных сред разработки (IDE) для Python.\nНа данный момент мы готовы двигаться дальше и начать изучать различные типы данных Python. В следующей главе мы начнем со строк.\n","description":"Python 101","title":"1. Программирование IDLE","uri":"/ru/docs/python101/chapter1_idle/"},{"content":"Окружение Go В 8-м дне мы кратко рассмотрели рабочее пространство Go, чтобы запустить его и перейти к демонстрации «Hello #90DaysOfDevOps». Но мы должны немного рассказать о рабочем пространстве Go.\nПомните, что мы выбрали значения по умолчанию, а затем прошли и создали нашу папку Go в GOPATH, который уже был определен, но на самом деле этот GOPATH можно изменить, чтобы он находился там, где вы хотите.\nЕсли вы запустите\necho $GOPATH Вывод должен быть похож на мой (может быть с другим именем пользователя), а именно:\n/home/michael/projects/go Затем здесь мы создали 3 директории. src, pkg и bin\nsrc is where all of your Go programs and projects are stored. This handles namespacing package management for all your Go repositories. This is where you will see on our workstation we have our Hello folder for the Hello #90DaysOfDevOps project.\npkg — это место, где хранятся ваши заархивированные файлы пакетов, которые установлены или были установлены в программах. Это помогает ускорить процесс компиляции в зависимости от того, были ли изменены используемые пакеты. bin — это место, где хранятся все ваши скомпилированные двоичные файлы.\nНаш Hello #90DaysOfDevOps не является сложной программой, поэтому вот пример более сложной программы Go, взятой из другого замечательного ресурса, на который стоит обратить внимание GoChronicles Компиляция и запуск кода На 9-й день мы также рассмотрели краткое введение в компиляцию кода, но здесь мы можем пойти немного глубже.\nЧтобы запустить наш код, мы сначала должны его скомпилировать. В Go это можно сделать тремя способами.\ngo build go install go run Прежде чем мы перейдем к описанному выше этапу компиляции, нам нужно взглянуть на то, что мы получаем при установке Go.\nКогда мы установили Go на 8-й день, мы установили что-то, известное как инструменты Go, которые состоят из нескольких программ, которые позволяют нам создавать и обрабатывать наши исходные файлы Go. Одним из инструментов является «Go».\nСтоит отметить, что вы можете установить дополнительные инструменты, которых нет в стандартной установке Go.\nЕсли вы откроете командную строку и наберете «go», вы должны увидеть что-то вроде изображения ниже, а затем вы увидите «Дополнительные разделы справки» ниже, и пока нам не нужно беспокоиться об этом.\nВозможно, вы также помните, что мы уже использовали как минимум два из этих инструментов в День 8. Мы хотим узнать больше о сборке, установке и запуске.\ngo run - Эта команда компилирует и запускает основной пакет, состоящий из файлов .go, указанных в командной строке. Команда компилируется во временную папку. go build - чтобы скомпилировать пакеты и зависимости, скомпилируйте пакет в текущем каталоге. Если пакет «main», поместит исполняемый файл в текущий каталог, если нет, то он поместит исполняемый файл в папку «pkg». go build также позволяет вам создать исполняемый файл для любой платформы ОС, поддерживаемой Go. go install - то же самое, что и go build, но помещает исполняемый файл в папку bin Мы прошли через go build и go run, но не стесняйтесь запускать их снова здесь, если хотите, go install, как указано выше, помещает исполняемый файл в нашу папку bin. Надеюсь, что вы следите за мной и смотрите один из плейлистов или видеороликов ниже. Я беру их по кусочкам и перевожу в свои заметки, чтобы понять основы языка Голанг. Приведенные ниже ресурсы, вероятно, дадут вам гораздо лучшее понимание многих областей, которые вам нужны в целом, но я пытаюсь задокументировать 7 дней или 7 часов путешествия с интересными вещами, которые я нашел.\nИсточники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 11-й день\n","description":"Окружение Go","title":"10. Окружение Go","uri":"/ru/docs/90daysofdevops/day10/"},{"content":"Функция - это структура, которую вы определяете. Вы можете решать, есть ли у них аргументы или нет. Вы можете добавить аргументы в виде ключевых слов и аргументы по умолчанию. Функция - это блок кода, который начинается с ключевого слова def, имени функции и двоеточия. Вот простой пример:\ndef a_function(): print(\"You just created a function!\") Эта функция ничего не делает, кроме вывода какого-то текста. Чтобы вызвать функцию, нужно напечатать ее имя, за которым следуют открытые и закрытые круглые скобки:\na_function() You just created a function! Просто, да?\nПустая функция (заглушка) Иногда, когда вы пишете код, вы просто хотите написать определения функций, не вставляя в них никакого кода. Я делал это в качестве своеобразного наброска. Это помогает вам увидеть, как будет выглядеть ваше приложение. Вот пример:\ndef empty_function(): pass Вот нечто новое: оператор pass. По сути, это операция null, то есть при выполнении pass ничего не происходит.\nПередача аргументов в функцию Теперь мы готовы узнать, как создать функцию, которая может принимать аргументы, а также как передать эти аргументы в функцию. Давайте создадим простую функцию, которая может складывать два числа:\ndef add(a, b): return a + b add(1, 2) # 3 Все функции что-то возвращают. Если не указать ей, что она должна что-то вернуть, то она вернет None. В данном случае мы говорим ей вернуть a + b. Как видите, мы можем вызвать функцию, передав два значения. Если вы передадите недостаточно или слишком много аргументов, то получите ошибку:\nadd(1) Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: add() takes exactly 2 arguments (1 given) Вы также можете вызвать функцию, передав ей имя аргументов:\nadd(a=2, b=3) # 5 total = add(b=4, a=5) print(total) # 9 Вы заметите, что не имеет значения, в каком порядке вы передаете их в функцию, лишь бы они были названы правильно. Во втором примере видно, что мы присваиваем результат функции переменной с именем total. Это обычный способ вызова функции, поскольку вы захотите что-то сделать с результатом. Вам, вероятно, интересно, что произойдет, если мы передадим аргументы с неправильными именами. Будет ли это работать? Давайте узнаем:\nadd(c=5, d=2) Traceback (последний последний вызов): Файл \"\u003cstring\u003e\", строка 1, в \u003cфрагменте\u003e. TypeError: add() получил неожиданный аргумент ключевого слова 'c' Мы получили ошибку. Это означает, что мы передали аргумент с ключевым словом, который функция не распознала. Какое совпадение, аргументы с ключевыми словами - наша следующая тема!\nАргументы с ключевыми словами Функции также могут принимать аргументы в виде ключевых слов! На самом деле они могут принимать как обычные аргументы, так и аргументы с ключевыми словами. Значит, вы можете указать, какие ключевые слова какими являются, и передать их. Вы видели такое поведение в предыдущем примере.\ndef keyword_function(a=1, b=2): return a+b keyword_function(b=4, a=5) # 9 Вы также могли бы вызвать эту функцию без указания ключевых слов. Эта функция также демонстрирует концепцию аргументов по умолчанию. Каким образом? Ну, попробуйте вызвать функцию вообще без аргументов!\nkeyword_function() # 3 Функция вернула число 3! Почему? Причина в том, что a и b имеют значения по умолчанию 1 и 2 соответственно. Теперь давайте создадим функцию, которая имеет как обычный аргумент, так и пару аргументов в виде ключевых слов:\ndef mixed_function(a, b=2, c=3): return a+b+c mixed_function(b=4, c=5) Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: mixed_function() takes at least 1 argument (2 given) mixed_function(1, b=4, c=5) # 10 mixed_function(1) # 6 В приведенном выше коде есть 3 примера. Давайте рассмотрим каждый из них. В первом примере мы пытаемся вызвать нашу функцию, используя только аргументы ключевого слова. Это приведет нас к непонятной ошибке. В Traceback говорится, что наша функция принимает хотя бы один аргумент, но было передано два. Что же здесь происходит? Дело в том, что первый аргумент является обязательным, так как он ничем не задан, поэтому если вы вызываете функцию только с аргументами ключевых слов, это приводит к ошибке.\nВо втором примере мы вызываем смешанную функцию с 3 значениями, называя два из них. Это работает и дает нам ожидаемый результат - 1+4+5=10. Третий пример показывает, что произойдет, если мы вызовем функцию, передав только одно значение… то, которое не имеет значения по умолчанию. Это также работает, если взять значение “1” и добавить его к двум значениям по умолчанию “2” и “3”, чтобы получить результат “6”! Разве это не круто?\n*args и **kwargs Вы также можете настроить функции на прием любого количества аргументов или ключевых слов, используя специальный синтаксис. Чтобы получить бесконечное количество аргументов, используйте *args, а для бесконечного количества аргументов ключевых слов - **kwargs. Слова “args” и “kwargs” не имеют значения. Это просто условность. Вы могли бы назвать их *bill и **ted, и это работало бы точно так же. Ключ здесь в количестве звездочек.\nПримечание: в дополнение к соглашению о *args и **kwargs, вы также будете время от времени встречать *a и **kw.\nДавайте рассмотрим небольшой пример:\ndef many(*args, **kwargs): print(args) print(kwargs) many(1, 2, 3, name=\"Mike\", job=\"programmer\") # (1, 2, 3) # {'job': 'programmer', 'name': 'Mike'} Сначала мы создадим нашу функцию, используя новый синтаксис, а затем вызовем ее с тремя обычными аргументами и двумя аргументами в виде ключевых слов. Сама функция выведет оба типа аргументов. Как видите, параметр args превращается в кортеж, а kwargs - в словарь. Вы можете увидеть этот тип кодирования в исходном тексте Python и во многих сторонних пакетах Python.\nЗамечание об области видимости и глобальных значениях В Python есть понятие области видимости, как и в большинстве языков программирования. Область видимости подскажет нам, когда переменная доступна для использования и где. Если мы определяем переменные внутри функции, то эти переменные могут быть использованы только внутри этой функции. После завершения функции они больше не могут быть использованы, поскольку выходят из области видимости. Давайте рассмотрим пример:\ndef function_a(): a = 1 b = 2 return a+b def function_b(): c = 3 return a+c print( function_a() ) print( function_b() ) Если вы запустите этот код, вы получите следующую ошибку:\nNameError: global name 'a' is not defined Это происходит потому, что переменная a определена только в первой функции и недоступна во второй. Это можно обойти, сказав Python, что a является глобальной переменной. Давайте посмотрим, как это делается:\ndef function_a(): global a a = 1 b = 2 return a+b def function_b(): c = 3 return a+c print(function_a()) # 3 print(function_b()) # 4 Этот код будет работать, потому что мы сказали Python сделать переменную глобальной, что означает, что она будет доступна везде в нашей программе. Обычно это плохая идея не рекомендуется. А всё потому, что в этом случае трудно определить, когда переменная определена. Другая проблема заключается в том, что, определив глобальную переменную в одном месте, мы можем случайно переопределить ее значение в другом, что впоследствии может привести к логическим ошибкам, которые трудно отладить.\nСоветы по кодированию Одной из самых больших проблем, которую необходимо усвоить начинающим программистам, является идея “Не повторяй себя”(Don’t Repeat Yourself -DRY). Эта концепция заключается в избегании написания одного и того же кода более одного раза. Если вы обнаружите, что делаете это, то знайте, что этот кусок кода должен быть помещен в функцию. Основная причина заключается в том, что в будущем вам почти наверняка понадобится снова изменить этот кусок кода, а если он находится в нескольких местах, то чтобы изменить его, вам придется вспоминать где ещё вы его писали.\nКопирование и вставка одного и того же фрагмента кода повсюду - это пример “спагетти-кода”. Старайтесь максимально избегать этого. В какой-то момент вы пожалеете об этом либо потому, что вам придется исправлять его, либо потому, что вы найдете чужой код с подобными проблемами, который вам придется поддерживать.\nПодведение итогов Теперь у вас есть базовые знания, необходимые для эффективного использования функций. Вам следует попрактиковаться в создании некоторых простых функций и попробовать вызывать их различными способами. После того как вы немного поиграете с функциями или просто решите, что хорошо понимаете концепции, вы можете перейти к следующей главе, посвященной классам.\nРесурсы https://vegibit.com/python-function-tutorial/ ","description":"Python 101","title":"10. Функции","uri":"/ru/docs/python101/chapter10_functions/"},{"content":"Все в Python является объектом. Это означает, что каждая сущность в Python имеет методы и значения. Причина в том, что в основе всего лежит класс.\n\u003e\u003e\u003e x = \"Some String\" \u003e\u003e\u003e dir(x) ['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] Здесь у нас есть строка, присвоенная переменной x. Может показаться, что это не так много, но у этой строки есть много методов. Если вы используете ключевое слово dir в Python, то сможете получить список всех методов, которые можно вызвать для вашей строки.\nТехнически мы не должны напрямую вызывать методы, начинающиеся с символов подчеркивания, но их можно вызвать.\nЭто значит, что строка основана на классе, а x- это экземпляр этого класса!\nВ Python мы можем создавать свои собственные классы.\nСоздание класса Создать класс в Python очень просто. Вот очень простой пример:\nclass Vehicle(object): \"\"\"docstring\"\"\" def __init__(self): \"\"\"Constructor\"\"\" pass Этот класс не делает ничего особенного, однако он является очень хорошим инструментом обучения. Например, чтобы создать класс, нам нужно использовать ключевое слово Python class, за которым следует имя класса. В Python принято, что в имени класса первая буква должна быть заглавной. Далее следует открытая скобка, за которой следует слово object и закрытая скобка. object - это то, на чем основан класс или от чего он наследуется. Он известен как базовый класс или родительский класс.\nБольшинство классов в Python основаны на объекте. У классов есть специальный метод init (для инициализации). Этот метод вызывается всякий раз, когда вы создаете (или инстанцируете) объект на основе данного класса. Метод init вызывается только один раз и не должен вызываться повторно внутри программы. Другим термином для init является конструктор, хотя этот термин не часто используется в Python.\nВам может быть интересно, почему я все время говорю метод, а не функция. Функция меняет свое название на “метод”, когда она находится внутри класса. Вы также заметите, что каждый метод должен иметь хотя бы один аргумент (т.е. self), чего нельзя сказать об обычной функции.\nВ Python 3 нам не нужно прямо указывать, что мы наследуем у объекта. Вместо этого мы могли бы написать вышеописанное следующим образом:\n# Python 3.x syntax class Vehicle: \"\"\"docstring\"\"\" def __init__(self): \"\"\"Constructor\"\"\" pass Вы заметите, что единственное различие заключается в том, что нам больше не нужны круглые скобки, если мы основываем наш класс на объекте. Давайте немного расширим определение нашего класса и наделим его некоторыми атрибутами и методами.\nclass Vehicle(object): \"\"\"docstring\"\"\" def __init__(self, color, doors, tires): \"\"\"Constructor\"\"\" self.color = color self.doors = doors self.tires = tires def brake(self): \"\"\" Stop the car \"\"\" return \"Braking\" def drive(self): \"\"\" Drive the car \"\"\" return \"I'm driving!\" Приведенный выше код добавил три атрибута и два метода. Тремя атрибутами являются:\nself.color = color self.doors = doors self.tires = tires Атрибуты описывают транспортное средство. Так, автомобиль имеет цвет, некоторое количество дверей и некоторое количество шин. У него также есть два метода. Метод описывает, что делает класс. В данном случае автомобиль может тормозить(brake) и ехать(drive). Возможно, вы заметили, что все методы, включая первый, имеют забавный аргумент self. Давайте поговорим об этом!\nЧто такое self? Классы Python нуждаются в способе обращения к самим себе. Это не какое-то самовлюбленное созерцание класса. Напротив, это способ отличить один экземпляр от другого. Слово “self” - это способ самоописания любого объекта, в буквальном смысле. Давайте рассмотрим пример, поскольку я всегда нахожу это полезным, когда изучаю что-то новое и непонятное:\nДобавьте следующий код в конец класса, который вы написали выше, и сохраните его:\nif __name__ == \"__main__\": car = Vehicle(\"blue\", 5, 4) print(car.color) truck = Vehicle(\"red\", 3, 6) print(truck.color) Условия оператора if в данном примере это стандартный способ указать Пайтону на то, что вы хотите запустить код, если он выполняется как автономный файл. Если вы импортировали свой модуль в другой скрипт, то код, расположенный ниже проверки if не заработает. В любом случае, если вы выполните этот код, вы создадите два экземпляра класса Vehicle: экземпляр легкового автомобиля и экземпляр грузовика. У каждого экземпляра будут свои атрибуты и методы.\nВот почему, когда мы выводим цвет каждого экземпляра, они отличаются. Причина в том, что класс использует аргумент self, чтобы сообщить себе, кто из них кто. Давайте немного изменим класс, чтобы сделать методы более уникальными:\nclass Vehicle(object): \"\"\"docstring\"\"\" def __init__(self, color, doors, tires, vtype): \"\"\"Constructor\"\"\" self.color = color self.doors = doors self.tires = tires self.vtype = vtype def brake(self): \"\"\" Stop the car \"\"\" return \"%s braking\" % self.vtype def drive(self): \"\"\" Drive the car \"\"\" return \"I'm driving a %s %s!\" % (self.color, self.vtype) if __name__ == \"__main__\": car = Vehicle(\"blue\", 5, 4, \"car\") print(car.brake()) print(car.drive()) truck = Vehicle(\"red\", 3, 6, \"truck\") print(truck.drive()) print(truck.brake()) В этом примере мы передаем еще один параметр, чтобы сообщить классу, какой тип автомобиля мы создаем. Затем мы вызываем каждый метод для каждого экземпляра. Если вы запустите этот код, вы должны увидеть следующий результат:\ncar braking I'm driving a blue car! I'm driving a red truck! truck braking Это демонстрирует, как экземпляр отслеживает свой аргумент “self”. Вы также могли заметить, что мы можем получать значения атрибутов из метода init в другие методы. Причина в том, что все эти атрибуты снабжены предлогом self. Если бы мы этого не сделали, переменные вышли бы из области видимости в конце метода init.\nПодклассы / Наследование Настоящая сила классов становится очевидной, когда вы переходите к подклассам. Мы уже создали подкласс, когда создавали класс на основе объекта. Другими словами, мы создали подкласс object. Поскольку объект не очень интересен, предыдущие примеры не демонстрируют возможности подклассификации.\nСоздадим подкласс нашего класса Vehicle:\nclass Car(Vehicle): \"\"\" The Car class \"\"\" def brake(self): \"\"\" Override brake method \"\"\" return \"The car class is breaking slowly!\" if __name__ == \"__main__\": car = Car(\"yellow\", 2, 4, \"car\") car.brake() 'The car class is breaking slowly!' car.drive() \"I'm driving a yellow car!\" Для этого примера мы создали подкласс нашего класса Vehicle. Вы заметите, что мы не включили метод init или метод drive. Причина в том, что при создании подкласса Vehicle вы получаете все его атрибуты и методы, если только вы не переопределите их. Таким образом, вы заметите, что мы переопределили метод brake и заставили его делать что-то другое. Остальные методы мы оставили прежними. Поэтому, когда вы говорите машине ехать, она использует оригинальный метод, и мы узнаем, что едем на желтой машине. Разве это не здорово?\nИспользование значений по умолчанию родительского класса известно как наследование. Это большая тема в объектно-ориентированном программировании (ООП). Это также простой пример полиморфизма. Полиморфные классы обычно имеют одинаковые интерфейсы (т.е. методы, атрибуты), но они не контактируют друг с другом. В языке Python полиморфизм не является очень жестким в плане обеспечения точного совпадения интерфейсов. Вместо этого он следует концепции утиной типизации. Идея утиной типизации заключается в том, что если объект ходит как утка и говорит как утка, то он должен быть уткой. Поэтому в Python, пока класс имеет одинаковые имена методов, не имеет значения, если реализация методов разная.\nТеперь, когда вы создаете подкласс, вы можете переопределить как можно больше или меньше функций родительского класса. Если вы полностью переопределите его, то вам, вероятно, будет лучше просто создать новый класс.\nРесурсы https://vegibit.com/python-abstract-base-classes/ ","description":"Python 101","title":"11. Классы","uri":"/ru/docs/python101/chapter11_classes/"},{"content":"Прежде чем мы перейдем к темам сегодняшнего дня, я хочу выразить огромную благодарность Techworld with Nana и этому фантастическому краткому путешествию по основам Go.\nВ 8-м дне мы настроили нашу среду, в 9-м дне мы разобрали код Hello #90DaysOfDevOps, а в 10-м дне) мы поработали с нашей рабочей средой Go и немного углубились в компиляцию и запуск кода.\nСегодня мы рассмотрим переменные, константы и типы данных при написании новой программы.\nПеременные и константы в Go Давайте начнем с планирования нашего приложения, я думаю, было бы неплохо поработать над программой, которая сообщает нам, сколько дней осталось в нашем испытании #90DaysOfDevOps.\nПервое, что нужно учитывать, это то, что, поскольку мы создаем наше приложение, мы приветствуем наших посетителей и даем пользователям отзывы о количестве дней, которые они выполнили, мы можем использовать термин #90DaysOfDevOps много раз на протяжении всей программы. Это отличный вариант использования переменной #90DaysOfDevOps в нашей программе.\nПеременные используются для хранения значений. Как маленькая коробка с нашей сохраненной информацией или ценностями. Затем мы можем использовать эту переменную во всей программе, что также выгодно тем, что если эта задача или переменная изменится, нам нужно будет изменить это только в одном месте. Это означает, что мы могли бы перенести это на другие проблемы, с которыми мы сталкиваемся в сообществе, просто изменив значение этой переменной. Чтобы объявить это в нашей программе Go, мы определяем значение, используя ключевое слово для переменных. Это будет жить в нашем блоке кода func main, который вы увидите позже. Подробнее о Ключевых словах можно узнать здесь.\nНе забудьте убедиться, что ваши имена переменных являются понятными. Если вы объявляете переменную, вы должны использовать ее, иначе вы получите ошибку. Это делается для того, чтобы избежать возможного неиспользованного кода. То же самое для неиспользуемых пакетов.\nvar challenge = \"#90DaysOfDevOps\" С приведенным выше набором и использованием, как мы увидим в следующем фрагменте кода, вы можете видеть из вывода ниже, что мы использовали переменную.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" fmt.Println(\"Welcome to\", challenge \"\") } Затем вы увидите ниже, что мы построили наш код с помощью приведенного выше примера и получили вывод, показанный ниже. Мы также знаем, что наш челендж длится как минимум 90 дней для этой задачи, но в следующей, может быть, будет 100, поэтому мы хотим определить переменную, которая поможет нам. Однако для нашей программы мы хотим определить это как константу. Константы похожи на переменные, за исключением того, что их значение не может быть изменено в коде (мы все еще можем создать новое приложение позже с этим кодом и изменить эту константу, но это 90 не изменится, пока мы запускаем наше приложение)\nДобавим const в наш код и добавим еще одну строку кода, чтобы напечатать результат.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 fmt.Println(\"Welcome to\", challenge) fmt.Println(\"This is a\", daystotal, \"challenge\") } Если мы затем снова пройдем этот процесс go build и запустим, вы увидите результат.\nНо это не будет концом нашей программы, мы вернемся к ней в 12-м дне, чтобы добавить больше функциональности. Теперь мы хотим добавить еще одну переменную для количества дней, в течение которых мы выполнили задание.\nНиже я добавил переменную dayscomplete с количеством завершенных дней.\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 var dayscomplete = 11 fmt.Println(\"Welcome to\", challenge, \"\") fmt.Println(\"This is a\", daystotal, \"challenge and you have completed\", dayscomplete, \"days\") fmt.Println(\"Great work\") } Давайте снова запустим go build, или вы можете просто использовать go run\nВот несколько других примеров, которые я использовал, чтобы упростить чтение и редактирование кода. До сих пор мы использовали Println, но мы можем упростить это, используя Printf, используя %v, что означает, что мы определяем наши переменные по порядку в конце строки кода. мы также используем \\n для разрыва строки.\nЯ использую %v, поскольку здесь используется значение по умолчанию, но есть и другие параметры, которые можно найти документации пакета fmt.\nПеременные также могут быть определены в вашем коде в более простом формате. Вместо того, чтобы определять, что это var и type, вы можете закодировать это следующим образом, чтобы получить ту же функциональность, но более чистый и простой вид вашего кода. Это будет работать только для переменных, а не для констант.\nfunc main() { challenge := \"#90DaysOfDevOps\" const daystotal = 90 Типы в Go В приведенных выше примерах мы не определили тип переменных, это потому, что мы можем задать им значение, Go достаточно умен, чтобы знать, что это за тип, или, по крайней мере, может сделать вывод, что это на основе значения, которое вы сохранили. . Однако, если мы хотим, чтобы пользователь ввел данные, для этого потребуется определенный тип.\nДо сих пор в нашем коде использовались строки и целые числа. Целые числа для количества дней и строки для названия задачи.\nТакже важно отметить, что каждый тип данных может выполнять разные действия и вести себя по-разному. Например, целые числа могут умножаться там, где нет строк.\nЕсть четыре категории\nBasic type: в эту категорию попадают числа, строки и логические значения. Aggregate type: к этой категории относятся массивы и структуры. Reference type: в эту категорию попадают указатели, срезы, карты, функции и каналы. Interface type Тип данных — важная концепция в программировании. Тип данных определяет размер и тип значений переменных.\nGo статически типизирован, а это означает, что после определения типа переменной он может хранить данные только этого типа.\nВ Go есть три основных типа данных:\nbool: представляет логическое значение и может быть либо истинным, либо ложным. Numeric: представляет целые типы, значения с плавающей запятой и сложные типы. string: представляет строковое значение. Я нашел этот ресурс очень подробным о типах данных Golang by example\nЯ бы также посоветовал Techworld with Nana на этом этапе довольно подробно рассказать о типах данных в Go.\nЕсли нам нужно определить тип в нашей переменной, мы можем сделать это так:\nvar TwitterHandle string var DaysCompleted uint Поскольку Go принимает переменные, которым задано значение, мы можем распечатать эти значения следующим образом:\nfmt.Printf(\"challenge is %T, daystotal is %T, dayscomplete is %T\\n\", conference, daystotal, dayscomplete) Существует много различных типов целых чисел и типов с плавающей запятой, ссылки выше подробно описывают их.\nint = целые числа unint = беззнаковые целые числа floating point types = числа с плавающей запятой Источники Введение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Далее мы начнем добавлять в нашу программу некоторые функции пользовательского ввода, чтобы программа спрашивала, сколько дней было завершено.\nУвидимся завтра.\n","description":"Переменные и константы в Go","title":"11. Переменные и константы в Go","uri":"/ru/docs/90daysofdevops/day11/"},{"content":"Получение данных с клавиуатуры Вчера (Днем 11-м) мы создали нашу первую программу Go, и данные, которые мы хотели получить от пользователя, были созданы как переменные в нашем коде. Теперь мы хотим спросить пользователя данные для ввода, чтобы дать переменной значение для конечного сообщения.\nПолучение пользовательских данных Прежде чем мы это сделаем, давайте еще раз взглянем на наше приложение и пройдемся по переменным, которые нам нужны в качестве теста, прежде чем получить этот пользовательский ввод.\nДавайте теперь добавим новую переменную с именем TwitterName, вы можете найти этот новый код ниже, и если мы запустим этот код, это будет наш вывод.\npackage main import \"fmt\" func main() { challenge := \"#90DaysOfDevOps\" const daystotal = 90 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge\\n\", daystotal) var TwitterName string var DaysComplete int // ask user for their twitter handle TwitterName = \"@MichaelCade1\" DaysComplete = 12 fmt.Printf(\"%v has completed %v days of the challenge\\n\", TwitterName, DaysComplete) fmt.Println(\"Great work\") } Прежде чем мы это сделаем, давайте еще раз взглянем на наше приложение и пройдемся по переменным, которые нам нужны в качестве теста, прежде чем получить этот пользовательский ввод.\nВчера мы закончили с нашим кодом, выглядящим так:\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" const daystotal = 90 var dayscomplete = 11 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge and you have completed %v days\\n\", daystotal, dayscomplete) fmt.Println(\"Great work\") } Мы вручную определили в коде наши переменные и константы challenge, daystotal, dayscomplete.\nДавайте теперь добавим новую переменную с именем TwitterName\nУ нас 12-й день, и нам нужно было бы менять dayscomplete каждый день и компилировать наш код каждый день, если бы он был жестко запрограммирован, что звучит не так уж здорово.\nПолучая пользовательский ввод, мы хотим получить значение, возможно, имя и количество завершенных дней. Для этого мы можем использовать другую функцию из пакета fmt.\nКратко о пакете fmt, различные функции для: форматированного ввода и вывода (I/O) (input and output)\nПечать сообщений Собирать пользовательский ввод Записать в файл Это вместо того, чтобы присваивать значение переменной, мы хотим попросить пользователя ввести его.\nfmt.Scan(\u0026TwitterName) Обратите внимание, что мы также используем \u0026 перед переменной. Этот символ известен как указатель, который мы рассмотрим в следующем разделе.\nВ нашем коде вы можете видеть, что мы просим пользователя ввести две переменные, TwitterName и DaysCompleted\npackage main import \"fmt\" func main() { const DaysTotal int = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Println(\"Good luck\") } Давайте теперь запустим нашу программу, и вы увидите, что у нас есть входные данные для обоих вышеперечисленных.\nХорошо, мы получили некоторый пользовательский ввод и напечатали сообщение, но как насчет того, чтобы заставить нашу программу сообщать нам, сколько дней у нас осталось в нашей задаче.\nДля этого мы создали переменную с именем remainingDays, и мы жестко оценили ее в нашем коде как 90. Затем нам нужно изменить значение этого значения, чтобы распечатать remainingDays, когда мы получим пользовательский ввод DaysCompleted мы можем сделать это с помощью этого простого изменения переменной.\nremainingDays = remainingDays - DaysCompleted Наша программа теперь выглядит вот так:\npackage main import \"fmt\" func main() { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } Если мы теперь запустим эту программу, вы увидите, что простой расчет выполняется на основе пользовательского ввода и значения remainingDays\nЧто такое указатель? (Специальные переменные) Указатель — это (специальная) переменная, которая указывает на адрес памяти другой переменной.\nОтличное объяснение этого можно найти здесь geeksforgeeks\npackage main import \"fmt\" func main() { var challenge = \"#90DaysOfDevOps\" fmt.Println(challenge) fmt.Println(\u0026challenge) } Ниже выполняется этот код.\nРесурсы Введение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся завтра.\n","description":"Получение пользовательского ввода с помощью указателей и готовой программы","title":"12. Golang - чтение данных и указатели","uri":"/ru/docs/90daysofdevops/day12/"},{"content":"Независимо от того, новичок ли вы в Python, используете ли вы его уже несколько лет или являетесь экспертом, умение использовать возможности интроспекции Python может помочь вам понять ваш код и тот новый пакет с ужасной документацией, который вы только что скачали. Интроспекция - это модное слово, которое означает наблюдение за собой и размышление о своих мыслях, чувствах и желаниях. В мире Python интроспекция - это нечто похожее. В данном случае интроспекция - это использование Python для изучения Python. В этой главе вы узнаете, как использовать Python, чтобы дать себе подсказку о коде, над которым вы работаете или пытаетесь изучить. Некоторые могут даже назвать это формой отладки.\nВот что мы рассмотрим:\ntype dir help Тип Python Вы можете не знать этого, но Python может быть вашим типом. Да, Python может сказать вам, какого типа у вас переменная или какой тип возвращается из функции. Это очень удобный инструмент. Давайте рассмотрим несколько примеров, чтобы все стало ясно:\n\u003e\u003e\u003e x = \"test\" \u003e\u003e\u003e y = 7 \u003e\u003e\u003e z = None \u003e\u003e\u003e type(x) \u003cclass 'str'\u003e \u003e\u003e\u003e type(y) \u003cclass 'int'\u003e \u003e\u003e\u003e type(z) \u003cclass 'NoneType'\u003e Как вы видите, в Python есть ключевое слово type, которое позволяет определить, что есть что. В реальной жизни я использовал тип, чтобы понять, что происходит, когда данные моей базы данных повреждены или не соответствуют моим ожиданиям. Я просто добавляю пару строк и вывожу данные каждой строки вместе с ее типом. Это очень помогло мне, когда я был ошарашен каким-то глупым кодом, который я написал.\nPython Dir Что такое dir? Это что-то, что вы говорите, когда кто-то говорит или делает что-то глупое? Не в этом контексте! Нет, здесь, на планете Python, ключевое слово dir используется для того, чтобы сообщить программисту, какие атрибуты и методы есть в переданном объекте. Если вы забыли передать объект, dir вернет список имен в текущей области видимости. Как обычно, это легче понять на нескольких примерах.\n\u003e\u003e\u003e dir(\"test\") ['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__str__', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'replace', 'rfind', 'rindex', 'rjust', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'] Поскольку в Python все является объектом, мы можем передать строку в dir и узнать, какие методы у него есть. Довольно ловко, да? Теперь давайте попробуем сделать это с импортированным модулем:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e dir(sys) ['__displayhook__', '__doc__', '__egginsert', '__excepthook__', '__name__', '__plen', '__stderr__', '__stdin__', '__stdout__', '_getframe', 'api_version', 'argv', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dllhandle', 'exc_clear', 'exc_info', 'exc_traceback', 'exc_type', 'exc_value', 'excepthook', 'exec_prefix', 'executable', 'exit', 'exitfunc', 'getcheckinterval', 'getdefaultencoding', 'getfilesystemencoding', 'getrecursionlimit', 'getrefcount', 'getwindowsversion', 'hexversion', 'maxint', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'setcheckinterval', 'setprofile', 'setrecursionlimit', 'settrace', 'stderr', 'stdin', 'stdout', 'version', 'version_info', 'warnoptions', 'winver']. Вот теперь это удобно! Если вы еще не поняли, функция dir очень удобна для тех пакетов сторонних разработчиков, которые вы скачали (или скоро скачаете) и которые практически не имеют документации. Как узнать, какие методы доступны в таких случаях? Ну, dir поможет вам разобраться в этом. Конечно, иногда документация находится в самом коде, что приводит нас к встроенной справочной утилите.\nPython Help! Python поставляется с удобной утилитой помощи. Просто введите “help()” (без кавычек) в оболочке Python, и вы увидите следующие указания (версия Python может отличаться)\n\u003e\u003e\u003e help() Welcome to Python 3.9's help utility! If this is your first time using Python, you should definitely check out the tutorial on the Internet at https://docs.python.org/3.9/tutorial/. Enter the name of any module, keyword, or topic to get help on writing Python programs and using Python modules. To quit this help utility and return to the interpreter, just type \"quit\". To get a list of available modules, keywords, symbols, or topics, type \"modules\", \"keywords\", \"symbols\", or \"topics\". Each module also comes with a one-line summary of what it does; to list the modules whose name or summary contain a given string such as \"spam\", type \"modules spam\". help\u003e Обратите внимание, что теперь у вас есть подсказка “help\u003e” вместо “»\u003e”. Когда вы находитесь в режиме справки, вы можете изучить различные модули, ключевые слова и темы, найденные в Python. Также обратите внимание, что при вводе слова “модули” вы увидите задержку, пока Python будет искать список в папке библиотеки. Если у вас установлено много сторонних модулей, это может занять довольно много времени, так что будьте готовы сделать себе мокко, пока ждете. Когда все будет готово, просто следуйте инструкциям и поиграйте с этим, и я думаю, вы поймете суть.\n","description":"Python 101","title":"12. Интроспекция","uri":"/ru/docs/python101/chapter12_introspection/"},{"content":"Твитните о своем прогрессе с нашим новым приложением В последний день изучения этого языка программирования мы только коснулись его основ, но я думаю, что это начало.\nЗа последние несколько дней мы взяли небольшую идею для приложения и добавили функциональность, в этой статье я хочу воспользоваться преимуществами тех пакетов, которые мы упомянули, и создать функциональность для нашего приложения, чтобы не только дать вам обновление вашего прогресса на экране, но также отправьте твит с подробностями задачи и вашим статусом.\nДобавление возможности твитить свой прогресс Первое, что нам нужно сделать, это настроить доступ API разработчика к Twitter, чтобы это работало.\nПерейдите на Платформу разработчиков Twitter и войдите в систему, используя свой идентификатор Twitter и данные. Оказавшись внутри, вы должны увидеть что-то вроде приведенного ниже без приложения, которое я уже создал.\nЗдесь вы также можете запросить дополнительный доступ. Это может занять некоторое время, но для меня это было очень быстро.\nЗатем мы должны выбрать «Projects \u0026 Apps» и создать наше приложение. Ограничения зависят от доступа к вашей учетной записи, при этом у вас должно быть только одно приложение и один проект, а с повышенными правами у вас может быть 3 приложения.\nДайте вашему приложению имя\nЗатем вам будут предоставлены эти токены API, важно сохранить их в безопасном месте. (С тех пор я удалил это приложение) Они понадобятся нам позже с нашим приложением Go.\nТеперь у нас создано наше приложение (мне пришлось изменить имя моего приложения, так как то, что на скриншоте выше, уже было сделано, эти имена должны быть уникальными)\nКлючи, которые мы собрали ранее, известны как наши потребительские ключи, и нам также понадобятся наш токен доступа и секреты. Мы можем собрать эту информацию, используя вкладку «Ключи и токены».\nХорошо, на данный момент мы закончили работу с порталом для разработчиков Twitter. Убедитесь, что вы сохранили свои ключи, потому что они понадобятся нам позже.\nПерейти Twitter бот Помните код, который мы запускаем в нашем приложении?\npackage main import \"fmt\" func main() { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } Теперь нам нужно подумать о коде для отправки нашего вывода или сообщения в Twitter в виде твита. Мы будем использовать go-twitter. Это клиентская библиотека Go для Twitter API.\nЧтобы проверить это, прежде чем помещать это в наше основное приложение, я создал новый каталог в нашей папке src с именем go-twitter-bot, запустил go mod init github.com/michaelcade/go-twitter-bot в папке который затем создал файл go.mod, а затем мы можем начать писать наш новый main.go и протестировать его.\nТеперь нам нужны те ключи, токены и секреты, которые мы собрали на портале разработчиков Twitter. Мы собираемся установить их в наших переменных среды. Это будет зависеть от ОС, которую вы используете:\nWindows\nset CONSUMER_KEY set CONSUMER_SECRET set ACCESS_TOKEN set ACCESS_TOKEN_SECRET Linux / macOS\nexport CONSUMER_KEY export CONSUMER_SECRET export ACCESS_TOKEN export ACCESS_TOKEN_SECRET At this stage, you can take a look at day13_example2 at the code but you will see here that we are using a struct to define our keys, secrets and tokens.\nWe then have a func to parse those credentials and make that connection to the Twitter API\nThen based on the success we will then send a tweet.\nНа этом этапе вы можете взглянуть на следующий код\npackage main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := \u0026twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { fmt.Println(\"Go-Twitter Bot v0.01\") creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } client, err := getClient(\u0026creds) if err != nil { log.Println(\"Error getting Twitter Client\") log.Println(err) } tweet, resp, err := client.Statuses.Update(\"A Test Tweet from the future, testing a #90DaysOfDevOps Program that tweets, tweet tweet\", nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } Здесь вы увидите, что мы используем структуру для определения наших ключей, секретов и токенов.\nЗатем у нас есть func, чтобы проанализировать эти учетные данные и установить это соединение с API Twitter.\nЗатем, в зависимости от успеха, мы отправим твит.\nКод выше либо выдаст вам ошибку в зависимости от того, что происходит, либо будет выполнен успешно, и вам будет отправлен твит с сообщением, указанным в коде.\nСоединение двух вместе - Go-Twitter-Bot + наше приложение Теперь нам нужно объединить эти два файла в наш main.go. Я уверен, что кто-то кричит, что есть лучший способ сделать это, и, пожалуйста, прокомментируйте это, поскольку вы можете иметь более одного файла .go в одном файле. project это может иметь смысл, но это работает.\nТак выглядит итоговый рзультат:\npackage main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := \u0026twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } { const DaysTotal int = 90 var remainingDays uint = 90 challenge := \"#90DaysOfDevOps\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(\u0026TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(\u0026DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted //fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) //fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) // fmt.Println(\"Good luck\") client, err := getClient(\u0026creds) if err != nil { log.Println(\"Error getting Twitter Client, this is expected if you did not supply your Twitter API tokens\") log.Println(err) } message := fmt.Sprintf(\"Hey I am %v I have been doing the %v for %v days and I have %v Days left\", TwitterName, challenge, DaysCompleted, remainingDays) tweet, resp, err := client.Statuses.Update(message, nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } } Результатом этого должен быть твит, но если вы не указали свои переменные среды, вы должны получить сообщение об ошибке, подобное приведенному ниже.\nПосле того, как вы исправите это или решите не проходить аутентификацию в Twitter, вы можете использовать код, с которым мы закончили вчера. Вывод терминала в случае успеха будет выглядеть примерно так:\nПолученный твит должен выглядеть примерно так:\nКак скомпилировать для нескольких ОС Далее я хочу затронуть вопрос: «Как компилировать для нескольких операционных систем?» Отличительной особенностью Go является то, что он может легко компилироваться для многих различных операционных систем. Вы можете получить полный список, выполнив следующую команду:\ngo tool dist list Использование наших команд go build до сих пор было замечательным, и оно будет использовать переменные среды GOOS и GOARCH, чтобы определить хост-компьютер и то, для чего должна быть собрана сборка. Но мы также можем создавать другие двоичные файлы, используя приведенный ниже код в качестве примера.\nGOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.1_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin_arm64 main.go Это даст вам двоичные файлы в вашем каталоге для всех вышеперечисленных платформ. Затем вы можете взять это и создать make-файл для создания этих двоичных файлов всякий раз, когда вы добавляете новые функции и функции в свой код.\nФайл: makefile\nBINARY_NAME=90DaysOfDevOps build: GOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.2_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.2_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.2_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.2_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.2_darwin_arm64 main.go run: ./${BINARY_NAME} build_and_run: build run clean: go clean rm ${BINARY_NAME}-darwin rm ${BINARY_NAME}-linux rm ${BINARY_NAME}-windows Источники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist A great repo full of all things DevOps \u0026 exercises GoByExample - Example based learning go.dev/tour/list go.dev/learn На этом блок “язык программирования”. Так много всего, что можно охватить, и я надеюсь, что вы смогли продолжить изучение вышеизложенного и понять некоторые другие аспекты языка программирования Go.\nЗатем мы сосредоточимся на Linux и некоторых основах, которые мы все должны знать.\n","description":"Go - подключение Twitter API","title":"13. Go - подключение Twitter API","uri":"/ru/docs/90daysofdevops/day13/"},{"content":"Модуль csv дает программисту Python возможность анализировать файлы CSV (Comma Separated Values – переменные, разделенные запятыми). CSV-файл - это текстовый файл, в котором каждая строка содержит несколько полей, разделенных запятыми или каким-либо другим разделителем. Каждую строку можно представить как ряд, а каждое поле - как столбец. Формат CSV не имеет стандарта, но они достаточно похожи, чтобы модуль csv мог читать подавляющее большинство CSV-файлов. Вы также можете записывать CSV-файлы с помощью модуля csv.\nЧтение файла CSV Существует два способа чтения CSV-файла. Вы можете использовать функцию чтения модуля csv или класс DictReader. Мы рассмотрим оба метода. Но сначала нам нужно получить CSV-файл, чтобы было что разбирать. Существует множество сайтов, предоставляющих интересную информацию в формате CSV. Мы будем использовать сайт Всемирной организации здравоохранения (ВОЗ) для загрузки информации о туберкулезе. Вы можете перейти сюда, чтобы получить ее: http://www.who.int/tb/country/data/download/en/. Как только вы получите файл, мы будем готовы начать. Готовы? Тогда давайте посмотрим на код!\nimport csv def csv_reader(file_obj): \"\"\" Read a csv file \"\"\" reader = csv.reader(file_obj) for row in reader: print(\" \".join(row)) if __name__ == \"__main__\": csv_path = \"TB_data_dictionary_2014-02-26.csv\" with open(csv_path, \"r\") as f_obj: csv_reader(f_obj) Давайте немного разберемся с этим. Во-первых, мы должны импортировать модуль csv. Затем мы создаем очень простую функцию csv_reader, которая получает доступ к объекту файла. Внутри функции мы передаем объект файла в функцию csv.reader, которая возвращает объект reader. Объект reader позволяет выполнять итерацию, как и обычный объект файла. Это позволяет нам итерировать каждую строку в объекте reader и выводить строку данных за вычетом запятых. Это работает по той причине, что каждый ряд является списком, и мы можем объединить все элементы в списке вместе, создав одну большую строку\nТеперь давайте создадим собственный CSV-файл и передадим его в класс DictReader. Вот очень простой вариант:\nfirst_name,last_name,address,city,state,zip_code Tyrese,Hirthe,1404 Turner Ville,Strackeport,NY,19106-8813 Jules,Dicki,2410 Estella Cape Suite 061,Lake Nickolasville,ME,00621-7435 Dedric,Medhurst,6912 Dayna Shoal,Stiedemannberg,SC,43259-2273 Сохраним его в файле с именем data.csv. Теперь мы готовы разобрать файл с помощью класса DictReader. Давайте попробуем это сделать:\nimport csv def csv_dict_reader(file_obj): \"\"\" Read a CSV file using csv.DictReader \"\"\" reader = csv.DictReader(file_obj, delimiter=',') for line in reader: print(line[\"first_name\"]), print(line[\"last_name\"]) if __name__ == \"__main__\": with open(\"data.csv\") as f_obj: csv_dict_reader(f_obj) В приведенном выше примере мы открываем файл и передаем объект файла в нашу функцию, как мы это делали раньше. Функция передает объект файла нашему классу DictReader. Мы сообщаем DictReader, что разделителем является запятая. На самом деле это не обязательно, так как код будет работать и без этого ключевого слова. Тем не менее, это хорошая идея, так как это позволяет пролить свет на то, что именно происходит внутри кода. Далее мы переходим к объекту reader и обнаруживаем, что каждая строка в объекте reader является словарем. Это позволяет очень просто распечатать определенные фрагменты строки.\nТеперь мы готовы узнать, как записать файл csv на диск.\nЗапись файла CSV Модуль csv также имеет два метода, которые вы можете использовать для записи CSV-файла. Вы можете использовать функцию writer или класс DictWriter. Мы рассмотрим оба этих метода. Мы будем работать с функцией writer. Давайте рассмотрим простой пример:\nimport csv def csv_writer(data, path): \"\"\" Write data to a CSV file path \"\"\" with open(path, \"w\", newline='') as csv_file: writer = csv.writer(csv_file, delimiter=',') for line in data: writer.writerow(line) if __name__ == \"__main__\": data = [\"first_name,last_name,city\".split(\",\"), \"Tyrese,Hirthe,Strackeport\".split(\",\"), \"Jules,Dicki,Lake Nickolasville\".split(\",\"), \"Dedric,Medhurst,Stiedemannberg\".split(\",\") ] path = \"output.csv\" csv_writer(data, path) В приведенном выше коде мы создаем функцию csv_writer, которая принимает два аргумента: data и path. data - это список списков, который мы создаем в нижней части сценария. Мы используем сокращенную версию данных из предыдущего примера и разделяем строки на запятые. Это возвращает список. В итоге мы получаем вложенный список, который выглядит следующим образом:\n[['first_name', 'last_name', 'city'], ['Tyrese', 'Hirthe', 'Strackeport'], ['Jules', 'Dicki', 'Lake Nickolasville'], ['Dedric', 'Medhurst', 'Stiedemannberg']] Функция csv_writer открывает путь, по которому мы проходим, и создает объект csv writer. Затем мы перебираем структуру вложенного списка и записываем каждую строку на диск. Обратите внимание, что при создании объекта writer мы указали, каким должен быть разделитель. Если вы хотите, чтобы разделителем была не запятая, а что-то другое, то это то место, где вы должны ее установить.\nТеперь мы готовы узнать, как записать CSV-файл с помощью класса DictWriter! Мы собираемся использовать данные из предыдущей версии и преобразовать их в список словарей, которые мы можем скормить нашему голодному DictWriter. Давайте посмотрим:\nimport csv def csv_dict_writer(path, fieldnames, data): \"\"\" Writes a CSV file using DictWriter \"\"\" with open(path, \"w\", newline='') as out_file: writer = csv.DictWriter(out_file, delimiter=',', fieldnames=fieldnames) writer.writeheader() for row in data: writer.writerow(row) if __name__ == \"__main__\": data = [\"first_name,last_name,city\".split(\",\"), \"Tyrese,Hirthe,Strackeport\".split(\",\"), \"Jules,Dicki,Lake Nickolasville\".split(\",\"), \"Dedric,Medhurst,Stiedemannberg\".split(\",\") ] my_list = [] fieldnames = data[0] for values in data[1:]: inner_dict = dict(zip(fieldnames, values)) my_list.append(inner_dict) path = \"dict_output.csv\" csv_dict_writer(path, fieldnames, my_list) Сначала мы начнем со второго раздела. Как вы видите, мы начинаем со структуры вложенного списка, которая была у нас раньше. Далее мы создаем пустой список и список, содержащий имена полей, который будет первым списком во вложенном списке. Помните, что списки основаны на нулях, поэтому первый элемент в списке начинается с нуля! Далее мы перебираем вложенные списки, начиная со второго элемента:\nfor values in data[1:]: inner_dict = dict(zip(fieldnames, values)) my_list.append(inner_dict) Внутри цикла for мы используем встроенные модули Python для создания словаря. Метод zip* возьмет два итератора (в данном случае списки) и превратит их в список кортежей. Вот пример:\nzip(fieldnames, values) [('first_name', 'Dedric'), ('last_name', 'Medhurst'), ('city', 'Stiedemannberg')] Теперь, когда вы обернете этот вызов в dict, он превратит список кортежей в словарь. Наконец, мы добавляем словарь к списку. По окончании работы функции for вы получите структуру данных, которая будет выглядеть следующим образом:\n**[{‘city’: ‘Strackeport’, ‘first_name’: ‘Tyrese’, ‘last_name’: ‘Hirthe’},** {‘city’: ‘Lake Nickolasville’, ‘first_name’: ‘Jules’, ‘last_name’: ‘Dicki’}, {‘city’: ‘Stiedemannberg’, ‘first_name’: ‘Dedric’, ‘last_name’: ‘Medhurst’}] В конце второй сессии мы вызываем нашу функцию csv_dict_writer и передаем все необходимые аргументы. Внутри функции мы создаем экземпляр DictWriter и передаем ему объект файла, значение разделителя и список имен полей. Затем мы записываем имена полей на диск и в цикле просматриваем данные по одной строке за раз, записывая их на диск. Класс DictWriter также поддерживает метод writerows, который мы могли бы использовать вместо цикла. Функция csv.writer также поддерживает это сделать.\nВозможно, вам будет интересно узнать, что с помощью модуля csv можно также создавать диалекты. Это позволит вам указывать модулю csv, как именно читать или писать файл в очень простой форме. Если вам нужно что-то подобное из-за странно отформатированного файла от клиента, то вы найдете эту функциональность бесценной.\nПодведение итогов Теперь вы знаете, как использовать модуль csv для чтения и записи CSV-файлов. Существует множество веб-сайтов, которые размещают свои данные в этом формате, и он часто используется в деловом мире. В следующей главе мы начнем изучать модуль ConfigParser.\n","description":"Python 101","title":"13. Модуль csv","uri":"/ru/docs/python101/chapter13_csv/"},{"content":"Общая картина: DevOps и Linux Linux и DevOps имеют очень схожие культуры и взгляды; оба ориентированы на настройку и масштабируемость. Оба эти аспекта Linux имеют особое значение для DevOps.\nМногие технологии начинаются с Linux, особенно если они связаны с разработкой программного обеспечения или управлением инфраструктурой.\nКроме того, многие проекты с открытым исходным кодом, особенно инструменты DevOps, с самого начала разрабатывались для работы в Linux.\nС точки зрения DevOps или фактически с точки зрения какой-либо операционной роли вы столкнетесь с Linux, я бы сказал, в основном. Есть место для WinOps, но большую часть времени вы будете администрировать и развертывать серверы Linux.\nЯ использую Linux ежедневно в течение нескольких лет, но мой настольный компьютер всегда был либо macOS, либо Windows. Однако, когда я перешел на роль Cloud Native, в которой я сейчас нахожусь, я сделал решительный шаг, чтобы убедиться, что мой ноутбук полностью основан на Linux и является моим ежедневным драйвером, в то время как мне по-прежнему нужна была Windows для рабочих приложений и многих моих аудио и видеоаппаратура не работает в Linux Я заставлял себя постоянно работать на рабочем столе Linux, чтобы лучше понять многие вещи, которые мы собираемся затронуть в течение следующих 7 дней.\nНачало Я не предлагаю вам делать то же самое, что и я, в любом случае, поскольку есть более простые варианты и менее разрушительные, но я скажу, что этот полный рабочий день заставит вас быстрее научиться тому, как заставить все работать в Linux.\nВ течение большей части этих 7 дней я фактически собираюсь развернуть виртуальную машину в Virtual Box на моей машине с Windows. Я также собираюсь развернуть настольную версию дистрибутива Linux, в то время как многие серверы Linux, которыми вы будете администрировать, скорее всего, будут серверами без графического интерфейса и полностью основанными на оболочке. Однако, как я сказал в начале, многие инструменты, которые мы рассмотрели в течение всех этих 90 дней, начинались с Linux, я также настоятельно рекомендую вам погрузиться в работу этого рабочего стола Linux для этого обучения.\nВ оставшейся части этого поста мы сосредоточимся на настройке и запуске виртуальной машины Ubuntu Desktop в нашей среде Virtual Box. Теперь мы можем просто загрузить Virtual Box и получить последний Ubuntu ISO с сайтов, на которые даны ссылки, и продолжить сборку. нашу среду рабочего стола, но это не было бы очень DevOps с нашей стороны, не так ли?\nЕще одна веская причина использовать большинство дистрибутивов Linux заключается в том, что они бесплатны и имеют открытый исходный код. Мы также выбираем Ubuntu, поскольку это, вероятно, наиболее широко используемый дистрибутив, не думая о мобильных устройствах и корпоративных серверах RedHat Enterprise. Я могу ошибаться, но с CentOS и ее историей я уверен, что Ubuntu занимает первое место в списке, и это очень просто.\nHashiCorp Vagrant Vagrant — это утилита CLI, которая управляет жизненным циклом ваших виртуальных машин. Мы можем использовать vagrant для запуска и отключения виртуальных машин на разных платформах, включая vSphere, Hyper-v, Virtual Box, а также Docker. У него есть другие провайдеры, но мы будем придерживаться того, что здесь мы используем Virtual Box, так что все готово.\nVagrant — свободное и открытое программное обеспечение для создания и конфигурирования виртуальной среды разработки. Является обёрткой для программного обеспечения виртуализации, например VirtualBox, и средств управления конфигурациями, таких как Chef, Salt и Puppet.\nПервое, что нам нужно сделать, это установить Vagrant на нашу машину, когда вы перейдете на страницу загрузок, вы увидите все операционные системы, перечисленные на ваш выбор. HashiCorp Vagrant Я использую Windows, поэтому я взял двоичный файл для своей системы и установил его в свою систему.\nДалее нам также нужно установить Virtual Box. Опять же, это также может быть установлено на многих разных операционных системах.\nФайл VAGRANTFILE VAGRANTFILE описывает тип машины, которую мы хотим развернуть. Он также определяет, как мы хотим, чтобы конфигурация и подготовка этой машины выглядели.\nКогда дело доходит до их сохранения и организации ваших VAGRANTFILE, я стараюсь помещать их в отдельные папки в своем рабочем пространстве. Ниже вы можете увидеть, как это выглядит в моей системе. Надеюсь, после этого вы поиграете с Vagrant и увидите легкость запуска разных систем, это также отлично подходит для этой кроличьей норы, известной как скачок дистрибутива для Linux Desktops.\nДавайте взглянем на этот VAGRANTFILE и посмотрим, что мы строим.\nVagrant.configure(\"2\") do |config| config.vm.box = \"chenhan/ubuntu-desktop-20.04\" config.vm.provider :virtualbox do |v| v.memory = 8096 v.cpus = 4 v.customize [\"modifyvm\", :id, \"--vram\", \"128mb\"] end end Это очень простой VAGRANTFILE. В целом, мы говорим, что нам нужна конкретная «сборка». Сборка, возможно, является либо общедоступным образом, либо частной сборкой системы, которую вы ищете. Вы можете найти длинный список здесь, в общедоступном каталоге Vagrant\nДалее мы говорим, что хотим использовать определенного провайдера, в данном случае это «VirtualBox», а затем мы хотим определить память нашей машины как «8 ГБ, а количество процессоров — как «4». Мой опыт также говорит мне, что вы можете также добавить следующую строку, если у вас возникли проблемы с отображением. Это установит видеопамять на то, что вы хотите, я бы увеличил ее до 128 МБ, но зависит от вашей системы.\nv.customize [\"modifyvm\", :id, \"--vram\", \"\"] Инициализация нашего рабочего стола Linux Теперь мы готовы запустить нашу первую машину в терминале нашего ПК. В моем случае я использую PowerShell на своем компьютере с Windows, перейдите в папку своих проектов и там, где вы найдете свой VAGRANTFILE. Оказавшись там, вы можете ввести команду vagrant up, и если все правильно, вы увидите что-то вроде того, что показано ниже.\nЕще одна вещь, которую следует добавить, это то, что сеть будет настроена на NAT на вашей виртуальной машине, на данном этапе нам действительно не нужно знать о NAT, и я планирую провести целую сессию в следующем разделе о сети. Но знайте, что это просто кнопка, когда дело доходит до включения машины в вашу домашнюю сеть, это также сетевой режим по умолчанию в Virtual Box. Вы можете узнать больше в документации Virtual Box\nКак только vagrant up завершен, мы можем использовать vagrant ssh, чтобы перейти прямо в терминал нашей новой виртуальной машины.\nИменно здесь мы будем проводить большую часть наших исследований в течение следующих нескольких дней, но я также хочу погрузиться в некоторые настройки для вашей рабочей станции разработчика, которые я сделал, и это значительно упрощает вашу жизнь при использовании этого в качестве ежедневного драйвера, и, конечно же, а ты реально в DevOps разве что у тебя крутой нестандартный терминал?\nНо просто для подтверждения в Virtual Box вы должны увидеть приглашение для входа в систему при выборе виртуальной машины.\nО, и если вы зашли так далеко и спрашивали: «ЧТО ТАКОЕ ИМЯ ПОЛЬЗОВАТЕЛЯ И ПАРОЛЬ?»\nUsername = vagrant Password = vagrant Завтра мы рассмотрим некоторые команды и то, что они делают. Терминал станет местом, где все произойдет.\nРесурсы Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need be a hacker!) Vargant tutorial Как я уже упоминал, далее мы рассмотрим команды, которые мы можем использовать ежедневно в наших средах Linux.\n","description":"DevOps и Linux","title":"14. DevOps и Linux","uri":"/ru/docs/90daysofdevops/day14/"},{"content":"Файлы конфигурации используются как пользователями, так и программистами. Обычно они используются для хранения настроек вашего приложения или даже настроек вашей операционной системы. Основная библиотека Python включает модуль configparser, который можно использовать для создания конфигурационных файлов и взаимодействия с ними. В этой главе мы потратим несколько минут на изучение его работы.\nСоздание конфигурационного файла Создать конфигурационный файл с помощью configparser очень просто. Давайте создадим код для демонстрации:\nimport configparser def createConfig(path): \"\"\" Create a config file \"\"\" config = configparser.ConfigParser() config.add_section(\"Settings\") config.set(\"Settings\", \"font\", \"Courier\") config.set(\"Settings\", \"font_size\", \"10\") config.set(\"Settings\", \"font_style\", \"Normal\") config.set(\"Settings\", \"font_info\", \"You are using %(font)s at %(font_size)s pt\") with open(path, \"w\") as config_file: config.write(config_file) if __name__ == \"__main__\": path = \"settings.ini\" createConfig(path) Данный код создает файл config с одной секцией, под названием Settings, которая будет содержать наши опции: font, font_size, font_style и font_info. . Также обратите внимание, что в Python 3 нам нужно указать, что мы записываем файл только в режиме записи, т.е. “w”. Еще в Python 2 для записи в двоичном режиме нужно было использовать “wb”.\nКак читать, обновлять и удалять опции Теперь мы готовы к тому, что бы научиться чтению файла config, обновлять его опции и даже удалять их. В этом случае проще научиться, написав код! Просто добавьте следующую функцию в код, который вы написали выше.\nimport configparser import os def crudConfig(path): \"\"\" Create, read, update, delete config \"\"\" if not os.path.exists(path): createConfig(path) config = configparser.ConfigParser() config.read(path) # read some values from the config font = config.get(\"Settings\", \"font\") font_size = config.get(\"Settings\", \"font_size\") # change a value in the config config.set(\"Settings\", \"font_size\", \"12\") # delete a value from the config config.remove_option(\"Settings\", \"font_style\") # write changes back to the config file with open(path, \"w\") as config_file: config.write(config_file) if __name__ == \"__main__\": path = \"settings.ini\" crudConfig(path) Этот код сначала проверяет, существует ли путь к файлу конфигурации. Если нет, то для его создания используется функция createConfig, которую мы создали ранее. Затем мы создаем объект ConfigParser и передаем ему путь к файлу конфигурации для чтения. Чтобы прочитать опцию в конфигурационном файле, мы вызываем метод get нашего объекта ConfigParser, передавая ему имя секции и имя опции. Это вернет значение опции. Если вы хотите изменить значение параметра, используйте метод set, в котором передайте имя секции, имя опции и новое значение. Наконец, для удаления параметра можно использовать метод remove_option.\nВ нашем примере мы изменяем значение font_size на 12 и полностью удаляем опцию font_style. Затем мы записываем изменения обратно на диск.\nОднако это не совсем удачный пример, так как вам не стоит иметь функцию, которая делает всё таким образом. Поэтому давайте разделим ее на несколько функций:\nimport configparser import os def create_config(path): \"\"\" Create a config file \"\"\" config = configparser.ConfigParser() config.add_section(\"Settings\") config.set(\"Settings\", \"font\", \"Courier\") config.set(\"Settings\", \"font_size\", \"10\") config.set(\"Settings\", \"font_style\", \"Normal\") config.set(\"Settings\", \"font_info\", \"You are using %(font)s at %(font_size)s pt\") with open(path, \"w\") as config_file: config.write(config_file) def get_config(path): \"\"\" Returns the config object \"\"\" if not os.path.exists(path): create_config(path) config = configparser.ConfigParser() config.read(path) return config def get_setting(path, section, setting): \"\"\" Print out a setting \"\"\" config = get_config(path) value = config.get(section, setting) msg = \"{section} {setting} is {value}\".format( section=section, setting=setting, value=value) print(msg) return value def update_setting(path, section, setting, value): \"\"\" Update a setting \"\"\" config = get_config(path) config.set(section, setting, value) with open(path, \"w\") as config_file: config.write(config_file) def delete_setting(path, section, setting): \"\"\" Delete a setting \"\"\" config = get_config(path) config.remove_option(section, setting) with open(path, \"w\") as config_file: config.write(config_file) if __name__ == \"__main__\": path = \"settings.ini\" font = get_setting(path, 'Settings', 'font') font_size = get_setting(path, 'Settings', 'font_size') update_setting(path, \"Settings\", \"font_size\", \"12\") delete_setting(path, \"Settings\", \"font_style\") Этот пример выглядит более организованно, по сравнению с первым. Я пошел настолько далеко, что назвал функции в соответствии с PEP8. Каждая функция должна быть самоочевидной и самодостаточной. Вместо того чтобы помещать всю логику в одну функцию, мы разделили ее на несколько функций, а затем продемонстрировали их функциональность в нижнем выражении if. Теперь вы можете импортировать модуль и использовать его самостоятельно.\nОбратите внимание на то, что в этом примере есть сложная секция, так что вам, возможно, захочется усовершенствовать этот пример в дальнейшем, чтобы сделать его более универсальным.\nКак использовать интерполяцию Модуль configparser также позволяет интерполяцию, что означает, что вы можете использовать некоторые опции для создания другой опции. Мы фактически делаем это с опцией font_info, поскольку ее значение основано на опциях font и font_size. Мы можем изменить интерполированное значение с помощью словаря Python. Давайте вкратце продемонстрируем оба этих случая.\nimport configparser import os def interpolationDemo(path): if not os.path.exists(path): createConfig(path) config = configparser.ConfigParser() config.read(path) print(config.get(\"Settings\", \"font_info\")) print(config.get(\"Settings\", \"font_info\", vars={\"font\": \"Arial\", \"font_size\": \"100\"})) if __name__ == \"__main__\": path = \"settings.ini\" interpolationDemo(path) Если вы запустите этот код, вы увидите примерно следующий результат:\nВы используете Courier размером 12 pt Вы используете шрифт Arial размером 100 пт Подведение итогов На данном этапе вы должны знать достаточно о возможностях configparser, чтобы использовать его в своих собственных проектах. Есть еще один проект под названием ConfigObj, который не является частью Python, и с которым вы, возможно, захотите ознакомиться. ConfigObj более гибкий и имеет больше возможностей, чем configparser. Но если вы находитесь в затруднительном положении или ваша организация не разрешает использование пакетов сторонних разработчиков, то configparser, вероятно, подойдет.\n","description":"Python 101","title":"14. Модуль configparser","uri":"/ru/docs/python101/chapter14_config_parser/"},{"content":"Команды Linux для DevOps Я упомянул вчера, что мы собираемся провести много времени в терминале с некоторыми командами, чтобы что-то сделать.\nЯ также упомянул, что с нашей виртуальной машиной, подготовленной с помощью vagrant, мы можем использовать vagrant ssh и получить доступ к нашей машине. Вам нужно будет находиться в том же каталоге, из которого мы его предоставили.\nДля SSH нам не понадобятся имя пользователя и пароль, они понадобятся нам только в том случае, если решим войти в консоль Virtual Box.\nВот где мы хотим быть, как показано ниже:\nКоманды Очевидно, что я не могу охватить здесь все команды. Есть тонны документации, которые охватывают их, но также, если вы находитесь в своем терминале, и вам просто нужно понять параметры конкретной команды, у нас есть команда man, сокращенная от manual. Мы можем использовать это, чтобы просмотреть каждую из команд, которые мы коснемся в этом посте, чтобы узнать больше вариантов для каждой из них. Мы можем запустить man man, который поможет вам со страницами руководства. Чтобы выйти из справочных страниц, вы должны нажать q для выхода.\nПримеры:\nman ls man whoami ... sudo Если вы знакомы с Windows и щелкаете правой кнопкой мыши по запустить от имени администратора, мы можем думать о sudo как об этом. Когда вы запускаете команду с помощью этой команды, вы будете запускать ее как «root», она запросит у вас пароль перед запуском команды.\nДля разовых работ, таких как установка приложений или служб, вам может понадобиться эта команда sudo, но что, если у вас есть несколько задач, и вы хотите какое-то время пожить как sudo? Здесь вы можете снова использовать sudo su так же, как sudo, после ввода вам будет предложено ввести пароль root. В тестовой виртуальной машине, такой как наша, это нормально, но мне было бы очень сложно работать как «root» в течение длительного времени, могут произойти плохие вещи. Чтобы выйти из этого возвышенного положения, вы просто набираете «exit».\nЯ ловлю себя на том, что все время использую clear. Команда clear делает именно то, о чем говорит: она очищает экран от всех предыдущих команд, помещая курсор наверх и предоставляя вам красивое чистое рабочее пространство. Windows, это «cls» в .mdprompt.\nДавайте теперь посмотрим на некоторые команды, с помощью которых мы можем создавать вещи в нашей системе, а затем визуализировать их в нашем терминале. Прежде всего, у нас есть mkdir, это позволит нам создать папку в нашей системе. С помощью следующей команды мы можем создать папку в нашем домашнем каталоге с именем Day15 mkdir Day15\nС помощью cd это позволяет нам изменить каталог, поэтому для перехода в наш вновь созданный каталог мы можем сделать это с помощью вкладки cd Day15, которая также может использоваться для автозаполнения доступного каталога. Если мы хотим вернуться к тому, с чего начали, мы можем использовать cd ..\nrmdir позволяет нам удалить каталог, если мы запустим rmdir Day15, тогда папка будет удалена (обратите внимание, что это будет работать, только если у вас ничего нет в папке)\nЯ уверен, что все мы делали это, когда мы переходили в глубины нашей файловой системы в каталог и не знали, где мы находимся. pwd дает нам распечатку рабочего каталога, pwd, насколько это похоже на пароль, означает печать рабочего каталога.\nМы знаем, как создавать папки и каталоги, но как мы создаем файлы? Мы можем создавать файлы с помощью команды «touch», если бы мы запускали «touch Day15», это создало бы файл. Игнорируйте mkdir, мы еще увидим это позже.\nls Я могу поставить на это свой дом, вы будете использовать эту команду так много раз, что она выведет список всех файлов и папок в текущем каталоге. Давайте посмотрим, сможем ли мы увидеть тот файл, который мы только что создали.\nКак мы можем найти файлы в нашей системе Linux? locate позволит нам искать в нашей файловой системе. Если мы используем locate Day15, он сообщит о местонахождении файла. Бонусом является то, что если вы знаете, что файл существует, но вы получаете пустой результат, запустите sudo updatedb, который проиндексирует все файлы в файловой системе, а затем снова запустите locate. Если у вас нет locate, вы можете установить его с помощью этой команды sudo apt install mlocate\nКак насчет перемещения файлов из одного места в другое? mv позволит вам перемещать ваши файлы. Пример mv Day15 90DaysOfDevOps переместит ваш файл в папку 90DaysOfDevOps.\nМы переместили наш файл, но что, если мы хотим переименовать его сейчас во что-то другое? Мы можем сделать это снова с помощью команды mv. Мы можем просто использовать mv Day15 day15, чтобы перейти к верхнему регистру, или мы могли бы использовать mv day15 AnotherDay, чтобы полностью изменить его, теперь используйте ls для проверки файла.\nХватит, теперь давайте избавимся (удалим) от нашего файла и, возможно, даже от нашего каталога, если он у нас есть. rm просто rm AnotherDay удалит наш файл. Мы также будем использовать rm -R, который будет рекурсивно работать через папку или местоположение. Мы также можем использовать rm -R -f, чтобы принудительно удалить все эти файлы. Спойлер, если вы запустите rm -R -f /, добавьте к нему sudo, и вы можете попрощаться со своей системой ….!\nМы рассмотрели перемещение файлов, но что, если я просто хочу скопировать файлы из одной папки в другую, просто скажу, что это очень похоже на команду mv, но мы используем cp, чтобы теперь мы могли сказать cp Day15 Desktop\nМы создали папки и файлы, но на самом деле мы не поместили никакого содержимого в нашу папку, мы можем добавить содержимое несколькими способами, но самый простой способ - это echo, мы также можем использовать echo, чтобы распечатать много вещей в нашей папке. терминал, я лично часто использую эхо для вывода системных переменных, чтобы узнать, установлены они или нет. мы можем использовать echo \"Hello #90DaysOfDevOps\" \u003e Day15, и это добавит это в наш файл. Мы также можем добавить к нашему файлу, используя echo \"Commands are fun!\" \u003e\u003e День15\nЕще одна из тех команд, которые вы будете часто использовать! кошка сокращение от конкатенации. Мы можем использовать cat Day15, чтобы увидеть содержимое внутри файла. Отлично подходит для быстрого чтения этих файлов конфигурации.\nЕсли у вас есть длинный сложный файл конфигурации, и вы хотите или вам нужно найти что-то быстрое в этом файле, а не читать каждую строку, тогда grep вам в помощь, это позволит нам искать в вашем файле определенное слово, используя cat Day15 | grep \"#90DaysOfDevOps\"\nЕсли вы похожи на меня и часто используете эту команду clear, то вы можете пропустить некоторые из ранее запущенных команд, мы можем использовать «историю», чтобы узнать все те команды, которые мы запускали ранее. history -c удалит историю.\nКогда вы запускаете history и хотите выбрать конкретную команду, вы можете использовать !3, чтобы выбрать 3-ю команду в списке.\nВы также можете использовать history | grep \"Команда\" для поиска чего-то определенного.\nНа серверах для отслеживания времени выполнения команды может быть полезно добавлять дату и время к каждой команде в файле истории.\nСледующая системная переменная управляет этим поведением:\nHISTTIMEFORMAT=\"%d-%m-%Y %T \" Вы можете легко добавить ее в свой bash_profile:\necho 'export HISTTIMEFORMAT=\"%d-%m-%Y %T \"' \u003e\u003e ~/.bash_profile Можем увеличить размер файла для хранения истории:\necho 'export HISTSIZE=100000' \u003e\u003e ~/.bash_profile echo 'export HISTFILESIZE=10000000' \u003e\u003e ~/.bash_profile Нужно сменить пароль? passwd позволит нам изменить наш пароль. Обратите внимание, что когда вы добавляете свой пароль таким образом, когда он скрыт, он не будет отображаться в history, однако, если ваша команда имеет -p ПАРОЛЬ, тогда он будет виден в вашей history.\nМы также можем добавить новых пользователей в нашу систему, мы можем сделать это с помощью useradd, мы должны добавить пользователя с помощью нашей команды sudo, мы можем добавить нового пользователя с помощью sudo useradd NewUser\nДля повторного создания группы требуется sudo, и мы можем использовать sudo groupadd DevOps, тогда, если мы хотим добавить нашего нового пользователя в эту группу, мы можем сделать это, запустив sudo usermod -a -G DevOps -a is add а -G это имя группы.\nКак добавить пользователей в группу sudo? Это было бы очень редким случаем но для того, чтобы сделать это, выполним: usermod -a -G sudo NewUser\nПрава / Permissions read, write and execute - — это права доступа ко всем нашим файлам и папкам в нашей системе Linux.\nПолный список:\n0 = None --- 1 = Execute only --X 2 = Write only -W- 3 = Write \u0026 Exectute -WX 4 = Read Only R-- 5 = Read \u0026 Execute R-X 6 = Read \u0026 Write RW- 7 = Read, Write \u0026 Execute RWX Вы также увидите «777» или «775», и они представляют те же числа, что и в приведенном выше списке, но каждый из них представляет User - Group - Everyone*\nДавайте посмотрим на наш файл. ls -al Day15 вы можете увидеть 3 группы, упомянутые выше, пользователь и группа могут читать и изменять (write), но все остальыне только читать (read).\nМы можем изменить это с помощью chmod, вы можете сделать это, если вы также создаете двоичные файлы в своих системах, и вам нужно дать возможность запускать эти двоичные файлы. chmod 750 Day15 теперь запустите ls -la Day15, если вы хотите запустить это для всей папки, вы можете использовать -R, чтобы сделать это рекурсивно.\nКак насчет смены владельца файла? Мы можем использовать «chown» для этой операции, если мы хотим изменить владельца нашего «Day15» с пользователя «vagrant» на «NewUser», мы можем запустить «sudo chown NewUser Day15» снова, можно использовать «-R».\nКоманда, с которой вы столкнетесь, это awk, где она реально используется, когда у вас есть выходные данные, из которых вам нужны только определенные данные. например, запуская who, мы получаем строки с информацией, но, возможно, нам нужны только имена. Мы можем запустить кто | awk '{print $1}', чтобы получить только список этого первого столбца.\nЕсли вы хотите читать потоки данных из стандартного ввода, то генерирует и выполняет командные строки; это означает, что он может принимать вывод команды и передавать его в качестве аргумента другой команды. xargs — полезный инструмент для этого случая использования. Если, например, мне нужен список всех учетных записей пользователей Linux в системе, которую я могу запустить. cut -d: -f1 \u003c /etc/passwd и получите длинный список, который мы видим ниже.\nЕсли я хочу заархивировать этот список, я могу сделать это, используя xargs в команде вроде этой cut -d: -f1 \u003c /etc/passwd | sort | xargs\nЯ также не упомянул команду cut, которая позволяет нам удалять разделы из каждой строки файла. Его можно использовать для вырезания частей строки по положению байта, символу и полю. Команда cut -d \" \" -f 2 list.txt позволяет нам удалить первую букву, которая у нас есть, и просто отобразить наши числа. Есть так много комбинаций, которые можно использовать здесь с этой командой, я уверен, что потратил слишком много времени, пытаясь использовать эту команду, когда я мог бы быстрее извлечь данные вручную.\nТакже обратите внимание, если вы вводите команду, и вы больше не довольны ею, и вы хотите начать снова, просто нажмите Ctrl + c, и это отменит эту строку и начнет все заново.\nРесурсы Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need be a hacker!) Это уже довольно большой список, но я могу с уверенностью сказать, что я использую все эти команды в своей повседневной жизни, будь то администрирование серверов Linux или мой рабочий стол Linux, это очень легко, когда вы находитесь в Windows или macOS для навигации по пользовательскому интерфейсу, но в Linux Servers их нет, все делается через терминал.\n","description":"Команды Linux в DevOps","title":"15. Команды Linux в DevOps","uri":"/ru/docs/90daysofdevops/day15/"},{"content":"Глава 15 - Логирование Python предоставляет очень мощную библиотеку протоколирования в своей стандартной библиотеке. Многие программисты используют операторы печати для отладки (в том числе и я), но вы также можете использовать для этого протоколирование. Использование лога также более чистый метод, если вы не хотите просматривать весь свой код, чтобы удалить все операторы print. В данном разделе мы рассмотрим следующее:\nСоздание простого логгера Как вести журнал из нескольких модулей Форматирование лога Конфигурация лога К концу этой главы вы должны быть в состоянии уверенно создавать собственные логи для своих приложений. Давайте приступим!\nСоздание простого логгера Создать лог с помощью модуля logging легко и просто. Проще всего посмотреть на кусок кода, а затем объяснить его, так что вот вам код для чтения:\nimport logging # add filemode=\"w\" to overwrite logging.basicConfig(filename=\"sample.log\", level=logging.INFO) logging.debug(\"This is a debug message\") logging.info(\"Informational message\") logging.error(\"An error has happened!\") Как и следовало ожидать, чтобы получить доступ к модулю logging, его необходимо сначала импортировать. Самый простой способ создать лог - использовать функцию basicConfig модуля logging и передать ему несколько аргументов с ключевыми словами. Она принимает следующие аргументы: filename, filemode, format, datefmt, level и stream. В нашем примере мы передаем ей имя файла и уровень протоколирования, который мы установили на INFO. Существует пять уровней протоколирования (в порядке возрастания): DEBUG, INFO, WARNING, ERROR и CRITICAL. По умолчанию, если вы запустите этот код несколько раз, он будет добавляться в лог, если он уже существует. Если вы предпочитаете, чтобы ваш логгер перезаписывал лог, то передайте filemode=“w”, как указано в комментарии в коде. Говоря о выполнении кода, вот что вы получите, если выполните его один раз:\nINFO:root:Informational message ERROR:root:An error has happened! Обратите внимание, что отладочное сообщение отсутствует в выводе. Это потому, что мы установили уровень INFO, поэтому наш логгер будет вести лог только в том случае, если это сообщение INFO, WARNING, ERROR или CRITICAL. Часть root означает, что это сообщение поступает от корневого или главного логгера. В следующем разделе мы рассмотрим, как изменить это значение, чтобы оно было более описательным. Если вы не используете basicConfig, то модуль протоколирования будет выводить сообщения в консоль / stdout.\nМодуль протоколирования также может записывать некоторые исключения в файл или в любое другое место, куда вы настроите его. Вот пример:\nimport logging logging.basicConfig(filename=\"sample.log\", level=logging.INFO) log = logging.getLogger(\"ex\") try: raise RuntimeError except RuntimeError: log.exception(\"Error!\") Давайте немного разложим это по полочкам. Здесь мы используем метод getLogger модуля logging, чтобы вернуть объект logger с именем ex. Это удобно, когда в одном приложении используется несколько логгеров, так как позволяет определить, какие сообщения поступили от каждого из них. Этот пример заставит возникнуть RuntimeError, выявит ошибку и запишет весь трассировочный откат в файл, что может быть очень удобно при отладке.\nЛогирование из нескольких модулей (а также форматирование!) Чем больше вы кодите, тем чаще вы создаете набор пользовательских модулей, которые работают вместе. Если вы хотите, чтобы запись велась в одном месте, значит, вы обратились по адресу. Мы рассмотрим простой способ, а затем покажем более сложный метод, который также является и более настраиваемым. Вот один простой способ:\nimport logging import otherMod def main(): \"\"\" The main entry point of the application \"\"\" logging.basicConfig(filename=\"mySnake.log\", level=logging.INFO) logging.info(\"Program started\") result = otherMod.add(7, 8) logging.info(\"Done!\") if __name__ == \"__main__\": main() Здесь мы импортируем logging и модуль нашего собственного создания (“otherMod”). Затем мы создаем наш файл журнала, как делали раньше. Другой модуль выглядит следующим образом:\n# otherMod.py import logging def add(x, y): \"\"\"\"\"\" logging.info(\"added %s and %s to get %s\" % (x, y, x+y)) return x+y Если вы запустите основной код, вы должны получить лог со следующим содержанием:\nINFO:root:Program started INFO:root:added 7 and 8 to get 15 INFO:root:Done! Заметили проблему в этом? Вы не можете однозначно сказать, откуда приходят сообщения. При этом, чем больше модулей пишут в лог, тем сложнее становится картина. Так что нам нужно это исправить. Таким образом, мы приходим к более сложному способу создание логгера. Давайте взглянем на другой способ создания:\nimport logging import otherMod2 def main(): \"\"\" The main entry point of the application \"\"\" logger = logging.getLogger(\"exampleApp\") logger.setLevel(logging.INFO) # create the logging file handler fh = logging.FileHandler(\"new_snake.log\") formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') fh.setFormatter(formatter) # add handler to logger object logger.addHandler(fh) logger.info(\"Program started\") result = otherMod2.add(7, 8) logger.info(\"Done!\") if __name__ == \"__main__\": main() Здесь мы создаем экземпляр логгера с именем “exampleApp”. Мы устанавливаем его уровень протоколирования, создали объект обработчика лог-файла, и объект форматирование. Обработчик файла должен установить объект форматирование в качестве своего форматтера, после чего обработчик файла должен быть добавлен в регистратор логгера.. Остальной код в main в основном такой же. Только обратите внимание, что вместо “logging.info” будет “logger.info” или как бы вы ни назвали свою переменную logger. Вот обновленный код OtherMod2:\n# otherMod2.py import logging module_logger = logging.getLogger(\"exampleApp.otherMod2\") def add(x, y): \"\"\"\"\"\" logger = logging.getLogger(\"exampleApp.otherMod2.add\") logger.info(\"added %s and %s to get %s\" % (x, y, x+y)) return x+y Обратите внимание, что здесь у нас определены два логгера. Мы ничего не делаем с module_logger в данном случае, но используем другой. Если вы запустите основной скрипт, вы должны увидеть следующий вывод в вашем файле:\n2022-12-22 154:21:30,592 - exampleApp - INFO - Program started 2022-12-22 154:21:30,592 - exampleApp.otherMod2.add - INFO - added 7 and 8 to get 15 2022-12-22 154:21:30,592 - exampleApp - INFO - Done Вы заметите, что все ссылки на root были удалены. Вместо этого он использует наш объект Formatter, который говорит, что мы должны получить человекочитаемое время, имя логгера, уровень логгирования и затем сообщение. На самом деле эти параметры известны как атрибуты LogRecord. Полный список атрибутов LogRecord см. в документации, так как их слишком много, чтобы перечислять их здесь.\nКонфигурация логов для работы Модуль logging может быть настроен тремя различными способами. Вы можете настроить его с помощью методов (логгеров, форматоров, обработчиков), как мы делали ранее в этой статье; вы можете использовать файл конфигурации и передать его в fileConfig(); или вы можете создать словарь информации о конфигурации и передать его в функцию dictConfig(). Давайте сначала создадим файл конфигурации, а затем рассмотрим, как выполнить его с помощью Python. Вот пример файла конфигурации:\n[loggers] keys=root,exampleApp [handlers] keys=fileHandler, consoleHandler [formatters] keys=myFormatter [logger_root] level=CRITICAL handlers=consoleHandler [logger_exampleApp] level=INFO handlers=fileHandler qualname=exampleApp [handler_consoleHandler] class=StreamHandler level=DEBUG formatter=myFormatter args=(sys.stdout,) [handler_fileHandler] class=FileHandler formatter=myFormatter args=(\"config.log\",) [formatter_myFormatter] format=%(asctime)s - %(name)s - %(levelname)s - %(message)s datefmt= Вы заметите, что у нас указаны два регистратора: root и exampleApp. По какой-то причине “root” является обязательным. Если вы не включите его, Python выдаст ошибку ValueError из функции config.py’s _install_loggers, которая является частью модуля logging. Если вы установите обработчик root в fileHandler, то в итоге вы удвоите вывод журнала, поэтому, чтобы этого не произошло, вместо этого мы отправляем его на консоль. Внимательно изучите этот пример. Вам понадобится секция для каждого ключа в первых трех секциях. Теперь давайте посмотрим, как мы загружаем их в коде:\n# log_with_config.py import logging import logging.config import otherMod2 def main(): \"\"\" Based on http://docs.python.org/howto/logging.html#configuring-logging \"\"\" logging.config.fileConfig('logging.conf') logger = logging.getLogger(\"exampleApp\") logger.info(\"Program started\") result = otherMod2.add(7, 8) logger.info(\"Done!\") if __name__ == \"__main__\": main() Как вы видите, все, что вам нужно сделать, это передать путь к файлу конфигурации в logging.config.fileConfig. Вы также заметите, что нам больше не нужен весь этот код настройки, поскольку все это находится в файле конфигурации. Также мы можем просто импортировать модуль otherMod2 без изменений. В любом случае, если вы выполните вышеописанное, в конечном итоге в вашем файле журнала должно появиться следующее:\n2022-12-22 18:23:33,338 - exampleApp - INFO - Program started 2022-12-22 18:23:33,338 - exampleApp.otherMod2.add - INFO - added 7 and 8 to get 15 2022-12-22 18:23:33,338 - exampleApp - INFO - Done! Как вы уже догадались, он очень похож на другой пример. Теперь мы перейдем к другому методу config. Метод конфигурирования по словарю (dictConfig) был добавлен только в Python 2.7. В документации не сказано прямо, как это работает. На самом деле, примеры в документации почему-то показывают YAML. В любом случае, вот рабочий код, который вы можете посмотреть:\n# log_with_config.py import logging import logging.config import otherMod2 def main(): \"\"\" Based on http://docs.python.org/howto/logging.html#configuring-logging \"\"\" dictLogConfig = { \"version\":1, \"handlers\":{ \"fileHandler\":{ \"class\":\"logging.FileHandler\", \"formatter\":\"myFormatter\", \"filename\":\"config2.log\" } }, \"loggers\":{ \"exampleApp\":{ \"handlers\":[\"fileHandler\"], \"level\":\"INFO\", } }, \"formatters\":{ \"myFormatter\":{ \"format\":\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" } } } logging.config.dictConfig(dictLogConfig) logger = logging.getLogger(\"exampleApp\") logger.info(\"Program started\") result = otherMod2.add(7, 8) logger.info(\"Done!\") if __name__ == \"__main__\": main() Если вы выполните этот код, вы получите тот же результат, что и в предыдущем методе. Обратите внимание, что вам больше не нужен логгер root, когда вы используете словарь конфигурации.\nПодведение итогов На данном этапе вы должны знать, как начать использовать логгеры и как настроить их несколькими различными способами. Вы также должны получить знания о том, как изменять вывод с помощью объекта Formatter. Модуль протоколирования очень удобен для поиска и устранения неисправностей в вашем приложении. Обязательно уделите некоторое время практике работы с этим модулем перед написанием большого приложения.\nВ следующей главе мы рассмотрим, как использовать модуль os.\n","description":"Python 101","title":"15. Логирование","uri":"/ru/docs/python101/chapter15_logging/"},{"content":"Модуль os имеет множество применений. Мы не будем рассматривать все его возможности. Вместо этого мы получим обзор его возможностей, а также рассмотрим один из его подмодулей, известный как os.path. В частности, мы рассмотрим следующее:\nos.name os.environ os.chdir() os.getcwd() os.getenv() os.putenv() os.mkdir() os.makedirs() os.remove() os.rename() os.rmdir() os.startfile() os.walk() os.path Кажется, что этого очень много, но существует примерно в десять раз больше других действий, которые может выполнять модуль os. В этой главе мы просто дадим вам небольшое представление о том, что доступно. Чтобы использовать любой из методов, упомянутых в этом разделе, вам нужно импортировать модуль os, как показано ниже:\nimport os Давайте начнем изучать, как использовать этот модуль!\nos.name Модуль os имеет как вызываемые функции, так и обычные значения. В случае с os.name это просто значение. Когда вы обращаетесь к os.name, вы получите информацию о том, на какой платформе вы работаете. Вы увидите одно из следующих значений: ‘posix’, ’nt’, ‘os2’, ‘ce’, ‘java’, ‘riscos’. Давайте посмотрим, что мы получим при запуске на Windows 7:\n\u003e\u003e\u003e import os \u003e\u003e\u003e os.name 'nt' Это говорит нам о том, что наш экземпляр Python запущен на компьютере под управлением Windows. Откуда мы это знаем? Потому что Microsoft начала называть свою операционную систему NT много лет назад. Например, Windows 7 также известна как Windows NT 6.1.\nos.environ, os.getenv() и os.putenv() Значение os.environ известно как объект mapping, который возвращает словарь переменных окружения пользователя. Вы можете этого не знать, но каждый раз, когда вы используете свой компьютер, устанавливаются некоторые переменные окружения. Они могут дать вам ценную информацию, например, количество процессоров, тип ЦП, имя компьютера и т.д. Давайте посмотрим, что мы можем узнать о нашей машине:\n\u003e\u003e\u003e import os \u003e\u003e\u003e os.environ {'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\mike\\\\AppData\\\\Roaming', 'CLASSPATH': '.;C:\\\\Program Files\\\\QuickTime\\\\QTSystem\\\\QTJava.zip', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'MIKE-PC', 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe', 'FP_NO_HOST_CHECK': 'NO', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\mike', 'LOCALAPPDATA': 'C:\\\\Users\\\\mike\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\MIKE-PC', 'NUMBER_OF_PROCESSORS': '2', 'OS': 'Windows_NT', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'x86', 'PROCESSOR_IDENTIFIER': 'x86 Family 6 Model 15 Stepping 13, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PSMODULEPATH': 'C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules\\\\', 'PUBLIC': 'C:\\\\Users\\\\Public', 'PYTHONIOENCODING': 'cp437', 'QTJAVA': 'C:\\\\Program Files\\\\QuickTime\\\\QTSystem\\\\QTJava.zip', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\Windows', 'TEMP': 'C:\\\\Users\\\\mike\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\mike\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'mike-PC', 'USERNAME': 'mike', 'USERPROFILE': 'C:\\\\Users\\\\mike', 'VBOX_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\', 'VS90COMNTOOLS': 'C:\\\\Program Files\\\\Microsoft Visual Studio 9.0\\\\Common7\\\\Tools\\\\', 'WINDIR': 'C:\\\\Windows', 'WINDOWS_TRACING_FLAGS': '3', 'WINDOWS_TRACING_LOGFILE': 'C:\\\\BVTBin\\\\Tests\\\\installpackage\\\\csilogfile.log', 'WINGDB_ACTIVE': '1', 'WINGDB_PYTHON': 'c:\\\\python27\\\\python.exe', 'WINGDB_SPAWNCOOKIE': 'rvlxwsGdD7SHYIJm'} Ваш результат не будет таким же, как у меня, поскольку конфигурация ПК у всех немного отличается, но вы увидите нечто похожее. Как вы могли заметить, это возвращает словарь. Значит, вы можете получить доступ к переменным окружения, используя обычные методы работы со словарями. Вот пример:\n\u003e\u003e\u003e print(os.environ[\"TMP\"]) 'C:\\\\Users\\\\mike\\\\AppData\\\\Local\\\\Temp' Вы также можете использовать функцию os.getenv для доступа к этой переменной среды:\n\u003e\u003e\u003e os.getenv(\"TMP\") 'C:\\\\Users\\\\mike\\\\AppData\\\\Local\\\\Temp' Преимущество использования os.getenv() вместо словаря os.environ заключается в том, что если вы попытаетесь получить доступ к несуществующей переменной окружения, функция getenv просто вернет None. Если бы вы сделали то же самое с os.environ, то получили бы ошибку. Давайте попробуем это сделать, чтобы вы могли увидеть, что произойдет:\n\u003e\u003e\u003e os.environ[\"TMP2\"] Traceback (most recent call last): File \"\u003cpyshell#1\u003e\", line 1, in \u003cmodule\u003e os.environ[\"TMP2\"] File \"C:\\Python27\\lib\\os.py\", line 423, in __getitem__ return self.data[key.upper()] KeyError: 'TMP2' \u003e\u003e\u003e print(os.getenv(\"TMP2\")) None os.chdir() и os.getcwd() Функция os.chdir позволяет нам изменить каталог, в котором в данный момент запущена наша сессия Python. Если вы хотите узнать, в каком каталоге вы сейчас находитесь, то вызовите os.getcwd(). Давайте попробуем использовать обе функции:\n\u003e\u003e\u003e os.getcwd() 'C:\\\\Python27' \u003e\u003e\u003e os.chdir(r\"c:\\Users\\mike\\Documents\") \u003e\u003e\u003e os.getcwd() 'c:\\\\Users\\\\mike\\\\Documents' Код выше показывает нам, что мы начали работу в каталоге Python по умолчанию, когда мы запускаем этот код в IDLE. Затем мы меняем папки с помощью os.chdir(). Наконец, мы вызываем os.getcwd() во второй раз, чтобы убедиться, что мы успешно перешли в папку.\nos.mkdir() и os.makedirs() Возможно, вы уже догадались, но два метода, рассматриваемые в этом разделе, используются для создания каталогов. Первый из них - os.mkdir(), который позволяет нам создать одну папку. Давайте попробуем это сделать:\n\u003e\u003e\u003e os.mkdir(\"test\") \u003e\u003e\u003e path = r'C:\\Users\\mike\\Documents\\pytest' \u003e\u003e\u003e os.mkdir(path Первая строка кода создаст папку с именем test в текущем каталоге. Вы можете использовать методы из предыдущего раздела, чтобы выяснить, куда вы только что запустили свой код, если забыли. Во втором примере путь присваивается переменной, а затем мы передаем путь в os.mkdir(). Это позволяет вам создать папку в любом месте вашей системы, на которое у вас есть права.\nФункция os.makedirs() создаст все промежуточные папки в пути, если они еще не существуют. В принципе, это означает, что вы можете создать путь, содержащий вложенные папки. Я часто так делаю, когда создаю файл журнала, который находится в датированной структуре папок, например, Год/Месяц/День. Давайте рассмотрим пример:\n\u003e\u003e\u003e path = r'C:\\Users\\mike\\Documents\\pytest\\2014\\02\\19' \u003e\u003e\u003e os.makedirs(path) Что здесь произошло? Этот код просто создал кучу папок! Если в вашей системе все еще была папка pytest, то она просто добавила папку 2014 с другой папкой внутри, которая также содержала папку. Попробуйте сделать это сами, используя правильный путь в вашей системе.\nos.remove() и os.rmdir() Функции os.remove() и os.rmdir() используются для удаления файлов и каталогов соответственно. Давайте рассмотрим пример работы os.remove():\n\u003e\u003e\u003e os.remove(\"test.txt\") Этот фрагмент кода попытается удалить файл с именем test.txt из текущего рабочего каталога. Если он не сможет найти файл, вы, скорее всего, получите какую-либо ошибку. Вы также получите ошибку, если файл используется (т.е. заблокирован) или у вас нет разрешения на удаление файла. Возможно, вы также захотите проверить os.unlink, который делает то же самое. Термин unlink - это традиционное название этой процедуры в Unix.\nТеперь давайте рассмотрим пример os.rmdir():\n\u003e\u003e\u003e os.rmdir(\"pytest\") Приведенный выше код попытается удалить каталог с именем pytest из текущего рабочего каталога. Если попытка успешна, вы увидите, что каталог больше не существует. Если каталог не существует, у вас нет разрешения на его удаление или каталог не пуст, будет выдана ошибка. Возможно, вы также захотите взглянуть на os.removedirs(), которая может рекурсивно удалять вложенные пустые каталоги.\nos.rename(src, dst) Функция os.rename() переименовывает файл или папку. Давайте рассмотрим пример переименования файла:\n\u003e\u003e\u003e os.rename(\"test.txt\", \"pytest.txt\") В этом примере мы говорим os.rename переименовать файл с именем test.txt в pytest.txt. Это происходит в нашем текущем рабочем каталоге. Вы увидите ошибку, если попытаетесь переименовать несуществующий файл или если у вас нет соответствующего разрешения на переименование файла.\nСуществует также функция os.renames, которая рекурсивно переименовывает каталог или файл.\nos.startfile() Метод os.startfile() позволяет нам “запустить” файл с помощью связанной с ним программы. Другими словами, мы можем открыть файл с помощью связанной с ним программы, как если бы вы дважды щелкнули по PDF-файлу, и он открылся бы в Adobe Reader. Давайте попробуем!\n\u003e\u003e\u003e os.startfile(r'C:\\Users\\mike\\Documents\\labels.pdf') В приведенном выше примере я передаю os.startfile полный путь, который указывает ему открыть файл под названием labels.pdf. На моей машине это приведет к открытию PDF в Adobe Reader. Вы должны попробовать открыть свои собственные PDF, MP3 и фотографии с помощью этого метода, чтобы увидеть, как он работает.\nos.walk() Метод os.walk() дает нам способ итерации по пути корневого уровня. Это означает, что мы можем передать путь в эту функцию и получить доступ ко всем его подкаталогам и файлам. Давайте воспользуемся одной из папок Python, которые у нас есть под рукой, чтобы протестировать эту функцию. Мы будем использовать: C:\\Python27\\Tools\n\u003e\u003e\u003e path = r'C:\\Python27\\Tools' \u003e\u003e\u003e for root, dirs, files in os.walk(path): print(root) C:\\Python27\\Tools C:\\Python27\\Tools\\i18n C:\\Python27\\Tools\\pynche C:\\Python27\\Tools\\pynche\\X C:\\Python27\\Tools\\Scripts C:\\Python27\\Tools\\versioncheck C:\\Python27\\Tools\\webchecker При желании можно также перебирать dirs и files. Вот один из способов сделать это:\n\u003e\u003e\u003e for root, dirs, files in os.walk(path): print(root) for _dir in dirs: print(_dir) for _file in files: print(_file) Этот фрагмент кода выведет много информации, поэтому я не буду показывать его вывод здесь, но не стесняйтесь попробовать. Теперь мы готовы к изучению работы с путями!\nos.path Подмодуль os.path модуля os имеет множество замечательных функций, встроенных в него. Мы рассмотрим следующие функции:\n- basename - exists - isdir и isfile - join - split В этом подмодуле есть много других функций. Вы можете прочитать о них в документации Python, раздел 10.1.\nos.path.basename Функция basename возвращает только имя файла пути. Вот пример:\n\u003e\u003e\u003e os.path.basename(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') 'ChipViewer.py' Это полезно, когда мне нужно использовать имя файла для именования какого-либо связанного файла, например, файла лога. Это часто случается, когда я обрабатываю файл данных.\nos.path.dirname Функция dirname возвращает только часть пути, связанную с каталогом. Это легче понять, если мы посмотрим на некоторый код:\n\u003e\u003e\u003e os.path.dirname(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') 'C:\\\\Python27\\\\Tools\\\\pynche' В этом примере мы просто получаем путь к каталогу. Это также полезно, когда вы хотите сохранить другие файлы рядом с обрабатываемым файлом, например, вышеупомянутый файл лога.\nos.path.exists Функция exists сообщит вам, существует ли путь или нет. Все, что вам нужно сделать, это передать ей путь. Давайте посмотрим:\n\u003e\u003e\u003e os.path.exists(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') True \u003e\u003e\u003e os.path.exists(r'C:\\Python27\\Tools\\pynche\\fake.py') False В первом примере мы передаем функции exists реальный путь, и она возвращает True, что означает, что путь существует. Во втором примере мы передали ей плохой путь, и она сообщила нам, что путь не существует, вернув False.\nos.path.isdir / os.path.isfile Методы isdir и isfile тесно связаны с методом exists тем, что они также проверяют существование. Однако isdir проверяет только, является ли путь каталогом, а isfile - только, является ли путь файлом. Если вы хотите проверить, существует ли путь независимо от того, является ли он файлом или каталогом, то вам нужно использовать метод exists. В любом случае, давайте рассмотрим несколько примеров:\n\u003e\u003e\u003e os.path.isfile(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') True \u003e\u003e\u003e os.path.isdir(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') False \u003e\u003e\u003e os.path.isdir(r'C:\\Python27\\Tools\\pynche') True \u003e\u003e\u003e os.path.isfile(r'C:\\Python27\\Tools\\pynche') False Уделите немного времени изучению этого набора примеров. В первом примере мы передаем путь к файлу и проверяем, действительно ли этот путь является файлом. Затем во втором примере тот же путь проверяется на то, является ли он каталогом. Вы можете сами посмотреть, что из этого получилось. Затем в последних двух примерах мы немного изменили ситуацию, передав путь к каталогу тем же двум функциям. Эти примеры демонстрируют, как работают эти две функции.\nos.path.join Метод join дает вам возможность соединить один или несколько компонентов пути вместе с помощью соответствующего разделителя. Например, в Windows разделителем является обратная косая черта, а в Linux - прямая косая черта. Вот как это работает:\n\u003e\u003e\u003e os.path.join(r'C:\\Python27\\Tools\\pynche', 'ChipViewer.py') 'C:\\\\Python27\\\\Tools\\\\pynche\\\\ChipViewer.py' В этом примере мы объединили путь к каталогу и путь к файлу, чтобы получить полностью квалифицированный путь. Обратите внимание, что метод join не проверяет, существует ли результат!\nos.path.split Метод split разбивает путь на кортеж, содержащий каталог и файл. Давайте посмотрим:\n\u003e\u003e\u003e os.path.split(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') ('C:\\\\Python27\\\\Tools\\\\pynche', 'ChipViewer.py') Этот пример показывает, что происходит, когда мы указываем путь к файлу. Посмотрим, что произойдет, если в конце пути не будет имени файла:\n\u003e\u003e\u003e os.path.split(r'C:\\Python27\\Tools\\pynche') ('C:\\\\Python27\\\\Tools', 'pynche') Как вы можете видеть, он взял путь и разделил его таким образом, что последняя вложенная папка стала вторым элементом кортежа, а остальная часть пути - первым элементом.\nДля нашего последнего примера я подумал, что вы захотите увидеть типичный случай использования split:\n\u003e\u003e\u003e dirname, fname = os.path.split(r'C:\\Python27\\Tools\\pynche\\ChipViewer.py') \u003e\u003e\u003e dirname 'C:\\\\Python27\\\\Tools\\\\pynche' \u003e\u003e\u003e fname 'ChipViewer.py' Здесь показано, как выполнить множественное присваивание. Когда вы разделяете путь, он возвращает двухэлементный кортеж. Поскольку у нас две переменные слева, первый элемент кортежа присваивается первой переменной, а второй элемент - второй переменной.\nПодведение итогов К этому моменту вы должны быть хорошо знакомы с модулем oss. В этой главе вы узнали следующее:\nкак работать с переменными окружения изменять каталоги и определять текущий рабочий каталог создавать и удалять папки и файлы переименовывать файлы/папки запускать файл и связанное с ним приложение перемещаться по каталогу работать с путями В модуле os есть множество других функций, которые здесь не рассматриваются. Обязательно прочитайте документацию, чтобы узнать, что еще вы можете делать. В следующей главе мы познакомимся с модулями email и smtplib.\n","description":"Python 101","title":"16. Модуль os","uri":"/ru/docs/python101/chapter16_os/"},{"content":"Управление системой, файловой системой и хранилищем в Linux К этому времени мы кратко рассмотрели Linux и DevOps, а затем мы настроили нашу лабораторную среду с помощью vagant 14-й день), а затем коснулись небольшой части команд, которые будут в вашем ежедневном набор инструментов во время использования терминала - (День 15).\nСегодня мы рассмотрим три ключевые области обслуживания систем Linux с помощью обновлений, установки программного обеспечения. Поймем для чего используются системные папки, а также рассмотрим хранилище.\nУправление Ubuntu и программным обеспечением Первое, что мы собираемся рассмотреть, это то, как мы обновляем нашу операционную систему. Большинству из вас этот процесс знаком в ОС Windows и macOS, он немного отличается на рабочем столе и сервере Linux.\nМы рассмотрим диспетчер пакетов apt - утилита, которую мы собираемся использовать на нашей виртуальной машине Ubuntu для обновлений и установки программного обеспечения.\nКак правило, по крайней мере на рабочих станциях разработчиков, мы запускаем эту команду, чтобы убедиться, что у нас есть последние доступные обновления из центральных репозиториев перед установкой любого программного обеспечения.\nsudo apt-get update\nТеперь у нас есть обновленная виртуальная машина Ubuntu с установленными последними обновлениями ОС. Теперь мы хотим установить здесь некоторое программное обеспечение. Давайте выберем figlet — программу, генерирующую текстовые баннеры. Если мы введем «figlet» в наш терминал, вы увидите, что приложение не установлен в нашей системе.\nОднако из вышеизложенного вы увидите, что утилита apt предлагает нам некотоыре опции установки apt install ... , которые мы можем попробовать. Это потому, что в репозиториях по умолчанию есть программа figlet. Давайте попробуем sudo apt install figlet Теперь мы можем использовать наше приложение figlet Если мы хотим удалить эту или любую из наших установок программного обеспечения, мы также можем сделать это с помощью менеджера пакетов «apt». sudo apt remove figlet\nСуществуют сторонние репозитории, которые мы также можем добавить в нашу систему, те, к которым у нас есть доступ из коробки, являются репозиториями Ubuntu по умолчанию.\nЕсли бы, например, мы хотели установить vagrant на нашу виртуальную машину Ubuntu, мы не смогли бы сделать это прямо сейчас, и вы можете увидеть это ниже в первой введенной команде. Затем мы добавляем ключ к репозиторию HashiCorp, а затем добавляем репозиторий в нашу систему.\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" Как только мы добавим репозиторий HashiCorp, мы можем запустить sudo apt install vagrant и установить vagrant в нашей системе.\nСуществует много вариантов, когда дело доходит до установки программного обеспечения, различных вариантов менеджеров пакетов, встроенных в Ubuntu, мы также могли бы использовать сохраненные темплейты (snapshots) для установки нашего программного обеспечения.\nНадеюсь, это даст вам представление о том, как управлять установками ОС и программного обеспечения в Linux.\nФайловая система Linux состоит из файлов конфигурации, и если вы хотите что-то изменить, вы меняете эти файлы конфигурации.\nВ Windows у вас есть диск C:, и это то, что мы считаем корнем. В Linux у нас есть /, где мы собираемся найти важные папки в нашей системе Linux.\n/bin - Сокращенно от binary, папка bin — это место, где в основном находятся наши двоичные файлы, которые нужны вашей системе, исполняемые файлы и инструменты. /boot - Все файлы, необходимые вашей системе для загрузки. Как загрузиться и с какого диска загрузиться. /dev - Вы можете найти информацию об устройстве здесь, здесь вы найдете указатели на ваши диски sda, которые будут вашим основным диском ОС. /etc - Вероятно, это самая важная папка в вашей системе Linux, где находится большинство ваших файлов конфигурации. /home - здесь вы найдете свои пользовательские папки и файлы. У нас есть пользовательская папка vagrant. В ней вы найдете папки “Documents” и «Desktop», с которыми мы работали для раздела команд. /lib - Мы упомянули, что /bin — это место, где находятся наши бинарные и исполняемые файлы, а /lib — это место, где вы найдете разделяемые библиотеки для них. /media - Съемные носители. Флешки, диски и тд). /mnt - Mount. Это временная точка монтирования. Подробнее мы расскажем в следующем разделе о хранении данных. /opt - Дополнительные пакеты программного обеспечения. Вы заметите, что здесь хранится некоторое программное обеспечение для vagrant и virtual box. /proc - Информация о ядре (kernel) и процессе (process), аналогичная /dev /root - Домашняя папка для root. Чтобы получить доступ, вам нужно войти в эту папку с помощью sudo. /run - Каталог, содержащий PID файлы процессов, похожий на /var/run, но в отличие от него, он размещен в TMPFS, а поэтому после перезагрузки все файлы теряются. Сохраняет состояния текущих процессов /sbin - System binaries. Так же как и /bin, содержит двоичные исполняемые файлы, которые доступны на ранних этапах загрузки, когда не примонтирован каталог /usr. Но здесь находятся программы, которые можно выполнять только с правами суперпользователя. Это разные утилиты для обслуживания системы. Например, iptables, reboot, fdisk, ifconfig,swapon и т д. /tmp - Содержит временные файлы, созданные системой, любыми программами или пользователями /usr - User Aplications. Если бы мы, как обычный пользователь, установили пакеты программного обеспечения, они обычно устанавливались бы в папку /usr/bin. Здесь находятся исполняемые файлы, исходники программ, различные ресурсы приложений, картинки, музыка и документация\n/usr/bin - Содержит исполняемые файлы различных программ, которые не нужны на первых этапах загрузки системы, например, музыкальные плееры, графические редакторы, браузеры и т.д.\n/var - Variable. Переменные файлы. Наши приложения устанавливаются в папку bin. Нам нужно где-то хранить все файлы журналов, это /var. Здесь содержатся файлы системных журналов, различные кеши, базы данных и так далее /var/log - Logs. Здесь содержатся большинство файлов логов всех программ, установленных в операционной системе. У многих программ есть свои подкаталоги в этой папке, например, /var/log/apache - логи веб-сервера, /var/log/squid - файлы журналов кеширующего сервера squid. Если в системе что-либо сломалось, скорее всего, ответы вы найдете здесь.\n/var/run - Содержит файлы с PID процессов, которые могут быть использованы, для взаимодействия между программами. В отличие от каталога /run данные сохраняются после перезагрузки.\n/sys - System. Информация о системе. Назначение каталогов Linux из этой папки - получение информации о системе непосредственно от ядра. Это еще одна файловая система организуемая ядром и позволяющая просматривать и изменить многие параметры работы системы, например, работу swap, контролировать вентиляторы и многое другое.\nХранение Когда мы подходим к системе Linux или любой другой системе, мы можем захотеть узнать о доступных дисках и о том, сколько свободного места у нас есть на этих дисках. Следующие несколько команд помогут нам идентифицировать, использовать и управлять хранилищем.\nlsblk Список заблокированных устройств. «sda» — это наш физический диск, а затем «sda1, sda2, sda3» — наши разделы на этом диске. df дает нам немного больше информации об этих разделах, сколько всего, используется и доступно. Здесь вы можете использовать и другие флаги. Я обычно использую df -h, чтобы дать нам “человеческий (понятный” (human) вывод данных. Если вы добавляли новый диск в свою систему, и это то же самое в Windows, вам нужно было бы отформатировать диск в управлении дисками, в терминале Linux вы можете сделать это с помощью sudo mkfs -t ext4 /dev/sdb с sdb, относящимся к нашему недавно добавленному диску.\nЗатем нам нужно будет смонтировать наш недавно отформатированный диск, чтобы его можно было использовать. Мы сделали бы это в нашей ранее упомянутой папке /mnt и создали бы там каталог с sudo mkdir NewDisk, а затем использовали бы sudo mount /dev/sdb newdisk для монтирования диска в это место.\nТакже возможно, что вам нужно будет безопасно отключить хранилище из вашей системы, а не просто вытащить его из конфигурации. Мы можем сделать это с помощью sudo umount /dev/sdb.\nЕсли вы не хотите размонтировать этот диск и собираетесь использовать этот диск для базы данных или какого-либо другого варианта постоянного использования, тогда вы хотите, чтобы он был там при перезагрузке системы. Чтобы это произошло, нам нужно добавить этот диск в наш файл конфигурации /etc/fstab, чтобы он сохранялся, если вы этого не сделаете, его нельзя будет использовать при перезагрузке машины, и вам придется вручную выполнить описанное выше. процесс. Данные по-прежнему будут на диске, но они не будут автоматически монтироваться, пока вы не добавите конфигурацию в этот файл.\nПосле того, как вы отредактировали файл конфигурации fstab, вы можете проверить свою работу с помощью sudo mount -a, если ошибок нет, тогда ваши изменения теперь будут сохраняться при перезапусках.\nМы расскажем, как вы будете редактировать файл с помощью текстового редактора в будущем сеансе.\nРесурсы Структура файловой системы Linux Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Управление системой, файловой системой и хранилищем в Linux","title":"16. Управление системой, файловой системой и хранилищем в Linux","uri":"/ru/docs/90daysofdevops/day16/"},{"content":"Python предоставляет пару действительно хороших модулей, с помощью которых мы можем создавать электронные письма. Это модули email и smtplib. Вместо того чтобы рассматривать различные методы этих двух модулей, мы потратим некоторое время на изучение того, как на самом деле использовать эти модули. В частности, мы рассмотрим следующее:\nОсновы работы с почтой Как выполнять рассылку несколько адресов одновременно Как отправлять письма, используя строки TO, CC и BCC Как создавать содержимое и тело письма при помощи модуля email Давайте начнем!\nОсновы работы с электронной почтой - Как отправить письмо с помощью smtplib Модуль smtplib очень интуитивно понятен в использовании. Давайте напишем небольшой пример, показывающий, как отправить письмо. Сохраните следующий код в файл на жестком диске:\nimport smtplib HOST = \"mySMTP.server.com\" SUBJECT = \"Test email from Python\" TO = \"mike@someAddress.org\" FROM = \"python@mydomain.com\" text = \"Python 3.4 rules them all!\" BODY = \"\\r\\n\".join(( \"From: %s\" % FROM, \"To: %s\" % TO, \"Subject: %s\" % SUBJECT , \"\", text )) server = smtplib.SMTP(HOST) server.sendmail(FROM, [TO], BODY) server.quit() Мы импортировали два модуля, smtplib и модуль string. Две трети этого кода используется для настройки электронной почты. Большинство переменных не требуют пояснений, поэтому мы сосредоточимся только на переменной BODY. Здесь мы используем модуль string для объединения всех предыдущих переменных в одну строку, где каждая строка заканчивается (\"/r\"), а новая начинается с (\"/n\").После вывода BODY вы получите следующую картину:\n'From: python@mydomain.com\\r\\nTo: mike@mydomain.com\\r\\nSubject: Test email from Python\\r\\n\\r\\nblah blah blah' После этого мы устанавливаем соединение сервера с нашим хостом, а затем вызываем метод sendmail модуля smtplib для отправки письма. Затем мы отсоединяемся от сервера. Вы заметите, что в этом коде нет имени пользователя или пароля. Если ваш сервер требует аутентификации, то вам нужно будет добавить следующий код:\nserver.login(username, password) Эта часть должна быть добавлена сразу после создания объекта сервер. Как правило, вам, скорее всего, захочется добавить этот код в функцию и вызвать его с теми или иными параметрами. Или же вам может потребоваться использовать часть этой информации в файл config. Попробуем добавить этот код в функцию.\nimport smtplib def send_email(host, subject, to_addr, from_addr, body_text): \"\"\" Send an email \"\"\" BODY = \"\\r\\n\".join(( \"From: %s\" % from_addr, \"To: %s\" % to_addr, \"Subject: %s\" % subject , \"\", body_text )) server = smtplib.SMTP(host) server.sendmail(from_addr, [to_addr], BODY) server.quit() if __name__ == \"__main__\": host = \"mySMTP.server.com\" subject = \"Test email from Python\" to_addr = \"mike@someAddress.org\" from_addr = \"python@mydomain.com\" body_text = \"Python rules them all!\" send_email(host, subject, to_addr, from_addr, body_text) Теперь вы можете увидеть, насколько мал фактический код, просто взглянув на саму функцию. Это 13 строк! И мы могли бы сделать его короче, если бы не помещали каждый элемент в BODY на отдельной строке, но это было бы не так читабельно.Сейчас мы создадим файл config, чтобы сберечь информацию сервера и адреса from. Зачем? В работе, которой я занимаюсь, мы можем использовать разные почтовые серверы для отправки электронной почты, или если почтовый сервер будет обновлен и его имя изменится, то нам нужно будет изменить только файл config, а не код. То же самое может произойти и с адресом from, если наша компания будет куплена и объединена с другой.\nДавайте посмотрим на файл конфигурации (сохраните его как email.ini):\n[smtp] server = some.server.com from_addr = python@mydomain.com Это очень простой файл config. В нем у нас есть секция с надписью smtp, в которой у нас есть два элемента: server и from_addr. Мы будем использовать configObj для чтения этого файла и превращения его в словарь Python. Вот обновленная версия кода (сохраните ее как smtp_config.py):\nimport os import smtplib import sys from configparser import ConfigParser def send_email(subject, to_addr, body_text): \"\"\" Send an email \"\"\" base_path = os.path.dirname(os.path.abspath(__file__)) config_path = os.path.join(base_path, \"email.ini\") if os.path.exists(config_path): cfg = ConfigParser() cfg.read(config_path) else: print(\"Config not found! Exiting!\") sys.exit(1) host = cfg.get(\"smtp\", \"server\") from_addr = cfg.get(\"smtp\", \"from_addr\") BODY = \"\\r\\n\".join(( \"From: %s\" % from_addr, \"To: %s\" % to_addr, \"Subject: %s\" % subject , \"\", body_text )) server = smtplib.SMTP(host) server.sendmail(from_addr, [to_addr], BODY) server.quit() if __name__ == \"__main__\": subject = \"Test email from Python\" to_addr = \"mike@someAddress.org\" body_text = \"Python rules them all!\" send_email(subject, to_addr, body_text) Мы добавили небольшую проверку в этот код. Сначала мы хотим получить путь, по которому находится сам скрипт, который представляет собой base_path. Затем мы объединяем этот путь с именем файла, чтобы получить полный путь к файлу конфигурации. Затем мы проверяем существование этого файла. Если он есть, мы создаем ConfigParser, а если его нет, то выводим сообщение и выходим из сценария. На всякий случай следует добавить обработчик исключений вокруг вызова ConfigParser.read(), поскольку файл может существовать, но быть поврежденным или у нас может не быть разрешения на его открытие, что вызовет исключение. Это будет небольшой проект, который вы можете выполнить самостоятельно. В любом случае, предположим, что все идет хорошо и объект ConfigParser успешно создан. Теперь мы можем извлечь информацию о хосте и from_addr, используя обычный синтаксис ConfigParser.\nТеперь мы готовы узнать, как отправлять несколько писем одновременно!\nОтправка нескольких писем одновременно Давайте немного изменим наш последний пример и отправим несколько писем!\nimport os import smtplib import sys from configparser import ConfigParser def send_email(subject, body_text, emails): \"\"\" Send an email \"\"\" base_path = os.path.dirname(os.path.abspath(__file__)) config_path = os.path.join(base_path, \"email.ini\") if os.path.exists(config_path): cfg = ConfigParser() cfg.read(config_path) else: print(\"Config not found! Exiting!\") sys.exit(1) host = cfg.get(\"smtp\", \"server\") from_addr = cfg.get(\"smtp\", \"from_addr\") BODY = \"\\r\\n\".join(( \"From: %s\" % from_addr, \"To: %s\" % ', '.join(emails), \"Subject: %s\" % subject , \"\", body_text )) server = smtplib.SMTP(host) server.sendmail(from_addr, emails, BODY) server.quit() if __name__ == \"__main__\": emails = [\"mike@someAddress.org\", \"someone@gmail.com\"] subject = \"Test email from Python\" body_text = \"Python rules them all!\" send_email(subject, body_text, emails) Вы заметите, что в этом примере мы удалили параметр to_addr и добавили параметр emails, который представляет собой список адресов электронной почты. Чтобы это работало, нам нужно создать строку, разделенную запятыми, в части To: в BODY, а также передать список адресов электронной почты методу sendmail. Таким образом, для создания простой строки, разделенной запятыми, мы делаем следующее: ‘, ‘.join(emails). Просто, да?\nОтправка электронной почты с использованием строк TO, CC и BCC Теперь нам осталось выяснить, как отправить письмо, используя поля CC и BCC. Давайте создадим новую версию этого кода, которая будет поддерживать эту функциональность!\nimport os import smtplib import sys from configparser import ConfigParser def send_email(subject, body_text, to_emails, cc_emails, bcc_emails): \"\"\" Send an email \"\"\" base_path = os.path.dirname(os.path.abspath(__file__)) config_path = os.path.join(base_path, \"email.ini\") if os.path.exists(config_path): cfg = ConfigParser() cfg.read(config_path) else: print(\"Config not found! Exiting!\") sys.exit(1) host = cfg.get(\"smtp\", \"server\") from_addr = cfg.get(\"smtp\", \"from_addr\") BODY = \"\\r\\n\".join(( \"From: %s\" % from_addr, \"To: %s\" % ', '.join(to_emails), \"CC: %s\" % ', '.join(cc_emails), \"BCC: %s\" % ', '.join(bcc_emails), \"Subject: %s\" % subject , \"\", body_text )) emails = to_emails + cc_emails + bcc_emails server = smtplib.SMTP(host) server.sendmail(from_addr, emails, BODY) server.quit() if __name__ == \"__main__\": emails = [\"mike@somewhere.org\"] cc_emails = [\"someone@gmail.com\"] bcc_emails = [\"schmuck@newtel.net\"] subject = \"Test email from Python\" body_text = \"Python rules them all!\" send_email(subject, body_text, emails, cc_emails, bcc_emails) В этом коде мы передаем 3 списка, каждый из которых содержит по одному адресу электронной почты. Мы создаем поля CC и BCC точно так же, как и раньше, но нам также нужно объединить три списка в один, чтобы мы могли передать объединенный список в метод sendmail(). На форумах вроде StackOverflow обсуждалось, что некоторые почтовые клиенты могут обрабатывать поле BCC странным образом, что позволяет получателю видеть список BCC в заголовках письма. Я не могу подтвердить такое поведение, но знаю, что Gmail успешно удаляет информацию BCC из заголовка письма.\nТеперь мы готовы перейти к использованию модуля электронной почты Python!\nДобавление вложения/тела письма с помощью модуля email Теперь мы возьмем все то, чему мы научились в предыдущих разделах и смешаем их вместе с модулем email, чтобы отправлять письма с прикрепленными файлами. Модуль email позволяет прикреплять вложения к письму очень просто. Вот код\nimport os import smtplib import sys from configparser import ConfigParser from email import encoders from email.mime.text import MIMEText from email.mime.base import MIMEBase from email.mime.multipart import MIMEMultipart from email.utils import formatdate #---------------------------------------------------------------------- def send_email_with_attachment(subject, body_text, to_emails, cc_emails, bcc_emails, file_to_attach): \"\"\" Send an email with an attachment \"\"\" base_path = os.path.dirname(os.path.abspath(__file__)) config_path = os.path.join(base_path, \"email.ini\") header = 'Content-Disposition', 'attachment; filename=\"%s\"' % file_to_attach # get the config if os.path.exists(config_path): cfg = ConfigParser() cfg.read(config_path) else: print(\"Config not found! Exiting!\") sys.exit(1) # extract server and from_addr from config host = cfg.get(\"smtp\", \"server\") from_addr = cfg.get(\"smtp\", \"from_addr\") # create the message msg = MIMEMultipart() msg[\"From\"] = from_addr msg[\"Subject\"] = subject msg[\"Date\"] = formatdate(localtime=True) if body_text: msg.attach( MIMEText(body_text) ) msg[\"To\"] = ', '.join(to_emails) msg[\"cc\"] = ', '.join(cc_emails) attachment = MIMEBase('application', \"octet-stream\") try: with open(file_to_attach, \"rb\") as fh: data = fh.read() attachment.set_payload( data ) encoders.encode_base64(attachment) attachment.add_header(*header) msg.attach(attachment) except IOError: msg = \"Error opening attachment file %s\" % file_to_attach print(msg) sys.exit(1) emails = to_emails + cc_emails server = smtplib.SMTP(host) server.sendmail(from_addr, emails, msg.as_string()) server.quit() if __name__ == \"__main__\": emails = [\"mike@someAddress.org\", \"nedry@jp.net\"] cc_emails = [\"someone@gmail.com\"] bcc_emails = [\"anonymous@circe.org\"] subject = \"Test email with attachment from Python\" body_text = \"This email contains an attachment!\" path = \"/path/to/some/file\" send_email_with_attachment(subject, body_text, emails, cc_emails, bcc_emails, path) Здесь мы переименовали нашу функцию и добавили новый аргумент, file_to_attach. Нам также нужно добавить заголовок и создать объект MIMEMultipart. Заголовок может быть создан в любое время перед тем, как мы добавим вложение. Мы добавляем элементы в объект MIMEMultipart (msg), как ключи в словарь. Обратите внимание, что для вставки правильно отформатированной даты мы должны использовать метод formatdate модуля email. Чтобы добавить тело сообщения, нам нужно создать экземпляр MIMEText. Если вы внимательны, вы увидите, что мы не добавили информацию BCC, но вы можете легко сделать это, следуя условиям написанного выше кода. Далее мы добавляем вложение. Мы обернем его в обработчик исключений и используем оператор with, чтобы извлечь файл и поместить его в наш объект MIMEBase. Наконец, мы добавляем его в переменную msg и отправляем его. Обратите внимание, что в методе sendmail мы должны преобразовать msg в строку.\nПодведение итогов Теперь вы знаете, как отправлять электронные письма с помощью Python. Тем, кто любит мини-проекты, стоит вернуться назад и добавить дополнительную обработку ошибок в части кода server.sendmail на случай, если во время процесса произойдет что-то странное, например, SMTPAuthenticationError или SMTPConnectError. Мы можем также увеличить обработку ошибок во время прикрепления файла к телу письма, чтобы уловить другие ошибки. Наконец, мы можем взять списки различных писем, чтобы создать один нормальный, в котором отсутствуют дубликаты адресов. Это очень важно, если мы читаем список электронных адресов из файла.\nТакже обратите внимание, что наш адрес from является поддельным. Мы можем подделывать письма при помощи Python и других языков программирование, однако это крайне неэтично, а в некоторых странах еще и нелегально. Вы были предупреждены! Используйте свои знания с умом и пользуйтесь Python для удовольствия и прибыли!\n","description":"Python 101","title":"17. Модуль email / smtplib","uri":"/ru/docs/python101/chapter17_smtplib/"},{"content":"Текстовые редакторы nano и vim Большинство систем Linux - сервера, и у них не будет графического интерфейса. Я также упомянул в прошлой статье, что Linux в основном состоит из файлов конфигурации, и для внесения изменений вам потребуется иметь возможность редактировать эти файлы конфигурации, чтобы изменить что-либо в системе.\nСуществует множество вариантов, но я думаю, что мы должны рассмотреть, вероятно, два наиболее распространенных текстовых редактора терминала. Я использовал оба этих редактора, и для меня «nano» — это удобная кнопка, когда дело доходит до быстрых изменений, но у «vim» такой широкий набор возможностей.\nnano Доступна не во всех системах. Отлично для начала. Если вы запустите nano 90DaysOfDevOps.txt, мы создадим новый файл, в котором ничего не будет, здесь мы можем добавить наш текст, и в окне внизу есть инструкции о том, что мы хотим сделать с этим файлом.\nМы можем нажать control x + enter, а затем запустить ls, теперь вы можете увидеть наш новый текстовый файл.\nМожно запустить cat для этого файла, чтобы прочитать наш файл. Затем мы можем использовать тот же nano 90DaysOfDevOps.txt, чтобы добавить дополнительный текст или изменить ваш файл.\nДля меня nano очень удобен, когда дело доходит до внесения небольших изменений в файлы конфигурации.\nvim Возможно, самый распространенный текстовый редактор.\nВ значительной степени поддерживается в каждом дистрибутиве Linux. Невероятно мощный! Скорее всего, вы найдете полный 7-часовой курс, посвященный только vim. Мы можем перейти в vim с помощью команды vim или, если мы хотим отредактировать наш новый текстовый файл, мы могли бы запустить vim 90DaysOfDevOps.txt, но сначала вы увидите отсутствие меню справки внизу.\nПервый вопрос может быть «Как мне выйти из vim?» это будет escape, и если мы не внесли никаких изменений, то это будет :q\nВы начинаете в обычном «normal» режиме, есть и другие режимы «command, normal, visual, insert», если мы хотим добавить текст, нам нужно будет переключиться с «normal» на «insert», нам нужно нажать «i», если вы добавили какой-то текст и хотели бы сохранить эти изменения, тогда вы нажмете escape, а затем :wq\nВы можете подтвердить это с помощью команды cat, чтобы убедиться, что вы сохранили эти изменения.\nВ vim есть несколько крутых быстрых функций, которые позволяют очень быстро выполнять простые задачи, если вы знаете ярлыки, что само по себе является лекцией. Допустим, мы добавили список повторяющихся слов, и теперь нам нужно его изменить, может быть, это файл конфигурации, и мы повторяем сетевое имя, и теперь это изменилось, и мы хотим быстро изменить это. Я использую слово “Day” в этом примере.\nТеперь мы хотим заменить это слово на 90DaysOfDevOps, мы можем сделать это, нажав «esc» и набрав «:%s/Day/90DaysOfDevOps». В результате, когда вы нажимаете Enter, слово day заменяется на 90DaysOfDevOps.\nКопировать и вставить стало для меня большим открытием. Копия не копия, а дерьмо. мы можем скопировать, используя yy на клавиатуре в обычном режиме. p вставьте в ту же строку, P вставьте в новую строку.\nВы также можете удалить эти строки, выбрав количество строк, которые вы хотите удалить, а затем dd\nТакже, вероятно, вам понадобится время для поиска файла, теперь мы можем использовать grep, как упоминалось в предыдущем сеансе, но мы также можем использовать vim. мы можем использовать /word, и это найдет первое совпадение, для перехода к следующему вы будете использовать клавишу n и так далее.\nДля vim это даже не касается поверхности, самый большой совет, который я могу дать, — взяться за руки и использовать vim везде, где это возможно.\nОбычный вопрос на собеседовании: какой ваш любимый текстовый редактор в Linux, и я хотел бы убедиться, что у вас есть хотя бы эти знания об обоих, чтобы вы могли ответить: «Нано» — это нормально, потому что это просто. По крайней мере, вы показываете компетентность в понимании того, что такое текстовый редактор. Но потренируйтесь с ними, чтобы стать более опытным.\nЕще один указатель для навигации в vim, мы можем использовать «H, J, K, L», а также наши клавиши со стрелками.\nРесурсы Vim Cheat Sheet Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Текстовые редакторы nano и vim","title":"17. Текстовые редакторы Nano/Vim","uri":"/ru/docs/90daysofdevops/day17/"},{"content":"SSH Как мы уже упоминали, вы, скорее всего, будете управлять множеством удаленных серверов Linux, поэтому вам необходимо убедиться, что ваше подключение к этим удаленным серверам безопасно. В этом разделе мы хотим рассказать о некоторых основах SSH (Secure Shell), которые должен знать каждый, и которые помогут вам с этим безопасным туннелем к вашим удаленным системам.\nНастройка соединения по SSH Передача файлов Создайте свой закрытый ключ Введение в SSH Безопасная оболочка (Secure Shell) Сетевой протокол (Networking Protocol) Обеспечивает безопасную связь Может защитить любой сетевой сервис Обычно используется для удаленного доступа из командной строки В нашей среде, если вы следили за нами, мы уже использовали SSH, но все это было настроено и автоматизировано с помощью нашей конфигурации vagrant, поэтому нам нужно было только запустить vagrant ssh, и мы получили доступ к нашей удаленной виртуальной машине.\nЕсли бы наша удаленная машина не находилась в той же системе, что и наша рабочая станция, и находилась бы в удаленном месте, возможно, в облачной системе или в центре обработки данных, к которому мы могли бы получить доступ только через Интернет, нам потребовался бы безопасный способ, чтобы получить доступ к системе для управления ею.\nSSH обеспечивает безопасный туннель между клиентом и сервером, поэтому злоумышленники ничего не могут перехватить.\nНа сервере есть служба SSH на стороне сервера, которая всегда работает и прослушивает определенный TCP-порт (22).\nЕсли мы используем наш клиент для подключения с правильными учетными данными или ключом SSH, мы получаем доступ к этому серверу.\nДобавление bridged network adapter в нашу систему Чтобы мы могли использовать SSH с нашей виртуальной машиной, нам нужно добавить сетевой адаптер на нашу машину.\nВыключите виртуальную машину, щелкните ее правой кнопкой мыши в Virtual Box и выберите настройки. В новом окне выберите сеть.\nТеперь снова включите вашу машину, и теперь у вас будет IP-адрес на вашей локальной машине. Вы можете подтвердить это с помощью команды ip addr.\nПроверка работы SSH-сервера Мы знаем, что SSH уже настроен на нашей машине, поскольку мы использовали его с vagrant, но мы можем удостовериться, что сервер бежит, запустив\nsudo systemctl status ssh\nЕсли в вашей системе нет SSH-сервера, вы можете установить его, введя эту команду sudo apt install openssh-server\nЗатем вы хотите убедиться, что наш SSH разрешен и брандмауэр работает. Мы можем сделать это с помощью sudo ufw allow ssh. Это не требуется в нашей конфигурации, поскольку мы автоматизировали это с помощью нашего vagrant.\nУдаленный доступ — пароль SSH Теперь, когда наш SSH-сервер прослушивает порт 22 для любых входящих запросов на подключение, и мы добавили “мост” (bridged networking), мы можем использовать putty или SSH-клиент на нашей локальной машине для подключения к нашей системе с помощью SSH.\nЗатем нажмите «Открыть», если вы впервые подключаетесь к этой системе через этот IP-адрес, вы получите это предупреждение. Мы знаем, что это наша система, поэтому вы можете выбрать «yes».\nЗатем нам будет предложено ввести имя пользователя (vagrant) и пароль (пароль по умолчанию — vagrant). Ниже вы увидите, что теперь мы используем наш SSH-клиент (Putty) для подключения к нашей машине с использованием имени пользователя и пароля.\nНа этом этапе мы подключаемся к нашей виртуальной машине с нашего удаленного клиента и можем выполнять наши команды в нашей системе.\nУдаленный доступ — ключ SSH Вышеупомянутый простой способ получить доступ к вашим системам, однако, по-прежнему зависит от имени пользователя и пароля, и если какой-либо злоумышленник получит доступ к этой информации, а также к общедоступному адресу или IP-адресу вашей системы, это может быть легко скомпрометировано. Здесь предпочтительны SSH-ключи.\nКлючи SSH означают, что мы предоставляем пару ключей, чтобы и клиент, и сервер знали, что это доверенное устройство.\nСоздать ключ несложно. На нашем локальном компьютере (Windows) мы можем выполнить следующую команду: если у вас установлен ssh-клиент в любой системе, я полагаю, что эта же команда будет работать?\nssh-keygen -t ed25519\nЯ не буду вдаваться в подробности того, что такое ed25519 и что означает здесь, но вы можете воспользоваться поиском, если хотите узнать больше о криптографии\nНа данный момент у нас есть созданный ключ SSH, хранящийся в C:\\Users\\micha/.ssh/\nНо чтобы связать это с нашей виртуальной машиной Linux, нам нужно скопировать ключ. Мы можем сделать это, используя ssh-copy-id vagrant@192.168.169.135.\nЯ использовал PowerShell для создания своих ключей на моем клиенте Windows, но здесь нет доступного ssh-copy-id. Есть способы, которыми вы можете сделать это в Windows, и небольшой поиск в Интернете найдет вам альтернативу, но я просто использую git bash на своем компьютере с Windows, чтобы сделать копию.\nТеперь мы можем вернуться к Powershell, чтобы проверить, что наше соединение теперь работает с нашими ключами SSH, и пароль не требуется.\nssh vagrant@192.168.169.135\nПри необходимости мы могли бы защититься, используя кодовую фразу. Мы также могли бы сделать еще один шаг, заявив, что пароли вообще не нужны, что означает, что будут разрешены только пары ключей через SSH. Вы можете сделать это в следующем файле конфигурации.\nsudo nano /etc/ssh/sshd_config\nздесь есть строка с PasswordAuthentication yes, она будет закомментирована #, вы должны раскомментировать и изменить yes на no. Затем вам нужно будет перезагрузить службу SSH с помощью «sudo systemctl reload sshd».\nНастройка веб-сервера Не имеет прямого отношения к тому, что мы только что сделали с SSH выше, но я хотел рассмотрть, поскольку это снова еще одна задача, которая может показаться вам немного сложной, но на самом деле этого не должно быть.\nУ нас есть виртуальная машина с Linux, и на данном этапе мы хотим добавить веб-сервер apache к нашей виртуальной машине, чтобы мы могли разместить на нем простой веб-сайт, который обслуживает мою домашнюю сеть. Обратите внимание, что эта веб-страница не будет доступна из Интернета, это можно сделать, но здесь это не рассматривается.\nВы также можете увидеть, что это называется стеком LAMP.\nLinux Operating System Apache Web Server mySQL database PHP Apache2 Apache2 — это HTTP-сервер с открытым исходным кодом. Мы можем установить apache2 с помощью следующей команды.\nsudo apt-get install apache2\nЧтобы убедиться, что apache2 установлен правильно, мы можем запустить sudo service apache2 restart.\nЗатем, используя сетевой адрес моста из пошагового руководства по SSH, откройте браузер и перейдите по этому адресу. Мой http://192.168.169.135/\nmySQL MySQL — это база данных, в которой мы будем хранить данные для нашего простого веб-сайта. Чтобы установить MySQL, мы должны использовать следующую команду sudo apt-get install mysql-server\nPHP PHP — это серверный язык (server-side scripting language), мы будем использовать его для взаимодействия с базой данных MySQL. Окончательная установка заключается в установке PHP и зависимостей с помощью sudo apt-get install php libapache2-mod-php php-mysql.\nПервое изменение конфигурации, которое мы хотим внести в apache из коробки, — это использование index.html, и вместо этого мы хотим использовать index.php.\nМы будем использовать sudo nano /etc/apache2/mods-enabled/dir.conf и переместим index.php в первый элемент списка.\nПерезапустите службу apache2 sudo systemctl restart apache2\nТеперь давайте подтвердим, что наша система правильно настроена для PHP. Создайте следующий файл с помощью этой команды, это откроет пустой файл в nano.\nsudo nano /var/www/html/90Days.php\nзатем скопируйте следующее и используйте Ctrl + x, чтобы выйти и сохранить файл.\n\u003c?php phpinfo(); ?\u003e Теперь снова перейдите к IP-адресу виртуальной машины Linux с дополнительным 90Days.php в конце URL-адреса. http://192.168.169.135/90Days.php вы должны увидеть что-то похожее на показанное ниже, если PHP настроен правильно.\nУстановка WordPress Я просмотрел тьюториал, чтобы установить WordPress в наш стек LAMP, некоторые команды показаны ниже, если они не показаны правильно в пошаговом руководстве [How to install wordpress on Ubuntu with LAMP](https://blog.ssdnodes.com/blog/ как установить-wordpress-на-ubuntu-18-04-с-лампой-учебник/)\nsudo mysql -u root -p\nCREATE DATABASE wordpressdb;\nCREATE USER 'admin-user'@'localhost' IDENTIFIED BY 'password';\nGRANT ALL PRIVILEGES ON wordpressdb.* TO 'admin-user'@'localhost';\nFLUSH PRIVILEGES;\nEXIT;\nsudo apt install php-curl php-gd php-mbstring php-xml php-xmlrpc php-soap php-intl php-zip\nsudo systemctl restart apache2\ncd /var/www\nsudo curl -O https://wordpress.org/latest.tar.gz\nsudo tar -xvf latest.tar.gz\nsudo rm latest.tar.gz\nНа данный момент вы находитесь на шаге 4 в связанной статье, вам нужно будет выполнить шаги, чтобы убедиться, что для каталога WordPress установлены все правильные разрешения.\nПоскольку это только внутреннее действие, вам не нужно «генерировать ключи безопасности» на этом шаге. Перейдите к шагу 5, который меняет конфигурацию Apache на WordPress.\nЗатем, если все настроено правильно, вы сможете получить доступ через свой внутренний сетевой адрес и запустить установку WordPress.\nРесурсы Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Web Сервер и SSH","title":"18. Web Сервер и SSH","uri":"/ru/docs/90daysofdevops/day18/"},{"content":"SQLite - это самодостаточный, безсерверный, безконфигурационный транзакционный движок базы данных SQL. Python получил модуль sqlite3 еще в версии 2.5, что означает, что вы можете создавать базы данных SQLite с любым текущим Python без загрузки дополнительных зависимостей. Mozilla использует базы данных SQLite в своем популярном браузере Firefox для хранения закладок и другой различной информации. В этой главе вы узнаете следующее:\n- Как создать базу данных SQLite - Как вставить данные в таблицу - Как редактировать данные - Как удалить данные - Основные SQL-запросы Другими словами, вместо того, чтобы рассказывать о модуле sqlite3 по кусочкам, мы рассмотрим, как его реально использовать.\nЕсли вы хотите осмотреть свою базу данных визуально, вы можете использовать плагин SQLite Manager для Firefox (просто найдите его в Google) или, если вам нравится командная строка, вы можете использовать оболочку командной строки SQLite.\nКак создать базу данных и вставить некоторые данные Создать базу данных в SQLite очень просто, но для этого нужно знать немного SQL. Вот код, который создаст базу данных для хранения музыкальных альбомов:\nimport sqlite3 conn = sqlite3.connect(\"mydatabase.db\") # or use :memory: to put it in RAM cursor = conn.cursor() # create a table cursor.execute(\"\"\"CREATE TABLE albums (title text, artist text, release_date text, publisher text, media_type text) \"\"\") Сначала мы должны импортировать модуль sqlite3 и создать соединение с базой данных. Вы можете передать ему путь к файлу, имя файла или просто использовать специальную строку “:memory:” для создания базы данных в памяти. В нашем случае мы создали ее на диске в файле под названием mydatabase.db. Далее мы создаем объект курсора, который позволяет взаимодействовать с базой данных и добавлять записи, среди прочего. Здесь мы используем синтаксис SQL для создания таблицы с именем albums с 5 текстовыми полями: title, artist, release_date, publisher и media_type. SQLite поддерживает только пять типов данных: null, integer, real, text и blob. Давайте построим этот код и вставим некоторые данные в нашу новую таблицу!\nПримечание: Если вы выполните команду CREATE TABLE, а база данных уже существует, вы получите сообщение об ошибке.\n# insert some data cursor.execute(\"\"\"INSERT INTO albums VALUES ('Glow', 'Andy Hunter', '7/24/2012', 'Xplore Records', 'MP3')\"\"\" ) # save data to database conn.commit() # insert multiple records using the more secure \"?\" method albums = [('Exodus', 'Andy Hunter', '7/9/2002', 'Sparrow Records', 'CD'), ('Until We Have Faces', 'Red', '2/1/2011', 'Essential Records', 'CD'), ('The End is Where We Begin', 'Thousand Foot Krutch', '4/17/2012', 'TFKmusic', 'CD'), ('The Good Life', 'Trip Lee', '4/10/2012', 'Reach Records', 'CD')] cursor.executemany(\"INSERT INTO albums VALUES (?,?,?,?,?)\", albums) conn.commit() Здесь мы используем команду INSERT INTO SQL для вставки записи в нашу базу данных. Обратите внимание, что каждый элемент должен быть заключен в одинарные кавычки. Это может усложниться, если вам нужно вставить строки, содержащие одинарные кавычки. В любом случае, чтобы сохранить запись в базе данных, мы должны создать ее. Следующий фрагмент кода показывает, как добавить сразу несколько записей с помощью метода executemany курсора. Обратите внимание, что мы используем вопросительные знаки (?) вместо подстановки строк (%s) для вставки значений. Обратите внимание, что использование строки замещения НЕ безопасно, так как может стать причиной появления атаки инъекций SQL . Метод вопросительных знаков намного лучше, а использование SQLAlchemy еще лучше, потому что он делает все экранирование за вас, и вам не придется возиться с преобразованием встроенных одинарных кавычек в то, что примет SQLite.\nОбновление и удаление записей Возможность обновления записей в базе данных является ключевым условием сохранения точности данных. Если вы не можете обновлять записи, то ваши данные быстро устареют и станут бесполезными. Иногда вам также необходимо удалять строки из данных. В этом разделе мы рассмотрим обе эти темы. Для начала, давайте выполним обновление!\nimport sqlite3 conn = sqlite3.connect(\"mydatabase.db\") cursor = conn.cursor() sql = \"\"\" UPDATE albums SET artist = 'John Doe' WHERE artist = 'Andy Hunter' \"\"\" cursor.execute(sql) conn.commit() Здесь мы используем команду SQL UPDATE для обновления таблицы альбомов. Вы можете использовать SET для изменения поля, поэтому в данном случае мы изменим поле artist на John Doe в любой записи WHERE, поле artist установлено на Andy Hunter. Разве это не просто? Обратите внимание, что если вы не зафиксируете изменения, то ваши изменения не будут записаны в базу данных. Команда DELETE почти так же проста. Давайте проверим это!\nimport sqlite3 conn = sqlite3.connect(\"mydatabase.db\") cursor = conn.cursor() sql = \"\"\" DELETE FROM albums WHERE artist = 'John Doe' \"\"\" cursor.execute(sql) conn.commit() Удаление даже проще, чем обновление. SQL состоит всего из 2 строк! В данном случае все, что нам нужно было сделать, это указать SQLite, из какой таблицы удалять (альбомы) и какие записи удалять с помощью предложения WHERE. Таким образом, он искал все записи, у которых в поле artist было указано “John Doe”, и удалял их.\nОсновные запросы в SQLite Запросы в SQLite практически не отличаются от тех, которые вы используете для других баз данных, таких как MySQL или Postgres. Вы просто используете обычный синтаксис SQL для выполнения запросов, а затем заставляете объект курсора выполнить SQL. Вот несколько примеров:\nimport sqlite3 conn = sqlite3.connect(\"mydatabase.db\") #conn.row_factory = sqlite3.Row cursor = conn.cursor() sql = \"SELECT * FROM albums WHERE artist=?\" cursor.execute(sql, [(\"Red\")]) print(cursor.fetchall()) # or use fetchone() print(\"\\nHere's a listing of all the records in the table:\\n\") for row in cursor.execute(\"SELECT rowid, * FROM albums ORDER BY artist\"): print(row) print(\"\\nResults from a LIKE query:\\n\") sql = \"\"\" SELECT * FROM albums WHERE title LIKE 'The%'\"\"\" cursor.execute(sql) print(cursor.fetchall()) Первый запрос, который мы выполняем, это SELECT *, что означает, что мы хотим выбрать все записи, которые соответствуют имени исполнителя, которое мы вводим, в данном случае это “Red”. Далее мы выполняем SQL и используем fetchall(), чтобы вернуть все результаты. Вы также можете использовать fetchone(), чтобы получить первый результат. Вы также заметите, что здесь есть закомментированная секция, связанная с таинственным row_factory. Если вы уберете эту строку из комментария, результаты будут возвращаться в виде объектов Row, которые подобны словарям Python и дают вам доступ к полям строки, как словарь. Однако вы не можете выполнять присваивание элементов с объектом Row.\nВторой запрос очень похож на первый, но он возвращает все записи в базе данных и упорядочивает результаты по имени исполнителя в порядке возрастания. Здесь также показано, как мы можем перебирать результаты в цикле. Последний запрос показывает, как использовать команду LIKE в SQL для поиска частичных фраз. В данном случае мы выполняем поиск по всей таблице названий, которые начинаются со слова “The”. Знак процента (%) является оператором подстановки.\nПодведение итогов Теперь вы знаете, как использовать Python для создания базы данных SQLite. Вы можете создавать, обновлять и удалять записи, а также выполнять запросы к базе данных.\n","description":"Python 101","title":"18. Модуль sqlite","uri":"/ru/docs/python101/chapter18_sqlite/"},{"content":"Автоматизация задачи с помощью bash-скриптов Оболочка, которую мы собираемся использовать сегодня, — это bash, но мы рассмотрим другую оболочку завтра, когда будем углубляться в ZSH.\nBASH - Bourne Again Shell («возрождённый» shell)\nМы могли бы почти посвятить целую секцию из 7 дней написанию сценариев оболочки, как и языкам программирования. Bash дает нам возможность работать вместе с другими инструментами автоматизации для достижения цели.\nЯ до сих пор разговариваю со многими людьми, которые настроили несколько сложных сценариев оболочки, чтобы что-то произошло, и они полагаются на этот сценарий для некоторых из наиболее важных вещей в бизнесе, я не говорю, что нам нужно понимать сценарии оболочки/bash. для этой цели это не путь. Но мы должны изучить сценарии оболочки/bash, чтобы работать вместе с нашими инструментами автоматизации и для специальных задач.\nОдним из примеров, который мы использовали, может быть VAGRANTFILE, который мы использовали для создания нашей виртуальной машины, мы могли бы обернуть его в простой сценарий bash, который удалял и обновлял его каждый понедельник утром, чтобы у нас была свежая копия нашей виртуальной машины Linux. каждую неделю мы могли бы также добавлять весь программный стек, который нам нужен, на указанную машину с Linux и так далее с помощью одного сценария bash.\nЯ думаю, что еще одна вещь, которую я, по крайней мере, слышу, это то, что практические вопросы по скриптам становятся все более и более очевидными во всех интервью.\nНачало Как и в случае со многим, что мы рассмотрим за все эти 90 дней, единственный реальный способ научиться — это делать. Практический опыт поможет впитать все это в вашу мышечную память.\nПрежде всего, нам понадобится текстовый редактор. В День 17 мы рассказали, наверное, о двух самых распространенных текстовых редакторах и немного о том, как их использовать.\nДавайте приступим прямо к делу и создадим наш первый сценарий оболочки.\ntouch 90DaysOfDevOps.sh - создает файл 90DaysOfDevOps.sh\nЗа ним следует nano 90DaysOfDevOps.sh, это откроет наш новый пустой сценарий оболочки в nano. Опять же, вы можете выбрать другой текстовый редактор.\nПервая строка всех скриптов bash должна выглядеть примерно так: #!/usr/bin/bash, это путь к вашему двоичному файлу bash.\nОднако вы должны проверить это в терминале, запустив which bash, если вы не используете Ubuntu, вы также можете попробовать whereis bash из терминала.\nОднако вы можете увидеть другие пути, перечисленные в уже созданных сценариях оболочки, которые могут включать:\n#!/bin/bash #!/usr/bin/env bash В следующей строке нашего скрипта я хотел бы добавить комментарий и добавить цель скрипта или хотя бы какую-то информацию обо мне. Вы можете сделать это, используя #. Это позволяет нам комментировать определенные строки в нашем коде и предоставлять описания того, что будут делать следующие команды. Я считаю, что чем больше заметок, тем лучше для пользователя, особенно если вы делитесь этим.\nИногда я использую figlet, программу, которую мы установили ранее в разделе Linux, для создания аски-арта, чтобы начать что-то в наших скриптах.\nВсе команды, которые мы использовали ранее в этом разделе Linux (День 15) можно использовать здесь как простую команду для тестирования нашего скрипта.\nДавайте добавим в наш скрипт простой блок кода.\nmkdir 90DaysOfDevOps cd 90DaysOfDevOps touch Day19 ls Затем вы можете сохранить это и выйти из текстового редактора. Если мы запустим наш скрипт с ./90DaysOfDevOps.sh, вы должны получить сообщение об отказе в разрешении. Вы можете проверить права доступа к этому файлу с помощью команды ls -la, и вы увидите, что у нас нет прав на выполнение этого файла.\nМы можем изменить это, используя chmod +x 90DaysOfDevOps.sh, и тогда вы увидите x, означающий, что теперь мы можем запустить (execute) наш скрипт.\nТеперь мы можем снова запустить наш скрипт, используя ./90DaysOfDevOps.sh после того, как запуск скрипта создал новый каталог, перешел в этот каталог, а затем создал новый файл.\nДовольно простые вещи, но вы можете начать понимать, как это можно использовать для вызова других инструментов, как часть способов сделать вашу жизнь проще и автоматизировать вещи.\nПеременные, условные операторы Большая часть этого раздела на самом деле является повторением того, что мы рассмотрели, когда изучали Golang, но я думаю, что нам стоит углубиться в это снова.\nПеременные Переменные позволяют нам один раз определить конкретный повторяющийся термин, который используется в потенциально сложном сценарии.\nЧтобы добавить переменную, вы просто добавляете ее вот так на чистую строку в вашем скрипте.\nchallenge=\"90DaysOfDevOps\"\nТаким образом, когда и где мы используем $challenge в нашем коде, если мы изменим переменную, это будет отражено повсюду.\nЕсли мы сейчас запустим наш скрипт sh, вы увидите распечатку, которая была добавлена к нашему скрипту.\nМы также можем запросить пользовательский ввод, который может установить наши переменные, используя следующее:\necho \"Enter your name\" read name Затем это определило бы ввод как переменную $name. Затем мы могли бы использовать это позже.\nУсловные операторы Может быть, мы хотим узнать, кто участвует в нашем марафоне “90 дней” и сколько дней они прошли, мы можем определить это, используя условные выражения if if-else else-if, это то, что мы определили ниже в нашем скрипте. .\n#!/bin/bash # ___ ___ ____ ___ __ ____ ___ # / _ \\ / _ \\| _ \\ __ _ _ _ ___ / _ \\ / _| _ \\ _____ __/ _ \\ _ __ ___ #| (_) | | | | | | |/ _` | | | / __| | | | |_| | | |/ _ \\ \\ / / | | | '_ \\/ __| # \\__, | |_| | |_| | (_| | |_| \\__ \\ |_| | _| |_| | __/\\ V /| |_| | |_) \\__ \\ # /_/ \\___/|____/ \\__,_|\\__, |___/\\___/|_| |____/ \\___| \\_/ \\___/| .__/|___/ # |___/ |_| # # This script is to demonstrate bash scripting! # Variables to be defined ChallengeName=#90DaysOfDevOps TotalDays=90 # User Input echo \"Enter Your Name\" read name echo \"Welcome $name to $ChallengeName\" echo \"How Many Days of the $ChallengeName challenge have you completed?\" read DaysCompleted if [ $DaysCompleted -eq 90 ] then echo \"You have finished, well done\" elif [ $DaysCompleted -lt 90 ] then echo \"Keep going you are doing great\" else echo \"You have entered the wrong amount of days\" fi Вы также можете видеть из вышеприведенного, что мы проводим некоторые сравнения или сверяем значения друг с другом, чтобы перейти к следующему этапу. У нас есть разные варианты, которые стоит отметить.\neq - if the two values are equal will return TRUE ne - if the two values are not equal will return TRUE gt - if the first value is greater than the second value will return TRUE ge - if the first value is greater than or equal to the second value will return TRUE lt - if the first value is less than the second value will return TRUE le - if the first value is less than or equal to the second value will return TRUE Мы также можем использовать сценарии bash для получения информации о файлах и папках, это называется условиями файлов.\n-d file True if the file is a directory -e file True if the file exists -f file True if the provided string is a file g file True if the group id is set on a file -r file True if the file is readable -s file True if the file has a non-zero size FILE=\"90DaysOfDevOps.txt\" if [ -f \"$FILE\" ] then echo \"$FILE is a file\" else echo \"$FILE is not a file\" fi При условии, что этот файл все еще находится в нашем каталоге, мы должны вернуть первую команду echo. Но если мы удалим этот файл, мы должны получить вторую команду echo.\nНадеюсь, вы увидите, как это можно использовать для экономии времени при поиске в системе определенных элементов.\nЯ нашел этот удивительный репозиторий на GitHub, в котором, кажется, бесконечное количество скриптов DevOps Bash Tools\nПример Scenario: У нас есть наша компания под названием «90DaysOfDevOps», и мы работаем некоторое время, и теперь пришло время расширить команду с 1 человека до гораздо большего в ближайшие недели. Я пока единственный, кто знает процесс адаптации, поэтому мы хотим чтобы уменьшить это узкое место, автоматизировав некоторые из этих задач.\nRequirements:\nПользователь может быть передан в качестве аргумента командной строки. Пользователь создается с именем аргумента командной строки. Пароль может быть проанализирован как аргумент командной строки. Пароль установлен для пользователя Отображается сообщение об успешном создании учетной записи. Давайте начнем с создания нашего сценария оболочки с помощью touch create_user.sh.\nПрежде чем мы двинемся дальше, давайте также создадим этот исполняемый файл, используя chmod +x create_user.sh\nзатем мы можем использовать nano create_user.sh, чтобы начать редактирование нашего скрипта для сценария, который мы установили.\nМы можем взглянуть на первое требование «Пользователь может быть передан в качестве аргумента командной строки», мы можем использовать следующее\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1\" Идем далее и запускаем ./create_user.sh Michael, замените Michael своим именем при запуске скрипта. Далее мы можем выполнить второе требование: «Пользователь создается с именем аргумента командной строки», это можно сделать с помощью команды useradd. Опция -m предназначена для создания домашнего каталога пользователя как /home/username.\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1 user account being created.\" #A user is created with the name of command line argument sudo useradd -m \"$1\" Предупреждение: если вы не укажете имя учетной записи пользователя, произойдет ошибка, поскольку мы не заполнили переменную $1\nЗатем мы можем проверить, была ли создана эта учетная запись с помощью команды awk -F: '{print $1}' /etc/passwd.\nMore about awk linux command\nНаше следующее требование: «Пароль может быть проанализирован как аргумент командной строки». Во-первых, мы никогда не собираемся делать это в продакшене, нам нужно проработать список требований в лаборатории, чтобы понять.\n#! /usr/bin/bash #A user can be passed in as a command line argument echo \"$1 user account being created.\" #A user is created with the name of command line argument sudo useradd -m \"$1\" #A password can be parsed in as a command line argument. sudo chpasswd \u003c\u003c\u003c \"$1\":\"$2\" Если мы затем запустим этот скрипт с двумя параметрами ./create_user.sh пароль 90DaysOfDevOps\nНа изображении ниже вы можете видеть, что мы выполнили наш скрипт, он создал нашего пользователя и пароль, а затем мы вручную перешли к этому пользователю и подтвердили это с помощью команды whoami.\nПоследнее требование: «Отображается сообщение об успешном создании учетной записи». На самом деле у нас уже есть это в верхней строке нашего кода, и мы можем видеть на снимке экрана выше, что у нас есть «созданная учетная запись пользователя 90DaysOfDevOps». Это осталось от нашего тестирования с параметром $1.\nТеперь этот сценарий можно использовать для быстрого подключения и настройки новых пользователей в наших системах Linux. Но, может быть, вместо того, чтобы некоторым историческим людям приходилось работать с этим, а затем получать новые имена пользователей или пароли для других людей, мы могли бы добавить некоторый пользовательский ввод, который мы ранее рассмотрели ранее, для захвата наших переменных.\n#! /usr/bin/bash echo \"What is your intended username?\" read username echo \"What is your password\" read password #A user can be passed in as a command line argument echo \"$username user account being created.\" #A user is created with the name of command line argument sudo useradd -m $username #A password can be parsed in as a command line argument. sudo chpasswd \u003c\u003c\u003c $username:$password Шаги стали более интерактивными,\nПросто чтобы закончить это, возможно, мы хотим вывести успешный вывод, чтобы сказать, что наша новая учетная запись пользователя завершена.\nОдна вещь, которую я заметил, это то, что мы отображаем пароль на нашем входе, мы можем скрыть это, используя флаг -s в строке кода read -s password\nЕсли вы хотите удалить пользователя, которого вы создали для лабораторных целей, вы можете сделать это с помощью sudo userdel test_user\nЕще раз, я не говорю, что это будет то, что вы будете создавать в своей повседневной жизни, но я думал, что это то, что подчеркнет гибкость того, для чего вы можете использовать сценарии оболочки.\nПодумайте о любых повторяющихся задачах, которые вы выполняете каждый день, неделю или месяц, и о том, как вы могли бы лучше автоматизировать это. Первым вариантом, вероятно, будет использование сценария bash, прежде чем переходить к более сложной территории.\nЯ создал очень простой bash-файл, который помогает мне развернуть кластер Kubernetes с помощью minikube на моем локальном компьютере вместе со службами данных и Kasten K10, чтобы продемонстрировать требования и нужды, связанные с управлением данными. Project Pace. Но я не счел уместным поднимать вопрос здесь, поскольку мы еще не рассмотрели Kubernetes.\nРесурсы Bash in 100 seconds Bash script with practical examples - Full Course Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) ","description":"Автоматизация задачи с помощью bash-скриптов","title":"19. Автоматизация задачи с помощью bash-скриптов","uri":"/ru/docs/90daysofdevops/day19/"},{"content":"Модуль subprocess дает разработчику возможность запускать процессы или программы из Python. Другими словами, вы можете запускать приложения и передавать им аргументы с помощью модуля subprocess. Модуль subprocess был добавлен в Python 2.4, чтобы заменить модули os, состоящие из os.popen, os.spawn и os.system, а также заменить popen2 и старый модуль commands. Мы рассмотрим следующие аспекты модуля subprocess:\nфункция вызова класс Popen как взаимодействовать с порожденным процессом. Давайте начнем!\nФункция вызова call Модуль subprocess предоставляет функцию call. Эта функция позволяет вам вызвать другую программу, дождаться завершения команды и затем вернуть код возврата. Она принимает один или несколько аргументов, а также следующие ключевые аргументы (с их значениями по умолчанию): stdin=None, stdout=None, stderr=None, shell=False.\nРассмотрим простой пример:\n\u003e\u003e\u003e import subprocess \u003e\u003e\u003e subprocess.call(\"notepad.exe\") 0 Если вы запустите эту программу на машине под управлением Windows, вы увидите, что открылся блокнот. Вы заметите, что IDLE ждет, пока вы закроете Блокнот, а затем возвращает код ноль (0). Это означает, что программа завершилась успешно. Если вы получаете что-либо, кроме нуля, то это обычно означает, что произошла какая-то ошибка.\nОбычно, когда вы вызываете эту функцию, вы хотите присвоить полученный код возврата переменной, чтобы вы могли проверить, соответствует ли результат ожиданию. Давайте сделаем это:\n\u003e\u003e\u003e code = subprocess.call(\"notepad.exe\") \u003e\u003e\u003e if code == 0: print(\"Success!\") else: print(\"Error!\") Success! Если вы запустите этот код, вы увидите, что он выводит на экран сообщение Success!. Метод call также принимает аргументы для передачи в выполняемую программу. Давайте посмотрим, как это работает:\n\u003e\u003e\u003e code = subprocess.call([\"ping\", \"www.yahoo.com\"]) Pinging ds-any-fp3-real.wa1.b.yahoo.com [98.139.180.149] with 32 bytes of data: Reply from 98.139.180.149: bytes=32 time=66ms TTL=45 Reply from 98.139.180.149: bytes=32 time=81ms TTL=45 Reply from 98.139.180.149: bytes=32 time=81ms TTL=45 Reply from 98.139.180.149: bytes=32 time=69ms TTL=45 Ping statistics for 98.139.180.149: Packets: Sent = 4, Received = 4, Lost = 0 (0% loss), Approximate round trip times in milli-seconds: Minimum = 66ms, Maximum = 81ms, Average = 74ms \u003e\u003e\u003e code 0 Обратите внимание, что в этом примере мы передаем список аргументов. Первый элемент в списке - это программа, которую мы хотим вызвать. Все остальное в списке - это аргументы, которые мы хотим передать этой программе. Итак, в этом примере мы выполняем команду ping для сайта Yahoo. Вы заметите, что код возврата равен нулю, так что все завершилось успешно.\nВы также можете выполнить программу с помощью оболочки операционной системы. Это добавляет уровень абстракции к процессу и повышает вероятность возникновения проблем с безопасностью. Вот официальное предупреждение документации Python по этому вопросу:\nВыполнение необработанных вводных данных из ненадежного источника делает программу уязвимой для внедрений в оболочку, что является серьезным недостатком безопасности, который может привести к произвольному исполнению команд. По этой причине, применение shell=True настоятельно не рекомендуется в случаях, когда командная строка создана во внешнем входе.\nОбычная рекомендация - не использовать его, если внешний процесс или человек может изменить аргументы вызова. Если вы сами что-то жестко кодируете, то это не так важно.\nКласс Popen Класс Popen выполняет дочернюю программу в новом процессе. В отличие от метода call, он не ждет завершения вызванного процесса, если вы не попросите его об этом с помощью метода wait. Давайте попробуем запустить Notepad через Popen и посмотрим, в чем разница:\n\u003e\u003e\u003e program = \"notepad.exe\" \u003e\u003e\u003e subprocess.Popen(program) \u003csubprocess.Popen object at 0x01EE0430\u003e Здесь мы создаем переменную program и присваиваем ей значение “notepad.exe”. Затем мы передаем ее классу Popen. Когда вы запустите эту программу, вы увидите, что она немедленно возвращает объект subprocess.Popen и вызванное приложение выполняется. Давайте заставим Popen ждать завершения работы программы:\n\u003e\u003e\u003e program = \"notepad.exe\" \u003e\u003e\u003e process = subprocess.Popen(program) \u003e\u003e\u003e code = process.wait() \u003e\u003e\u003e print(code) 0 Когда вы делаете это в IDLE, блокнот всплывает и может оказаться перед сеансом IDLE. Просто уберите блокнот с дороги, но не закрывайте его! Вам нужно указать вашему процессу подождать, пока вы не получите код возврата. После того, как вы впишете эту строку, закройте блокнот и впишите код. Или вы можете просто поместить весь этот код в сохраненный файл Python и запустить его.\nОбратите внимание на то, что использование метода wait может вызвать блокировку дочернего процесса при использовании команды stdout/stderr=PIPE, когда процесс генерирует достаточно выходных данных для блокировки pipe Для облегчения этой ситуации можно использовать метод communicate. Мы рассмотрим этот метод в следующем разделе.\nТеперь давайте попробуем запустить Popen, используя несколько аргументов:\n\u003e\u003e\u003e subprocess.Popen([\"ls\", \"-l\"]) \u003csubprocess.Popen object at 0xb7451001\u003e Если вы запустите этот код в Linux, вы увидите возникшее сообщение объекта Popen, затем перечень разрешений и содержимого той или иной папки, которую вы используете. Вы можете использовать аргумент shell совместно с Popen, но с теми же предостережениями, что и с методом call.\nОбучение общению Существует несколько способов взаимодействия с процессом, который вы вызвали. Мы остановимся на том, как использовать метод communicate модуля subprocess. Давайте посмотрим:\nargs = [\"ping\", \"www.yahoo.com\"] process = subprocess.Popen(args, stdout=subprocess.PIPE) data = process.communicate() print(data) В этом примере кода мы создаем переменную args для хранения нашего списка аргументов. Затем мы перенаправляем стандартный выход (stdout) на наш subprocess, чтобы мы могли общаться с ним. Сам метод communicate позволяет нам общаться с процессом, который мы только что создали. На самом деле мы можем передавать процессу входные данные с помощью этого метода. Но в нашем примере, мы используем этот метод для чтения stdout. Обратите внимание на то, что когда вы запускаете этот код, цель которого – поддержка связи, он будет дожидаться финиша процесса, После чего выдаст кортеж, состоящий из двух элементов, которые являются содержимым stdout и stderr. Вот результат:\n('Pinging ds-any-fp3-real.wa1.b.yahoo.com [98.139.180.149] with 32 bytes of data: Reply from 98.139.180.149: bytes=32 time=139ms TTL=45 Reply from 98.139.180.149: bytes=32 time=162ms TTL=45 Reply from 98.139.180.149: bytes=32 time=164ms TTL=45 Reply from 98.139.180.149: bytes=32 time=110ms TTL=45 Ping statistics for 98.139.180.149: Packets: Sent = 4, Received = 4, Lost = 0 (0% loss), Approximate round trip times in milli-seconds: Minimum = 110ms, Maximum = 164ms, Average = 143ms ', None) Это довольно некрасиво. Давайте заставим его вывести результат в более читабельном формате?\nimport subprocess args = [\"ping\", \"www.yahoo.com\"] process = subprocess.Popen(args, stdout=subprocess.PIPE) data = process.communicate() for line in data: print(line) Если вы запустите этот код, на экране должно появиться нечто похожее на следующее:\nPinging ds-any-fp3-real.wa1.b.yahoo.com [98.139.180.149] with 32 bytes of data: Reply from 98.139.180.149: bytes=32 time=67ms TTL=45 Reply from 98.139.180.149: bytes=32 time=68ms TTL=45 Reply from 98.139.180.149: bytes=32 time=70ms TTL=45 Reply from 98.139.180.149: bytes=32 time=69ms TTL=45 Ping statistics for 98.139.180.149: Packets: Sent = 4, Received = 4, Lost = 0 (0% loss), Approximate round trip times in milli-seconds: Minimum = 67ms, Maximum = 70ms, Average = 68ms None Последняя строка, в которой написано “None”, является результатом stderr, что означает, что ошибок не было.\nПодведение итогов На данный момент у вас есть знания, позволяющие эффективно использовать модуль subprocess. Вы можете открыть процесс двумя различными способами, знаете, как дождаться кода возврата, и знаете, как взаимодействовать с созданным вами дочерним процессом.\nВ следующей главе мы рассмотрим модуль sys.\n","description":"Python 101","title":"19. Модуль subprocess","uri":"/ru/docs/python101/chapter19_subprocess/"},{"content":"В Python существует несколько типов данных. Основные типы данных, с которыми вы, вероятно, будете чаще всего встречаться, - это строка, целое число, плавающая цифра, список, словарь и кортеж. В этой главе мы рассмотрим строковый тип данных. Вы удивитесь, как много вещей можно делать со строками в Python прямо из коробки. Существует также модуль string, который можно импортировать для получения доступа к еще большей функциональности, но мы не будем рассматривать его в этой главе. Вместо этого мы рассмотрим следующие темы:\nКак создавать строки Конкатенация строк Методы работы со строками Нарезка строк Подстановка строк Как создать строку Строки обычно создаются одним из трех способов. Вы можете использовать одинарные, двойные или тройные кавычки. Давайте посмотрим!\n\u003e\u003e\u003e my_string = \"Welcome to Python!\" \u003e\u003e\u003e another_string = 'The bright red fox jumped the fence.' \u003e\u003e\u003e a_long_string = '''This is a multi-line string. It covers more than one line''' Строка с тройными кавычками может быть выполнена с помощью трех одинарных или трех двойных кавычек. В любом случае они позволяют программисту писать строки в несколько строк. Когда вы выведете ее, то заметите, что при выводе сохраняются разрывы строк. Если вам необходимо использовать одинарные кавычки в строке, то оберните их в двойные кавычки. Смотрите следующий пример.\n\u003e\u003e\u003e my_string = \"I'm a Python programmer!\" \u003e\u003e\u003e otherString = 'The word \"python\" usually refers to a snake' \u003e\u003e\u003e tripleString = \"\"\"Here's another way to embed \"quotes\" in a string\"\"\" Приведенный выше код демонстрирует, как можно поместить одинарные или двойные кавычки в строку. На самом деле существует еще один способ создания строки - это использование метода str. Вот как это работает:\n\u003e\u003e\u003e my_number = 123 \u003e\u003e\u003e my_string = str(my_number) Если вы введете приведенный выше код в свой интерпретатор, то обнаружите, что вы преобразовали целочисленное значение в строку и присвоили строку переменной my_string. Это известно как преобразование. Вы можете преобразовывать некоторые типы данных в другие типы данных, например, числа в строки. Но вы также увидите, что не всегда можно сделать обратное действие, например, преобразовать строку типа ‘ABC’ в целое число. В этом случае вы получите ошибку, подобную той, что приведена в следующем примере:\n\u003e\u003e\u003e int('ABC') Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e ValueError: invalid literal for int() with base 10: 'ABC' Мы рассмотрим обработку исключений в следующей главе, но, как вы уже догадались из сообщения, это означает, что вы не можете преобразовать литерал в целое число. Однако, если бы вы сделали\n\u003e\u003e\u003e x = int(\"123\") тогда это будет работать нормально.\nСледует отметить, что строка является одним из неизменяемых типов Python. Это значит, что вы не можете изменить содержимое строки после ее создания. Давайте попробуем изменить одну из них и посмотрим, что произойдет:\n\u003e\u003e\u003e my_string = \"abc\" \u003e\u003e\u003e my_string[0] = \"d\" Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: 'str' object does not support item assignment Здесь мы пытаемся изменить первый символ с “a” на “d”, однако это вызывает ошибку типа TypeError, которая не дает нам этого сделать. Теперь вы можете подумать, что, присвоив новую строку той же переменной, вы изменили строку. Давайте проверим, так ли это:\n\u003e\u003e\u003e my_string = \"abc\" \u003e\u003e\u003e id(my_string) 19397208 \u003e\u003e\u003e my_string = \"def\" \u003e\u003e\u003e id(my_string) 25558288 \u003e\u003e\u003e my_string = my_string + \"ghi\" \u003e\u003e\u003e id(my_string) 31345312 Проверяя id объекта, мы можем определить, что каждый раз, когда мы присваиваем переменной новое значение, ее идентификатор меняется.\nКонкатенация строк Конкатенация - это большое слово, которое означает объединение или сложение двух вещей вместе. В данном случае мы хотим узнать, как сложить две строки вместе. Как вы уже догадались, эта операция очень проста в Python:\n\u003e\u003e\u003e string_one = \"My dog ate \" \u003e\u003e\u003e string_two = \"my homework!\" \u003e\u003e\u003e string_three = string_one + string_two Оператор ‘+’ объединяет две строки в одну.\nМетоды работы со строками Строка - это объект в Python. Фактически, все в Python является объектом. Однако вы еще не готовы к этому. Если вы хотите узнать больше о том, что Python является объектно-ориентированным языком программирования, то вам нужно перейти к этой главе. А пока достаточно знать, что строки имеют свои собственные методы, встроенные в них. Например, допустим, у вас есть следующая строка:\n\u003e\u003e\u003e my_string = \"This is a string!\" Теперь вы хотите, чтобы эта строка была полностью в верхнем регистре. Для этого достаточно вызвать его метод upper(), как показано ниже:\n\u003e\u003e\u003e my_string.upper() Если у вас открыт интерпретатор, вы можете сделать то же самое следующим образом:\n\u003e\u003e\u003e \"This is a string!\".upper() Существует множество других методов работы со строками. Например, если бы вы хотели, чтобы все было в нижнем регистре, вы бы использовали метод lower(). Если бы вы хотели удалить все пробелы в начале и в конце строки, вы бы использовали метод strip(). Чтобы получить список всех методов работы со строками, введите в интерпретатор следующую команду:\n\u003e\u003e\u003e dir(my_string) В итоге вы должны увидеть нечто похожее на это:\n[‘add’, ‘class’, ‘contains’, ‘delattr’, ‘doc’, ‘eq’, ‘format’, ‘ge’, ‘getattribute’, ‘getitem’, ‘getnewargs’, ‘getslice’, ‘gt’, ‘hash’, ‘init’, ‘le’, ‘len’, ‘lt’, ‘mod’, ‘mul’, ‘ne’, ‘new’, ‘reduce’, ‘reduce_ex’, ‘repr’, ‘rmod’, ‘rmul’, ‘setattr’, ‘sizeof’, ‘str’, ‘subclasshook’, ‘_formatter_field_name_split’, ‘_formatter_parser’, ‘capitalize’, ‘center’, ‘count’, ‘decode’, ‘encode’, ‘endswith’, ‘expandtabs’, ‘find’, ‘format’, ‘index’, ‘isalnum’, ‘isalpha’, ‘isdigit’, ‘islower’, ‘isspace’, ‘istitle’, ‘isupper’, ‘join’, ‘ljust’, ‘lower’, ‘lstrip’, ‘partition’, ‘replace’, ‘rfind’, ‘rindex’, ‘rjust’, ‘rpartition’, ‘rsplit’, ‘rstrip’, ‘split’, ‘splitlines’, ‘startswith’, ‘strip’, ‘swapcase’, ‘title’, ‘translate’, ‘upper’, ‘zfill’]\nВы можете смело игнорировать методы, начинающиеся и заканчивающиеся двойными знаками, такие как add. Они не используются в повседневном кодировании на Python. Вместо этого сосредоточьтесь на других методах. Если вы хотите узнать, что делает один из них, просто попросите помощи. Например, вы хотите узнать, для чего нужна capitalize. Чтобы узнать это, введите\n\u003e\u003e\u003e help(my_string.capitalize) Это вернет следующую информацию:\nHelp on built-in function capitalize: capitalize(...) S.capitalize() -\u003e string Возвращает копию строки S, в которой заглавным является только первый символ.\nВы только что узнали немного о теме, называемой интроспекцией. Python позволяет легко проводить интроспекцию всех своих объектов, что делает его очень удобным в использовании. По сути, интроспекция позволяет вам спрашивать Python о самом себе. В одном из предыдущих разделов вы узнали о преобразовании. Возможно, вы задавались вопросом, как определить тип переменной (например, int или string). Вы можете попросить Python рассказать вам об этом!\n\u003e\u003e\u003e type(my_string) \u003ctype 'str'\u003e Как вы видите, переменная my_string имеет тип str!\nНарезка строка Один из пунктов, которым вы будете часто заниматься в реальном мире, - это нарезка строк. Я был удивлен, как часто мне приходилось сталкиваться с необходимостью знать, как это делается в моей повседневной работе. Давайте посмотрим, как работает нарезка на примере следующей строки:\n\u003e\u003e\u003e my_string = \"I like Python!\" Каждый символ в строке может быть доступен с помощью нарезки. Например, если я хочу получить только первый символ, я могу сделать следующее:\n\u003e\u003e\u003e my_string[0:1] Это захватит первый символ в строке до 2-го символа, но не включая его. Да, Python основан на нулях. Это будет немного проще понять, если мы обозначим позицию каждого символа в таблице:\n0 |\t1 |\t2 |\t3 |\t4 |\t5 |\t6 |\t7 |\t8 |\t9 |\t10 | 11 |\t12 | 13 I |\t|\tl |\ti |\tk |\te |\t|\tP |\ty |\tt |\th |\to |\tn |\t!\nТаким образом, у нас есть строка длиной 14 символов, начинающаяся с нуля и заканчивающаяся тринадцатью. Давайте рассмотрим еще несколько примеров, чтобы лучше закрепить эти понятия в голове.\n\u003e\u003e\u003e my_string[:1] 'I' \u003e\u003e\u003e my_string[0:12] 'I like Pytho' \u003e\u003e\u003e my_string[0:13] 'I like Python' \u003e\u003e\u003e my_string[0:14] 'I like Python!' \u003e\u003e\u003e my_string[0:-5] 'I like Py' \u003e\u003e\u003e my_string[:] 'I like Python!' \u003e\u003e\u003e my_string[2:] 'like Python!' Как видно из этих примеров, мы можем сделать срез, указав только начало среза (например, my_string[2:]), конец среза (например, my_string[:1]) или оба (например, my_string[0:13]). Мы можем даже использовать отрицательные значения, которые начинаются с конца строки. Так, в примере my_string[0:-5] начинается с нуля, но заканчивается за 5 символов до конца строки.\nВам может быть интересно, где можно использовать это. Я использую его для разбора записей фиксированной ширины в файлах или иногда для разбора сложных имен файлов, которые следуют очень специфическому соглашению об именовании. Я также использовал его при разборе значений из файлов двоичного типа. Любая работа, где вам нужно обрабатывать текстовые файлы, станет проще, если вы поймете, что такое нарезка и как ее эффективно использовать.\nВы также можете получить доступ к отдельным символам в строке с помощью индексации. Вот пример:\n\u003e\u003e\u003e print(my_string[0]) Приведенный выше код выведет первый символ в строке.\nФорматирование строк Форматирование строк (оно же подстановка) - это тема подстановки значений в базовую строку. В большинстве случаев вы будете вставлять строки в строки, однако вам также часто придется вставлять в строки целые и плавающие числа. Существует два различных способа выполнения этой задачи. Мы начнем со старого способа, а затем перейдем к новому.\nСтарый способ подстановки строк\nСамый простой способ узнать, как это делается, - посмотреть несколько примеров. Итак, приступим:\n\u003e\u003e\u003e my_string = \"I like %s\" % \"Python\" \u003e\u003e\u003e my_string 'I like Python' \u003e\u003e\u003e var = \"cookies\" \u003e\u003e\u003e newString = \"I like %s\" % var \u003e\u003e\u003e newString 'I like cookies' \u003e\u003e\u003e another_string = \"I like %s and %s\" % (\"Python\", var) \u003e\u003e\u003e another_string 'I like Python and cookies' Как вы уже, наверное, догадались, %s - это важный элемент в приведенном выше коде. Он сообщает Python, что скоро вы можете вставить текст. Если за строкой следует знак процента и другая строка или переменная, Python попытается вставить ее в строку. Вы можете вставить несколько строк, поместив несколько экземпляров %s внутрь строки. Вы увидите это в последнем примере. Обратите внимание, что при вставке более одной строки необходимо заключить в круглые скобки те строки, которые вы собираетесь вставить.\nТеперь давайте посмотрим, что произойдет, если мы вставим недостаточно строк:\nTraceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: not enough arguments for format string Упс! Мы не передали достаточно аргументов для форматирования строки! Если вы внимательно посмотрите на пример выше, то заметите, что в нем есть два экземпляра %s, поэтому, чтобы вставить в него строки, вы должны передать ему такое же количество строк! Теперь мы готовы узнать о вставке целых и плавающих чисел. Давайте посмотрим!\n\u003e\u003e\u003e my_string = \"%i + %i = %i\" % (1,2,3) \u003e\u003e\u003e my_string '1 + 2 = 3' \u003e\u003e\u003e float_string = \"%f\" % (1.23) \u003e\u003e\u003e float_string '1.230000' \u003e\u003e\u003e float_string2 = \"%.2f\" % (1.23) \u003e\u003e\u003e float_string2 '1.23' \u003e\u003e\u003e float_string3 = \"%.2f\" % (1.237) \u003e\u003e\u003e float_string3 '1.24' Первый пример довольно очевиден. Мы создаем строку, которая принимает три аргумента, и передаем их. На всякий случай, если вы еще не поняли, нет, Python не выполняет никакого сложения в этом первом примере. Во втором примере мы передаем плавающее число. Обратите внимание, что на выходе получается много лишних нулей. Нам это не нужно, поэтому мы говорим Python ограничиться двумя знаками после запятой в третьем примере (\"%.2f\"). Последний пример показывает, что Python сделает округление за вас, если вы передадите ему плавающее число с более чем двумя знаками после запятой.\nТеперь давайте посмотрим, что произойдет, если мы передадим ему плохие данные:\n\u003e\u003e\u003e int_float_err = \"%i + %f\" % (\"1\", \"2.00\") Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: %d format: a number is required, not str В этом примере мы передаем ему две строки вместо целого и плавающего числа. Это вызывает ошибку TypeError и говорит нам, что Python ожидал получить число. Это относится к тому, что мы не передали целое число, поэтому давайте исправим это и посмотрим, устранит ли это проблему:\n\u003e\u003e\u003e int_float_err = \"%i + %f\" % (1, \"2.00\") Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: must be real number, not str Неа. Мы получаем ту же ошибку, но другое сообщение, которое говорит нам, что мы должны были передать плавающее число. Как видите, Python дает нам довольно хорошую информацию о том, что пошло не так и как это исправить. Если вы правильно исправите входные данные, то сможете запустить этот пример.\nДавайте перейдем к новому методу форматирования строк!\nШаблоны и новая методика форматирования строк\nЭтот новый метод был фактически добавлен еще в Python 2.4 в виде шаблонов строк, но в Python 2.6 он был добавлен как обычный метод форматирования строк через метод format. Так что это не совсем новый метод, просто более новый. В любом случае давайте начнем с шаблонов!\n\u003e\u003e\u003e print(\"%(lang)s is fun!\" % {\"lang\":\"Python\"}) Python is fun! Возможно, это выглядит довольно странно, но, по сути, мы просто заменили %s на %(lang)s, что, является %s с переменной внутри. Вторая часть на самом деле называется словарем Python, который мы будем изучать в следующем разделе. По сути, это пара ключ:значение, поэтому когда Python видит ключ “lang” в строке И в ключе переданного словаря, он заменяет этот ключ на его значение. Давайте рассмотрим еще несколько примеров:\n\u003e\u003e\u003e print(\"%(value)s %(value)s %(value)s !\" % {\"value\":\"SPAM\"}) SPAM SPAM SPAM ! \u003e\u003e\u003e print(\"%(x)i + %(y)i = %(z)i\" % {\"x\":1, \"y\":2}) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e KeyError: 'z' \u003e\u003e\u003e print(\"%(x)i + %(y)i = %(z)i\" % {\"x\":1, \"y\":2, \"z\":3}) 1 + 2 = 3 В первом примере вы заметите, что мы передали только одно значение, но оно было вставлено 3 раза! Это одно из преимуществ использования шаблонов. Во втором примере есть проблема, связанная с тем, что мы забыли передать ключ, а именно ключ “z”. Третий пример исправляет эту проблему и показывает результат. Теперь давайте посмотрим, как можно сделать нечто подобное с помощью метода формата строки!\n\u003e\u003e\u003e \"Python is as simple as {0}, {1}, {2}\".format(\"a\", \"b\", \"c\") 'Python is as simple as a, b, c' \u003e\u003e\u003e \"Python is as simple as {1}, {0}, {2}\".format(\"a\", \"b\", \"c\") 'Python is as simple as b, a, c' \u003e\u003e\u003e xy = {\"x\":0, \"y\":10} \u003e\u003e\u003e print(\"Graph a point at where x={x} and y={y}\".format(**xy)) Graph a point at where x=0 and y=10 В первых двух примерах вы можете видеть, как мы можем передавать элементы позиционно. Если мы изменим порядок, то получим немного другой результат. В последнем примере используется словарь, как мы использовали в шаблонах выше. Однако нам нужно извлечь словарь с помощью двойной звездочки, чтобы он работал правильно.\nЕсть много других вещей, которые можно делать со строками, например, указывать ширину, выравнивать текст, конвертировать в различные базы и многое другое. Обязательно посмотрите некоторые из приведенных ниже ссылок для получения дополнительной информации.\nОфициальная документация Python по типу str Форматирование строк [Подробнее о форматировании строк(https://docs.python.org/3/library/string.html#formatexamples) Подведение итогов Мы многое рассмотрели в этой главе. Давайте подведем итоги:\nСначала мы узнали, как создавать сами строки, затем перешли к теме конкатенации строк. После этого мы рассмотрели некоторые методы, которые предоставляет нам объект string. Далее мы рассмотрели нарезку строк и закончили изучением подстановки строк.\nВ следующей главе мы рассмотрим еще три встроенных типа данных Python: списки, кортежи и словари. Приступаем!\n","description":"Python 101","title":"2. Все о строках","uri":"/ru/docs/python101/chapter2_strings/"},{"content":"Обязанности DevOps специалиста Надеюсь, вы приступили к этому после просмотра ресурсов и публикации в День 1 из #90DaysOfDevOps\nВ первом посте был краткий обзор, но теперь мы должны углубиться в концепцию DevOps и понять, что при создании приложения есть две основные части. У нас есть часть Разработка, где разработчики программного обеспечения программируют приложение и тестируют его. Затем у нас есть часть Операции, где приложение развертывается и поддерживается на сервере.\nDevOps — это связующее звено между двумя Чтобы разобраться с DevOps или задачами, которые будет выполнять инженер DevOps, нам нужно понять инструменты или процесс, а также разобраться как они вместе они вместе взаимодейтвуют.\nВсе начинается с приложения! Вы увидите так много всего, что все дело в приложении, когда речь идет о DevOps.\nРазработчики создадуют приложение, это можно сделать с помощью множества различных технологических стеков, и давайте пока оставим это воображению, поскольку мы вернемся к этому позже. Это также может включать множество различных языков программирования, инструменты сборки, репозиторий кода и т. д.\nБудучи инженером DevOps, вы не будете программировать приложение, но хорошее понимание концепций работы разработчика и используемых им систем, инструментов и процессов является ключом к успеху.\nНа очень высоком уровне вам нужно будет знать, как приложение настроено для взаимодействия со всеми необходимыми службами или службами данных, а затем также добавить требования о том, как это можно или нужно протестировать.\nПриложение нужно будет где-то развернуть, давайте сделаем его в целом простым и сделаем это сервером, неважно где, но сервером. Затем ожидается, что к нему будет обращаться клиент или конечный пользователь в зависимости от созданного приложения.\nЭтот сервер должен работать где-то локально, в общедоступном облаке, без сервера (Хорошо, я зашел слишком далеко, мы не будем рассматривать бессерверный вариант, но это вариант, и все больше и больше предприятий идут по этому пути). Кто-то должен создать настройте эти серверы и подготовьте их к запуску приложения. Теперь этот элемент может пригодиться вам как инженеру DevOps для развертывания и настройки этих серверов.\nЭти серверы должны будут работать под управлением операционной системы, и, вообще говоря, это будет Linux, но у нас есть целый раздел или потратим неделю, где мы рассмотрим некоторые фундаментальные знания, которые вы должны получить.\nТакже вероятно, что нам нужно взаимодействовать с другими службами в нашей сети или среде, поэтому нам также необходимо иметь такой уровень знаний о сети и настройке, что в некоторой степени также может оказаться в руках инженера DevOps. Опять же, мы рассмотрим это более подробно в специальном разделе, посвященном DNS, DHCP, балансировщикам нагрузки (Load Balancing) и т. д.\nМастер на все руки Однако на этом этапе я скажу, что вам не нужно быть специалистом по сетям или инфраструктуре, вам нужны базовые знания о том, как наладить работу и общаться друг с другом, во многом так же, как, возможно, иметь базовые знания язык программирования, но вам не нужно быть разработчиком. Однако вы можете прийти к этому как специалист в какой-то области, и это отличная основа для адаптации к другим областям.\nВы также, скорее всего, не будете ежедневно управлять этими серверами или приложением.\nМы говорили о серверах, но есть вероятность, что ваше приложение будет разработано для работы в виде контейнеров, которые по-прежнему работают на сервере по большей части, но вам также потребуется понимание не только виртуализации, облачной инфраструктуры как услуги (IaaS). ), но также и контейнеризация. В эти 90 дней основное внимание будет уделяться контейнерам.\nОбщий обзор С одной стороны, наши разработчики создают новые функции и функции (а также исправления ошибок) для приложения.\nС другой стороны, у нас есть какая-то среда, инфраструктура или серверы, которые настроены и управляются для запуска этого приложения и связи со всеми необходимыми службами.\nБольшой вопрос заключается в том, как нам внедрить эти функции и исправления ошибок в нашу продукцию и сделать их доступными для этих конечных пользователей?\nКак мы выпускаем новую версию приложения? Это одна из основных задач для DevOps-инженера, и здесь важно не просто понять, как это сделать один раз, а нам нужно делать это непрерывно и автоматизированным, эффективным способом, который также должен включать тестирование!\nНа этом мы собираемся закончить этот день обучения, надеюсь, это было полезно. В течение следующих нескольких дней мы собираемся немного глубже погрузиться в некоторые другие области DevOps, а затем мы перейдем к разделам, в которых более подробно рассматриваются инструменты и процессы, а также их преимущества.\nРесурсы Я всегда открыт для добавления дополнительных ресурсов в эти файлы Readme, поскольку они здесь в качестве учебного пособия.\nМой совет - просмотреть все ссылки из списка ниже, и, надеюсь, вы также что-то почерпнули из текста и объяснений выше.\nWhat is DevOps? - TechWorld with Nana What is DevOps? - GitHub YouTube What is DevOps? - IBM YouTube What is DevOps? - AWS What is DevOps? - Microsoft Если вы зашли так далеко, то поймете, хотите ли вы быть здесь или нет. До встречи в День 3\n","description":"Задачи DevOps-инженера","title":"2. Задачи DevOps-инженера","uri":"/ru/docs/90daysofdevops/day02/"},{"content":"Модуль sys предоставляет специфические для системы параметры и функции. Мы сузим наше исследование до следующих:\nsys.argv sys.executable sys.exit sys.modules sys.path sys.platform sys.stdin/stdout/stderr sys.argv Значение sys.argv - это список аргументов командной строки Python, которые были переданы сценарию Python. Первый аргумент, argv[0] - это имя самого сценария Python. В зависимости от платформы, на которой вы работаете, первый аргумент может содержать полный путь к скрипту или только имя файла. Для получения дополнительной информации следует изучить документацию.\nДавайте попробуем выполнить несколько примеров, чтобы ознакомиться с этим небольшим инструментом:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e sys.argv [''] Если вы выполните это в интерпретаторе, то получите список с пустой строкой. Давайте создадим файл с именем “sysargv.py” со следующим содержимым:\n# sysargv.py import sys print(sys.argv) Теперь запустите код в IDLE. Вы должны увидеть, что он выведет список с одним элементом, содержащим путь к вашему скрипту. Давайте попробуем передать скрипту несколько аргументов. Откройте терминал / консоль и измените директорию (используйте команду “cd”) на ту, где находится ваш скрипт. Затем запустите что-то вроде этого:\nВы заметите, что он выводит на экран следующее:\n['sysargv.py', '-v', 'somefile.py'] Первый аргумент - это имя написанного нами сценария. Следующие два аргумента в списке - это аргументы, которые мы передали нашему скрипту в командной строке.\nsys.executable Значение sys.executable - это абсолютный путь к интерпретатору Python. Это полезно, когда вы используете чужую машину и вам нужно знать, где установлен Python. На некоторых системах эта команда будет неудачной и вернет пустую строку или None. Вот как ее использовать:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e sys.executable 'C:\\\\Python27\\\\pythonw.exe' ##sys.exit\nФункция sys.exit() позволяет разработчику выйти из Python. Функция exit принимает необязательный аргумент, обычно целое число, которое выдает статус завершения. Ноль считается “успешным завершением”. Обязательно проверьте, имеет ли ваша операционная система какие-либо специальные значения для статусов выхода, чтобы вы могли следовать им в своем приложении. Обратите внимание, что когда вы вызываете exit, он вызывает исключение SystemExit, что позволяет функциям очистки работать в в конечных пунктах блоков try / except.\nДавайте рассмотрим, как вызвать exit:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e sys.exit(0) Traceback (most recent call last): File \"\u003cpyshell#5\u003e\", line 1, in \u003cmodule\u003e sys.exit(0) SystemExit: 0 Когда вы запустите этот код в IDLE, вы увидите, что возникла ошибка SystemExit. Давайте создадим несколько сценариев, чтобы проверить это. Сначала нужно создать главный сценарий, программу, которая будет вызывать другой сценарий Python. Назовем его “call_exit.py”. Поместите в него следующий код:\n# call_exit.py import subprocess code = subprocess.call([\"python.exe\", \"exit.py\"]) print(code) Теперь создайте еще один Python-скрипт под названием “exit.py” и сохраните его в той же папке. Поместите в него следующий код:\nimport sys sys.exit(0) Теперь давайте попробуем запустить этот код:\nНа скриншоте выше видно, что написанный нами сценарий exit вернул ноль, поэтому он был успешно запущен. Вы также узнали, как вызвать другой сценарий Python из самого Python!\nsys.path Значение path модуля sys - это список строк, который определяет путь поиска модулей. По сути, это указывает Python, в каких местах искать модуль, когда он пытается его импортировать. Согласно документации Python, sys.path инициализируется из переменной окружения PYTHONPATH, плюс по умолчанию, зависящему от установки. Давайте попробуем:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e print(sys.path) ['', 'C:\\\\Python27\\\\Lib\\\\idlelib', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\setuptools-0.9.5-py2.7.egg', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\pip-1.3.1-py2.7.egg', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\sphinx-1.2b3-py2.7.egg', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\docutils-0.11-py2.7.egg', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\pygments-1.6-py2.7.egg', 'C:\\\\Windows\\\\system32\\\\python27.zip', ' C:\\\\Python27\\\\DLLs', 'C:\\\\Python27\\\\lib', 'C:\\\\Python27\\\\lib\\\\plat-win', 'C:\\\\Python27\\\\lib\\\\lib-tk', 'C:\\\\Python27', 'C:\\\\Python27\\\\lib\\\\site-packages', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\PIL', 'C:\\\\Python27\\\\lib\\\\site-packages\\\\wx-2.9.4-msw'] Данная функция может быть весьма полезной во время отладки причины, по которой модуль не импортируется. Вы также можете изменить путь. Так как данная функция является путем, мы можем добавлять или удалять путь из неё. Давайте взглянем на то, как добавлять путь:\n\u003e\u003e\u003e sys.path.append(\"/path/to/my/module\") Я оставлю удаление пути в качестве упражнения для читателя.\nsys.platform Значение sys.platform - это идентификатор платформы. Вы можете использовать его для добавления модулей для конкретной платформы в sys.path, импорта различных модулей в зависимости от платформы или запуска различных частей кода. Давайте посмотрим:\n\u003e\u003e\u003e import sys \u003e\u003e\u003e sys.platform 'win32' Это говорит нам о том, что Python запущен на машине Windows. Вот пример того, как мы можем использовать эту информацию:\n\u003e\u003e\u003e os = sys.platform \u003e\u003e\u003e if os == \"win32\": # use Window-related code here import _winreg elif os.startswith('linux'): # do something Linux specific import subprocess subprocess.Popen([\"ls, -l\"]) Приведенный выше код показывает, как мы можем проверить, используем ли мы определенную операционную систему. Если мы находимся в Windows, мы получим информацию из реестра Window с помощью модуля Python под названием _winreg. Если мы находимся в Linux, мы можем выполнить команду ls, чтобы получить информацию о каталоге, в котором мы находимся.\nsys.stdin / stdout / stderr Параметры stdin, stdout и stderr соответствуют файловым объектам, которые соответствуют стандартным потокам ввода, вывода и ошибок интерпретатора, соответственно. stdin используется для всех входных данных интерпретатора, кроме скриптов, в то время как stdout используется для вывода операторов ** print** и expression. Основная причина, по которой я упоминаю об этом, заключается в том, что иногда вам потребуется перенаправить stdout или stderr или оба потока в файл, например, в журнал или на какой-либо дисплей в созданном вами пользовательском графическом интерфейсе. Вы также можете перенаправить stdin, но я редко видел, чтобы это делалось.\nПодведение итогов В модуле sys есть много других значений и методов. Обязательно посмотрите его в документации Python, раздел 27.1. Вы многому научились в этой главе. Теперь вы знаете, как выйти из программы Python, как получить информацию о платформе, как работать с аргументами, передаваемыми из командной строки, и многое другое. В следующей главе мы узнаем о потоках Python!\n","description":"Python 101","title":"20. Модуль sys","uri":"/ru/docs/python101/chapter20_sys/"},{"content":"Настройка рабочей среды Не путать с тем, как мы настраиваем серверы Linux таким образом. Я хочу продемонстрировать возможности выбора и гибкость, которые у нас есть при настройке настольного компьютера Linux.\nЯ использую рабочий стол Linux уже почти год, и я настроил его именно так, как я хочу с точки зрения внешнего вида. Используя нашу виртуальную машину Ubuntu в Virtual Box, мы можем выполнить некоторые настройки, которые я сделал для своего ежедневного драйвера.\nЯ собрал видео на YouTube, показывающее остальные, так как некоторые люди могли бы лучше следовать за ним:\nИз коробки наша система будет выглядеть примерно так:\nМы также можем увидеть нашу оболочку bash по умолчанию: Многое из этого сводится к точечным файлам, которые мы рассмотрим в этой заключительной статье Linux из этой серии.\ndotfiles Сначала я хочу покопаться в dotfiles, я сказал в предыдущий день, что Linux состоит из файлов конфигурации. Эти файлы представляют собой файлы конфигурации для вашей системы Linux и приложений.\nЯ также добавлю, что dotfiles используются не только для настройки и придания красивого вида вашему рабочему столу, но и для изменения и конфигурации dotfile, которые помогут вам повысить производительность.\nКак я уже упоминал, многие программы хранят свои конфигурации в этих точечных файлах. Эти файлы помогают управлять функциональностью.\nКаждый файл начинается с . Вы, наверное, догадались, откуда взялось название?\nДо сих пор мы использовали bash в качестве нашей оболочки, что означает, что у вас будут .bashrc и .bash_profile в нашей домашней папке. Ниже вы можете увидеть несколько точечных файлов, которые есть в нашей системе.\nМы собираемся изменить нашу оболочку, поэтому позже мы увидим новый точечный файл конфигурации .zshrc.\nНо теперь вы знаете, если мы ссылаемся на точечные файлы, вы знаете, что это файлы конфигурации. Мы можем использовать их для добавления псевдонимов в нашу командную строку, а также путей к различным местоположениям. Некоторые люди публикуют свои точечные файлы, чтобы они были общедоступными. Вы найдете мой здесь, на моем GitHub MichaelCade/dotfiles, здесь вы найдете мой пользовательский файл .zshrc, мой предпочтительный терминал - терминатор, который также имеет некоторые файлы конфигурации в папке, а затем также некоторые параметры фона.\nZSH Как я упоминал во время наших взаимодействий, до сих пор мы использовали оболочку bash по умолчанию с Ubuntu. ZSH очень похож, но имеет некоторые преимущества перед bash.\nZsh имеет такие функции, как интерактивное завершение с помощью табуляции, автоматический поиск файлов, интеграция с регулярными выражениями, расширенное сокращение для определения области действия команды и богатый движок тем.\nМы можем использовать наш менеджер пакетов «apt», чтобы установить zsh в нашей системе. Давайте продолжим и запустим sudo apt install zsh с нашего терминала bash. Я собираюсь сделать это из консоли виртуальной машины, а не через SSH.\nКогда команда установки завершена, вы можете запустить zsh внутри вашего терминала, это запустит сценарий настройки оболочки.\nЯ выбрал «1» на вопрос выше, и теперь у нас есть еще несколько вариантов. Из этого меню видно, что мы можем внести некоторые готовые изменения, чтобы настроить ZSH в соответствии с нашими потребностями.\nЕсли вы выходите из мастера с 0, а затем используете ls -la | grep .zshrc вы должны увидеть, что у нас есть новый файл конфигурации.\nТеперь мы хотим сделать zsh нашей оболочкой по умолчанию каждый раз, когда мы открываем наш терминал, мы можем сделать это, выполнив следующую команду, чтобы изменить нашу оболочку chsh -s $(which zsh), нам затем нужно выйти из системы и снова войти в нее для грядут изменения.\nКогда вы снова войдете в систему и откроете терминал, он должен выглядеть примерно так. Мы также можем подтвердить, что наша оболочка теперь изменена, запустив which $SHELL\nОбычно я выполняю этот шаг на каждом рабочем столе Ubuntu, который я запускаю, и в целом, не заходя дальше, обнаруживаю, что оболочка zsh немного быстрее, чем bash.\nOhMyZSH Далее мы хотим немного улучшить внешний вид, а также добавить некоторые функции, которые помогут нам перемещаться по терминалу.\nOhMyZSH — это бесплатная платформа с открытым исходным кодом для управления вашей конфигурацией zsh. Существует множество плагинов, тем и других вещей, которые просто делают взаимодействие с оболочкой zsh намного приятнее.\nВы можете узнать больше о ohmyzsh\nДавайте установим Oh My ZSH, у нас есть несколько вариантов с curl, wget или fetch, у нас есть первые два, доступные в нашей системе, но я начну с curl.\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nКогда вы запустите приведенную выше команду, вы должны увидеть вывод, как показано ниже. Теперь мы можем перейти к добавлению темы для нашего опыта, в комплекте с Oh My ZSH более 100, но я выбираю для всех своих приложений, и все это тема Дракулы.\nЯ также хочу добавить, что эти два плагина являются обязательными при использовании Oh My ZSH.\ngit clone https://github.com/zsh-users/zsh-autosuggestions.git $ZSH_CUSTOM/plugins/zsh-autosuggestions\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM/plugins/zsh-syntax-highlighting\nnano ~/.zshrc\nотредактируйте plugins, чтобы включить plugins=(git zsh-autosuggestions zsh-syntax-highlighting)\nРасширения Gnome Я также использую расширения Gnome, и в частности список ниже\nGnome extensions\n- Caffeine - CPU Power Manager - Dash to Dock - Desktop Icons - User Themes Установка программ Краткий список программ, которые я устанавливаю на машину с помощью apt\n- VSCode - azure-cli - containerd.io - docker - docker-ce - google-cloud-sdk - insomnia - packer - terminator - terraform - vagrant тема Dracula Этот сайт - единственная тема, которую я использую в данный момент. Выглядит четким, чистым и все выглядит отлично. Dracula Theme\nПо ссылке выше можем поискать zsh на сайте и найдем как минимум два варианта.\nСледуйте приведенным инструкциям, чтобы выполнить установку вручную или с помощью git. Затем вам нужно будет, наконец, отредактировать файл конфигурации .zshrc, как показано ниже.\nДалее нам понадобится тема Gnome Terminal Dracula со всеми инструкциями\nНа самом деле мне потребовалось бы много времени, чтобы задокументировать каждый шаг, поэтому я создал пошаговое видео процесса. (Нажмите на изображение ниже)\nЕсли вы дочитали до этого момента, значит, мы закончили наш раздел Linux в #90DaysOfDevOps. Я снова открыт для отзывов и дополнений к ресурсам здесь.\nЯ также подумал, что было проще показать вам многие шаги с помощью видео, чем записывать их здесь, что вы думаете об этом? У меня есть цель вернуться к этим дням и, где это возможно, создать видео-пошаговые руководства, чтобы добавить и, возможно, лучше объяснить и показать некоторые вещи, которые мы рассмотрели. Что вы думаете?\nРесурсы Bash in 100 seconds Bash script with practical examples - Full Course Client SSH GUI - Remmina The Beginner’s guide to SSH Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 Linux for hackers (don’t worry you don’t need to be a hacker!) Завтра мы начинаем наши 7 дней погружения в сетевое взаимодействие, мы будем стараться получить базовые знания и понимание сетевого взаимодействия (Networking) в DevOps.\n","description":"Настройка рабочей среды","title":"20. Настройка рабочей среды DevOps","uri":"/ru/docs/90daysofdevops/day20/"},{"content":"Общая картина: DevOps и Сеть Добро пожаловать в День 21! Мы собираемся заняться сетевыми технологиями в течение следующих 7 дней. Сеть и DevOps являются всеобъемлющей темой, но нам также необходимо изучить некоторые основы сетевых технологий.\nВ конечном счете, как мы уже говорили ранее, DevOps — это культура и изменение процессов в ваших организациях. Как мы уже говорили, это могут быть виртуальные машины, контейнеры, Kubernetes, но это также может быть и сеть. Если мы используем эти принципы DevOps для нашей инфраструктуры, которая чтобы включить сеть более точно с точки зрения DevOps, вам также необходимо знать о сети, а также о различных топологиях, сетевых инструментах и ​​стеках, которые у нас есть.\nЯ бы сказал, что наши сетевые устройства должны быть настроены с использованием инфраструктуры как кода, и все должно быть автоматизировано, как и наши виртуальные машины, но для этого мы должны хорошо понимать, что мы автоматизируем.\nЧто такое NetDevOps | Сетевой DevOps? Вы также можете услышать термины Network DevOps или NetDevOps. Возможно, вы уже являетесь сетевым инженером (network engineer) и хорошо разбираетесь в сетевых компонентах в инфраструктуре, вы понимаете элементы, используемые в сети, такие как DHCP, DNS, NAT и т. д. и т. д. У вас также будет хорошее понимание аппаратных или программно-определяемых сетей. опции, коммутаторы, маршрутизаторы и т.д. и т.п.\nНо если вы не сетевой инженер, то нам, вероятно, необходимо получить базовые знания по всем направлениям в некоторых из этих областей, чтобы мы могли понять конечную цель Network DevOps.\nНо в отношении этих терминов мы можем думать о NetDevOps или Network DevOps как о применении принципов и практик DevOps к сети, применении инструментов управления версиями и автоматизации к созданию, тестированию, мониторингу и развертыванию сети.\nЕсли мы думаем о сетевой DevOps как о необходимости автоматизации, мы упоминали ранее о том, что DevOps разрушает разрозненность между командами. Если сетевые команды не перейдут на аналогичную модель и процесс, они станут узким местом или даже полным провалом.\nИспользование принципов автоматизации подготовки, настройки, тестирования, контроля версий и развертывания — отличное начало. Автоматизация в целом обеспечит скорость развертывания, стабильность сетевой инфраструктуры и последовательное улучшение, а также процесс, который будет совместно использоваться в нескольких средах после их тестирования. Например, полностью протестированная сетевая политика, которая была полностью протестирована в одной среде, может быть быстро использована в другом месте из-за характера этого в коде, а не в процессе, созданном вручную, как это могло быть раньше. Действительно хорошую точку зрения и схему этого мышления можно найти здесь. Сетевой DevOps\nNetworking - основы Давайте для начала забудем о стороне DevOps, и теперь нам нужно очень кратко взглянуть на некоторые основы работы в сети.\nСетевые устройства Host — это любые устройства, которые отправляют или получают трафик. IP Address “определение” каждого хоста. (адрес)\nNetwork — (Сеть) это то, что транспортирует трафик между хостами. Если бы у нас не было сетей, было бы много ручного перемещения данных! Логическая группа хостов, для которых требуется аналогичное подключение. Switches (Коммутаторы) облегчают связь внутри сети. Коммутатор пересылает пакеты данных между хостами. Коммутатор отправляет пакеты напрямую хостам.\nСеть: группа хостов, которым требуется одинаковое подключение. Хосты в сети используют одно и то же пространство IP-адресов. Маршрутизатор (Router) облегчает связь между сетями. Если мы сказали ранее, что коммутатор следит за связью внутри сети, маршрутизатор позволяет нам объединить эти сети или, по крайней мере, предоставить им доступ друг к другу, если это разрешено. Маршрутизатор может обеспечить точку контроля трафика (безопасность, фильтрация, перенаправление). Все больше и больше коммутаторов теперь также предоставляют некоторые из этих функций.\nМаршрутизаторы узнают, к каким сетям они подключены. Это известно как маршруты, таблица маршрутизации — это все сети, о которых знает маршрутизатор.\nМаршрутизатор имеет IP-адрес в сетях, к которым он подключен. Этот IP-адрес также будет использоваться каждым хостом за пределами их локальной сети, также известной как шлюз.\nМаршрутизаторы также создают иерархию в сетях, о которой я упоминал ранее.\nКоммутаторы и маршрутизаторы (Switches vs Routers ) Маршрутизация – это процесс перемещения данных между сетями.\nМаршрутизатор — это устройство, основной задачей которого является маршрутизация. Коммутация — это процесс перемещения данных в сети.\nКоммутатор — это устройство, основное назначение которого — коммутация. Это во многом базовый обзор устройств, поскольку мы знаем, что существует множество различных сетевых устройств, таких как:\nAccess Points Firewalls Load Balancers Layer 3 Switches IDS / IPS Proxies Virtual Switches Virtual Routers Хотя все эти устройства будут выполнять маршрутизацию и/или коммутацию.\nВ течение следующих нескольких дней мы собираемся узнать немного больше об этом списке.\nOSI Model Network Protocols DNS (Domain Name System) NAT DHCP Subnets Ресурсы Computer Networking full course\n","description":"Общая картина - DevOps и Сеть","title":"21. DevOps настройка сети","uri":"/ru/docs/90daysofdevops/day21/"},{"content":"В Python есть несколько различных конструкций параллелизма, таких как threading, queues и мультипроцессинг. Раньше модуль threading был основным способом реализации multiprocessing. Несколько лет назад в набор стандартных библиотек Python был добавлен модуль multiprocessing. Эта глава будет посвящена использованию потоков и очередей.\nИспользование потоков Мы начнем с простого примера, который просто демонстрирует работу потоков. Мы создадим подкласс класса Thread и заставим его выводить свое имя в stdout. Приступим к кодированию!\nimport random import time from threading import Thread class MyThread(Thread): \"\"\" A threading example \"\"\" def __init__(self, name): \"\"\"Initialize the thread\"\"\" Thread.__init__(self) self.name = name def run(self): \"\"\"Run the thread\"\"\" amount = random.randint(3, 15) time.sleep(amount) msg = \"%s is running\" % self.name print(msg) def create_threads(): \"\"\" Create a group of threads \"\"\" for i in range(5): name = \"Thread #%s\" % (i+1) my_thread = MyThread(name) my_thread.start() if __name__ == \"__main__\": create_threads() В приведенном выше коде мы импортируем модуль Python random, модуль time и импортируем класс Thread из модуля threading. Далее мы создаем подкласс Thread и переопределяем его метод init, чтобы он принимал аргумент, который мы обозначим как name. Чтобы запустить поток, нужно вызвать его метод start(). Когда вы запускаете поток, автоматически вызывается метод run. Мы переопределили метод run потока, чтобы заставить его выбрать случайный промежуток времени для сна. Приведенный здесь пример random.randint заставит Python случайным образом выбрать число от 3 до 15. Затем мы заставим поток спать то количество секунд, которое мы только что случайно выбрали, чтобы имитировать, что он действительно что-то делает. Наконец, мы выводим имя потока, чтобы дать пользователю знать, что поток завершен.\nФункция create_threads создаст 5 потоков, присвоив каждому из них уникальное имя. Если вы запустите этот код, вы должны увидеть что-то вроде этого:\nThread #2 is running Thread #3 is running Thread #1 is running Thread #4 is running Thread #5 is running Порядок вывода будет отличаться каждый раз. Попробуйте выполнить код несколько раз, чтобы увидеть смену порядка. Теперь давайте напишем что-нибудь более практичное!\nНаписание потокового загрузчика Предыдущий пример был не очень полезен, кроме как в качестве инструмента для объяснения работы потоков. Поэтому в этом примере мы создадим класс Thread, который сможет загружать файлы из Интернета. Налоговая служба США имеет множество PDF-форм, которые граждане используют для уплаты налогов. Мы будем использовать этот бесплатный ресурс для нашей демонстрации. Вот код:\nimport os import urllib2 from threading import Thread class DownloadThread(Thread): \"\"\" A threading example that can download a file \"\"\" def __init__(self, url, name): \"\"\"Initialize the thread\"\"\" Thread.__init__(self) self.name = name self.url = url def run(self): \"\"\"Run the thread\"\"\" handle = urllib2.urlopen(self.url) fname = os.path.basename(self.url) with open(fname, \"wb\") as f_handler: while True: chunk = handle.read(1024) if not chunk: break f_handler.write(chunk) msg = \"%s has finished downloading %s!\" % (self.name, self.url) print(msg) def main(urls): \"\"\" Run the program \"\"\" for item, url in enumerate(urls): name = \"Thread %s\" % (item+1) thread = DownloadThread(url, name) thread.start() if __name__ == \"__main__\": urls = [\"http://www.irs.gov/pub/irs-pdf/f1040.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040a.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040ez.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040es.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"] main(urls) По сути, это полная переработка первого сценария. В нем мы импортируем модули os и urllib2, а также модуль threading. Мы будем использовать urllib2 для выполнения фактической загрузки внутри класса потока. Модуль os используется для извлечения имени загружаемого файла, чтобы мы могли использовать его для создания файла с таким же именем на нашей машине. В классе DownloadThread мы настраиваем init для приема url и имени потока. В методе run мы открываем url, извлекаем имя файла и затем используем это имя для именования / создания файла на диске. Затем мы используем цикл while для загрузки файла по килобайту за раз и записи его на диск. После завершения сохранения файла мы выводим имя потока и url, который закончил загрузку.\nВерсия кода для Python 3 немного отличается. Вы должны импортировать urllib вместо urllib2 и использовать urllib.request.urlopen вместо urllib2.urlopen. Вот код, чтобы вы могли увидеть разницу:\n# Python 3 version import os import urllib.request from threading import Thread class DownloadThread(Thread): \"\"\" A threading example that can download a file \"\"\" def __init__(self, url, name): \"\"\"Initialize the thread\"\"\" Thread.__init__(self) self.name = name self.url = url def run(self): \"\"\"Run the thread\"\"\" handle = urllib.request.urlopen(self.url) fname = os.path.basename(self.url) with open(fname, \"wb\") as f_handler: while True: chunk = handle.read(1024) if not chunk: break f_handler.write(chunk) msg = \"%s has finished downloading %s!\" % (self.name, self.url) print(msg) def main(urls): \"\"\" Run the program \"\"\" for item, url in enumerate(urls): name = \"Thread %s\" % (item+1) thread = DownloadThread(url, name) thread.start() if __name__ == \"__main__\": urls = [\"http://www.irs.gov/pub/irs-pdf/f1040.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040a.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040ez.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040es.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"] main(urls) Использование Queues Очередь(Queues Python) может быть использована для стековых реализаций «пришел первым – ушел первым» (first-in-first-out (FIFO)) или же «пришел последним – ушел последним» (last-in-last-out (LILO)) , если вы используете их правильно. В этом разделе мы смешаем потоки и создадим простой сценарий загрузки файлов, чтобы продемонстрировать, как работают очереди в случаях, когда нам нужен параллелизм.\nЧтобы объяснить, как работают Queues, мы перепишем сценарий загрузки из предыдущего раздела, чтобы использовать Queues. Давайте начнем!\nimport os import threading import urllib.request from queue import Queue class Downloader(threading.Thread): \"\"\"Threaded File Downloader\"\"\" def __init__(self, queue): \"\"\"Initialize the thread\"\"\" threading.Thread.__init__(self) self.queue = queue def run(self): \"\"\"Run the thread\"\"\" while True: # gets the url from the queue url = self.queue.get() # download the file self.download_file(url) # send a signal to the queue that the job is done self.queue.task_done() def download_file(self, url): \"\"\"Download the file\"\"\" handle = urllib.request.urlopen(url) fname = os.path.basename(url) with open(fname, \"wb\") as f: while True: chunk = handle.read(1024) if not chunk: break f.write(chunk) def main(urls): \"\"\" Run the program \"\"\" queue = Queue() # create a thread pool and give them a queue for i in range(5): t = Downloader(queue) t.setDaemon(True) t.start() # give the queue some data for url in urls: queue.put(url) # wait for the queue to finish queue.join() if __name__ == \"__main__\": urls = [\"http://www.irs.gov/pub/irs-pdf/f1040.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040a.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040ez.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040es.pdf\", \"http://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"] main(urls) Давайте немного разложим это по полочкам. Прежде всего, нам нужно посмотреть на определение главной функции, чтобы увидеть, как все это работает. Здесь мы видим, что она принимает список url адресов. Затем функция main создает экземпляр очереди, который она передает 5 демонизированным потокам. Основная разница между демонизированным и недемонизированным потоком в том, что вам нужно отслеживать недемонизированные потоки и закрывать их вручную, в то время как поток «демон» нужно только запустить и забыть о нем. Когда ваше приложение закроется, закроется и поток. Далее мы загрузили очередь (при помощи метода put) вместе с переданными url.\nНаконец, мы говорим очереди ждать, пока потоки выполнят свою обработку, используя метод join. В классе загрузки у нас есть строка self.queue.get(), которая блокирует очередь до тех пор, пока ей не будет что вернуть. Это означает, что потоки просто сидят без дела, ожидая, пока очередь что-нибудь получит. Это также означает, что для того, чтобы поток мог получить что-то из очереди, он должен вызвать метод очереди get. Таким образом, по мере добавления или помещения элементов в очередь пул потоков будет забирать или получать элементы и обрабатывать их. Это также известно как dequeing. Когда все элементы в очереди обработаны, сценарий завершает работу и выходит из программы. На моей машине он загружает все 5 документов менее чем за секунду.\nПодведение итогов Теперь вы знаете, как использовать потоки и очереди как в теории, так и на практике. Потоки особенно полезны, когда вы создаете пользовательский интерфейс и хотите сохранить его работоспособность. Без потоков пользовательский интерфейс стал бы неотзывчивым и завис бы во время загрузки большого файла или выполнения большого запроса к базе данных. Чтобы этого не произошло, вы выполняете длительные процессы в потоках, а затем возвращаетесь к интерфейсу, когда закончите.\n","description":"Python 101","title":"21. Модуль потоков Thread","uri":"/ru/docs/python101/chapter21_thread/"},{"content":"Модель OSI — 7 уровней Общая цель сети как отрасли состоит в том, чтобы позволить двум хостам обмениваться данными. Если я хочу передать данные от одного хоста к другому хосту, мне нужно будет что-то подключить к этому хосту, перейти к другому хосту, подключить его к первому хосту.\nСеть позволяет нам автоматизировать это, позволяя хосту автоматически обмениваться данными по сети, и для этого эти хосты должны следовать набору правил.\nЭто ничем не отличается от любого другого языка. У английского есть набор правил, которым должны следовать два носителя английского языка. У испанского есть свой собственный набор правил.\nПравила организации сети разделены на семь разных уровней, и эти уровни известны как модель OSI.\nВведение в модель OSI Модель OSI (модель взаимодействия открытых систем)/(Open Systems Interconnection Model) — это структура, используемая для описания функций сетевой системы. Модель OSI характеризует вычислительные функции в виде универсального набора правил и требований для обеспечения функциональной совместимости между различными продуктами и программным обеспечением. В эталонной модели OSI обмен данными между вычислительной системой разделен на семь различных уровней абстракции: физический, канальный, сетевой, транспортный, сеансовый, презентационный и прикладной (Physical, Data Link, Network, Transport, Session, Presentation, Application). Физический Уровень 1 в модели OSI, известный как физический, предполагает возможность передачи данных с одного хоста на другой с помощью средств, будь то физический кабель или мы также можем рассмотреть Wi-Fi на этом уровне. Мы также можем увидеть здесь более устаревшее оборудование вокруг концентраторов и повторителей для передачи данных с одного хоста на другой. Канал передачи данных Уровень 2, канал передачи данных обеспечивает передачу данных от узла к узлу, где данные упакованы в кадры. Существует также уровень исправления ошибок, которые могли возникнуть на физическом уровне. Здесь мы также вводим или впервые видим MAC-адреса.\nЗдесь мы видим первое упоминание о коммутаторах, о которых мы рассказали в первый день нашей работы с сетью День 21 Сеть Вы, вероятно, слышали термин «коммутаторы уровня 3» или «коммутаторы уровня 2». В нашей модели OSI уровень 3. Цель сети — прямая(end to end) доставка, именно здесь мы видим наши IP-адреса, также упомянутые в обзоре первого дня.\nМаршрутизаторы и хосты существуют на уровне 3, помните, что маршрутизатор — это возможность маршрутизации между несколькими сетями. Все, что имеет IP, может считаться уровнем 3. Так зачем же нам нужны схемы адресации как на уровне 2, так и на уровне 3? (MAC-адреса и IP-адреса)\nЕсли мы подумаем о передаче данных с одного хоста на другой, каждый хост имеет IP-адрес, но между ними есть несколько коммутаторов и маршрутизаторов. Каждое из устройств имеет этот MAC-адрес уровня 2.\nMAC-адрес уровня 2 будет передаваться только от хоста к коммутатору/маршрутизатору, он ориентирован на переходы, где IP-адреса уровня 3 будут оставаться с этим пакетом данных, пока он не достигнет своего конечного хоста. (Концы с концами)\nIP-адреса — уровень 3 = сквозная доставка\nMAC-адреса — уровень 2 = доставка между переходами\nТеперь есть сетевой протокол, который мы рассмотрим, но не сегодня, называемый ARP (протокол разрешения адресов), который связывает наши адреса Layer3 и Layer2.\nТранспорт Предоставление услуг между услугами, уровень 4 предназначен для различения потоков данных. Точно так же, как уровни 3 и 2 имели свои схемы адресации, на уровне 4 у нас есть порты.\nСессия, Презентация, Приложение Различие между слоями 5, 6, 7 немного расплывчато\nСтоит взглянуть на IP-модель TCP, чтобы получить более свежее представление.\nДавайте теперь попробуем объяснить, что на самом деле происходит, когда хосты общаются друг с другом, используя этот сетевой стек. На одном хосте есть приложение, которое будет генерировать данные, предназначенные для отправки на другой хост.\nИсходный хост будет проходить так называемый процесс инкапсуляции. Эти данные будут сначала отправлены на уровень 4.\nУровень 4 добавит заголовок к этим данным, что может облегчить задачу уровня 4, которая заключается в доставке услуг. Это будет порт, использующий либо TCP, либо UDP. Он также будет включать исходный порт и порт назначения.\nЭто также может быть известно как сегмент (данные и порт).\nЭтот сегмент будет передан по стеку osi на уровень 3, сетевой уровень, сетевой уровень добавит к этим данным еще один заголовок. Этот заголовок будет способствовать цели уровня 3, который является сквозной доставкой, что означает, что в этом заголовке у вас будет IP-адрес источника и IP-адрес назначения, заголовок плюс данные также могут называться пакетом.\nЗатем уровень 3 возьмет этот пакет и передаст его уровню 2, уровень 2 еще раз добавит еще один заголовок к этим данным для достижения цели уровня 2 по доставке переходов, что означает, что этот заголовок будет включать в себя MAC-адреса источника и получателя. Это называется кадром, когда у вас есть заголовок и данные уровня 2.\nЗатем этот кадр преобразуется в единицы и нули и отправляется по физическому кабелю уровня 1 или Wi-Fi.\nВыше я упомянул названия для каждого уровня заголовка и данных, но решил нарисовать и это.\nОчевидно, что приложение, отправляющее данные, отправляется куда-то, поэтому получение происходит в обратном порядке, чтобы получить эту резервную копию в стеке и на принимающем хосте. Ресурсы Computer Networking full course Practical Networking ","description":"7 уровней модели OSI","title":"22. Открытая сетевая модель OSI","uri":"/ru/docs/90daysofdevops/day22/"},{"content":"Python предоставляет разработчику несколько инструментов для работы с датами и временем. В этой главе мы рассмотрим модули datetime и time. Мы изучим, как они работают, и некоторые распространенные способы их использования. Начнем с модуля datetime!\nМодуль datetime Мы познакомимся со следующими классами модуля datetime:\ndatetime.date datetime.timedelta datetime.datetime Они будут охватывать большинство случаев, когда вам понадобится использовать дату и объект datetime в Python. Существует также класс tzinfo для работы с часовыми поясами, который мы не будем рассматривать. Не стесняйтесь заглянуть в документацию Python для получения дополнительной информации об этом классе.\ndatetime.date Python может представлять даты несколькими различными способами. Сначала мы рассмотрим формат datetime.date, поскольку он является одним из самых простых объектов даты.\n\u003e\u003e\u003e datetime.date(2012, 13, 14) Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e builtins.ValueError: month must be in 1..12 \u003e\u003e\u003e datetime.date(2012, 12, 14) datetime.date(2012, 12, 14) Этот код показывает, как создать простой объект даты. Класс date принимает три аргумента: год, месяц и день. Если вы передадите ему недопустимое значение, вы увидите ошибку ValueError, как показано выше. В противном случае будет возвращен объект datetime.date. Давайте рассмотрим другой пример:\n\u003e\u003e\u003e import datetime \u003e\u003e\u003e d = datetime.date(2012, 12, 14) \u003e\u003e\u003e d.year 2012 \u003e\u003e\u003e d.day 14 \u003e\u003e\u003e d.month 12 Здесь мы присваиваем объект date переменной d. Теперь мы можем обращаться к различным компонентам даты по имени, например, d.year или d.month. Теперь давайте узнаем, какой сегодня день:\n\u003e\u003e\u003e datetime.date.today() datetime.date(2014, 3, 5) Это может быть полезно, когда вам нужно записать, какой сегодня день. Или, возможно, вам нужно произвести вычисления на основе сегодняшнего дня. В любом случае, это удобный метод.\ndatetime.datetime Объект datetime.datetime содержит всю информацию из datetime.date плюс объект datetime.time. Давайте создадим пару примеров, чтобы лучше понять разницу между этим объектом и объектом datetime.date.\n\u003e\u003e\u003e datetime.datetime(2014, 3, 5) datetime.datetime(2014, 3, 5, 0, 0) \u003e\u003e\u003e datetime.datetime(2014, 3, 5, 12, 30, 10) datetime.datetime(2014, 3, 5, 12, 30, 10) \u003e\u003e\u003e d = datetime.datetime(2014, 3, 5, 12, 30, 10) \u003e\u003e\u003e d.year 2014 \u003e\u003e\u003e d.second 10 \u003e\u003e\u003e d.hour 12 Здесь мы видим, что datetime.datetime принимает несколько дополнительных аргументов: год, месяц, день, час, минуту и секунду. Он также позволяет указывать микросекунды и информацию о часовом поясе. При работе с базами данных вы часто будете использовать подобные объекты. Чаще всего вам нужно преобразовать формат даты или времени Python в формат даты или временной метки SQL. Сегодняшний день можно узнать с помощью datetime.datetime, используя два различных метода:\n\u003e\u003e\u003e datetime.datetime.today() datetime.datetime(2014, 3, 5, 17, 56, 10, 737000) \u003e\u003e\u003e datetime.datetime.now() datetime.datetime(2014, 3, 5, 17, 56, 15, 418000) В модуле datetime есть еще один метод, о котором вам следует знать, - strftime. Этот метод позволяет разработчику создать строку, которая представляет время в более удобном для восприятия формате. В документации по Python, раздел 8.1.7, есть целая таблица вариантов форматирования, с которой вам следует ознакомиться. Мы рассмотрим пару примеров, чтобы показать вам возможности этого метода:\n\u003e\u003e\u003e datetime.datetime.today().strftime(\"%Y%m%d\") '20140305' \u003e\u003e\u003e today = datetime.datetime.today() \u003e\u003e\u003e today.strftime(\"%m/%d/%Y\") '03/05/2014' \u003e\u003e\u003e today.strftime(\"%Y-%m-%d-%H.%M.%S\") '2014-03-05-17.59.53' Первый пример является своего рода хаком. Он показывает, как преобразовать сегодняшний объект datetime в строку, соответствующую формату YYYYMMDD (год, месяц, день). Второй пример лучше. Здесь мы присваиваем сегодняшний объект datetime переменной под названием today, а затем пробуем две различные операции форматирования строки. Первая добавляет прямые косые черты между элементами datetime, а также переставляет их так, чтобы получились месяц, день, год. Последний пример создает своеобразную временную метку, которая имеет довольно типичный формат: YYYY-MM-DD.HH.MM.SS. Если вы хотите перейти к двузначному году, вы можете заменить %Y на %y.\ndatetime.timedelta Объект datetime.timedelta представляет длительность времени. Другими словами, это разница между двумя датами или временем. Давайте рассмотрим простой пример:\n\u003e\u003e\u003e now = datetime.datetime.now() \u003e\u003e\u003e now datetime.datetime(2014, 3, 5, 18, 13, 51, 230000) \u003e\u003e\u003e then = datetime.datetime(2014, 2, 26) \u003e\u003e\u003e delta = now - then \u003e\u003e\u003e type(delta) \u003ctype 'datetime.timedelta'\u003e \u003e\u003e\u003e delta.days 7 \u003e\u003e\u003e delta.seconds 65631 Здесь мы создаем два объекта datetime. Один для сегодняшнего дня, а другой - для недели назад. Затем мы берем разницу между ними. Это возвращает объект timedelta, который мы можем использовать, чтобы узнать количество дней или секунд между двумя датами. Если вам нужно узнать количество часов или минут между двумя датами, вам придется прибегнуть к математическим вычислениям. Вот один из способов сделать это:\n\u003e\u003e\u003e seconds = delta.total_seconds() \u003e\u003e\u003e hours = seconds // 3600 \u003e\u003e\u003e hours 186.0 \u003e\u003e\u003e minutes = (seconds % 3600) // 60 \u003e\u003e\u003e minutes 13.0 Это говорит нам о том, что в неделе 186 часов и 13 минут. Обратите внимание, что в качестве оператора деления мы используем двойную прямую косую черту. Это известно как floor division.\nТеперь мы готовы двигаться дальше и узнать немного о модуле time!\nМодуль time Модуль time предоставляет разработчику Python доступ к различным функциям, связанным со временем. Модуль времени основан на так называемой эпохе - точке, с которой начинается отсчет времени. Для Unix-систем эпохой является 1970 год. Чтобы узнать, какая эпоха в вашей системе, попробуйте выполнить следующее:\n\u003e\u003e\u003e import time \u003e\u003e\u003e time.gmtime(0) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0) Я запустил эту программу на Windows 7, и она тоже считает, что время началось в 1970 году. В любом случае, в этом разделе мы будем изучать следующие функции, связанные со временем:\ntime.ctime time.sleep time.strftime time.time Давайте начнем!\ntime.ctime Функция time.ctime преобразует время в секундах начиная с эпохи в строку, показывающую местное время. Если вы не передадите ей ничего, то будет возвращено текущее время. Давайте опробуем пару примеров:\n\u003e\u003e\u003e import time \u003e\u003e\u003e time.ctime() 'Thu Mar 06 07:28:48 2014' \u003e\u003e\u003e time.ctime(1384112639) 'Sun Nov 10 13:43:59 2013' Здесь показаны результаты вызова ctime , как со случайным набором секунд, начиная с эпохи, так и с пустным значением. Я видел, как подобные вещи используются, когда кто-то сохраняет дату в виде секунд от эпохи, а затем хочет преобразовать ее во что-то понятное человеку. Немного проще, сохранить большое целое число (или длинное) в базу данных, чем страдать над ним, форматируя объект datetime в какой-либо объект даты, который принимает база данных. Конечно, это также имеет свой недостаток: вам, возможно, нужно будет преобразовать целое число или значение с плавающей запятой обратно в строку.\ntime.sleep Функция time.sleep дает разработчику возможность приостановить выполнение вашего сценария на заданное количество секунд. Это как добавление паузы в вашу программу.Я нашел этот класс особенно полезным, когда мне нужно было подождать несколько секунд, пока закроется файл, или база данных закончит выполнять свою задачу. Давайте взглянем на пример. Откройте новое окно в IDLE и сохраните следующий код:\nimport time for x in range(5): time.sleep(2) print(\"Slept for 2 seconds\") Теперь запустите код в IDLE. Это можно сделать, перейдя в меню Run, а затем выбрав пункт меню Run module. После этого вы увидите, как модуль выведет фразу Slept for 2 seconds пять раз с двухсекундной паузой между каждой печатью. Это действительно так просто в использовании!\n##time.strftime\nМодуль time имеет функцию strftime, которая работает практически так же, как и версия datetime. Разница в основном в том, что она принимает на вход: кортеж или объект struct_time, подобный тем, которые возвращаются при вызове time.gmtime() или time.localtime(). Вот небольшой пример:\n\u003e\u003e\u003e time.strftime(\"%Y-%m-%d-%H.%M.%S\", time.localtime()) '2014-03-06-20.35.56 Этот код очень похож на код временной метки, который мы создали в части datetime этой главы. Я думаю, что метод datetime немного более интуитивен, поскольку вы просто создаете объект datetime.datetime и затем вызываете его метод strftime с нужным вам форматом. В модуле time вам нужно передать формат плюс кортеж времени. Вы сами решаете, какой из этих вариантов наиболее удобен для вас.\ntime.time Функция time.time возвращает время в секундах от эпохи в виде числа с плавающей точкой. Давайте посмотрим:\n\u003e\u003e\u003e time.time() 1394199262.318 Весьма просто. Это можно использовать, когда вы хотите сохранить текущее время в базу данных, но не хотите возиться с преобразованием его в метод datetime базы данных. Вы также можете вспомнить, что метод ctime принимает время в секундах, поэтому мы можем использовать time.time, чтобы получить количество секунд, которое нужно передать в ctime, вот так:\n\u003e\u003e\u003e time.ctime(time.time()) 'Fri Mar 07 07:36:38 2014' Если вы немного покопаетесь в документации к модулю времени или просто немного поэкспериментируете с ним, вы, вероятно, найдете еще несколько вариантов использования этой функции.\nПодведение итогов На данном этапе вы должны знать, как работать с датами и временем с помощью стандартных модулей Python. Python дает вам много возможностей, когда дело доходит до работы с датами. Эти модули пригодятся вам, если вам понадобится создать приложение, которое будет отслеживать назначенные встречи или должно работать в определенные дни. Они также полезны при работе с базами данных.\n","description":"Python 101","title":"22. Работа с датами и временем","uri":"/ru/docs/python101/chapter22_time/"},{"content":"Python имеет встроенные возможности разбора XML, доступ к которым можно получить с помощью модуля xml. В этой статье мы сосредоточимся на двух подмодулях модуля xml:\nminidom ElementTree . Мы начнем с minidom просто потому, что этот метод раньше был де-факто методом разбора XML. Затем мы рассмотрим, как вместо него использовать ElementTree.\nРабота с minidom Для начала необходимо разобрать XML. Взгляните на следующий короткий пример XML:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Это довольно типичный XML, и на самом деле он довольно интуитивно понятен для чтения. В будущем вы, скорее всего, столкнетесь с более сложным примером XML, так что в нашем случае мы работаем с очень удобным материалом. В любом случае, сохраните описанный выше код XML под следующим названием: appt.xml\nДавайте потратим некоторое время на ознакомление с тем, как разобрать этот файл с помощью модуля Python minidom. Это довольно длинный кусок кода, так что приготовьтесь.\nimport xml.dom.minidom import urllib.request class ApptParser(object): def __init__(self, url, flag='url'): self.list = [] self.appt_list = [] self.flag = flag self.rem_value = 0 xml = self.getXml(url) self.handleXml(xml) def getXml(self, url): try: print(url) f = urllib.request.urlopen(url) except: f = url doc = xml.dom.minidom.parse(f) node = doc.documentElement if node.nodeType == xml.dom.Node.ELEMENT_NODE: print('Element name: %s' % node.nodeName) for (name, value) in node.attributes.items(): print(' Attr -- Name: %s Value: %s' % (name, value)) return node def handleXml(self, xml): rem = xml.getElementsByTagName('zAppointments') appointments = xml.getElementsByTagName(\"appointment\") self.handleAppts(appointments) def getElement(self, element): return self.getText(element.childNodes) def handleAppts(self, appts): for appt in appts: self.handleAppt(appt) self.list = [] def handleAppt(self, appt): begin = self.getElement(appt.getElementsByTagName(\"begin\")[0]) duration = self.getElement(appt.getElementsByTagName(\"duration\")[0]) subject = self.getElement(appt.getElementsByTagName(\"subject\")[0]) location = self.getElement(appt.getElementsByTagName(\"location\")[0]) uid = self.getElement(appt.getElementsByTagName(\"uid\")[0]) self.list.append(begin) self.list.append(duration) self.list.append(subject) self.list.append(location) self.list.append(uid) if self.flag == 'file': try: state = self.getElement(appt.getElementsByTagName(\"state\")[0]) self.list.append(state) alarm = self.getElement(appt.getElementsByTagName(\"alarmTime\")[0]) self.list.append(alarm) except Exception as e: print(e) self.appt_list.append(self.list) def getText(self, nodelist): rc = \"\" for node in nodelist: if node.nodeType == node.TEXT_NODE: rc = rc + node.data return rc if __name__ == \"__main__\": appt = ApptParser(\"appt.xml\") print(appt.appt_list) Этот код основан на примере из документации Python, и я должен признать, что моя мутация этого кода кажется мне немного уродливой. Давайте немного разберем этот код. Параметр url, который вы видите в классе ApptParser, может быть либо url, либо файлом. В методе getXml мы используем обработчик исключений, чтобы попытаться открыть url. Если он выдает ошибку, то мы считаем, что url - это путь к файлу. Далее мы используем метод minidom’s parse для разбора XML. Затем мы извлекаем узел из XML. Мы проигнорируем условие, поскольку оно не имеет значения для данного обсуждения. Наконец, мы возвращаем объект node.\nТехнически, node - это XML, и мы передаем его методу handleXml. Чтобы получить все экземпляры назначений в XML, мы делаем следующее:\nxml.getElementsByTagName(\"appointment\"). Затем мы передаем эту информацию в метод handleAppts. Это большой объем информации. Возможно, было бы неплохо немного отрефакторить этот код, чтобы вместо передачи информации он просто устанавливал переменные класса, а затем вызывал следующий метод без каких-либо аргументов. Я оставлю это в качестве упражнения для читателя. В любом случае, все, что делает метод handleAppts, это перебирает каждую встречу и вызывает метод handleAppt, чтобы извлечь из нее некоторую дополнительную информацию, добавить данные в список и добавить этот список в другой список. Идея заключалась в том, чтобы в итоге получить список списков, содержащих все необходимые данные о моих встречах.\nВы заметите, что метод handleAppt вызывает метод getElement, который вызывает метод getText. Технически, вы можете пропустить вызов getElement и просто вызвать getText напрямую. С другой стороны, вам может потребоваться дополнительная обработка getElement для преобразования текста в другой тип перед возвращением его обратно. Например, вы можете захотеть преобразовать числа в целые числа, плавающие или объекты decimal.Decimal.\nДавайте попробуем еще один пример с minidom, прежде чем двигаться дальше. Мы будем использовать пример XML с сайта Microsoft MSDN: http://msdn.microsoft.com/en-us/library/ms762271%28VS.85%29.aspx. Сохраните следующий XML как example.xml\n\u003c?xml version=\"1.0\"?\u003e \u003ccatalog\u003e \u003cbook id=\"bk101\"\u003e \u003cauthor\u003eGambardella, Matthew\u003c/author\u003e \u003ctitle\u003eXML Developer's Guide\u003c/title\u003e \u003cgenre\u003eComputer\u003c/genre\u003e \u003cprice\u003e44.95\u003c/price\u003e \u003cpublish_date\u003e2000-10-01\u003c/publish_date\u003e \u003cdescription\u003eAn in-depth look at creating applications with XML.\u003c/description\u003e \u003c/book\u003e \u003cbook id=\"bk102\"\u003e \u003cauthor\u003eRalls, Kim\u003c/author\u003e \u003ctitle\u003eMidnight Rain\u003c/title\u003e \u003cgenre\u003eFantasy\u003c/genre\u003e \u003cprice\u003e5.95\u003c/price\u003e \u003cpublish_date\u003e2000-12-16\u003c/publish_date\u003e \u003cdescription\u003eA former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.\u003c/description\u003e \u003c/book\u003e \u003cbook id=\"bk103\"\u003e \u003cauthor\u003eCorets, Eva\u003c/author\u003e \u003ctitle\u003eMaeve Ascendant\u003c/title\u003e \u003cgenre\u003eFantasy\u003c/genre\u003e \u003cprice\u003e5.95\u003c/price\u003e \u003cpublish_date\u003e2000-11-17\u003c/publish_date\u003e \u003cdescription\u003eAfter the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.\u003c/description\u003e \u003c/book\u003e \u003c/catalog\u003e В данном примере мы просто разберем XML, извлечем названия книг и выведем их в stdout. Вот код:\nimport xml.dom.minidom as minidom def getTitles(xml): \"\"\" Print out all titles found in xml \"\"\" doc = minidom.parse(xml) node = doc.documentElement books = doc.getElementsByTagName(\"book\") titles = [] for book in books: titleObj = book.getElementsByTagName(\"title\")[0] titles.append(titleObj) for title in titles: nodes = title.childNodes for node in nodes: if node.nodeType == node.TEXT_NODE: print(node.data) if __name__ == \"__main__\": document = 'example.xml' getTitles(document) Этот код - всего лишь одна короткая функция, принимающая один аргумент - XML-файл. Мы импортируем модуль minidom и даем ему такое же имя, чтобы на него было легче ссылаться. Затем мы разбираем XML. Первые две строки в функции практически такие же, как и в предыдущем примере. Мы используем метод getElementsByTagName для захвата нужных нам частей XML, затем перебираем результаты и извлекаем из них названия книг. На самом деле извлекаются объекты заголовков, поэтому нам нужно также выполнить итерацию и извлечь обычный текст, для чего мы используем вложенный цикл for.\nТеперь давайте уделим немного времени на то, чтобы опробовать другой подмодуль модуля xml под названием ElementTree.\nПарсинг с помощью ElementTree В этом разделе вы узнаете, как создать XML-файл, отредактировать XML и разобрать XML с помощью ElementTree. Для сравнения мы будем использовать тот же XML, который мы использовали в предыдущем разделе, чтобы проиллюстрировать различия между использованием minidom и ElementTree. Вот исходный XML:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Давайте начнем с изучение того, как создать этот фрагмент XML программно с помощью Python!\nКак создать XML с помощью ElementTree Создать XML с помощью ElementTree очень просто. В этом разделе мы попытаемся создать приведенный выше XML с помощью Python. Вот код:\nimport xml.etree.ElementTree as xml def createXML(filename): \"\"\" Create an example XML file \"\"\" root = xml.Element(\"zAppointments\") appt = xml.Element(\"appointment\") root.append(appt) # add appointment children begin = xml.SubElement(appt, \"begin\") begin.text = \"1181251680\" uid = xml.SubElement(appt, \"uid\") uid.text = \"040000008200E000\" alarmTime = xml.SubElement(appt, \"alarmTime\") alarmTime.text = \"1181572063\" state = xml.SubElement(appt, \"state\") location = xml.SubElement(appt, \"location\") duration = xml.SubElement(appt, \"duration\") duration.text = \"1800\" subject = xml.SubElement(appt, \"subject\") tree = xml.ElementTree(root) with open(filename, \"w\") as fh: tree.write(fh) if __name__ == \"__main__\": createXML(\"appt.xml\") Если вы запустите этот код, вы должны получить что-то вроде нижеизложенного (возможно, все в одной строке):\n\u003czAppointments\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate /\u003e \u003clocation /\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject /\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Это довольно близко к оригиналу и, безусловно, является действительным XML. Хотя это не совсем то же самое, но достаточно близко. Давайте уделим немного времени коду и убедимся, что мы его поняли. Сначала мы создаем корневой элемент с помощью функции ElementTree’s Element. Затем мы создаем элемент назначения и добавляем его к корню. Затем мы создаем подэлементы, передавая объект элемента назначения (appt) в SubElement вместе с именем, например “begin”. Затем для каждого подэлемента мы устанавливаем свойство text, чтобы придать ему значение. В конце сценария мы создаем ElementTree и используем его для записи XML в файл.\nТеперь мы готовы узнать, как редактировать этот файл!\nКак редактировать XML с помощью ElementTree Редактировать XML с помощью ElementTree также просто. Однако, чтобы сделать все немного интереснее, мы добавим в XML еще один блок назначений:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003cappointment\u003e \u003cbegin\u003e1181253977\u003c/begin\u003e \u003cuid\u003esdlkjlkadhdakhdfd\u003c/uid\u003e \u003calarmTime\u003e1181588888\u003c/alarmTime\u003e \u003cstate\u003eTX\u003c/state\u003e \u003clocation\u003eDallas\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Теперь давайте напишем код, чтобы изменить значение каждого из тегов begin с секунд с момента эпохи на что-то более удобочитаемое. Для этого мы воспользуемся модулем time Python:\nimport time import xml.etree.cElementTree as ET def editXML(filename): \"\"\" Edit an example XML file \"\"\" tree = ET.ElementTree(file=filename) root = tree.getroot() for begin_time in root.iter(\"begin\"): begin_time.text = time.ctime(int(begin_time.text)) tree = ET.ElementTree(root) with open(\"updated.xml\", \"w\") as f: tree.write(f) if __name__ == \"__main__\": editXML(\"original_appt.xml\") Здесь мы создаем объект ElementTree (дерево) и извлекаем из него root. Затем мы используем метод iter() ElementTree, чтобы найти все теги с меткой “begin”. Обратите внимание, что метод iter() был добавлен в Python 2.7. В нашем цикле for мы устанавливаем свойство text каждого элемента в более удобочитаемый для человека формат времени с помощью time.ctime(). Обратите внимание, что при передаче строки в ctime нам пришлось преобразовать ее в целое число. Результат должен выглядеть примерно следующим образом:\n\u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003eThu Jun 07 16:28:00 2007\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate /\u003e \u003clocation /\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003cappointment\u003e \u003cbegin\u003eThu Jun 07 17:06:17 2007\u003c/begin\u003e \u003cuid\u003esdlkjlkadhdakhdfd\u003c/uid\u003e \u003calarmTime\u003e1181588888\u003c/alarmTime\u003e \u003cstate\u003eTX\u003c/state\u003e \u003clocation\u003eDallas\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Вы также можете использовать методы find() или findall() ElementTree для поиска определенных тегов в вашем XML. Метод find() просто найдет первый экземпляр, тогда как findall() найдет все теги с указанной меткой. Эти методы полезны для редактирования или для разбора, о чем мы поговорим в следующей теме!\nКак разобрать XML с помощью ElementTree Теперь мы научимся выполнять базовый разбор с помощью ElementTree. Сначала мы прочитаем код, а затем пройдемся по нему шаг за шагом, чтобы понять его. Обратите внимание, что этот код основан на первоначальном примере, но он должен работать и на втором.\nimport xml.etree.cElementTree as ET def parseXML(xml_file): \"\"\" Parse XML with ElementTree \"\"\" tree = ET.ElementTree(file=xml_file) print(tree.getroot()) root = tree.getroot() print(\"tag=%s, attrib=%s\" % (root.tag, root.attrib)) for child in root: print(child.tag, child.attrib) if child.tag == \"appointment\": for step_child in child: print(step_child.tag) # iterate over the entire tree print(\"-\" * 40) print(\"Iterating using a tree iterator\") print(\"-\" * 40) iter_ = tree.getiterator() for elem in iter_: print(elem.tag) # get the information via the children! print(\"-\" * 40) print(\"Iterating using getchildren()\") print(\"-\" * 40) appointments = root.getchildren() for appointment in appointments: appt_children = appointment.getchildren() for appt_child in appt_children: print(\"%s=%s\" % (appt_child.tag, appt_child.text)) if __name__ == \"__main__\": parseXML(\"appt.xml\") Вы уже должны понять, что и как работает, но в этом примере и предыдущем мы импортируем cElementTree вместо обычного ElementTree. Разница между этими двумя в том, что cElementTree основан на С, а не на Python, так что он намного быстрее. В любом случае, мы снова создаем объект ElementTree и извлекаем root из него. Обратите внимание на то, что мы выводим root, его тег и атрибуты. Далее мы покажем несколько способов итерации тегов. Первый цикл просто итерирует XML, дочку за дочкой. Таким образом выведется только дочерний код (назначение) с наивысшим уровнем , так что мы добавили оператор if, чтобы проверить дочерний код и выполнить его итерацию.\nДалее мы возьмем итератор из самого объекта дерева и выполним итерацию таким образом. Вы получите ту же информацию, но без лишних шагов в первом примере. Третий метод использует функцию getchildren() корня. Здесь снова нужен внутренний цикл, чтобы перебрать все дочерние элементы внутри каждого тега назначения. Последний пример использует метод iter() корня, чтобы просто перебрать все теги, которые соответствуют строке “begin”.\nКак упоминалось в предыдущем разделе, вы также можете использовать find() или findall(), чтобы помочь вам найти определенные теги или наборы тегов соответственно. Также обратите внимание, что каждый объект Element имеет свойство tag и свойство text, которые можно использовать для получения точной информации.\nПодведение итогов Теперь вы знаете, как использовать minidom для разбора XML. Вы также узнали, как использовать ElementTree для создания, редактирования и разбора XML. Существуют и другие библиотеки вне Python, которые предоставляют дополнительные методы работы с XML. Убедитесь в том, что вы пользуетесь понятным вам инструментом, так как данный вопрос может быть очень сложным и непонятным, если пытаться решить его неправильным инструментом.\n","description":"Python 101","title":"23. Модуль xml","uri":"/ru/docs/python101/chapter23_xml/"},{"content":"Протоколы сети Набор правил и сообщений, образующих стандарт.\nARP - Address Resolution Protocol - протокол разрешения адресов Если вы хотите по-настоящему разобраться в ARP, вы можете прочитать Internet Standard здесь RFC 826\nARP соединяет IP-адреса с фиксированными физическими адресами машин, также известными как MAC-адреса, в сети уровня 2.\nFTP - File Transfer Protocol - протокол передачи файлов Позволяет передавать файлы из источника в место назначения. Как правило, этот процесс аутентифицируется, но при настройке можно использовать анонимный доступ. Теперь вы будете чаще видеть FTPS, который обеспечивает подключение SSL/TLS к FTP-серверам от клиента для повышения безопасности. Этот протокол можно найти на прикладном уровне модели OSI.\nSMTP - Simple Mail Transfer Protocol - протокол передачи почты Почтовые серверы, используемые для передачи электронной почты, используют SMTP для отправки и получения почтовых сообщений. Вы по-прежнему обнаружите, что даже с Microsoft 365 протокол SMTP используется для той же цели.\nHTTP - Hyper Text Transfer Protocol - Протокол передачи гипертекста HTTP является основой Интернета и просмотра контента. Дает нам возможность легко получить доступ к нашим любимым веб-сайтам. HTTP по-прежнему широко используется, но HTTPS используется или должен использоваться на большинстве ваших любимых сайтов.\nSSL - Secure Sockets Layer | TLS - Transport Layer Security - Уровень защищенных сокетов | TLS — безопасность транспортного уровня TLS заменил SSL, TLS — это криптографический протокол, который обеспечивает безопасность связи по сети. Его можно найти в почте, мессенджерах и других приложениях, но чаще всего он используется для защиты HTTPS.\nHTTPS - HTTP secured with SSL/TLS - HTTP, защищенный с помощью SSL/TLS Расширение HTTP, используемое для безопасной связи по сети, HTTPS шифруется с помощью TLS, как упоминалось выше. Основное внимание здесь уделялось обеспечению аутентификации, конфиденциальности и целостности при обмене данными между хостами.\nDNS - Domain Name System - система доменных имен DNS используется для сопоставления удобных для человека доменных имен, например, все мы знаем google.com, но если вы откроете браузер и введете 8.8.8.8 вы получите Google в том виде, в каком мы его знаем. Однако удачи вам в попытках запомнить все IP-адреса всех ваших веб-сайтов, на некоторых из них мы даже используем Google для поиска информации.\nИменно здесь в дело вступает DNS, он гарантирует доступность хостов, служб и других ресурсов.\nНа всех хостах, если им требуется подключение к Интернету, они должны иметь DNS, чтобы иметь возможность разрешать эти доменные имена. DNS — это область, на изучение которой вы можете потратить дни и годы. Я бы также сказал по опыту, что DNS в основном является распространенной причиной всех ошибок, когда речь идет о сети. Однако не уверен, что сетевой инженер согласится с этим.\nDHCP - Dynamic Host Configuration Protocol - Протокол динамического конфигурирования сервера Мы много обсуждали протоколы, необходимые для работы наших хостов, будь то доступ в Интернет или передача файлов между собой.\nНа каждом хосте нам нужны 4 вещи, чтобы он мог выполнять обе эти задачи.\nIP Address Subnet Mask Default Gateway DNS Мы рассмотрели IP-адрес, являющийся уникальным адресом для вашего хоста в сети, в которой он находится, мы можем думать об этом как о нашем домашнем номере.\nМаску подсети мы скоро рассмотрим, но вы можете думать об этом как о почтовом индексе или почтовом индексе.\nШлюз по умолчанию — это IP-адрес нашего маршрутизатора, как правило, в нашей сети, предоставляющий нам возможность подключения уровня 3. Вы могли бы думать об этом как о единственной дороге, которая позволяет нам покинуть нашу улицу.\nЗатем у нас есть DNS, как мы только что рассмотрели, чтобы помочь нам преобразовать сложные общедоступные IP-адреса в более подходящие и запоминающиеся доменные имена. Может быть, мы можем думать об этом как о гигантском сортировочном офисе, чтобы убедиться, что мы получаем правильный пост.\nКак я уже сказал, каждому хосту требуются эти 4 вещи, если у вас 1000 или 10 000 хостов, вам потребуется очень много времени, чтобы определить каждый из них по отдельности. Здесь в дело вступает DHCP, который позволяет вам определить область действия вашей сети, а затем этот протокол будет распространяться на все доступные хосты в вашей сети.\nДругой пример: вы идете в кафе, берете кофе и садитесь за свой ноутбук, или ваш телефон позволяет назвать это вашим хостом. Вы подключаете свой хост к Wi-Fi в кофейне, и вы получаете доступ к Интернету, сообщения и почта начинают пинговаться, и вы можете просматривать веб-страницы и социальные сети. Когда вы подключались к Wi-Fi в кофейне, ваша машина получала DHCP-адрес либо от выделенного DHCP-сервера, либо, скорее всего, от маршрутизатора, который также обрабатывает DHCP.\nSubnetting - Подсети Подсеть — это логическое подразделение IP-сети.\nПодсети разбивают большие сети на более мелкие, более управляемые сети, которые работают более эффективно.\nКаждая подсеть является логическим подразделением большей сети. Подключенные устройства с достаточным количеством подсетей имеют общий идентификатор IP-адреса, что позволяет им взаимодействовать друг с другом.\nМаршрутизаторы управляют связью между подсетями.\nРазмер подсети зависит от требований к подключению и используемой сетевой технологии.\nОрганизация несет ответственность за определение своего количества и размера подсетей в пределах адресного пространства. доступны, и детали остаются локальными для этой организации. Подсети также могут быть сегментированы на еще более мелкие подсети для таких вещей, как соединения «точка-точка», или для подсетей, поддерживающих несколько устройств.\nСреди прочих преимуществ сегментация крупных сети в подсети включает IP-адрес перераспределение и уменьшает перегрузку сети, оптимизацию, сетевую связь и эффективность.\nПодсети также могут повысить безопасность сети. Если часть сети скомпрометирована, ее можно поместить в карантин, что затруднит перемещение злоумышленников по более крупной сети.\nРесурсы Computer Networking full course Practical Networking ","description":"Протоколы сети","title":"23. Протоколы сети","uri":"/ru/docs/90daysofdevops/day23/"},{"content":"Автоматизация сети Основы сетевой автоматизации Основные задачи для сетевой автоматизации\nТестирование устройств и проверка конфигурации; Инициализация развернутых физических устройств и сервисов, а также развертывание и инициализация виртуальных устройств; Сбор сетевых данных, относящихся к устройствам, системам, программному обеспечению, топологии сети, трафику и сервисам в реальном времени; Анализ данных, в том числе упреждающая аналитика ИИ и машинного обучения, для обеспечения информации о текущем и будущем поведении сети; Проверка соответствия конфигурации требованиям для обеспечения правильной работы всех сетевых устройств и сервисов; Обновление программного обеспечения, включая откат программного обеспечения при необходимости; Замкнутая коррекция проблем с сетью, включая поиск и устранение неисправностей, а также исправление сложных и трудновыявляемых сбоев; Подробный анализ отчетов, панелей наблюдения, оповещений и предупреждений; Реализация требований безопасности; Мониторинг сети и ее сервисов для поддержания уровня обслуживания и удовлетворенности клиентов Процесс внедрения автоматизации специфичен для каждого бизнеса. Когда дело доходит до развертывания автоматизации, не существует универсального решения. Способность определить и использовать подход, который лучше всего подходит для вашей организации, имеет решающее значение для продвижения к поддержке и созданию более гибкой среды для пользователей. (Мы обсуждали что-то подобное в самом начале в отношении всего DevOps, изменения культуры и автоматизированного процесса, который это приносит)\nЧтобы разобраться во всем, вам нужно будет определить, как задача или процесс, которые вы пытаетесь автоматизировать, будут улучшать опыт конечного пользователя или ценность для бизнеса, следуя пошаговому систематическому подходу.\n«Если не знаешь, куда идешь, любая дорога приведет тебя туда».\nИмея структуру проекта, которую вы пытаетесь достичь, зная, какова ваша конечная цель, а затем шаг за шагом работая над достижением этой цели, измеряйте успех автоматизации на различных этапах на основе бизнес-результатов.\nСоздавайте концепции, моделируя существующие приложения. Нет необходимости разрабатывать концепции автоматизации в пузыре, потому что их нужно применять к вашему приложению, вашему сервису, вашей инфраструктуре, поэтому начните создавать концепции и моделировать их вокруг вашей существующей инфраструктуры, вы повторно существующие приложения.\nПодход к автоматизации сети Мы должны определить задачи и выполнить обнаружение запросов на изменение сети, чтобы у вас были наиболее распространенные проблемы и проблемы, решение которых нужно автоматизировать.\nСоставьте список всех запросов на изменение и рабочих процессов, которые в настоящее время обрабатываются вручную. Определить наиболее распространенные, трудоемкие и подверженные ошибкам действия. Приоритизируйте запросы, используя бизнес-ориентированный подход. Это основа построения процесса автоматизации, что нужно автоматизировать, а что нет. Затем мы должны разделить задачи и проанализировать, как разные сетевые функции работают и взаимодействуют друг с другом.\nКоманда инфраструктуры/сети получает заявки на изменения на нескольких уровнях для развертывания приложений. На основе сетевых сервисов разделить их на разные области и понять, как они взаимодействуют друг с другом. Оптимизация приложений ADC (контроллер доставки приложений) (Application Delivery Controller) Межсетевой экран DDI (DNS, DHCP, IPAM и т. д.) Маршрутизация Другие Определите различные зависимости, чтобы устранить деловые и культурные различия и обеспечить сотрудничество между командами. Повторно используемые политики, определение и упрощение повторно используемых сервисных задач, процессов и ввода/вывода.\nОпределить предложения для различных услуг, процессов и ввода/вывода. Упрощение процесса развертывания сократит время выхода на рынок как новых, так и существующих рабочих нагрузок. Когда у вас есть стандартный процесс, его можно упорядочить и согласовать с отдельными запросами для многопоточного подхода и доставки. Объедините политики со специфическими для бизнеса действиями. Как внедрение этой политики помогает бизнесу? Экономит время? Экономит деньги? Обеспечивает лучший бизнес-результат?\nУбедитесь, что сервисные задачи совместимы. Свяжите добавочные сервисные задачи, чтобы они соответствовали созданию бизнес-сервисов. Обеспечьте гибкость связывания и повторного связывания сервисных задач по запросу. Разверните возможности самообслуживания и проложите путь к повышению операционной эффективности. Разрешить несколько наборов технологических навыков продолжать вносить свой вклад в надзор и соответствие. Управляйте политиками и процессами, добавляя и улучшая их, сохраняя при этом доступность и обслуживание.\nНачните с малого, автоматизировав существующие задачи. Ознакомьтесь с процессом автоматизации, чтобы вы могли определить другие области, которые могут выиграть от автоматизации. повторяйте свои инициативы по автоматизации, постепенно добавляя гибкость при сохранении требуемой доступности. Использование поэтапного подхода прокладывает путь к успеху! Оркестрируйте сетевой сервис!\nДля быстрой доставки приложений требуется автоматизация процесса развертывания. Создание гибкой сервисной среды требует управления различными элементами в рамках набора технологических навыков. Подготовьтесь к комплексной оркестровке, обеспечивающей контроль над автоматизацией и порядком развертывания. Инструменты автоматизации сети Хорошей новостью здесь является то, что по большей части инструменты, которые мы используем для автоматизации сети, как правило, те же, что мы будем использовать для других областей автоматизации.\nОпреационная система. Большую часть своего обучения я сосредоточился на использовании инструментов под Linux. Но почти все инструменты, которых мы коснемся, кросплатформенные.\nИнтегрированная среда разработки (IDE). Опять же, здесь особо нечего сказать, кроме всего прочего, я бы предложил Visual Studio Code в качестве вашей IDE, основываясь на обширных подключаемых модулях, доступных для стольких разных языков.\nУправление конфигурацией. Мы еще не добрались до раздела «Управление конфигурацией», но совершенно очевидно, что Ansible является фаворитом в этой области для управления и автоматизации конфигураций. Ansible написан на Python, но вам не нужно знать Python. Link to Ansible Network Modules\nМы также коснемся Ansible Tower в разделе управления конфигурацией, рассматривая его как внешний интерфейс с графическим интерфейсом (GUI) для Ansible.\nCI/CD. Мы рассмотрим больше концепций и инструментов, связанных с этим, но важно хотя бы упомянуть здесь, поскольку это охватывает не только сеть, но и все предоставление услуг и платформ.\nВ частности, Jenkins предоставляет или кажется популярным инструментом для сетевой автоматизации.\nОтслеживает репозиторий git на наличие изменений, а затем инициирует их. Контроль версий (Version Control). Углубимся в это позже.\nGit обеспечивает контроль версий вашего кода на локальном устройстве - Кроссплатформенность GitHub, GitLab, BitBucket и т. д. — это онлайн-сайты, на которых вы определяете свои репозитории и загружаете свой код. Language | Scripting. Что-то, что мы здесь не рассмотрели, это Python как язык, я решил вместо этого погрузиться в Go как язык программирования, исходя из моих обстоятельств, я бы сказал, что это был тесный контакт между Golang и Python и Python, кажется, Победитель в категории «Сетевая автоматизация».\nЗдесь стоит упомянуть Nornir, фреймворк автоматизации, написанный на Python. Кажется, что это берет на себя роль Ansible, но особенно в отношении сетевой автоматизации. Документация Nornir Анализ API. Postman — отличный инструмент для анализа RESTful API. Помогает создавать, тестировать и изменять API.\nPOST »\u003e Для создания объектов ресурсов. GET »\u003e Для получения ресурсов. PUT »\u003e Для создания или замены ресурсов. PATCH »\u003e Для создания или обновления объекта ресурсов. Delete »\u003e Чтобы удалить ресурс Postman tool Download\nЕще инструменты Cisco NSO (Network Services Orchestrator)\nNetYCE - Simplify Network Automation\nNetwork Test Automation\nВ течение следующих 3 дней я планирую более подробно изучить некоторые вещи, которые мы рассмотрели, и поработать над Python и сетевой автоматизацией.\nДо сих пор мы далеко не охватили все сетевые темы, но хотели сделать это достаточно широким, чтобы следовать за ним и продолжать учиться на ресурсах, которые я добавляю ниже.\nРесурсы 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation ","description":"Автоматизация сети","title":"24. Автоматизация сети","uri":"/ru/docs/90daysofdevops/day24/"},{"content":"Python поставляется с собственным модулем отладчика, который называется pdb. Этот модуль предоставляет интерактивный отладчик исходного кода для ваших программ на Python. Вы можете устанавливать брейкпоинты, просматривать код, изучать кадры стека и многое другое. Мы рассмотрим следующие аспекты этого модуля:\nКак запустить отладчик Переход по коду Установка точек останова Давайте начнем с создания небольшого фрагмента кода, чтобы попробовать отладку. Вот глупый пример:\n# debug_test.py def doubler(a): \"\"\"\"\"\" result = a*2 print(result) return result def main(): \"\"\"\"\"\" for i in range(1,10): doubler(i) if __name__ == \"__main__\": main() Теперь давайте узнаем, как запустить отладчик на этом фрагменте кода.\nКак запустить отладчик Вы можете запустить отладчик тремя различными способами. Первый - просто импортировать его и вставить pdb.set_trace() в свой код, чтобы запустить отладчик. Вы можете импортировать отладчик в IDLE и заставить его запустить ваш модуль. Или можете вызвать отладчик в командной строке. В этом разделе мы сосредоточимся на двух последних методах. Мы начнем с использования отладчика в интерпретаторе (IDLE). Откройте терминал (окно командной строки) и перейдите к месту, где вы сохранили приведенный выше пример кода. Затем запустите Python. Теперь сделайте следующее:\n\u003e\u003e\u003e import debug_test \u003e\u003e\u003e import pdb \u003e\u003e\u003e pdb.run('debug_test.main()') \u003e \u003cstring\u003e(1)\u003cmodule\u003e() (Pdb) continue 2 4 6 8 10 12 14 16 18 Здесь мы импортируем наш модуль и pdb. Затем мы выполняем метод pdb run и говорим ему вызвать метод main нашего модуля. Это вызывает подсказку отладчика. Здесь мы набрали continue, чтобы сказать ему, что нужно продолжить выполнение сценария. Вы также можете набрать букву c в качестве сокращения для continue. При наборе continue отладчик продолжит выполнение до тех пор, пока не достигнет точки останова или пока сценарий не завершится.\nДругой способ запустить отладчик - выполнить следующую команду в терминале:\npython -m pdb debug_test.py Если вы запустите его таким образом, вы увидите немного другой результат:\n-\u003e def doubler(a): (Pdb) c 2 4 6 8 10 12 14 16 18 The program finished and will be restarted Вы заметите, что в этом примере мы использовали c вместо continue. Вы также заметите, что отладчик перезапускается в конце. Это сохраняет состояние отладчика (например, точки останова) и может быть более полезным, чем остановка отладчика. Иногда вам потребуется просмотреть код несколько раз, чтобы понять, что в нем не так.\nДавайте копнем немного глубже и узнаем, как пройтись по коду.\nПошаговый просмотр кода Если вы хотите просмотреть код по одной строке за раз, вы можете использовать команду step (или просто “s”). Вот сессия для вашего удовольствия:\nC:\\Users\\mike\u003ecd c:\\py101 c:\\py101\u003epython -m pdb debug_test.py \u003e c:\\py101\\debug_test.py(4)\u003cmodule\u003e() -\u003e def doubler(a): (Pdb) step \u003e c:\\py101\\debug_test.py(11)\u003cmodule\u003e() -\u003e def main(): (Pdb) s \u003e c:\\py101\\debug_test.py(16)\u003cmodule\u003e() -\u003e if __name__ == \"__main__\": (Pdb) s \u003e c:\\py101\\debug_test.py(17)\u003cmodule\u003e() -\u003e main() (Pdb) s --Call-- \u003e c:\\py101\\debug_test.py(11)main() -\u003e def main(): (Pdb) next \u003e c:\\py101\\debug_test.py(13)main() -\u003e for i in range(1,10): (Pdb) s \u003e c:\\py101\\debug_test.py(14)main() -\u003e doubler(i) (Pdb) Здесь мы запускаем отладчик и говорим ему, что нужно войти в код. Он начинает сверху и проходит через первые два определения функций. Затем он доходит до условной и обнаруживает, что должен выполнить функцию main. Мы переходим в главную функцию, а затем используем команду next. Команда next выполнит вызываемую функцию, если встретит ее без перехода в нее. Если вы хотите сделать шаг в вызываемую функцию, то достаточно использовать команду step.\nКогда вы видите строку типа \u003e c:py101debug_test.py(13)main(), обратите внимание на число в круглых скобках. Это число - номер текущей строки в коде.\nВы можете использовать команду args (или a) для вывода текущего списка аргументов на экран. Еще одна удобная команда - jump (или j), за которой следует пробел и номер строки, на которую вы хотите “перепрыгнуть”. Это дает вам возможность пропустить кучу монотонных шагов, чтобы добраться до нужной строки. Это приводит нас к изучению точек останова!\nНастройка точек останова Точка останова - это строка в коде, где вы хотите приостановить выполнение. Вы можете установить точку останова, вызвав команду break (или b), за которой следует пробел и номер строки, на которой вы хотите прерваться. Вы также можете дополнить номер строки именем файла и двоеточием, чтобы указать breakpoint в другом файле. Команда break также позволяет установить точку останова с помощью аргумента function. Существует также команда tbreak, которая устанавливает временную точку останова, которая автоматически удаляется при ее достижении.\nВот пример:\nc:\\py101\u003epython -m pdb debug_test.py \u003e c:\\py101\\debug_test.py(4)\u003cmodule\u003e() -\u003e def doubler(a): (Pdb) break 6 Breakpoint 1 at c:\\py101\\debug_test.py:6 (Pdb) c \u003e c:\\py101\\debug_test.py(6)doubler() -\u003e result = a*2 Мы запускаем отладчик, а затем говорим ему установить breakpoint на строке 6. Затем мы продолжаем, и он останавливается на строке 6, как и должно быть. Сейчас самое время проверить список аргументов, чтобы убедиться, что он соответствует вашим ожиданиям. Попробуйте это сделать, набрав args сейчас. Затем выполните еще одно continue и еще один args, чтобы посмотреть, как изменился результат.\nПодведение итогов Существует множество других команд, которые вы можете использовать в отладчике. Я рекомендую прочитать документацию, чтобы узнать о других командах. Однако на данном этапе вы должны уметь эффективно использовать отладчик для отладки собственного кода.\n","description":"Python 101","title":"24. Отладчик Python","uri":"/ru/docs/python101/chapter24_debugging/"},{"content":"Python для автоматизации сети Python — это стандартный язык, используемый для автоматизированных сетевых операций.\nХотя это не только автоматизация сети, кажется, что оно везде, когда вы ищете ресурсы, и, как упоминалось ранее, если это не Python, то обычно это Ansible, который также написан на Python.\nЯ думаю, что уже упоминал об этом, но в разделе «Изучение языка программирования» я выбрал Golang, а не Python, по причинам, связанным с тем, что моя компания разрабатывает Go, так что это было хорошей причиной для меня, чтобы учиться, но если это не так, тогда Python взял бы это время.\nУдобочитаемость и простота использования. Кажется, что Python просто имеет смысл. Похоже, что в коде нет требований к {} для начального и конечного блоков. Соедините это с сильной IDE, такой как VS Code, у вас будет довольно легкий старт, если вы хотите запустить какой-либо код Python. Pycharm может быть еще одной IDE, о которой стоит упомянуть.\nБиблиотеки. Расширяемость Python - это настоящая золотая жила, я упоминал ранее, что это не только для сетевой автоматизации, но на самом деле существует множество библиотек для всех видов устройств и конфигураций. Вы можете увидеть огромное количество здесь PyPi Если вы хотите загрузить библиотеку на свою рабочую станцию, вы используете инструмент под названием «pip», чтобы подключиться к PyPI и загрузить его локально. Сетевые поставщики, такие как Cisco, Juniper и Arista, разработали библиотеки для облегчения доступа к своим устройствам.\nМощный и эффективный - Помните, во времена Go я прошел сценарий “Hello World”, и мы прошли, кажется, 6 строк кода? В Питоне это print('hello world') Сложите все вышеперечисленные пункты вместе, и должно быть легко понять, почему Python обычно упоминается как инструмент де-факто при работе над автоматизацией.\nЯ думаю, важно отметить, что, возможно, несколько лет назад существовали сценарии, которые могли взаимодействовать с вашими сетевыми устройствами, чтобы, возможно, автоматизировать резервное копирование конфигурации или собирать журналы и другую информацию о ваших устройствах. Автоматизация, о которой мы здесь говорим, немного отличается, потому что общий сетевой ландшафт также изменился, чтобы лучше соответствовать этому образу мышления и обеспечить большую автоматизацию.\nПрограммно-определяемая сеть (Software-Defined Network). Контроллеры SDN несут ответственность за доставку конфигурации уровня управления на все устройства в сети, что означает только единую точку контакта для любых изменений в сети, больше не требуется telnet или SSH для доступа к каждому устройству, а также полагаются на люди, чтобы сделать это, что имеет повторяющийся шанс отказа или неправильной конфигурации.\nОркестрация высокого уровня (High-Level Orchestration ). Поднимитесь на уровень выше этих контроллеров SDN, и это позволит оркестровать уровни обслуживания, а затем интегрировать этот уровень оркестровки в выбранные вами платформы, VMware, Kubernetes, общедоступные облака и т. д.\nУправление на основе политик (Policy-based management) - Что вы хотите иметь? Какое желаемое состояние? Вы описываете это, и в системе есть все детали, как это понять, чтобы стать желаемым состоянием.\nНастройка рабочей среды Не у всех есть доступ к физическим маршрутизаторам, коммутаторам и другим сетевым устройствам.\nЯ хотел дать нам возможность ознакомиться с некоторыми из ранее упомянутых инструментов, а также получить практические навыки и научиться автоматизировать настройку наших сетей.\nКогда дело доходит до вариантов, есть несколько, из которых мы можем выбрать.\nGNS3 VM Eve-ng Unimus Мы построим нашу среду, используя Eve-ng, как упоминалось ранее, вы можете использовать физическое устройство, но, честно говоря, виртуальная среда означает, что у нас может быть среда-песочница. для тестирования множества различных сценариев. Кроме того, может быть интересна возможность играть с различными устройствами и топологиями.\nМы собираемся делать все на EVE-NG с изданием сообщества.\nНачало Издание сообщества поставляется в форматах ISO и OVF для загрузки.\nМы будем использовать загрузку в формате OVF, но в случае с ISO есть возможность сборки на «голом железе» без использования гипервизора.\nДля нашего пошагового руководства мы будем использовать VMware Workstation, поскольку у меня есть лицензия через мой vExpert, но вы в равной степени можете использовать VMware Player или любой другой вариант, упомянутый в документации. К сожалению, мы не можем использовать нашу ранее созданную среду в Virtual box!\nЗдесь также у меня возникла проблема с GNS3 с Virtual Box, хотя он и поддерживается.\nDownload VMware Workstation Player - FREE\nVMware Workstation PRO. Есть бесплатный пробный период.\nУстановка на VMware Workstation PRO Теперь у нас загружено и установлено программное обеспечение hypervisor, а также загружен файл EVE-NG OVF. Теперь мы готовы к настройке. Откройте VMware Workstation, а затем выберите file -\u003e open.\nКогда вы загружаете образ EVE-NG OVF, он будет находиться в сжатом файле. Извлеките содержимое в свою папку, чтобы оно выглядело так. Перейдите в папку, в которую вы загрузили образ EVE-NG OVF, и начните импорт. Дайте ему узнаваемое имя и сохраните виртуальную машину где-нибудь в вашей системе.\nКогда процесс импорта завершится, увеличьте количество процессоров до 4 и объем выделенной памяти до 8 ГБ. (Это должно быть после импорта с последней версией, если нет, то отредактируйте настройки ВМ)\nТакже убедитесь, что установлен флажок Virtualise Intel VT-x/EPT или AMD-V/RVI. Этот параметр указывает рабочей станции VMware передавать флаги виртуализации гостевой ОС (вложенная виртуализация). Это была проблема, с которой я столкнулся с GNS3 с Virtual Box, хотя мой процессор это позволяет.\nВключение и доступ Примечание и кроличья нора: помните, я упоминал, что это не будет работать с VirtualBox! Ну да, была такая же проблема с VMware Workstation и EVE-NG, но это не вина платформы виртуализации!\nУ меня есть WSL2, работающий на моей машине с Windows, и это, похоже, лишает возможности запускать что-либо, вложенное в вашу среду. Я смущен тем, почему виртуальная машина Ubuntu работает, поскольку она, кажется, устраняет аспект виртуализации Intel VT-d ЦП при использовании WSL2.\nЧтобы решить эту проблему, мы можем запустить следующую команду на нашем компьютере с Windows и перезагрузить систему, обратите внимание, что, пока она отключена, вы не сможете использовать WSL2.\nbcdedit /set hypervisorlaunchtype off\nЕсли вы хотите вернуться и использовать WSL2, вам нужно будет запустить эту команду и перезагрузиться.\nbcdedit /set hypervisorlaunchtype auto\nОбе эти команды нужно запускать от имени администратора!\nХорошо, вернемся к шоу. Теперь у вас должна быть включенная машина в VMware Workstation, и у вас должно появиться приглашение, похожее на это.\nДанные для входа:\nusername = root password = eve\nЗатем вас попросят снова ввести пароль root, который позже будет использоваться для SSH-соединения с хостом. Затем мы можем изменить имя хоста.\nЗатем мы определяем доменное имя DNS, я использовал имя ниже, но я не уверен, нужно ли будет его изменить позже.\nЗатем мы настраиваем сеть, я выбираю статический, чтобы указанный IP-адрес оставался постоянным после перезагрузки. На последнем шаге укажите статический IP-адрес из сети, доступной с вашей рабочей станции. Здесь есть несколько дополнительных шагов, где вам нужно будет указать маску подсети для вашей сети, шлюз по умолчанию и DNS. После завершения он перезагрузится, когда будет выполнено резервное копирование, вы можете взять свой статический IP-адрес и ввести его в свой браузер. Имя пользователя по умолчанию для графического интерфейса — «admin», пароль — «eve», а имя пользователя по умолчанию для SSH — «root» и пароль — «eve», но это было бы изменено, если бы вы изменили его во время установки. Я выбрал HTML5 для консоли вместо нативной, так как это откроет новую вкладку в вашем браузере, когда вы будете перемещаться по разным консолям.\nДалее мы собираемся:\nУстановить клиентский пакет EVE-NG Загрузить некоторые сетевые образы в EVE-NG. Построить топологию сети Добавить “ноды” (машины/хосты, Nodes) Соединить ноды между собой Начнем создавать скрипты Python Посмотрим на telnetlib, Netmiko, Paramiko и Pexpect Ресурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation ","description":"Автоматизация сети с помощью Python","title":"25. Автоматизация сети с помощью Python","uri":"/ru/docs/90daysofdevops/day25/"},{"content":"Декораторы в Python - это действительно здорово, но поначалу их может быть трудно понять. Декоратор в Python - это функция, которая принимает в качестве аргумента другую функцию. Декоратор обычно изменяет или улучшает функцию, которую он принял, и возвращает измененную функцию. Это означает, что при вызове декорированной функции вы получите функцию, которая может быть немного другой, иметь дополнительные возможности по сравнению с базовым определением. Но давайте вернемся немного назад. Возможно, нам следует рассмотреть основной строительный блок декоратора, а именно функцию.\nПростая функция Функция - это блок кода, который начинается с ключевого слова def в Python, за которым следует фактическое имя функции. Функция может принимать от нуля и более аргументов, ключевые аргументы или сочетание этих аргументов. Функция всегда выдает результат. Если вы не укажете, что она должна возвращать, вернется None. Вот очень простая функция, которая просто возвращает строку:\ndef a_function(): \"\"\"A pretty useless function\"\"\" return \"1+1\" if __name__ == \"__main__\": value = a_function() print(value) Все, что мы делаем в приведенном выше коде, - это вызываем функцию и печатаем возвращаемое значение. Давайте создадим еще одну функцию:\ndef another_function(func): \"\"\" A function that accepts another function \"\"\" def other_func(): val = \"The result of %s is %s\" % (func(), eval(func()) ) return val return other_func Эта функция принимает один аргумент, и этот аргумент должен быть функцией или вызываемой. На самом деле, ее следует вызывать только с помощью ранее определенной функции. Вы заметите, что внутри этой функции есть вложенная функция, которую мы называем other_func. Она берет результат переданной ей функции, оценивает его и создает строку, рассказывающую о том, что она сделала, которую затем возвращает. Давайте посмотрим на полную версию кода:\ndef another_function(func): \"\"\" A function that accepts another function \"\"\" def other_func(): val = \"The result of %s is %s\" % (func(), eval(func()) ) return val return other_func def a_function(): \"\"\"A pretty useless function\"\"\" return \"1+1\" if __name__ == \"__main__\": value = a_function() print(value) decorator = another_function(a_function) print(decorator()) Вот как работает декоратор. Мы создаем одну функцию, а затем передаем ее во вторую функцию. Вторая функция является функцией декоратора. Декоратор изменяет или улучшает переданную ему функцию и возвращает модификацию. Если вы запустите этот код, вы должны увидеть следующее в качестве вывода в stdout:\n1+1 The result of 1+1 is 2 Давайте немного изменим код, чтобы превратить another_function в декоратор:\ndef another_function(func): \"\"\" A function that accepts another function \"\"\" def other_func(): val = \"The result of %s is %s\" % (func(), eval(func()) ) return val return other_func @another_function def a_function(): \"\"\"A pretty useless function\"\"\" return \"1+1\" if __name__ == \"__main__\": value = a_function() print(value) Вы заметите, что в Python декоратор начинается с символа @, за которым следует имя функции, которую мы собираемся “декорировать”. Чтобы применить декоратор, достаточно поместить его в строку перед определением функции. Теперь, когда мы вызываем функцию a_function, она будет декорирована, и мы получим следующий результат:\nThe result of 1+1 is 2 Давайте создадим декоратор, который действительно делает что-то полезное.\nСоздание декоратора логирования Иногда вы захотите создать лог того, что делает функция. В большинстве случаев вы, вероятно, будете вести журнал в самой функции. Иногда вы можете захотеть сделать это на уровне функции, чтобы получить представление о потоке программы или, возможно, для выполнения некоторых бизнес-правил, например, аудита. Вот небольшой декоратор, который мы можем использовать для записи имени любой функции и того, что она возвращает:\nimport logging def log(func): \"\"\" Log what function is called \"\"\" def wrap_log(*args, **kwargs): name = func.__name__ logger = logging.getLogger(name) logger.setLevel(logging.INFO) # add file handler fh = logging.FileHandler(\"%s.log\" % name) fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s' formatter = logging.Formatter(fmt) fh.setFormatter(formatter) logger.addHandler(fh) logger.info(\"Running function: %s\" % name) result = func(*args, **kwargs) logger.info(\"Result: %s\" % result) return func return wrap_log @log def double_function(a): \"\"\" Double the input parameter \"\"\" return a*2 if __name__ == \"__main__\": value = double_function(2) Этот небольшой скрипт имеет функцию log, которая принимает функцию в качестве единственного аргумента. Она создаст объект logger и имя файла журнала на основе имени функции. Затем функция log будет записывать, какая функция была вызвана и что функция вернула, если таковая имеется.\nВстроенные декораторы Python поставляется с несколькими встроенными декораторами. Основных три:\n@classmethod @staticmethod @property Также декораторы есть в различных частях стандартной библиотеки Python. Примером может служить functools.wraps. Однако мы ограничимся тремя вышеперечисленными.\n@classmethod и @staticmethod Я никогда не использовал их сам, поэтому провел небольшое исследование. Декоратор @classmethod может быть вызван с экземпляром класса или непосредственно самим классом в качестве первого аргумента. Согласно документации Python: ОВ соответствии с документацией Python: он может быть вызван как в классе (например, C.f()), или в экземпляре (например, C().f()). Экземпляр игнорируется, за исключением его класса. Если метод класса вызван для выведенного класса, то объект выведенного класса передается в качестве подразумеваемого первого аргумента. Основной случай использования декоратора @classmethod, который я обнаружил в своем исследовании, - это альтернативный конструктор или вспомогательный метод для инициализации.\nДекоратор @staticmethod - это просто функция внутри класса. Вы можете вызывать его как с инстанцированием класса, так и без него. Типичный случай использования - когда у вас есть функция, которая, по вашему мнению, связана с классом. По большей части это стилистический выбор.\nВозможно, вам поможет пример кода, показывающий, как работают эти два декоратора:\nclass DecoratorTest(object): \"\"\" Test regular method vs @classmethod vs @staticmethod \"\"\" def __init__(self): \"\"\"Constructor\"\"\" pass def doubler(self, x): \"\"\"\"\"\" print(\"running doubler\") return x*2 @classmethod def class_tripler(klass, x): \"\"\"\"\"\" print(\"running tripler: %s\" % klass) return x*3 @staticmethod def static_quad(x): \"\"\"\"\"\" print(\"running quad\") return x*4 if __name__ == \"__main__\": decor = DecoratorTest() print(decor.doubler(5)) print(decor.class_tripler(3)) print(DecoratorTest.class_tripler(3)) print(DecoratorTest.static_quad(2)) print(decor.static_quad(3)) print(decor.doubler) print(decor.class_tripler) print(decor.static_quad) Этот пример демонстрирует, что вы можете одинаково вызывать обычный метод и оба декорированных метода. Вы заметите, что декорированные функции @classmethod и @staticmethod можно вызывать непосредственно из класса или из экземпляра класса. Если вы попытаетесь вызвать обычную функцию из класса (например, DecoratorTest.doubler(2)), вы получите TypeError. Вы также заметите, что последний оператор печати показывает, что decor.static_quad возвращает обычную функцию, а не связанный метод.\nСвойства Python В Python есть небольшое понятие, называемое property, которое может выполнять несколько полезных функций. Мы рассмотрим, как сделать следующее:\nПреобразовать методы класса в атрибуты, доступные только для чтения Реализовать сеттеры и геттеры в атрибут. Один из самых простых способов использования свойства - использовать его в качестве декоратора метода. Это позволяет превратить метод класса в атрибут класса. Я нахожу это полезным, когда мне нужно сделать какую-то комбинацию значений. Другие находят это полезным для написания методов преобразования, к которым они хотят иметь доступ как к методам. Давайте рассмотрим простой пример:\nclass Person(object): \"\"\"\"\"\" def __init__(self, first_name, last_name): \"\"\"Constructor\"\"\" self.first_name = first_name self.last_name = last_name @property def full_name(self): \"\"\" Return the full name \"\"\" return \"%s %s\" % (self.first_name, self.last_name) В приведенном выше коде мы создаем два атрибута или свойства класса: self.first_name и self.last_name. Затем мы создаем метод full_name, к которому прикреплен декоратор @property. Это позволяет нам сделать следующее в сессии интерпретатора:\n\u003e\u003e\u003e person = Person(\"Mike\", \"Driscoll\") \u003e\u003e\u003e person.full_name 'Mike Driscoll' \u003e\u003e\u003e person.first_name 'Mike' \u003e\u003e\u003e person.full_name = \"Jackalope\" Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e AttributeError: can't set attribute Как видите, поскольку мы превратили метод в свойство, мы можем обращаться к нему, используя обычную точечную нотацию. Однако, если мы попытаемся установить свойство на что-то другое, мы вызовем ошибку AttributeError. Единственный способ изменить свойство full_name - сделать это косвенно:\n\u003e\u003e\u003e person.first_name = \"Dan\" \u003e\u003e\u003e person.full_name 'Dan Driscoll' Это несколько ограничивает возможности, поэтому давайте рассмотрим другой пример, где мы можем создать свойство, которое позволит нам устанавливать его.\nЗамена сеттеров и геттеров свойством Python Давайте представим, что у нас есть старый код, который написал кто-то, кто не очень хорошо понимал Python. Если вы похожи на меня, вы уже сталкивались с подобным кодом:\nfrom decimal import Decimal class Fees(object): \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self._fee = None def get_fee(self): \"\"\" Return the current fee \"\"\" return self._fee def set_fee(self, value): \"\"\" Set the fee \"\"\" if isinstance(value, str): self._fee = Decimal(value) elif isinstance(value, Decimal): self._fee = value Чтобы использовать этот класс, мы должны использовать сеттеры и геттеры, которые определены:\n\u003e\u003e\u003e f = Fees() \u003e\u003e\u003e f.set_fee(\"1\") \u003e\u003e\u003e f.get_fee() Decimal('1') Если вы хотите добавить в этот код обычный доступ к атрибутам в точечной нотации, не ломая все приложения, которые зависят от этого куска кода, вы можете изменить его очень просто, добавив свойство:\nfrom decimal import Decimal class Fees(object): \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self._fee = None def get_fee(self): \"\"\" Return the current fee \"\"\" return self._fee def set_fee(self, value): \"\"\" Set the fee \"\"\" if isinstance(value, str): self._fee = Decimal(value) elif isinstance(value, Decimal): self._fee = value fee = property(get_fee, set_fee) Мы добавили одну строку в конец этого кода. Теперь мы можем делать что-то вроде этого:\n\u003e\u003e\u003e f = Fees() \u003e\u003e\u003e f.set_fee(\"1\") \u003e\u003e\u003e f.fee Decimal('1') \u003e\u003e\u003e f.fee = \"2\" \u003e\u003e\u003e f.get_fee() Decimal('2') Как вы можете видеть, когда мы используем property таким образом, это позволяет свойству fee устанавливать и получать значение самостоятельно, не нарушая унаследованный код. Давайте перепишем этот код с использованием декоратора property и посмотрим, сможем ли мы заставить его разрешить установку.\nfrom decimal import Decimal class Fees(object): \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self._fee = None @property def fee(self): \"\"\" The fee property - the getter \"\"\" return self._fee @fee.setter def fee(self, value): \"\"\" The setter of the fee property \"\"\" if isinstance(value, str): self._fee = Decimal(value) elif isinstance(value, Decimal): self._fee = value if __name__ == \"__main__\": f = Fees() Приведенный выше код демонстрирует, как создать “сеттер” для свойства fee. Это можно сделать, украсив второй метод, который также называется fee, декоратором @fee.setter. Сеттер вызывается, когда вы делаете что-то вроде этого:\n\u003e\u003e\u003e f = Fees() \u003e\u003e\u003e f.fee = \"1\" Если вы посмотрите на сигнатуру для property, то в качестве “аргументов” в ней указаны fget, fset, fdel и doc. Вы можете создать другой декорированный метод с тем же именем, чтобы он соответствовал функции удаления, используя @fee.deleter, если вы хотите перехватить команду del для атрибута.\nПодведение итогов На данном этапе вы должны знать, как создавать свои собственные декораторы и как использовать несколько встроенных декораторов Python. Мы рассмотрели @classmethod, @property и @staticmethod. Мне было бы интересно узнать, как мои читатели используют встроенные декораторы и как они используют свои собственные декораторы.\n","description":"Python 101","title":"25. Декораторы","uri":"/ru/docs/python101/chapter25_decorators/"},{"content":"Оператор лямбда в Python - это анонимная или несвязанная функция, причем довольно ограниченная. Давайте рассмотрим несколько типичных примеров и посмотрим, сможем ли мы найти для нее применение. Примеры, которые обычно встречаются при изучении лямбды, - это что-то вроде скучной функции удвоения. Чтобы не быть голословным, наш простой пример покажет, как найти квадратный корень. Сначала мы покажем обычную функцию, а затем ее лямбда-эквивалент:\nimport math def sqroot(x): \"\"\" Finds the square root of the number passed in \"\"\" return math.sqrt(x) square_rt = lambda x: math.sqrt(x) Если вы попробуете каждую из этих функций, то в итоге получите плавающее число. Вот несколько примеров:\n\u003e\u003e\u003e sqroot(49) 7.0 \u003e\u003e\u003e square_rt(64) 8.0 Довольно ловко, верно? Но где мы можем использовать лямбду в реальной жизни? Может быть, в программе-калькуляторе? Ну, это может сработать, но это довольно ограниченное применение для встроенного модуля Python! Одна из основных частей Python, к которой регулярно применяются примеры лямбд, - это обратные вызовы Tkinter. Tkinter - это набор инструментов для создания графических интерфейсов, который входит в состав Python.\nTkinter + lambda Мы начнем с Tkinter, поскольку он входит в стандартный пакет Python. Вот очень простой сценарий с тремя кнопками, две из которых привязаны к обработчику событий с помощью лямбды:\nimport Tkinter as tk class App: \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" frame = tk.Frame(parent) frame.pack() btn22 = tk.Button(frame, text=\"22\", command=lambda: self.printNum(22)) btn22.pack(side=tk.LEFT) btn44 = tk.Button(frame, text=\"44\", command=lambda: self.printNum(44)) btn44.pack(side=tk.LEFT) quitBtn = tk.Button(frame, text=\"QUIT\", fg=\"red\", command=frame.quit) quitBtn.pack(side=tk.LEFT) def printNum(self, num): \"\"\"\"\"\" print(\"You pressed the %s button\" % num) if __name__ == \"__main__\": root = tk.Tk() app = App(root) root.mainloop() Обратите внимание на переменные btn22 и btn44. Именно здесь происходит действие. Мы создаем экземпляр tk.Button и одним махом привязываем его к нашему методу printNum. Наша лямбда присваивается параметру команды кнопки. Это значит, что мы создаем одноразовую функцию для команды, по аналогии с кнопкой выхода, где мы вызываем метод выхода из фрейма. Разница в том, что отдельная лямбда – это метод, который вызывает другой метод и передает ему целое число. В методе printNum, мы пишем в stdout о том, какая кнопка была нажата, пользуясь информацией, которая была передана функцией lambda. Улавливаете? Если да, то мы продолжим. Если нет – перечитайте данный параграф столько раз, сколько нужно для того, чтобы эта информация усвоилась, или пока не сойдете с ума, в любом случае, что-то должно произойти первым.\nПодведение итогов Оператор лямбда используется и во многих других проектах. Если набрать в Google название проекта Python и лямбда, можно найти множество живого кода. Например, набрав в поиске “django lambda”, вы узнаете, что в django есть фабрика modelformset, использующая лямбды. Плагин Elixir для SqlAlchemy также использует лямбды. Будьте внимательны, и вы удивитесь, как часто вы будете натыкаться на этот удобный механизм создания функций.\n","description":"Python 101","title":"26. Лямбда","uri":"/ru/docs/python101/chapter26_lambda/"},{"content":"Создание нашей лаборатории Мы собираемся продолжить настройку нашей эмулируемой сети с помощью EVE-NG, а затем, надеюсь, развернуть несколько устройств и начать думать о том, как мы можем автоматизировать настройку этих устройств. В День 25 мы рассказали об установке EVE-NG на нашу машину с помощью VMware Workstation.\nУстановка клиента EVE-NG Существует также клиентский пакет, который позволяет нам выбирать, какое приложение используется при подключении к устройствам по SSH. Он также настроит Wireshark для захвата пакетов между ссылками. Вы можете установить клиентский пакет для своей ОС (Windows, macOS, Linux).\nEVE-NG Client Download\nПодсказка: если вы используете Linux в качестве клиента, то есть этот клиентский пакет.\nУстановка проста: next, next и я бы посоветовал оставить значения по умолчанию.\nПолучение сетевых образов Этот шаг непростой, я просмотрел несколько видеороликов, на которые я дам ссылки в конце, которые ссылаются на некоторые ресурсы и загрузки для нашего маршрутизатора и переключают изображения, рассказывая нам, как и куда их загрузить.\nВажно отметить, что я использую все в образовательных целях. Я бы предложил загрузить официальные образы от сетевых поставщиков.\nBlog \u0026 Links to YouTube videos\nHow To Add Cisco VIRL vIOS image to Eve-ng\nВ целом шаги здесь немного сложны и могли бы быть намного проще, но приведенные выше блоги и видео показывают процесс добавления изображений в вашу коробку EVE-NG.\nЯ использовал FileZilla для передачи qcow2 на виртуальную машину через SFTP.\nДля нашей лаборатории нам нужны Cisco vIOS L2 (коммутаторы) и Cisco vIOS (маршрутизатор).\nСоздаем лабораторию Внутри веб-интерфейса EVE-NG мы собираемся создать нашу новую топологию сети. У нас будет четыре коммутатора и один маршрутизатор, который будет нашим шлюзом во внешние сети.\nNode IP Address Router 10.10.88.110 Switch1 10.10.88.111 Switch2 10.10.88.112 Switch3 10.10.88.113 Switch4 10.10.88.114 Добавление наших узлов в EVE-NG Когда вы впервые войдете в EVE-NG, вы увидите экран, как показано ниже, мы хотим начать с создания нашей первой лаборатории.\nДайте вашей лаборатории имя, а остальные поля являются необязательными.\nЗатем увидим пустой экран, чтобы начать создание вашей сети. Щелкните правой кнопкой мыши на своем холсте и выберите ‘add node’.\nДалее появляется длинный список опций. Если вы следовали вышеизложенному, у вас будут два синих, показанных ниже, а остальные будут серыми и недоступными для выбора.\nМы хотим добавить следующее в нашу лабораторию:\n1 x Cisco vIOS Router 4 x Cisco vIOS Switch Соединяем наши ноды Теперь нам нужно добавить возможность подключения между нашими маршрутизаторами и коммутаторами. Мы можем сделать это довольно легко, наведя курсор на устройство и увидев значок подключения, как показано ниже, а затем подключив его к устройству, к которому мы хотим подключиться.\nКогда вы закончите подключение своей среды, вы также можете добавить способ определения физических границ или местоположений с помощью прямоугольников или кругов, которые также можно найти в контекстном меню. Вы также можете добавить текст, который полезен, когда мы хотим определить наши имена или IP-адреса в наших лабораториях.\nЯ пошел дальше и сделал свою лабораторию такой, как показано ниже. You will also notice that the lab above is all powered off, we can start our lab by selecting everything and right-clicking and selecting start selected.\nКак только мы запустим нашу лабораторию, вы сможете подключаться к консоли на каждом устройстве, и вы заметите, что на этом этапе они довольно тупые без настройки. Мы можем добавить некоторую конфигурацию к каждому узлу, скопировав или создав свою собственную в каждом терминале.\nЯ оставлю свою конфигурацию в сетевой папке репозитория для справки.\nNode Configuration Router R1 Switch1 SW1 Switch2 SW2 Switch3 SW3 Switch4 SW4 Ресурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation Большинство примеров, которые я использую здесь, поскольку я не сетевой инженер, взяты из этой обширной книги, которая не является бесплатной, но я использую некоторые примеры оттуда, чтобы помочь понять автоматизацию сети.\nHands-On Enterprise Automation with Python (Book) ","description":"Развертывание виртуальной лаборатории EVE-NG в домашних условиях","title":"26. Развертывание виртуальной лаборатории EVE-NG в домашних условиях","uri":"/ru/docs/90daysofdevops/day26/"},{"content":"Профилирование кода - это попытка найти узкие места в вашем коде. Профилирование должно выявить, какие части вашего кода занимают больше всего времени на выполнение. Узнав это, вы можете посмотреть на эти части кода и попытаться найти способы их оптимизации. Python содержит три встроенных профайлера: cProfile, profile и hotshot. Согласно документации Python, hotshot “больше не поддерживается и может быть отменен в будущей версии Python”. Модуль profile - это чистый модуль Python, но он добавляет много накладных расходов в профилируемые программы. Поэтому мы сосредоточимся на cProfile, который имеет интерфейс, имитирующий модуль profile.\nПрофилирование кода с помощью cProfile Профилирование кода с помощью cProfile достаточно просто. Все, что вам нужно сделать, это импортировать модуль и вызвать его функцию run. Давайте рассмотрим простой пример:\n\u003e\u003e\u003e import hashlib \u003e\u003e\u003e import cProfile \u003e\u003e\u003e cProfile.run(\"hashlib.md5(b'abcdefghijkl').digest()\") 4 function calls in 0.000 CPU seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 0.000 0.000 \u003cstring\u003e:1(\u003cmodule\u003e) 1 0.000 0.000 0.000 0.000 {_hashlib.openssl_md5} 1 0.000 0.000 0.000 0.000 {method 'digest' of '_hashlib.HASH' objects} 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} Здесь мы импортируем модуль hashlib и используем cProfile для профилирования создания хэша MD5. Первая строка показывает, что было 4 вызова функций. Следующая строка говорит нам о том, как упорядочены результаты. Согласно документации, стандартное имя относится к крайнему правому столбцу. Здесь есть несколько столбцов.\nncalls - количество выполненных вызовов. tottime - общее время, проведенное в данной функции. percall - это отношение tottime к ncalls. cumtime - суммарное время, проведенное в данной и всех подфункциях. Это работает также и с рекурсивными функциями! Второй столбец percall - это коэффициент cumtime, деленный на примитивные вызовы filename:lineno(function) предоставляет соответствующие данные каждой функции Примитивный вызов - это вызов, который не был вызван с помощью рекурсии.\nЭто не очень интересный пример, поскольку здесь нет очевидных узких мест. Давайте создадим кусок кода с некоторыми встроенными узкими местами и посмотрим, обнаружит ли их профайлер.\nimport time def fast(): \"\"\"\"\"\" print(\"I run fast!\") def slow(): \"\"\"\"\"\" time.sleep(3) print(\"I run slow!\") def medium(): \"\"\"\"\"\" time.sleep(0.5) print(\"I run a little slowly...\") def main(): \"\"\"\"\"\" fast() slow() medium() if __name__ == '__main__': main() В этом примере мы создаем четыре функции. Первые три выполняются с разной скоростью. Функция fast будет выполняться с нормальной скоростью; функция medium будет выполняться примерно полсекунды, а slow* функции потребуется около 3 секунд. Функция main вызывает остальные три. Теперь давайте запустим cProfile против этой маленькой глупой программы:\n\u003e\u003e\u003e import cProfile \u003e\u003e\u003e import ptest \u003e\u003e\u003e cProfile.run('ptest.main()') I run fast! I run slow! I run a little slowly... 8 function calls in 3.500 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 3.500 3.500 \u003cstring\u003e:1(\u003cmodule\u003e) 1 0.000 0.000 0.500 0.500 ptest.py:15(medium) 1 0.000 0.000 3.500 3.500 ptest.py:21(main) 1 0.000 0.000 0.000 0.000 ptest.py:4(fast) 1 0.000 0.000 3.000 3.000 ptest.py:9(slow) 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} 2 3.499 1.750 3.499 1.750 {time.sleep} На этот раз мы видим, что программе потребовалось 3,5 секунды для выполнения. Если вы изучите результаты, то увидите, что cProfile определил slow функцию как занявшую 3 секунды. Это самое большое узкое место после main функции. Обычно, когда вы обнаруживаете такое узкое место, вы пытаетесь найти более быстрый способ выполнения кода или, возможно, решаете, что время выполнения является приемлемым. В данном примере мы знаем, что лучший способ ускорить работу функции - удалить вызов time.sleep или, по крайней мере, уменьшить длительность сна.\nВы также можете вызвать cProfile в командной строке, а не использовать его в интерпретаторе. Вот один из способов сделать это:\npython -m cProfile ptest.py Это позволит запустить cProfile против вашего сценария точно так же, как мы делали это раньше. Но что если вы хотите сохранить результаты работы профайлера? Это легко сделать с помощью cProfile! Все, что вам нужно сделать, это передать ему команду -o, за которой следует имя (или путь) выходного файла. Вот пример:\npython -m cProfile -o output.txt ptest.py К сожалению, файл, который он выводит, не совсем удобен для чтения. Если вы хотите прочитать этот файл, то вам нужно использовать модуль Python pstats. Вы можете использовать pstats для форматирования вывода различными способами. Вот код, который показывает, как получить результат, похожий на тот, что мы видели до сих пор:\n\u003e\u003e\u003e import pstats \u003e\u003e\u003e p = pstats.Stats(\"output.txt\") \u003e\u003e\u003e p.strip_dirs().sort_stats(-1).print_stats() Thu Mar 20 18:32:16 2014 output.txt 8 function calls in 3.501 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 1 0.000 0.000 3.501 3.501 ptest.py:1(\u003cmodule\u003e) 1 0.001 0.001 0.500 0.500 ptest.py:15(medium) 1 0.000 0.000 3.501 3.501 ptest.py:21(main) 1 0.001 0.001 0.001 0.001 ptest.py:4(fast) 1 0.001 0.001 3.000 3.000 ptest.py:9(slow) 1 0.000 0.000 0.000 0.000 {method 'disable' of '_lsprof.Profiler' objects} 2 3.499 1.750 3.499 1.750 {time.sleep} \u003cpstats.Stats instance at 0x017C9030\u003e Вызов strip_dirs удалит из вывода все пути к модулям, а вызов sort_stats выполнит сортировку, которую мы привыкли видеть. В документации по cProfile есть множество действительно интересных примеров, показывающих различные способы извлечения информации с помощью модуля pstats.\nПодведение итогов На данном этапе вы должны уметь использовать модуль cProfile для диагностики причин медленной работы вашего кода. Возможно, вы также захотите взглянуть на модуль Python timeit. Он позволяет засекать время на небольших участках кода, если вы не хотите разбираться со сложностями, связанными с профилированием. Есть также несколько других модулей сторонних разработчиков, которые хорошо подходят для профилирования, например, проекты line_profiler и memory_profiler.\n","description":"Python 101","title":"27. Профилирование кода","uri":"/ru/docs/python101/chapter27_profiling/"},{"content":"Практическое знакомство с Python и сетью В этом заключительном разделе основ работы с сетью мы рассмотрим некоторые задачи и инструменты автоматизации с помощью нашей лабораторной среды, созданной День 26\nМы будем использовать туннель SSH для подключения к нашим устройствам с нашего клиента по сравнению с telnet. Туннель SSH, созданный между клиентом и устройством, зашифрован. Мы также рассмотрели SSH в разделе Linux в День 18\nДоступ к нашей виртуальной эмулируемой среде Чтобы мы могли взаимодействовать с нашими коммутаторами, нам либо нужна рабочая станция внутри сети EVE-NG, и вы можете развернуть там Linux-систему с установленным Python для выполнения вашей автоматизации (Ресурс для настройки Linux внутри EVE-NG) или можно сделать как я и определить облако для доступа со своей рабочей станции.\nДля этого мы щелкнули правой кнопкой мыши на нашем холсте и выбрали сеть, а затем выбрали “Management(Cloud0)”, чтобы подключиться к нашей домашней сети.\nОднако внутри этой сети у нас ничего нет, поэтому нам нужно добавить соединения из новой сети на каждое из наших устройств. Я вошел в систему на каждом из наших устройств и выполнил следующие команды для интерфейсов, применимых к тому месту, где появляется облако.\nenable config t int gi0/0 ip add dhcp no sh exit exit sh ip int br Последний шаг дает нам адрес DHCP из нашей домашней сети. Список сетей моего устройства выглядит следующим образом:\nNode IP Address Home Network IP Router 10.10.88.110 192.168.169.115 Switch1 10.10.88.111 192.168.169.178 Switch2 10.10.88.112 192.168.169.193 Switch3 10.10.88.113 192.168.169.125 Switch4 10.10.88.114 192.168.169.197 SSH к сетевому устройству Имея все вышеперечисленное, мы теперь можем подключаться к нашим устройствам в нашей домашней сети, используя нашу рабочую станцию. Я использую Putty, но также имею доступ к другим терминалам, таким как git bash, которые дают мне возможность подключаться к нашим устройствам по SSH.\nНиже вы можете видеть, что у нас есть SSH-соединение с нашим маршрутизатором. (Р1)\nИспользование Python для сбора информации с наших устройств Первый пример того, как мы можем использовать Python, — это сбор информации со всех наших устройств, и, в частности, я хочу иметь возможность подключаться к каждому из них и запускать простую команду, чтобы предоставить мне конфигурацию и настройки интерфейса. Я сохранил этот скрипт:\n#!/usr/bin/env python from netmiko import ConnectHandler from getpass import getpass #password = getpass() R1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.115\", \"username\": \"admin\", \"password\": \"access123\", } SW1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.178\", \"username\": \"admin\", \"password\": \"access123\", } SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", } SW3 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.125\", \"username\": \"admin\", \"password\": \"access123\", } SW4 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.197\", \"username\": \"admin\", \"password\": \"access123\", } command = \"show ip int brief\" for device in (R1, SW1, SW2, SW3, SW4): net_connect = ConnectHandler(**device) print(net_connect.find_prompt()) print(net_connect.send_command(command)) net_connect.disconnect() Теперь, когда я запускаю это, я вижу каждую конфигурацию порта на всех моих устройствах.\nЭто может быть удобно, если у вас много разных устройств, создайте этот один скрипт, чтобы вы могли централизованно контролировать и быстро понимать все конфигурации в одном месте.\nИспользование Python для настройки наших устройств Вышеупомянутое полезно, но как насчет использования Python для настройки наших устройств, в нашем сценарии у нас есть транковый порт между ‘SW1’ и ‘SW2’, снова представьте, если бы это нужно было сделать на многих из тех же коммутаторов, которые мы хотим автоматизировать, и не нужно вручную подключаться к каждому коммутатору, чтобы внести изменения в конфигурацию.\nДля этого мы можем использовать следующий скрипт. Это подключится через SSH и выполнит это изменение на нашем ‘SW1’, которое также изменится на ‘SW2’.\nfrom netmiko import ConnectHandler SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", \"secret\": \"access123\", } core_sw_config = [\"int range gig0/1 - 2\", \"switchport trunk encapsulation dot1q\", \"switchport mode trunk\", \"switchport trunk allowed vlan 1,2\"] print(\"########## Connecting to Device {0} ############\".format(SW2)) net_connect = ConnectHandler(**SW2) net_connect.enable() print(\"***** Sending Configuration to Device *****\") net_connect.send_config_set(core_sw_config) Теперь если посмотреть на код, вы увидите, что появляется сообщение «sending configuration to device», но нет подтверждения того, что это произошло. Мы могли бы добавить дополнительный код в наш скрипт, чтобы выполнить эту проверку и проверку на нашем switch или мы могли бы изменить наш сценарий, прежде чем показать нам это.\n#!/usr/bin/env python from netmiko import ConnectHandler from getpass import getpass #password = getpass() SW1 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.178\", \"username\": \"admin\", \"password\": \"access123\", } SW2 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.193\", \"username\": \"admin\", \"password\": \"access123\", } SW3 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.125\", \"username\": \"admin\", \"password\": \"access123\", } SW4 = { \"device_type\": \"cisco_ios\", \"host\": \"192.168.169.197\", \"username\": \"admin\", \"password\": \"access123\", } command = \"show int trunk\" for device in (SW1, SW2, SW3, SW4): net_connect = ConnectHandler(**device) print(net_connect.find_prompt()) print(net_connect.send_command(command)) net_connect.disconnect() Резервное копирование конфигураций вашего устройства Другим вариантом использования может быть захват наших сетевых конфигураций и обеспечение их резервного копирования, но опять же, мы не хотим подключаться ко всем устройствам, которые у нас есть в нашей сети, поэтому мы также можем автоматизировать это с помощью скрипта\nimport sys import time import paramiko import os import cmd import datetime now = datetime.datetime.now() dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\") print(\"Your backup has started at\", dt_string)\ttic = time.perf_counter() #user = input(\"Enter username:\") #password = input(\"Enter Paswd:\") #enable_password = input(\"Enter enable pswd:\") user = \"admin\" password = \"access123\" enable_password = \"access123\" port=22 f0 = open('backup.txt') for ip in f0.readlines(): ip = ip.strip() filename_prefix ='/Users/shambhu/Documents' + ip ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(ip,port, user, password, look_for_keys=False) chan = ssh.invoke_shell() time.sleep(2) chan.send('enable\\n') chan.send(enable_password +'\\n') time.sleep(1) chan.send('term len 0\\n') time.sleep(1) chan.send('sh run\\n') time.sleep(20) output = chan.recv(999999) filename = \"%s_%.2i%.2i%i_%.2i%.2i%.2i\" % (ip,now.year,now.month,now.day,now.hour,now.minute,now.second) f1 = open(filename, 'a') f1.write(output.decode(\"utf-8\") ) f1.close() ssh.close() f0.close() toc = time.perf_counter() print(\"Congratulations You Have Backed Up Your 90DaysOfDevOps Lab\") print(f\"Your backup duration was {toc - tic:0.4f} seconds\") dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\") print(\"Your backup completed at\", dt_string) Вам также потребуется заполнить backup.txt IP-адресами, для которых вы хотите сделать резервную копию.\n192.168.169.115 192.168.169.178 192.168.169.193 192.168.169.125 192.168.169.197 Запустите свой скрипт, и вы должны увидеть что-то вроде того, что показано ниже.\nЭто может быть я просто пишу простой скрипт печати на питоне, поэтому я также должен показать вам файлы резервных копий. Paramiko Широко используемый модуль Python для SSH. Вы можете узнать больше по официальной ссылке GitHub здесь\nМы можем установить этот модуль с помощью команды pip install paramiko.\nМы можем проверить установку, войдя в оболочку Python и импортировав модуль paramiko.\nNetmiko Модуль netmiko предназначен специально для сетевых устройств, тогда как paramiko — это более широкий инструмент для обработки SSH-соединений в целом.\nNetmiko, который мы использовали выше вместе с paramiko, можно установить с помощью pip install netmiko.\nNetmiko поддерживает множество сетевых поставщиков и устройств, список поддерживаемых устройств можно найти на странице GitHub.\nДругие модули Также стоит упомянуть несколько других модулей, на которые у нас не было возможности взглянуть, но они дают гораздо больше функциональных возможностей, когда речь идет об автоматизации сети.\nnetaddr используется для работы с IP-адресами и управления ими, опять же установка проста с помощью pip install netaddr\nвы можете захотеть сохранить большую часть конфигурации вашего коммутатора в электронной таблице Excel, xlrd позволит вашим сценариям читать книгу Excel и преобразовывать строки и столбцы в матрицу. pip install xlrd, чтобы установить модуль.\nЕще несколько случаев использования сетевой автоматизации, которые я не имел возможности изучить, можно найти здесь\nЯ думаю, что это завершает наш раздел «Сетевые ресурсы» #90DaysOfDevOps. Networking — это одна из областей, которую я действительно не касался какое-то время, и есть так много всего, что нужно осветить, но я надеюсь, что мои заметки и ресурсы, которыми я делюсь, будут полезны для некоторый.\nРесурсы Free Course: Introduction to EVE-NG EVE-NG - Creating your first lab 3 Necessary Skills for Network Automation Computer Networking full course Practical Networking Python Network Automation Hands-On Enterprise Automation with Python (Book) Увидимся завтра, где начнем изучать облачные вычисления и получите хорошее представление и базовые знания\n","description":"Работа с сетью в Python","title":"27. Работа с сетью в Python","uri":"/ru/docs/90daysofdevops/day27/"},{"content":"Общая картина: DevOps и облака Когда дело доходит до облачных вычислений и того, что они предлагают, это очень хорошо сочетается с духом и процессами DevOps. Мы можем думать об облачных вычислениях, предоставляющих технологии и услуги, в то время как DevOps, как мы уже много раз упоминали ранее, касается процессов и их улучшения.\nНо начать с этого путешествия по обучению в облаке сложно, и убедиться, что вы знаете и понимаете все элементы или лучший сервис для выбора по правильной цене, сбивает с толку. Накладывается ли на облака парадигма DevOps? Мой ответ здесь — нет, но чтобы по-настоящему воспользоваться преимуществами облачных вычислений и, возможно, избежать больших счетов за облачные вычисления, от которых пострадало так много людей, важно думать об облачных вычислениях и DevOps вместе.\nЕсли мы посмотрим на то, что мы подразумеваем под Public Cloud в общем смысле, речь идет о снятии некоторой ответственности с управляемой службы, чтобы вы и ваша команда могли сосредоточиться на более важных аспектах, имя которых должно быть приложением и конечными пользователями. . В конце концов, Public Cloud — это просто чей-то компьютер. В этом первом разделе я хочу немного подробнее рассказать о том, что такое Public Cloud, и о некоторых блоках, которые в целом называются Public Cloud .\nSaaS Первая область, которую следует рассмотреть, — это программное обеспечение как услуга (SaaS - Software as a service,). Эта услуга устраняет почти все накладные расходы на управление службой, которую вы, возможно, когда-то запускали локально. Давайте подумаем о Microsoft Exchange для нашей электронной почты. Раньше это была физическая коробка, которая находилась в вашем центре обработки данных или, может быть, в шкафу под лестницей. Вам нужно будет кормить и поить этот сервер. Под этим я подразумеваю, что вам нужно будет обновлять его, и вы будете нести ответственность за покупку серверного оборудования, скорее всего, за установку операционной системы, установку необходимых приложений, а затем за исправление, если что-то пойдет не так, вам придется устранить неполадки и получить вещи встали на свои места.\nО, и вам также нужно будет убедиться, что вы делаете резервную копию своих данных, хотя по большей части это не меняется и с SaaS.\nЧто делает SaaS и, в частности, Microsoft 365, потому что я упомянул, что Exchange устраняет эти накладные расходы на администрирование, и они предоставляют услугу, которая обеспечивает ваши функции обмена по почте, а также многие другие параметры производительности (Office 365) и варианты хранения (OneDrive), которые в целом дают большой опыт для конечного пользователя.\nШироко распространены и другие приложения SaaS, такие как Salesforce, SAP, Oracle, Google, Apple. Все это избавляет от необходимости управлять большим количеством стека.\nЯ уверен, что есть история с приложениями на основе DevOps и SaaS, но я изо всех сил пытаюсь выяснить, что они могут собой представлять. Я знаю, что у Azure DevOps есть отличная интеграция с Microsoft 365, которую я мог бы изучить и сообщить.\nPublic Cloud Далее у нас есть public cloud. Большинство людей думают об этом по-разному, некоторые считают, что это только гипермасштаберы, такие как Microsoft Azure, Google Cloud Platform и AWS. Некоторые также видят в общедоступном облаке гораздо более широкое предложение, включающее не только гиперскейлеры, но и тысячи MSP (managed service provider) по всему миру. В этом посте мы собираемся рассмотреть общедоступное облако, включая гиперскейлеры и MSP, хотя позже мы специально углубимся в один или несколько гиперскейлеров, чтобы получить базовые знания.\nтысячи других компаний могли бы присоединиться к этому, я просто выбираю из местных, региональных, телекоммуникационных и глобальных брендов, с которыми я работал и о которых знаю.\nВ разделе SaaS мы упомянули, что облако сняло ответственность или бремя администрирования частей системы. Если SaaS, мы видим, что многие уровни абстракции удалены, то есть физические системы, сеть, хранилище, операционная система и даже приложения в некоторой степени. Когда дело доходит до облака, существуют различные уровни абстракции, которые мы можем удалить или оставить в зависимости от ваших требований.\nМы уже упоминали SaaS, но есть еще по крайней мере два, которые следует упомянуть в отношении общедоступного облака.\nИнфраструктура как услуга. Вы можете думать об этом уровне как о виртуальной машине, но в то время как локально вам придется заботиться о физическом уровне в облаке, это не так, физический уровень является обязанностью облачных провайдеров, и вы будете управлять и управлять операционной системой, данными и приложениями, которые вы хотите запустить.\nПлатформа как услуга. Это по-прежнему снимает ответственность уровней, и на самом деле это означает, что вы берете под свой контроль данные и приложение, но вам не нужно беспокоиться об аппаратном обеспечении или операционной системе.\nЕсть много других предложений AaS, но это два основных принципа. Вы можете увидеть предложения вокруг StaaS (Storage as a service), которые предоставляют вам уровень хранения, но не нужно беспокоиться об оборудовании под ним. Или вы, возможно, слышали о CaaS для контейнеров как об услуге, к которой мы вернемся позже. Еще одна услуга как услуга, которую мы рассмотрим в течение следующих 7 дней, — это FaaS (Functions as a Service), где, возможно, вам не нужна работающая система. все время, и вы просто хотите, чтобы функция выполнялась как и когда.\nЕсть много способов, которыми общедоступное облако может предоставить уровни абстракции управления, от которых вы хотите отказаться и заплатить за них.\nPrivate Cloud Наличие собственного центра обработки данных не осталось в прошлом. Я думаю, что это стало возрождением среди многих компаний, которым было трудно управлять моделью OPEX, а также набором навыков только в использовании общедоступного облака.\nЗдесь важно отметить, что общедоступное облако, скорее всего, теперь будет вашей ответственностью и будет находиться на вашей территории.\nУ нас есть некоторые интересные вещи, происходящие в этой сфере не только с VMware, которая доминировала в эпоху виртуализации, и с локальными инфраструктурными средами. У нас также есть гиперскейлеры, предлагающие локальную версию своих публичных облаков. Hybrid Cloud В продолжение упоминаний о публичном и частном облаке мы также можем охватить обе эти среды, чтобы обеспечить гибкость между ними, возможно, воспользоваться услугами, доступными в общедоступном облаке, а затем также воспользоваться преимуществами функций и возможностей локальной среды. или это может быть правило, которое предписывает вам хранить данные локально. Собрав все это вместе, у нас есть много вариантов, где мы будем хранить и запускать наши рабочие нагрузки. Прежде чем мы перейдем к конкретному гипермасштабу, я спросил силу Твиттера, куда нам следует двигаться? Link to Twitter Poll\nКакой бы процент ни получил самый высокий процент, мы углубимся в предложения, я думаю, что важно упомянуть, что услуги во всех них очень похожи, поэтому я говорю начать с одного, потому что я обнаружил, что, зная основа одного из них и как создавать виртуальные машины, настраивать сеть и т. д. Я смог перейти к другим и быстро набраться опыта в этих областях.\nВ любом случае, я поделюсь отличными БЕСПЛАТНЫМИ ресурсами, которые охватывают все три гиперскейлера.\nЯ также собираюсь разработать сценарий, как я делал это в других разделах, где мы можем что-то построить по мере продвижения по дням.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Обзор применения инфрастуктуры DevOps в облаке","title":"28. DevOps в облаке","uri":"/ru/docs/90daysofdevops/day28/"},{"content":"Python включает пару встроенных модулей для тестирования кода. Эти два метода называются doctest и unittest. Сначала мы рассмотрим, как использовать doctest, а во втором разделе мы представим модульные тесты, используя Test Driven Development.\nТестирование с помощью doctest Модуль doctest будет искать в вашем коде фрагменты текста, напоминающие интерактивные сессии Python. Затем он выполнит эти сессии, чтобы проверить, что они работают именно так, как написано. Это означает, что если вы написали пример в docstring, который показывает вывод с пробелом или табуляцией, то фактический вывод функции также должен содержать пробел. В большинстве случаев именно в docstring вы захотите поместить свои тесты. Будут рассмотрены следующие аспекты работы с doctest:\nКак запустить doctest из терминала Как использовать doctest внутри модуля Как запустить doctest из отдельного файла. Давайте начнем!\nЗапуск doctest через терминал Мы начнем с создания действительно простой функции, которая будет удваивать все, что ей дано. Мы включим пару тестов в docstring функции. Вот код (обязательно сохраните его под именем “dtest1.py”):\n# dtest1.py def double(a): \"\"\" \u003e\u003e\u003e double(4) 8 \u003e\u003e\u003e double(9) 18 \"\"\" return a*2 Теперь нам нужно просто запустить этот код в doctest. Откройте терминал (или командную строку) и измените директории на папку, содержащую ваш скрипт. Вот скриншот того, что я сделал:\nВы заметите, что в первом примере я выполнил следующее:\npython -m doctest dtest1.py Это запустило тест и ничего не вывело на экран. Когда вы не видите ничего на экране, это означает, что все тесты прошли успешно. Во втором примере показана следующая команда:\npython -m doctest -v dtest1.py “-v” означает, что мы хотим получить подробный вывод, что мы и получили. Откройте код снова и добавьте пробел после “18” в строке docstring. Затем снова запустите тест. Вот вывод, который я получил:\nВ сообщении об ошибке говорится, что ожидалось “18”, а получилось “18”. Что здесь происходит? Мы добавили пробел после “18” в нашу строку документа, поэтому doctest на самом деле ожидал получить число “18”, за которым следует пробел. Также остерегайтесь помещать словари в качестве вывода в примерах docstring. Словари могут располагаться в любом порядке, поэтому вероятность того, что они совпадут с реальным выводом, не очень велика.\nЗапуск doctest внутри модуля Давайте немного изменим пример, чтобы импортировать модуль doctest и использовать его функцию testmod.\ndef double(a): \"\"\" \u003e\u003e\u003e double(4) 8 \u003e\u003e\u003e double(9) 18 \"\"\" return a*2 if __name__ == \"__main__\": import doctest doctest.testmod(verbose=True) Здесь мы импортируем doctest и вызываем doctest.testmod. Мы передаем ему ключевой аргумент verbose=True, чтобы мы могли увидеть некоторые выходные данные. В противном случае этот скрипт будет выполняться без какого-либо вывода, что будет означать, что тесты прошли успешно.\nЕсли вы не хотите жестко кодировать опцию verbose, вы также можете сделать это в командной строке:\npython dtest2.py -v Теперь мы готовы узнать, как поместить тесты в отдельный файл.\nЗапуск doctest из отдельного файла Модуль doctest также поддерживает размещение тестов в отдельном файле. Это позволяет нам отделить тесты от кода. Давайте вычленим тесты из предыдущего примера и поместим их в текстовый файл с именем *tests.txt:\nThe following are tests for dtest2.py \u003e\u003e\u003e from dtest2 import double \u003e\u003e\u003e double(4) 8 \u003e\u003e\u003e double(9) 18 Давайте запустим этот тестовый файл в командной строке. Вот как:\nВы заметите, что синтаксис для вызова doctest с текстовым файлом такой же, как и для вызова его с файлом Python. Результаты также одинаковы. В данном случае есть три теста вместо двух, потому что мы также импортируем модуль. Вы также можете запускать тесты, находящиеся в текстовом файле, внутри интерпретатора Python. Вот один из примеров:\nЗдесь мы просто импортируем doctest и вызываем его метод testfile. Обратите внимание, что вам также нужно передать имя файла или путь к нему функции testfile. Она вернет объект TestResults, содержащий информацию о том, сколько тестов было выполнено и сколько из них не удалось.\nРазработка, управляемая тестами, с помощью unittest В этом разделе вы узнаете о разработке под управлением тестов (TDD) в Python с помощью встроенного в Python модуля unittest. Я хочу поблагодарить Мэтта и Аарона за их помощь в демонстрации того, как TDD работает в реальном мире. Чтобы продемонстрировать концепции TDD, мы рассмотрим, как забивать кегли в Python. Если вы еще не знаете правил игры в боулинг, воспользуйтесь Google. Как только вы узнали правила, пришло время написать несколько тестов. Если вы не знали, идея Test Driven Development заключается в том, что вы пишете тесты ДО того, как пишете фактический код. В этой главе мы напишем тест, а затем код для прохождения теста. Мы будем итерационно переходить от написания тестов к написанию кода, пока не закончим. В этой главе мы напишем всего три теста. Давайте начнем!\nПервый тест Первым тестом мы протестируем наш игровой объект и посмотрим, сможет ли он вычислить правильное общее количество очков, если мы бросим одиннадцать раз и каждый раз будем сбивать только одну кеглю. Это должно дать нам общее число одиннадцать.\nimport unittest class TestBowling(unittest.TestCase): \"\"\"\"\"\" def test_all_ones(self): \"\"\"Constructor\"\"\" game = Game() game.roll(11, 1) self.assertEqual(game.score, 11) Это довольно простой тест. Мы создаем игровой объект, а затем вызываем его метод roll одиннадцать раз, причем каждый раз счет равен единице. Затем мы используем метод assertEqual из модуля unittest для проверки правильности счета игрового объекта (то есть одиннадцати). Следующий шаг - написать самый простой код, который вы можете придумать, чтобы тест прошел. Вот один из примеров:\nclass Game: \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self.score = 0 def roll(self, numOfRolls, pins): \"\"\"\"\"\" for roll in numOfRolls: self.score += pins Для простоты вы можете просто скопировать и вставить это в тот же файл с вашим тестом. Мы разобьем их на два файла для нашего следующего теста. В любом случае, как вы можете видеть, наш класс Game очень прост. Все, что было необходимо для прохождения теста, это свойство score и метод roll, который может его обновлять.\nДавайте запустим тест и посмотрим, пройдет ли он! Самый простой способ запустить тесты - добавить следующие две строки кода в конец файла:\nif __name__ == '__main__': unittest.main() Затем просто запустите файл Python через командную строку. Если вы это сделаете, вы должны получить что-то вроде следующего:\nE ====================================================================== ERROR: test_all_ones (__main__.TestBowling) Constructor ---------------------------------------------------------------------- Traceback (most recent call last): File \"C:\\Users\\Mike\\Documents\\Scripts\\Testing\\bowling\\test_one.py\", line 27, in test_all_ones game.roll(11, 1) File \"C:\\Users\\Mike\\Documents\\Scripts\\Testing\\bowling\\test_one.py\", line 15, in roll for roll in numOfRolls: TypeError: 'int' object is not iterable ---------------------------------------------------------------------- Ran 1 test in 0.001s FAILED (errors=1) Упс! Где-то здесь у нас ошибка. Похоже, что мы передаем целое число, а затем пытаемся выполнить итерацию по нему. Это не работает! Чтобы все заработало, нам нужно изменить метод roll нашего объекта Game на следующий:\ndef roll(self, numOfRolls, pins): \"\"\"\"\"\" for roll in range(numOfRolls): self.score += pins Если вы запустите тест сейчас, вы должны получить следующее:\n. ---------------------------------------------------------------------- Ran 1 test in 0.000s OK Обратите внимание на “.”, потому что это важно. Эта маленькая точка означает, что был выполнен один тест и что он прошел. Надпись “OK” в конце также указывает на этот факт. Если вы изучите исходный вывод, то заметите, что он начинается с буквы “E”, означающей ошибку, а точки там нет! Давайте перейдем к тесту №2.\nВторой тест Во втором тесте мы проверим, что происходит, когда мы получаем страйк. Нам придется изменить первый тест, чтобы использовать список для количества сбитых кеглей в каждом кадре, поэтому мы рассмотрим оба теста. Вы, вероятно, обнаружите, что это довольно распространенный процесс, когда вам может понадобиться отредактировать пару тестов из-за фундаментальных изменений в том, на что вы тестируете. Обычно это происходит только в начале вашего кодирования, и в дальнейшем вы станете лучше, так что вам не придется этого делать. Поскольку я делаю это в первый раз, я не думал достаточно далеко вперед. В любом случае, давайте посмотрим на код:\nfrom game import Game import unittest class TestBowling(unittest.TestCase): \"\"\"\"\"\" def test_all_ones(self): \"\"\"Constructor\"\"\" game = Game() pins = [1 for i in range(11)] game.roll(11, pins) self.assertEqual(game.score, 11) def test_strike(self): \"\"\" A strike is 10 + the value of the next two rolls. So in this case the first frame will be 10+5+4 or 19 and the second will be 5+4. The total score would be 19+9 or 28. \"\"\" game = Game() game.roll(11, [10, 5, 4]) self.assertEqual(game.score, 28) if __name__ == '__main__': unittest.main() Давайте посмотрим на наш первый тест и на то, как он изменился. Да, здесь мы немного нарушаем правила, когда речь идет о TDD. Не стесняйтесь НЕ изменять первый тест и посмотрите, что сломается. В методе test_all_ones мы установили переменную pins равной list comprehension, что создало список из одиннадцати единиц. Затем мы передали его в метод roll нашего game объекта вместе с количеством бросков.\nВо втором тесте мы бросаем страйк в первом броске, пятерку во втором и четверку в третьем. Заметьте, что мы пошли по головам и сказали, что передаем одиннадцать бросков, но передаем только три. Это означает, что нам нужно установить остальные восемь бросков на нули. Далее мы используем наш надежный метод assertEqual, чтобы проверить, получили ли мы правильное общее число. Наконец, обратите внимание, что теперь мы импортируем класс Game, а не сохраняем его вместе с тестами. Теперь нам нужно реализовать код, необходимый для прохождения этих двух тестов. Давайте рассмотрим одно из возможных решений:\nclass Game: \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self.score = 0 self.pins = [0 for i in range(11)] def roll(self, numOfRolls, pins): \"\"\"\"\"\" x = 0 for pin in pins: self.pins[x] = pin x += 1 x = 0 for roll in range(numOfRolls): if self.pins[x] == 10: self.score = self.pins[x] + self.pins[x+1] + self.pins[x+2] else: self.score += self.pins[x] x += 1 print(self.score) Сразу после этого вы заметите, что у нас есть новый атрибут класса под названием self.pins, который содержит список кеглей по умолчанию, состоящий из одиннадцати нулей. Затем в нашем методе roll в первом цикле мы добавляем нужные очки в нужную позицию в списке self.pins. Затем во втором цикле мы проверяем, равна ли сумма сбитых кеглей десяти. Если да, то мы добавляем его и следующие два очка к счету. В противном случае мы делаем то же самое, что и раньше. В конце метода мы выводим счет, чтобы проверить, соответствует ли он нашим ожиданиям. На этом этапе мы готовы к написанию нашего последнего теста.\nТретий (и последний) тест В нашем последнем тесте мы проверим правильность результата, который будет получен, если кто-то бросит запасной вариант. Тест прост, решение немного сложнее. Пока мы здесь, мы немного рефакторим код теста. Как обычно, сначала мы рассмотрим тест.\nfrom game_v2 import Game import unittest class TestBowling(unittest.TestCase): \"\"\"\"\"\" def setUp(self): \"\"\"\"\"\" self.game = Game() def test_all_ones(self): \"\"\" If you don't get a strike or a spare, then you just add up the face value of the frame. In this case, each frame is worth one point, so the total is eleven. \"\"\" pins = [1 for i in range(11)] self.game.roll(11, pins) self.assertEqual(self.game.score, 11) def test_spare(self): \"\"\" A spare is worth 10, plus the value of your next roll. So in this case, the first frame will be 5+5+5 or 15 and the second will be 5+4 or 9. The total is 15+9, which equals 24, \"\"\" self.game.roll(11, [5, 5, 5, 4]) self.assertEqual(self.game.score, 24) def test_strike(self): \"\"\" A strike is 10 + the value of the next two rolls. So in this case the first frame will be 10+5+4 or 19 and the second will be 5+4. The total score would be 19+9 or 28. \"\"\" self.game.roll(11, [10, 5, 4]) self.assertEqual(self.game.score, 28) if __name__ == '__main__': unittest.main() Во-первых, мы добавили метод setUp, который будет создавать для нас объект self.game для каждого теста. Если бы мы обращались к базе данных или чему-то подобному, у нас, вероятно, был бы метод tear down для закрытия соединений, файлов и тому подобных вещей. Они выполняются в начале и в конце каждого теста, соответственно, если они существуют. Тесты test_all_ones и test_strike в основном одинаковы, за исключением того, что теперь они используют “self.game”. Единственный новый тест - test_spare. В документации объясняется, как работают запасные части, а код состоит всего из двух строк. Да, вы можете разобраться в этом. Давайте посмотрим на код, который нам понадобится для прохождения этих тестов:\n# game_v2.py class Game: \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self.score = 0 self.pins = [0 for i in range(11)] def roll(self, numOfRolls, pins): \"\"\"\"\"\" x = 0 for pin in pins: self.pins[x] = pin x += 1 x = 0 spare_begin = 0 spare_end = 2 for roll in range(numOfRolls): spare = sum(self.pins[spare_begin:spare_end]) if self.pins[x] == 10: self.score = self.pins[x] + self.pins[x+1] + self.pins[x+2] elif spare == 10: self.score = spare + self.pins[x+2] x += 1 else: self.score += self.pins[x] x += 1 if x == 11: break spare_begin += 2 spare_end += 2 print(self.score) Для этой части головоломки мы добавляем условный оператор в наш цикл. Чтобы вычислить значение запасного, мы используем позиции списка spare_begin и spare_end, чтобы получить нужные значения из нашего списка, а затем суммируем их. Вот для чего нужна переменная spare. Возможно, ее лучше поместить в elif, но я оставлю это на усмотрение читателя. Технически, это только первая половина запасного результата. Вторая половина - это следующие два броска, которые вы найдете в вычислениях в части elif текущего кода. Остальная часть кода не изменилась.\nДругие примечания Как вы уже догадались, модуль unittest имеет гораздо больше возможностей, чем то, что было рассмотрено здесь. Существует множество других утверждений, которые можно использовать для проверки результатов. Вы можете пропускать тесты, запускать тесты из командной строки, использовать TestLoader для создания набора тестов и многое, многое другое. Обязательно прочитайте полную документацию, когда у вас будет такая возможность, так как это руководство лишь поверхностно изучает эту библиотеку.\nПодведение итогов На данном этапе вы должны понимать, как эффективно использовать модули doctest и unittest в своем собственном коде. Вам следует прочитать документацию Python по этим двум модулям, поскольку там есть дополнительная информация о других опциях и функциональных возможностях, которые вы можете найти полезными. Вы также знаете немного о том, как использовать концепции Test Driven Development при написании собственных сценариев.\n","description":"Python 101","title":"28. Введение в тестирование","uri":"/ru/docs/python101/chapter28_testing/"},{"content":"Знакомство с Microsoft Azure Прежде чем мы начнем, победителем опроса в Твиттере стала Microsoft Azure, отсюда и название страницы. Это было довольно интересно увидеть результаты, полученные в течение 24 часов.\nЯ бы сказал, что с точки зрения освещения этой темы я лучше понимаю и пользуюсь услугами, доступных в Microsoft Azure. Сегодня я склоняюсь к Amazon AWS. Однако я выделил разделы для всех трех основных облачных провайдеров.\nЯ ценю, что их больше, и опрос включал только эти 3, и, в частности, были некоторые комментарии об Oracle Cloud. Я хотел бы услышать больше о других облачных провайдерах, которые используются в дикой природе.\nОсновы Предоставляет общедоступные облачные сервисы\nГеографически распределены (более 60 регионов по всему миру)\nДоступ через Интернет и/или частные соединения\nМультитенантная модель\nВыставление счетов на основе потребления - (Плати по мере использования | Плати по мере роста)\nБольшое количество типов услуг и предложений для различных требований.\nMicrosoft Azure Global Infrastructure Сколько бы мы ни говорили о SaaS и Hybrid Cloud, мы не планируем затрагивать эти темы здесь.\nЛучший способ начать и продолжить работу — щелкнуть ссылку, которая позволит вам зарегистрировать Бесплатную учетную запись Microsoft Azure\nРегионы Я связал интерактивную карту выше, но мы можем видеть изображение под широтой регионов, предлагаемых на платформе Microsoft Azure по всему миру. image taken from Microsoft Docs - 01/05/2021\nВы также увидите несколько sovereign облаков, что означает, что они не связаны или не могут взаимодействовать с другими регионами, например, они будут связаны с правительствами, такими как «AzureUSGovernment», а также «AzureChinaCloud» и другими.\nКогда мы развертываем наши службы в Microsoft Azure, мы выбираем регион почти для всего. Однако важно отметить, что не все услуги доступны в каждом регионе. Вы можете увидеть Продукты, доступные по регионам на момент написания моего письма, что в западно-центральной части США мы не можем использовать Azure Databricks.\nЯ также упомянул «почти все» выше, есть определенные службы, связанные с регионом, такие как Azure Bot Services, Bing Speech, Azure Virtual Desktop, статические веб-приложения и некоторые другие.\nЗа кулисами регион может состоять из более чем одного центра обработки данных. Они будут называться зонами доступности.\nНа изображении ниже вы увидите, что это снова взято из официальной документации Microsoft, в которой описывается, что такое регион и как он состоит из зон доступности. Однако не во всех регионах есть несколько зон доступности.\nВ Microsoft хорошая документация, и вы можете прочитать больше о Регионах и зонах доступности здесь.\nПодписки Помните, что мы упоминали, что Microsoft Azure — это облако модели потребления, и вы обнаружите, что все основные поставщики облачных услуг следуют этой модели.\nЕсли вы являетесь Предприятием, вы можете захотеть или заключить соглашение Enterprise с Microsoft, чтобы ваша компания могла использовать эти службы Azure.\nЕсли вы похожи на меня и используете Microsoft Azure для обучения, у нас есть несколько других вариантов.\nУ нас есть Бесплатная учетная запись Microsoft Azure, которая обычно дает вам несколько бесплатных облачных кредитов, которые вы можете потратить в Azure в течение некоторого времени.\nСуществует также возможность использовать подписку Visual Studio, которая дает вам, возможно, несколько бесплатных кредитов каждый месяц вместе с вашей годовой подпиской на Visual Studio, которая много лет назад была широко известна как MSDN. Visual Studio\nЗатем, наконец, вручите кредитную карту и заплатите, как вы идете, модель. Оплата по мере использования\nПодписку можно рассматривать как границу между разными подписками, потенциально являющимися центрами затрат, но совершенно разными средами. Подписка — это место, где создаются ресурсы.\nManagement Groups Группы управления дают нам возможность разделять управление в нашей Azure AD или в нашей клиентской среде. Группы управления позволяют нам контролировать политики, RBAC (Role-based access control) и бюджеты.\nПодписки принадлежат этим группам управления, поэтому у вас может быть много подписок в вашем клиенте Azure AD. Эти подписки также могут управлять политиками, RBAC и бюджетами.\nResource Manager and Resource Groups Azure Resource Manager\nAPI на основе JSON, основанный на поставщиках ресурсов. Ресурсы принадлежат группе ресурсов и имеют общий жизненный цикл. Параллелизм Развертывания на основе JSON являются декларативными, идемпотентными и понимают зависимости между ресурсами для управления созданием и порядком. Resource Groups\nКаждый ресурс Azure Resource Manager существует в одной и только одной группе ресурсов! Группы ресурсов создаются в регионе, который может содержать ресурсы из-за пределов региона. Ресурсы можно перемещать между группами ресурсов Группы ресурсов не отгорожены от других групп ресурсов, между группами ресурсов может быть связь. Группы ресурсов также могут управлять политиками, RBAC и бюджетами. Практика Давайте подключимся и убедимся, что у нас есть Подписка. Мы можем проверить нашу простую готовую Группу управления. Затем мы можем пойти и создать новую выделенную Группу ресурсов в предпочитаемом нами Регионе.\nПри первом входе на наш портал Azure вверху вы увидите возможность поиска ресурсов, служб и документов.\nСначала мы рассмотрим нашу подписку. Здесь вы увидите, что я использую подписку Visual Studio Professional, которая дает мне бесплатный “кредит” каждый месяц.\nЕсли мы углубимся в это, вы получите более широкое представление и посмотрите, что происходит или что можно сделать с подпиской, мы можем увидеть информацию о выставлении счетов с функциями управления слева, где вы можете определить контроль доступа к IAM, а ниже доступно больше ресурсов.\nМожет возникнуть ситуация, когда у вас есть несколько подписок, и вы хотите управлять ими всеми в рамках одной, и именно здесь можно использовать группы управления для разделения групп ответственности. В моем ниже вы можете видеть, что есть только моя корневая группа арендатора с моей подпиской.\nВы также увидите на предыдущем изображении, что родительская группа управления — это тот же идентификатор, который используется в корневой группе арендатора.\nЗатем у нас есть группы ресурсов, здесь мы объединяем наши ресурсы и можем легко управлять ими в одном месте. У меня есть несколько созданных для различных других проектов.\nЧто мы собираемся делать в течение следующих нескольких дней, мы хотим создать нашу группу ресурсов. Это легко сделать в этой консоли, выбрав опцию создания на предыдущем изображении.\nПроисходит этап проверки, после чего у вас есть возможность просмотреть свое творение, а затем создать его. Вы также увидите внизу «Загрузить шаблон для автоматизации», это позволяет нам получить формат JSON, чтобы мы могли выполнить это просто автоматически позже, если мы захотим, мы также рассмотрим это позже. Нажмите «Create», затем в нашем списке групп ресурсов у нас теперь есть группа «90DaysOfDevOps», готовая к тому, что мы будем делать в следующем сеансе. Ресурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Туториал по Microsoft Azure с нуля","title":"29. Знакомство с Microsoft Azure","uri":"/ru/docs/90daysofdevops/day29/"},{"content":"Когда вы только начинаете программировать на Python, вы не задумываетесь о том, что вам может понадобиться установить внешний пакет или модуль. Но когда такая необходимость возникнет, вы захотите узнать, как это сделать в кратчайшие сроки! Пакеты Python можно найти по всему интернету. Большинство популярных из них можно найти в Python Package Index (PyPI). Вы также найдете множество пакетов Python на github, bitbucket и Google code. В этой статье мы рассмотрим следующие методы установки пакетов Python:\nУстановка из исходного кода easy_install pip Другие способы установки пакетов Установка из исходного кода Установка из исходного кода - отличный навык. Есть и более простые способы, о которых мы расскажем далее в статье. Однако есть некоторые пакеты, которые необходимо устанавливать из исходного кода. Например, чтобы использовать easy_install, вам нужно сначала установить setuptools. Для этого вам нужно скачать tar или zip файл из индекса пакетов Python и распаковать его где-нибудь в вашей системе. Затем найдите файл setup.py. Откройте сеанс терминала и перейдите в папку, содержащую файл setup. Затем выполните следующую команду:\npython setup.py install Если Python отсутствует в системном пути, вы получите сообщение об ошибке, в котором будет сказано, что команда python не найдена или является неизвестным приложением. Вы можете вызвать эту команду, используя полный путь к Python. Вот как это можно сделать, если вы работаете в Windows:\nc:\\python34\\python.exe setup.py install Этот метод особенно удобен, если у вас установлено несколько версий Python и вам нужно установить пакет на разные версии. Все, что вам нужно сделать, это ввести полный путь к нужной версии Python и установить пакет на нее.\nНекоторые пакеты содержат C-код, например, заголовочные файлы C, которые необходимо скомпилировать, чтобы пакет установился правильно. В Linux обычно уже установлен компилятор C/C++, и вы можете установить пакет с минимальной головной болью. В Windows для корректной компиляции пакета вам потребуется установить правильную версию Visual Studio. Некоторые говорят, что можно использовать и MingW, но я пока не нашел способа заставить его работать. Если в пакете уже есть готовый установщик для Windows, используйте его. Тогда вам вообще не придется возиться с компиляцией.\nИспользование easy_install После установки setuptools вы можете использовать easy_install. Вы можете найти его установленным в папке Scripts вашей установки Python. Не забудьте добавить папку Scripts в системный путь, чтобы можно было вызывать easy_install из командной строки без указания полного пути. Попробуйте выполнить следующую команду, чтобы узнать обо всех опциях easy_install:\neasy_install -h Когда вы хотите установить пакет с помощью easy_install, все, что вам нужно сделать, это следующее:\neasy_install package_name easy_install попытается загрузить пакет из PyPI, скомпилировать его (если необходимо) и установить. Если вы зайдете в каталог site-packages вашего Python, вы найдете файл easy-install.pth, который будет содержать запись для всех пакетов, установленных с помощью easy_install. Этот файл используется Python для помощи в импорте модуля или пакета.\nВы также можете указать easy_install установить пакет с URL или с пути на вашем компьютере. Он также может устанавливать пакеты непосредственно из tar-файла. Вы можете использовать easy_install для обновления пакета с помощью команды -upgrade (или -U). Наконец, вы можете использовать easy_install для установки eggs Python. Файлы eeg можно найти на PyPI и в других местах. Egg - это, по сути, специальный zip-файл. На самом деле, если вы измените расширение на .zip, вы сможете разархивировать файл egg.\nВот несколько примеров:\neasy_install -U SQLAlchemy easy_install http://example.com/path/to/MyPackage-1.2.3.tgz easy_install /path/to/downloaded/package Существуют некоторые проблемы с easy_install. Он будет пытаться установить пакет до завершения его загрузки. Не существует способа удалить пакет с помощью easy_install. Вам придется удалить пакет самостоятельно и обновить файл easy-install.pth, удалив запись о пакете. По этим и другим причинам в сообществе Python возникло желание создать что-то другое, что привело к появлению pip.\nИспользование pip Программа pip фактически поставляется с Python 3.4. Если у вас более старая версия Python, то вам придется установить pip вручную. Установка pip немного отличается от того, что мы обсуждали ранее. Вы по-прежнему заходите на PyPI, но вместо загрузки пакета и запуска его сценария setup.py, вам будет предложено загрузить один сценарий get-pip.py. Затем вам нужно будет выполнить его, сделав следующее:\npython get-pip.py Это позволит установить setuptools или альтернативу setuptools под названием distribute, если одна из них еще не установлена. Она также установит pip. pip работает с CPython версий 2.6, 2.7, 3.1, 3.2, 3.3, 3.4, а также с pypy. Вы можете использовать pip для установки всего, что может установить easy_install, но вызов немного отличается. Чтобы установить пакет, сделайте следующее:\npip install package_name Чтобы обновить пакет, сделайте следующее:\npip install -U PackageName Вы можете вызвать pip -h, чтобы получить полный список всего, что может сделать pip. Одна вещь, которую pip может установить, но не может установить easy_install, - это формат Python wheel. Wheel - это архив в формате ZIP со специально отформатированным именем файла и расширением .whl. Вы также можете установить wheel с помощью собственной утилиты командной строки. С другой стороны, pip не может установить яйцо. Если вам нужно установить egg, воспользуйтесь easy_install.\nЗамечание о зависимостях Одним из преимуществ использования easy_install и pip является то, что если пакет имеет зависимости, указанные в скрипте setup.py, то easy_install и pip попытаются загрузить и установить и их. Это может облегчить многие разочарования, когда вы пробуете новые пакеты и не знаете, что пакет A зависит от пакетов B, C и D. С easy_install или pip вам больше не нужно беспокоиться об этом.\nПодведение итогов На данный момент вы можете установить практически любой пакет, который вам нужен, при условии, что пакет поддерживает вашу версию Python. Программисту Python доступно множество инструментов. Хотя упаковка в Python сейчас немного запутана, как только вы узнаете, как использовать соответствующие инструменты, вы обычно сможете установить или упаковать то, что вам нужно. Мы подробнее рассмотрим создание собственных пакетов, eggs и wheels в части V.\n","description":"Python 101","title":"29. Установка пакетов","uri":"/ru/docs/python101/chapter29_pip/"},{"content":"Жизненный цикл DevOps — ориентированность на приложения По мере того, как мы будем продолжать в течение следующих нескольких недель, мы будем сталкиваться с этими названиями (Continuous Development, Testing, Deployment, Monitor) (непрерывная разработка, тестирование, развертывание, мониторинг) снова и снова. Если вы стремитесь статья инженером DevOps, то повторяемость будет тем, к чему вы привыкнете, но постоянное улучшение каждый раз — это еще одна вещь, которая делает вещи интересными.\nВ этом часе мы рассмотрим общий вид приложения от начала до конца, а затем вернемся назад, как в постоянном цикле.\nРазработка Давайте возьмем совершенно новый пример приложения, для начала у нас ничего не создано, возможно, как разработчик вы должны обсудить с вашим клиентом или конечным пользователем требования и придумать какой-то план или требования для вашего приложения. Затем нам нужно создать согласно требованиям наше новое приложение.\nЧто касается инструментов на данном этапе, здесь нет никаких реальных требований, кроме выбора вашей IDE и языка программирования, который вы хотите использовать для написания своего приложения.\nКак инженер DevOps, помните, что вы, вероятно, не тот, кто создает этот план или создает приложение для конечного пользователя, этим занимается опытный разработчик.\nНо вам также не помешает иметь возможность прочитать часть кода, чтобы вы могли принимать наилучшие решения по инфраструктуре для своего приложения.\nРанее мы упоминали, что приложение может быть написано на любом языке. Важно, чтобы это поддерживалось с помощью системы контроля версий, это то, что мы также подробно рассмотрим позже, и, в частности, мы углубимся в Git.\nТакже вероятно, что над этим проектом будет работать не один разработчик, хотя это может иметь место, но даже в этом случае передовой опыт потребует репозиторий кода для хранения и совместной работы над кодом, он может быть частным или общедоступным и может быть размещен или если говорить о частном развертывании, вы наверняка слышали, как GitHub или GitLab используются в качестве репозитория кода. Мы снова рассмотрим их позже в разделе Git.\nТестирование На данном этапе у нас есть свои требования и наша задача - разработать приложение. Но нам нужно убедиться, что мы тестируем наш код во всех различных средах, которые у нас есть, или, возможно, в выбранном языке программирования.\nЭтот этап позволяет QA тестировать на наличие ошибок, чаще мы видим, что контейнеры используются для моделирования тестовой среды, что в целом может снизить накладные расходы на физическую или облачную инфраструктуру.\nЭтот этап также, вероятно, будет автоматизирован как часть следующей области — непрерывной интеграции.\nВозможность автоматизировать это тестирование по сравнению с 10, 100 или даже 1000 инженерами по контролю качества, которые должны делать это вручную, говорит сама за себя, эти инженеры могут сосредоточиться на чем-то другом в стеке, чтобы гарантировать, что вы двигаетесь быстрее и разрабатываете больше функций по сравнению с тестированием ошибок и программного обеспечения. что, как правило, является задержкой для большинства традиционных выпусков программного обеспечения, использующих методологию водопада (Waterfall).\nИнтеграция Очень важно, что интеграция находится в середине жизненного цикла DevOps. Это практика, когда разработчикам требуется чаще вносить изменения в исходный код. Это может быть ежедневно или еженедельно.\nС каждым коммитом ваше приложение может проходить этапы автоматизированного тестирования, что позволяет на раннем этапе обнаруживать проблемы или ошибки до следующего этапа.\nНа этом этапе вы можете сказать: «Но мы не создаем приложения, мы покупаем их в готовом виде у поставщика программного обеспечения». Не волнуйтесь, многие компании делают это и будут продолжать делать, и именно поставщик программного обеспечения будет концентрируется на трех вышеупомянутых этапах, но вы, возможно, захотите принять последний этап, поскольку это позволит быстрее и эффективнее развертывать готовые развертывания.\nЯ бы также сказал, что очень важно просто иметь эти вышеперечисленные знания, поскольку сегодня вы можете купить готовое программное обеспечение, но что насчет завтра или в будущем … может быть, на следующей работе?\nРазвертывание / Deployment Итак, наше приложение создано и протестировано в соответствии с требованиями нашего конечного пользователя, и теперь нам нужно приступить к развертыванию этого приложения в рабочей среде для использования нашими конечными пользователями.\nЭто этап, когда код развертывается на рабочих серверах, теперь все становится чрезвычайно интересным, и именно здесь оставшиеся 86 дней мы глубже погружаемся в эти области. Потому что разные приложения требуют различного аппаратного обеспечения или конфигураций. Именно здесь Управление конфигурацией приложений и Инфраструктура как код могут сыграть ключевую роль в жизненном цикле DevOps. Возможно, ваше приложение контейнеризовано, но его также можно запустить на виртуальной машине. Это также приводит наше изучение к таким платформам, как Kubernetes, которые будут организовывать эти контейнеры и следить за тем, чтобы желаемое состояние было доступно вашим конечным пользователям.\nВсе эти смелые темы мы рассмотрим более подробно в течение следующих нескольких недель, чтобы лучше понять основы того, что они из себя представляют и когда их использовать.\nМониторинг / Monitoring Все быстро меняется, и у нас есть наше приложение, которое мы постоянно обновляем новыми функциями и функциями, и у нас есть наше тестирование, чтобы убедиться, что функциональность не нарушена. У нас есть приложение, работающее в нашей среде, которое может постоянно поддерживать требуемую конфигурацию и производительность.\nНо теперь мы должны быть уверены, что наши конечные пользователи получают то, что им нужно. Здесь нам нужно убедиться, что производительность нашего приложения постоянно отслеживается, этот этап позволит вашим разработчикам принимать более взвешенные решения об улучшениях приложения в будущих выпусках, чтобы лучше обслуживать конечных пользователей.\nНадежность также является ключевым фактором здесь, в конце концов, мы хотим, чтобы наше приложение было доступно все время, когда оно требуется. Затем это дает возможность другим областям наблюдаемости, безопасности и управления данными, которые следует постоянно контролировать, а обратную связь всегда можно использовать для улучшения, обновления и непрерывного выпуска приложения.\nНекоторый вклад от сообщества здесь, в частности @_ediri, упоминает также часть этого непрерывного процесса, мы также должны привлечь команды FinOps. Приложения и данные работают и хранятся где-то, за чем вы должны постоянно следить, чтобы убедиться, что если что-то изменится с точки зрения ресурсов, ваши расходы не вызовут серьезных финансовых проблем с вашими облачными счетами.\nЯ думаю, что сейчас самое время упомянуть упомянутого выше «инженера DevOps». Я имею в виду, что из разговора с другими членами сообщества звание инженера DevOps не должно быть целью ни для кого, потому что на самом деле любая должность должна включать процессы DevOps и культуру, описанную здесь. DevOps следует использовать на самых разных должностях, таких как облачный инженер/архитектор, администратор виртуализации, облачный архитектор/инженер, администратор инфраструктуры. Это лишь некоторые из них, но причина использования DevOps Engineer, описанная выше, на самом деле заключалась в том, чтобы выделить объем или процесс, используемый любой из вышеперечисленных должностей, и многое другое.\nИсточники Я всегда открыт для добавления дополнительных ресурсов в эти файлы readme, поскольку они здесь в качестве учебного пособия.\nМой совет — посмотрите все, что ниже, и, надеюсь, вы тоже что-то почерпнули из текста и объяснений выше.\nМетодология разработки CI/CD Continuous Development Continuous Testing - IBM YouTube Continuous Integration - IBM YouTube Continuous Monitoring The Remote Flow FinOps Foundation - What is FinOps NOT FREE The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win До встречи в День 4\n","description":"Ориентированность на приложения","title":"3. Ориентированность на приложения","uri":"/ru/docs/90daysofdevops/day03/"},{"content":" В Python есть еще несколько важных типов данных, которые вы, вероятно, будете использовать каждый день. Они называются списками, кортежами и словарями. Цель этой главы - познакомить вас с каждым из этих типов данных. Они не являются особенно сложными, так что думаю, что вам будет очень легко научиться их использовать. Когда вы освоите эти три типа данных, а также строковый тип данных из предыдущей главы, вы пройдете довольно большой путь в изучении Python. Вы будете использовать эти четыре строительных блока в 99% всех приложений, которые вы будете писать.\nСписки Список в Python похож на массив в других языках. В Python пустой список может быть создан следующими способами.\n\u003e\u003e\u003e my_list = [] \u003e\u003e\u003e my_list = list() Как вы видите, список можно создать с помощью квадратных скобок или с помощью встроенной в Python функции list. Список содержит перечень элементов, таких как строки, целые числа, объекты или смесь типов. Давайте рассмотрим несколько примеров:\n\u003e\u003e\u003e my_list = [1, 2, 3] \u003e\u003e\u003e my_list2 = [\"a\", \"b\", \"c\"] \u003e\u003e\u003e my_list3 = [\"a\", 1, \"Python\", 5] Первый список содержит 3 целых числа, второй - 3 строки, а третий - смесь. Вы также можете создавать списки списков следующим образом:\n\u003e\u003e\u003e my_nested_list = [my_list, my_list2] \u003e\u003e\u003e my_nested_list [[1, 2, 3], ['a', 'b', 'c']] Иногда возникает необходимость объединить два списка вместе. Первый способ - использовать метод extend:\n\u003e\u003e\u003e combo_list = [] \u003e\u003e\u003e one_list = [4, 5] \u003e\u003e\u003e combo_list.extend(one_list) \u003e\u003e\u003e combo_list [4, 5] Более простой способ - просто сложить два списка вместе.\n\u003e\u003e\u003e my_list = [1, 2, 3] \u003e\u003e\u003e my_list2 = [\"a\", \"b\", \"c\"] \u003e\u003e\u003e combo_list = my_list + my_list2 \u003e\u003e\u003e combo_list [1, 2, 3, 'a', 'b', 'c'] Да, это действительно так просто. Вы также можете сортировать список. Давайте потратим немного времени, чтобы посмотреть, как это сделать:\n\u003e\u003e\u003e alpha_list = [34, 23, 67, 100, 88, 2] \u003e\u003e\u003e alpha_list.sort() \u003e\u003e\u003e alpha_list [2, 23, 34, 67, 88, 100] А вот здесь уже есть зацепка. Вы видите ее? Давайте напишем еще один пример, чтобы сделать его очевидным:\n\u003e\u003e\u003e alpha_list = [34, 23, 67, 100, 88, 2] \u003e\u003e\u003e sorted_list = alpha_list.sort() \u003e\u003e\u003e sorted_list \u003e\u003e\u003e print(sorted_list) None В этом примере мы пытаемся присвоить отсортированный список переменной. Однако, когда вы вызываете метод sort() для списка, он сортирует список на месте. Поэтому если вы попытаетесь присвоить результат другой переменной, то получите объект None, который в других языках похож на Null. Таким образом, когда вы хотите что-то отсортировать, помните, что вы сортируете на месте и не можете присвоить результат другой переменной.\nВы можете разрезать список так же, как и строку:\n\u003e\u003e\u003e alpha_list[0:3] [2, 23, 34] Этот код возвращает список, состоящий только из первых 3 элементов.\nКортежи Кортеж похож на список, но при его создании вместо квадратных скобок используются круглые скобки. Вы также можете использовать tuple встроенно. Основное отличие состоит в том, что кортеж неизменяем, а список - изменяем. Давайте рассмотрим несколько примеров:\n\u003e\u003e\u003e my_tuple = (1, 2, 3, 4, 5) \u003e\u003e\u003e my_tuple[0:3] (1, 2, 3) \u003e\u003e\u003e another_tuple = tuple() \u003e\u003e\u003e abc = tuple([1, 2, 3]) Приведенный выше код демонстрирует один из способов создания кортежа с пятью элементами. Он также показывает, что вы можете выполнять нарезку кортежей. Однако вы не можете отсортировать кортеж! Последние два примера показывают, как создавать кортежи с помощью ключевого слова tuple. Первый пример просто создает пустой кортеж, в то время как второй пример содержит три элемента. Обратите внимание, что внутри него находится список. Это пример преобразования. Мы можем изменить или преобразовать элемент из одного типа данных в другой. В данном случае мы приводим список к кортежу. Если вы хотите превратить кортеж abc обратно в список, вы можете сделать следующее:\n\u003e\u003e\u003e abc_list = list(abc) Повторим, что приведенный выше код преобразует кортеж (abc) в список с помощью функции list.\nСловари Словарь в Python - это, по сути, хэш-таблица или хэш-сопоставление. В некоторых языках они могут называться ассоциативной памятью или ассоциативными массивами. Они индексируются ключами, которые могут быть любого неизменяемого типа. Например, ключом может быть строка или число. Необходимо знать, что словарь - это неупорядоченный набор пар ключ:значение, и ключи должны быть уникальными. Вы можете получить список ключей, вызвав метод keys экземпляра словаря. Чтобы проверить, есть ли у словаря ключ, можно использовать ключевое слово in в Python. В некоторых старых версиях Python (точнее, в 2.3 и старше) для проверки наличия ключа в словаре используется ключевое слово has_key. Это ключевое слово устарело в Python 2.x и полностью удалено из Python 3.x.\nДавайте рассмотрим, как мы создаем словарь.\n\u003e\u003e\u003e my_dict = {} \u003e\u003e\u003e another_dict = dict() \u003e\u003e\u003e my_other_dict = {\"one\":1, \"two\":2, \"three\":3} \u003e\u003e\u003e my_other_dict {'three': 3, 'two': 2, 'one': 1} Первые два примера показывают, как создать пустой словарь. Все словари заключены в фигурные скобки. Последняя строка выводится на печать, чтобы вы могли увидеть, насколько словарь неупорядочен. Теперь пришло время узнать, как получить доступ к значению в словаре.\n\u003e\u003e\u003e my_other_dict[\"one\"] 1 \u003e\u003e\u003e my_dict = {\"name\":\"Mike\", \"address\":\"123 Happy Way\"} \u003e\u003e\u003e my_dict[\"name\"] 'Mike' В первом примере мы используем словарь из предыдущего примера и извлекаем значение, связанное с ключом “one”. Во втором примере показано, как получить значение для ключа “name”. Теперь давайте посмотрим, как определить, находится ли ключ в словаре или нет:\n\u003e\u003e\u003e \"name\" in my_dict True \u003e\u003e\u003e \"state\" in my_dict False Таким образом, если ключ находится в словаре, Python возвращает булевое значение True. В противном случае он возвращает булево значение False. Если вам нужно получить список всех ключей в словаре, то вы делаете следующее:\n\u003e\u003e\u003e my_dict.keys() dict_keys(['name', 'address']) В Python 3 метод keys возвращает объект представления. Это дает разработчику возможность обновить словарь, и представление тоже автоматически обновится. Также обратите внимание, что при использовании ключевого слова in для тестирования членства в словаре, лучше делать это по словарю, а не по списку, возвращаемому методом keys. См. ниже:\n\u003e\u003e\u003e \"name\" in my_dict # this is good \u003e\u003e\u003e \"name\" in my_dict.keys() # this works too, but is slower Хотя сейчас это, вероятно, не имеет для вас большого значения, в реальной рабочей ситуации секунды важны. Когда вам нужно обработать тысячи файлов, эти маленькие хитрости помогут вам сэкономить много времени в долгосрочной перспективе!\nИтоги В этой главе вы только что узнали, как построить список, кортеж и словарь Python. Прежде чем двигаться дальше, убедитесь, что вы поняли все, что было написано в этом разделе. Эти понятия помогут вам при разработке программ. Вы будете каждый день создавать сложные структуры данных с помощью этих строительных блоков, если решите работать программистом Python. Каждый из этих типов данных может быть вложен в другие. Например, у вас может быть вложенный словарь, словарь кортежей, кортеж, состоящий из нескольких словарей, и так далее.\nКогда вы будете готовы двигаться дальше, мы познакомимся с поддержкой условных операторов в Python.\nСсылки Множества в Python ","description":"Python 101","title":"3. Списки, кортежи и словари","uri":"/ru/docs/python101/chapter3_lists_dicts/"},{"content":"Python поставляется с удобным модулем под названием ConfigParser. Он хорошо подходит для создания и чтения конфигурационных файлов (они же INI-файлы). Однако Майкл Форд (автор IronPython in Action) и Никола Лароса решили написать свой собственный модуль конфигурации под названием ConfigObj. Во многих отношениях он является улучшением модуля стандартной библиотеки. Например, при чтении файла конфигурации он возвращает объект, похожий на словарь. ConfigObj также может понимать некоторые типы Python. Еще одна интересная особенность заключается в том, что вы можете создать спецификацию конфигурации, которую ConfigObj будет использовать для проверки файла конфигурации.\nНачало работы Прежде всего, вам нужно получить ConfigObj. Сейчас самое время использовать знания из последней главы об установке пакетов. Вот как можно получить ConfigObj с помощью pip:\npip install configobj После того как вы установили его, мы можем двигаться дальше. Для начала откройте текстовый редактор и создайте файл с таким содержимым:\nproduct = Sony PS3 accessories = controller, eye, memory stick # This is a comment that will be ignored retail_price = $400 Сохраните его в любом удобном для вас месте. Я назову свой файл config.ini. Теперь давайте посмотрим, как можно использовать ConfigObj для извлечения этой информации:\n\u003e\u003e\u003e from configobj import ConfigObj \u003e\u003e\u003e config = ConfigObj(r\"path to config.ini\") \u003e\u003e\u003e config[\"product\"] 'Sony PS3' \u003e\u003e\u003e config[\"accessories\"] ['controller', 'eye', 'memory stick'] \u003e\u003e\u003e type(config[\"accessories\"]) \u003ctype 'list'\u003e Как вы можете видеть, ConfigObj использует API dict Python для доступа к извлеченной информации. Чтобы заставить ConfigObj разобрать файл, достаточно передать ConfigObj путь к файлу. Если бы информация находилась в разделе (например, [Sony]), то вам пришлось бы предварительно поместить все в [“Sony”], например, так: config[“Sony”][“product”]. Также обратите внимание, что раздел accessories был возвращен в виде списка строк. ConfigObj возьмет любую допустимую строку со списком, разделенным запятыми, и вернет ее в виде списка Python. Вы также можете создавать многострочные строки в конфигурационном файле при условии, что вы заключите их в тройные одинарные или двойные кавычки.\nЕсли вам нужно создать подраздел в файле, то используйте дополнительные квадратные скобки. Например, [Sony] - это верхний раздел, [[Playstation]] - подраздел, а [[[PS3]] - подраздел подраздела. Вы можете создавать подразделы любой глубины. Для получения дополнительной информации о форматировании файла я рекомендую прочитать документацию ConfigObj.\nТеперь мы сделаем обратное и создадим конфигурационный файл программно.\nimport configobj def createConfig(path): config = configobj.ConfigObj() config.filename = path config[\"Sony\"] = {} config[\"Sony\"][\"product\"] = \"Sony PS3\" config[\"Sony\"][\"accessories\"] = ['controller', 'eye', 'memory stick'] config[\"Sony\"][\"retail price\"] = \"$400\" config.write() if __name__ == \"__main__\": createConfig(\"config.ini\") Как вы можете видеть, все, что для этого потребовалось, - это 13 строк кода. В приведенном выше коде мы создаем функцию и передаем ей путь к нашему файлу конфигурации. Затем мы создаем объект ConfigObj и устанавливаем его свойство filename. Для создания секции мы создаем пустой dict с именем “Sony”. Затем таким же образом добавляем каждую строку содержимого секции. Наконец, мы вызываем метод write нашего объекта config, чтобы записать данные в файл.\nИспользование configspec ConfigObj также предоставляет способ проверки ваших конфигурационных файлов с помощью configspec. Когда я упомянул, что собираюсь написать на эту тему, Стивен Спраут (Steven Sproat, создатель Whyteboard) предложил свой код configspec в качестве примера. Я взял его спецификацию и использовал ее для создания конфигурационного файла по умолчанию. В этом примере для проверки мы используем модуль validate от Foord. Я не думаю, что он включен в вашу загрузку ConfigObj, поэтому вам может понадобиться загрузить и его. Теперь давайте посмотрим на код:\nimport configobj, validate cfg = \"\"\" bmp_select_transparent = boolean(default=False) canvas_border = integer(min=10, max=35, default=15) colour1 = list(min=3, max=3, default=list('280', '0', '0')) colour2 = list(min=3, max=3, default=list('255', '255', '0')) colour3 = list(min=3, max=3, default=list('0', '255', '0')) colour4 = list(min=3, max=3, default=list('255', '0', '0')) colour5 = list(min=3, max=3, default=list('0', '0', '255')) colour6 = list(min=3, max=3, default=list('160', '32', '240')) colour7 = list(min=3, max=3, default=list('0', '255', '255')) colour8 = list(min=3, max=3, default=list('255', '165', '0')) colour9 = list(min=3, max=3, default=list('211', '211', '211')) convert_quality = option('highest', 'high', 'normal', default='normal') default_font = string default_width = integer(min=1, max=12000, default=640) default_height = integer(min=1, max=12000, default=480) imagemagick_path = string handle_size = integer(min=3, max=15, default=6) language = option('English', 'English (United Kingdom)', 'Russian', 'Hindi', default='English') print_title = boolean(default=True) statusbar = boolean(default=True) toolbar = boolean(default=True) toolbox = option('icon', 'text', default='icon') undo_sheets = integer(min=5, max=50, default=10) \"\"\" def createConfig(path): \"\"\" Create a config file using a configspec and validate it against a Validator object \"\"\" spec = cfg.split(\"\\n\") config = configobj.ConfigObj(path, configspec=spec) validator = validate.Validator() config.validate(validator, copy=True) config.filename = path config.write() if __name__ == \"__main__\": createConfig(\"config.ini\") configspec дает программисту возможность указать, какие типы возвращаются для каждой строки в конфигурационном файле. Он также может быть использован для установки значения по умолчанию, min и max значений (среди прочего). Если вы выполните приведенный выше код, вы увидите, что в текущем рабочем каталоге будет создан файл config.ini, содержащий только значения по умолчанию. Если программист не указал значение по умолчанию, то эта строка даже не будет добавлена в конфигурацию.\nДавайте рассмотрим происходящее подробнее, чтобы убедиться, что вы все поняли. В функции createConfig мы создаем экземпляр ConfigObj, передавая путь к файлу и задавая configspec. Обратите внимание, что configspec может быть обычным текстовым файлом или файлом python, а не строкой, как в этом примере. Далее мы создаем объект Validator. Обычное использование - просто вызвать config.validate(validator), но в этом коде я установил аргумент copy в True, чтобы можно было создать файл. В противном случае, все, что бы он сделал, это проверил, что файл, который я передал, соответствует правилам configspec. Наконец, я задаю имя файла конфига и записываю данные.\nПодведение итогов Теперь вы знаете достаточно, чтобы начать работу с ConfigObj. Надеюсь, вы найдете его полезным, как и я. Не забудьте обратиться к документации модуля и прочитать больше о том, что он и validate могут делать.\n","description":"Python 101","title":"30. ConfigObj","uri":"/ru/docs/python101/chapter30_configobj/"},{"content":"Microsoft Azure Security Models Следуя обзору Microsoft Azure, мы начнем с безопасности Azure и посмотрим, как это может помочь в наши дни. По большей части я обнаружил, что встроенных ролей было достаточно, и зная это, мы можем создавать и работать со многими различными областями аутентификации и конфигураций. Я обнаружил, что Microsoft Azure довольно продвинута с ее инструментом Active Directory по сравнению с другими общедоступными облаками.\nЭто одна из областей, в которой Microsoft Azure, по-видимому, работает иначе, чем другие поставщики общедоступных облаков, в Azure ВСЕГДА есть Azure AD.\nСлужбы каталогов (Directory Services ) Azure Active Directory содержит принципы безопасности, используемые Microsoft Azure и другими облачными службами Microsoft. Аутентификация осуществляется с помощью таких протоколов, как SAML, WS-Federation, OpenID Connect и OAuth2. Запросы выполняются через REST API, который называется Microsoft Graph API. У арендаторов по умолчанию есть имя tenant.onmicrosoft.com, но они также могут иметь собственные доменные имена. Подписки связаны с арендатором Azure Active Directory. Если мы сравним с AWS, эквивалентным предложением будет AWS IAM (управление идентификацией и доступом), хотя все еще очень разные\nAzure AD Connect предоставляет возможность репликации учетных записей из AD в Azure AD. Сюда также могут входить группы и иногда объекты. Это может быть гранулировано и отфильтровано. Поддерживает несколько лесов и доменов.\nВ Microsoft Azure Active Directory (AD) можно создавать облачные учетные записи, но большинство организаций уже учли своих пользователей в собственной локальной Active Directory.\nAzure AD Connect также позволяет вам видеть не только серверы Windows AD, но и другие Azure AD, Google и другие. Это также дает возможность сотрудничать с внешними людьми и организациями, что называется Azure B2B.\nВарианты аутентификации между доменными службами Active Directory и Microsoft Azure Active Directory возможны с синхронизацией удостоверений с хэшем пароля.\nПередача хэша пароля необязательна, если он не используется, требуется сквозная аутентификация.\nНиже приведено видео, в котором подробно рассказывается о сквозной аутентификации.\nUser sign-in with Azure Active Directory Pass-through Authentication\nФедерации (Federation) Справедливости ради стоит сказать, что если вы используете Microsoft 365, Microsoft Dynamics и локальную Active Directory, их довольно легко понять и интегрировать в Azure AD для федерации. Однако вы можете использовать другие службы за пределами экосистемы Microsoft.\nAzure AD может выступать в качестве посредника федерации для этих других приложений сторонних производителей и других служб каталогов.\nЭто будет отображаться на портале Azure как корпоративные приложения, для которых существует большое количество вариантов.\nЕсли вы прокрутите вниз страницу корпоративного приложения, вы увидите длинный список рекомендуемых приложений.\nЭта опция также позволяет «принести свою» интеграцию, приложение, которое вы разрабатываете, или приложение, не являющееся галереей.\nЯ не изучал это раньше, но вижу, что это вполне подходящий набор функций по сравнению с другими облачными провайдерами и возможностями.\nУправление доступом на основе ролей Мы уже рассмотрели в День 29 области, которые мы собираемся охватить здесь, мы можем настроить управление доступом на основе ролей в соответствии с одной из этих областей.\nSubscriptions Management Group Resource Group Resources Роли можно разделить на три, в Microsoft Azure много встроенных ролей. Эти три:\nOwner Contributor Reader Владелец и участник очень похожи по своим границам, однако владелец может изменять разрешения.\nДругие роли относятся к определенным типам ресурсов Azure, а также к пользовательским ролям.\nМы должны сосредоточиться на назначении разрешений группам и пользователям.\nРазрешения наследуются.\nЕсли мы вернемся назад и посмотрим на группу ресурсов «90DaysOfDevOps», которую мы создали, и проверим контроль доступа (IAM) внутри, вы увидите, что у нас есть список участников и администратор доступа пользователей клиента, и у нас есть список владельцев (но Я не могу это показать)\nМы также можем проверить роли, которые мы назначили здесь, являются ли они встроенными ролями и к какой категории они относятся.\nМы также можем использовать вкладку проверки доступа, если мы хотим проверить учетную запись по этой группе ресурсов и убедиться, что учетная запись, к которой мы хотим иметь этот доступ, имеет правильные разрешения, или, может быть, мы хотим проверить, не имеет ли пользователь слишком много доступа.\nMicrosoft Defender for Cloud Microsoft Defender for Cloud (ранее известный как Azure Security Center) предоставляет информацию о безопасности всей среды Azure.\nЕдиная панель мониторинга для просмотра общего состояния безопасности всех ресурсов Azure и других ресурсов (через Azure Arc) и рекомендации по усилению безопасности.\nУровень бесплатного пользования включает постоянную оценку и рекомендации по безопасности.\nПлатные планы для защищенных типов ресурсов (например, серверы, AppService, SQL, хранилище, контейнеры, KeyVault).\nЯ перешел на другую подписку для просмотра Центра безопасности Azure, и вы можете увидеть здесь, основываясь на очень небольшом количестве ресурсов, что у меня есть некоторые рекомендации в одном месте.\nAzure Policy Azure Policy — это собственная служба Azure, которая помогает применять организационные стандарты и оценивать соответствие в масштабе.\nИнтегрирован в Microsoft Defender для облака. Azure Policy проверяет несоответствующие ресурсы и применяет исправления.\nОбычно используется для управления согласованностью ресурсов, соблюдением нормативных требований, безопасностью, стоимостью и стандартами управления.\nИспользует формат JSON для хранения логики оценки и определения того, соответствует ли ресурс требованиям или нет, а также любых действий, которые необходимо предпринять в случае несоответствия (например, аудит, аудит, если не существует, запретить, изменить, развернуть, если не существует).\nБесплатно для использования. Исключение составляют подключенные ресурсы Azure Arc, взимаемые за сервер в месяц за использование гостевой конфигурации политики Azure.\nПрактика Я купил домен и хотел бы добавить этот на свой портал Azure Active Directory, Add your custom domain name using the Azure Active Directory Portal\nТеперь мы можем создать нового пользователя в нашем новом домене Active Directory.\nТеперь мы хотим создать группу для всех наших новых пользователей 90DaysOfDevOps в одной группе. Мы можем создать группу, как показано ниже, обратите внимание, что я использую «Динамический пользователь», это означает, что Azure AD будет запрашивать учетные записи пользователей и добавлять их динамически по сравнению с назначенными, когда вы вручную добавляете пользователя в свою группу.\nСуществует множество вариантов создания вашего запроса, мой план состоит в том, чтобы просто найти основное имя и убедиться, что оно содержит мой запрос.\nТеперь, поскольку мы уже создали нашу учетную запись пользователя, мы можем проверить, работают ли правила. Для сравнения я также добавил здесь еще одну учетную запись, связанную с другим доменом, и вы можете видеть, что из-за этого правила наш пользователь не попадет в эту группу.\nС тех пор я добавил нового пользователя, и если мы пойдем и проверим группу, мы увидим наших участников.\nЕсли у нас есть это требование x100, то мы не собираемся делать все это в консоли, мы собираемся воспользоваться либо массовыми параметрами для создания, приглашения, удаления пользователей, либо вы захотите изучить PowerShell для достичь этого автоматизированного подхода к масштабированию.\nТеперь мы можем перейти к нашей группе ресурсов и указать, что в группе ресурсов 90DaysOfDevOps мы хотим, чтобы владельцем была группа, которую мы только что создали.\nМы также можем войти сюда и запретить доступ назначений к нашей группе ресурсов.\nТеперь, если мы войдем на портал Azure с нашей новой учетной записью пользователя, вы увидите, что у нас есть доступ только к нашей группе ресурсов 90DaysOfDevOps, а не к другим, показанным на предыдущих рисунках, потому что у нас нет доступа.\nВышеприведенное замечательно, если это пользователь, имеющий доступ к ресурсам внутри вашего портала Azure, но не каждый пользователь должен знать о портале, но для проверки доступа мы можем использовать Портал приложений Это портал единого входа, который мы тестируем.\nВы можете настроить этот портал под своим собственным брендом, и мы, возможно, вернемся к этому позже.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Модули безопасности Microsoft Azure","title":"30. Модули безопасности Microsoft Azure","uri":"/ru/docs/90daysofdevops/day30/"},{"content":"Среда выполнения приложений Вслед за вчерашним обзором основ моделей безопасности в Microsoft Azure, сегодня мы собираемся изучить различные службы вычислений, доступные нам в Azure.\nПараметры службы доступности Этот раздел мне близок, учитывая мою роль в управлении данными. Как и в случае с локальной средой, очень важно обеспечить доступность ваших служб.\nВысокая доступность (Защита в пределах региона) Аварийное восстановление (Защита между регионами) Резервное копирование (Восстановление с момента времени) Microsoft развертывает несколько регионов в пределах геополитических границ.\nДве концепции Azure для доступности услуг.\nНаборы доступности (виртуальных машин) — обеспечивают отказоустойчивость в центре обработки данных.\nЗоны доступности — обеспечивают отказоустойчивость между центрами обработки данных в пределах региона.\nВиртуальные машины Предоставляет виртуальные машины различных серий и размеров с различными возможностями (иногда огромными) Размеры виртуальных машин в Azure Существует множество различных вариантов и фокусов для виртуальных машин, от высокопроизводительных, с малой задержкой до виртуальных машин с большим объемом памяти. У нас также есть расширяемый тип ВМ, который можно найти в серии B. Это отлично подходит для рабочих нагрузок, где у вас могут быть низкие требования к ЦП по большей части, но требуется, чтобы, возможно, один раз в месяц требовалась всплеск производительности. Виртуальные машины размещаются в виртуальной сети, которая может обеспечить подключение к любой сети. Поддержка гостевых ОС Windows и Linux. Существуют также ядра, настроенные для Azure, если речь идет о конкретных дистрибутивах Linux. Ядра, настроенные Azure Шаблоны В Microsoft Azure шаблоны исполнений можно конфигурировать с помощью JSON.\nСуществует несколько различных порталов и консолей управления, которые мы можем использовать для создания наших ресурсов. Предпочтительнее будет через шаблоны JSON.\nИдемпотентные развертывания в инкрементном или полном режиме — т.е. повторяемое желаемое состояние.\nСуществует большой выбор шаблонов, которые могут экспортировать развернутые определения ресурсов. Мне нравится думать об этой функции шаблонов как о чем-то вроде AWS CloudFormation или, возможно, о Terraform для мультиоблачного варианта. Подробнее о Terraform мы расскажем в разделе «Инфраструктура как код».\nМасштабирование Автоматическое масштабирование — это крупная функция общедоступного облака, позволяющая сократить ресурсы, которые вы не используете, или активировать, когда они вам нужны.\nВ Azure у нас есть так называемые масштабируемые наборы виртуальных машин (VMSS) для IaaS. Это позволяет автоматически создавать и масштабировать изображение золотого стандарта на основе расписаний и показателей.\nЭто идеально подходит для обновления окон, чтобы вы могли обновлять свои образы и развертывать их с наименьшими последствиями.\nВ другие службы, такие как службы приложений Azure, встроено автоматическое масштабирование.\nКонтейнеры Мы не рассмотрели контейнеры как пример использования и то, что и как они могут и должны быть необходимы в нашем учебном путешествии по DevOps, но мы должны упомянуть, что у Azure есть некоторые конкретные службы, ориентированные на контейнеры, которые следует упомянуть.\nСлужба Azure Kubernetes (AKS) (Azure Kubernetes Service) — предоставляет управляемое решение Kubernetes.\nЭкземпляры контейнеров Azure — контейнеры как услуга с посекундной оплатой. Запустите образ и интегрируйте его с вашей виртуальной сетью, не нуждаясь в оркестровке контейнеров.\nService Fabric — имеет множество возможностей, но включает оркестрацию для экземпляров контейнеров.\nAzure также имеет реестр контейнеров, который предоставляет частный реестр для образов Docker, диаграмм Helm, артефактов Open Container Initiative (OCI) и образов. Подробнее об этом снова, когда мы дойдем до раздела контейнеров.\nМногие службы контейнеров действительно могут использовать контейнеры “под капотом”, но это абстрагируется от наших требований к управлению.\nСлужбы приложений Службы приложений Azure предоставляют решение для размещения приложений, которое обеспечивает простой способ установки служб. Автоматическое развертывание и масштабирование. Поддерживает решения на базе Windows и Linux. Службы выполняются в плане службы приложений, который имеет тип и размер. Количество различных сервисов, включая веб-приложения, приложения API и мобильные приложения. Поддержка слотов развертывания для надежного тестирования и продвижения. Бессерверные вычисления Цель бессерверных вычислений заключается в том, что мы платим только за время выполнения функции, и нам не нужно постоянно запускать виртуальные машины или приложения PaaS. Мы просто запускаем нашу функцию, когда она нам нужна, а затем она исчезает.\nФункции Azure — предоставляет бессерверный код. Если мы вернемся к нашему первому взгляду на общедоступное облако, вы вспомните уровень абстракции управления, с бессерверными функциями вы будете управлять только кодом.\nУ меня есть план, ориентированный на события в больших масштабах, когда я получу здесь немного практики, надеюсь, позже.\nОбеспечивает входную и выходную привязку ко многим Azure и сторонним службам.\nПоддерживает множество различных языков программирования. (C#, NodeJS, Python, PHP, bash, Golang, Rust или любой исполняемый файл)\nСетка событий Azure позволяет запускать логику из служб и событий.\nПриложение Azure Logic обеспечивает графический рабочий процесс и интеграцию.\nМы также можем рассмотреть пакетную службу Azure, которая может выполнять крупномасштабные задания на узлах Windows и Linux с согласованным управлением и планированием.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Microsoft Azure Среда выполнения приложений","title":"31. Microsoft Azure Среда выполнения приложений","uri":"/ru/docs/90daysofdevops/day31/"},{"content":"В первой части мы рассмотрели некоторые встроенные в Python парсеры XML. В этой главе мы рассмотрим интересный пакет сторонних разработчиков, lxml от codespeak. Он использует, помимо прочего, ElementTree API. Пакет lxml имеет поддержку XPath и XSLT, включает API для SAX и API уровня C для совместимости с модулями C/Pyrex. Вот что мы рассмотрим:\nКак разобрать XML с помощью lxml Пример рефакторинга Как разобрать XML с помощью lxml.objectify Как создать XML с помощью lxml.objectify В этой статье, мы используем примеры, основанные на примерах парсинга minidom, и посмотрим, как выполнять парсинг при помощи lxml Python. Вот пример XML из программы, которая была написана для отслеживания назначений:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003cappointment\u003e \u003cbegin\u003e1234360800\u003c/begin\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eCheck MS Office website for updates\u003c/subject\u003e \u003clocation\u003e\u003c/location\u003e \u003cuid\u003e604f4792-eb89-478b-a14f-dd34d3cc6c21-1234360800\u003c/uid\u003e \u003cstate\u003edismissed\u003c/state\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Давайте узнаем, как разобрать его с помощью lxml!\nРазбор XML с помощью lxml Данный пример XML показывает два назначения. Время начинается спустя секунды после эпохи. Наш uid сгенерирован на основе хеша начала времени и ключа. Время сигнала – несколько секунд после эпохи, но не раньше начала времени. Состояние – если назначение было отменено или перенесено, или нет, так или иначе. Остальная часть XML, как мы видим, в пояснении не нуждается. Давайте взглянем на то, как делается парсинг:\nfrom lxml import etree def parseXML(xmlFile): \"\"\" Parse the xml \"\"\" with open(xmlFile) as fobj: xml = fobj.read() root = etree.fromstring(xml) for appt in root.getchildren(): for elem in appt.getchildren(): if not elem.text: text = \"None\" else: text = elem.text print(elem.tag + \" =\u003e \" + text) if __name__ == \"__main__\": parseXML(\"example.xml\") Прежде всего, мы импортируем необходимые модули, а именно модуль etree из пакета lxml и функцию StringIO из встроенного модуля StringIO. Наша функция parseXML принимает один аргумент: путь к рассматриваемому XML-файлу. Мы открываем файл, читаем его и закрываем. Теперь наступает самая интересная часть! Мы используем функцию etree’s parse для разбора XML-кода, возвращаемого модулем StringIO. По не совсем понятным мне причинам, функция parse требует объект, похожий на файл.\nВ любом случае, далее мы выполняем итерацию по контексту (т.е. объекту lxml.etree.iterparse) и извлекаем элементы тегов. Мы добавляем условный оператор if, чтобы заменить пустые поля на слово “None”, чтобы сделать вывод немного понятнее. Вот и все.\nРазбор примера с книгой Что ж, результат этого примера был довольно скучным. В большинстве случаев вы хотите сохранить извлеченные данные и что-то с ними сделать, а не просто вывести их на stdout. Так что в следующем нашем примере мы создадим структуру данных для сбора результатов. В данном примере структура наших данных будет представлять собой список словарей. Мы используем пример книги MSDN. Сохраните следующий код XML под названием example.xml.\n\u003c?xml version=\"1.0\"?\u003e \u003ccatalog\u003e \u003cbook id=\"bk101\"\u003e \u003cauthor\u003eGambardella, Matthew\u003c/author\u003e \u003ctitle\u003eXML Developer's Guide\u003c/title\u003e \u003cgenre\u003eComputer\u003c/genre\u003e \u003cprice\u003e44.95\u003c/price\u003e \u003cpublish_date\u003e2000-10-01\u003c/publish_date\u003e \u003cdescription\u003eAn in-depth look at creating applications with XML.\u003c/description\u003e \u003c/book\u003e \u003cbook id=\"bk102\"\u003e \u003cauthor\u003eRalls, Kim\u003c/author\u003e \u003ctitle\u003eMidnight Rain\u003c/title\u003e \u003cgenre\u003eFantasy\u003c/genre\u003e \u003cprice\u003e5.95\u003c/price\u003e \u003cpublish_date\u003e2000-12-16\u003c/publish_date\u003e \u003cdescription\u003eA former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.\u003c/description\u003e \u003c/book\u003e \u003cbook id=\"bk103\"\u003e \u003cauthor\u003eCorets, Eva\u003c/author\u003e \u003ctitle\u003eMaeve Ascendant\u003c/title\u003e \u003cgenre\u003eFantasy\u003c/genre\u003e \u003cprice\u003e5.95\u003c/price\u003e \u003cpublish_date\u003e2000-11-17\u003c/publish_date\u003e \u003cdescription\u003eAfter the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.\u003c/description\u003e \u003c/book\u003e \u003c/catalog\u003e Теперь давайте разберем этот XML и поместим его в нашу структуру данных!\nfrom lxml import etree def parseBookXML(xmlFile): with open(xmlFile) as fobj: xml = fobj.read() root = etree.fromstring(xml) book_dict = {} books = [] for book in root.getchildren(): for elem in book.getchildren(): if not elem.text: text = \"None\" else: text = elem.text print(elem.tag + \" =\u003e \" + text) book_dict[elem.tag] = text if book.tag == \"book\": books.append(book_dict) book_dict = {} return books if __name__ == \"__main__\": parseBookXML(\"books.xml\") Данный пример весьма похож на предыдущий, так что мы сосредоточимся только на различиях между ними. Перед началом итерации над контекстом, мы создадим объект пустого словаря и пустой список Python. Далее, в цикле, мы создадим наш словарь вот так:\nbook_dict[elem.tag] = text Текст - это либо elem.text, либо None. Наконец, если тегом является book, то мы находимся в конце раздела книги и должны добавить dict в наш список, а также сбросить dict для следующей книги. Как вы можете видеть, именно это мы и сделали. Более реалистичным примером было бы поместить извлеченные данные в класс Book. Я уже делал это с json-лентами.\nТеперь мы готовы узнать, как разобрать XML с помощью lxml.objectify!\nРазбор XML с помощью lxml.objectify Модуль lxml имеет модуль objectify, который может превращать XML-документы в объекты Python. Я считаю, что с “объективированными” XML-документами очень легко работать, и надеюсь, что вы тоже. Для его установки вам, возможно, придется проделать несколько шагов, поскольку pip не работает с lxml в Windows. Обязательно зайдите в индекс пакетов Python и поищите версию, созданную для вашей версии Python. Также обратите внимание, что последняя предварительная программа установки lxml поддерживает только Python 3.2 (на момент написания статьи), так что если у вас более новая версия Python, у вас могут возникнуть некоторые трудности с установкой lxml для вашей версии.\nВ любом случае, как только вы его установите, мы сможем снова приступить к изучению этого замечательного куска XML:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003cappointment\u003e \u003cbegin\u003e1234360800\u003c/begin\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eCheck MS Office website for updates\u003c/subject\u003e \u003clocation\u003e\u003c/location\u003e \u003cuid\u003e604f4792-eb89-478b-a14f-dd34d3cc6c21-1234360800\u003c/uid\u003e \u003cstate\u003edismissed\u003c/state\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Теперь нам нужно написать код, который будет разбирать и изменять XML. Давайте посмотрим на эту небольшую демонстрацию, которая показывает ряд возможностей, которые предоставляет objectify.\nfrom lxml import etree, objectify def parseXML(xmlFile): \"\"\"Parse the XML file\"\"\" with open(xmlFile) as f: xml = f.read() root = objectify.fromstring(xml) # returns attributes in element node as dict attrib = root.attrib # how to extract element data begin = root.appointment.begin uid = root.appointment.uid # loop over elements and print their tags and text for appt in root.getchildren(): for e in appt.getchildren(): print(\"%s =\u003e %s\" % (e.tag, e.text)) print() # how to change an element's text root.appointment.begin = \"something else\" print(root.appointment.begin) # how to add a new element root.appointment.new_element = \"new data\" # remove the py:pytype stuff objectify.deannotate(root) etree.cleanup_namespaces(root) obj_xml = etree.tostring(root, pretty_print=True) print(obj_xml) # save your xml with open(\"new.xml\", \"w\") as f: f.write(obj_xml) if __name__ == \"__main__\": f = r'path\\to\\sample.xml' parseXML(f) Код довольно хорошо прокомментирован, но мы все равно потратим немного времени на его изучение. В начале, мы передали наш пример файла XML и использовали objectify. Если вы хотите получить доступ к атрибутам тега, используйте свойство attrib*. Оно вернет словарь атрибутов тега. Чтобы получить доступ к элементам подтега, достаточно использовать точечную нотацию. Как видите, чтобы получить значение тега begin, можно поступить следующим образом:\nbegin = root.appointment.begin Следует помнить, что если в значении есть ведущие нули, то возвращаемое значение может быть усеченным. Если для вас это важно, то вместо этого используйте следующий синтаксис:\nbegin = root.appointment.begin.text Если вам нужно перебрать дочерние элементы, вы можете использовать метод iterchildren. Возможно, вам придется использовать вложенную структуру цикла for, чтобы получить все элементы. Изменить значение элемента так же просто, как присвоить ему новое значение.\nroot.appointment.new_element = \"new data\" Теперь мы готовы узнать, как создать XML с помощью lxml.objectify.\nСоздание XML с помощью lxml.objectify Подпакет lxml.objectify чрезвычайно удобен для разбора и создания XML. В этом разделе мы покажем, как создавать XML с помощью модуля lxml.objectify. Мы начнем с простого XML, а затем попытаемся воспроизвести его. Давайте начнем!\nДля примера мы будем использовать следующий XML:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments reminder=\"15\"\u003e \u003cappointment\u003e \u003cbegin\u003e1181251680\u003c/begin\u003e \u003cuid\u003e040000008200E000\u003c/uid\u003e \u003calarmTime\u003e1181572063\u003c/alarmTime\u003e \u003cstate\u003e\u003c/state\u003e \u003clocation\u003e\u003c/location\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e \u003cappointment\u003e \u003cbegin\u003e1234360800\u003c/begin\u003e \u003cduration\u003e1800\u003c/duration\u003e \u003csubject\u003eCheck MS Office website for updates\u003c/subject\u003e \u003clocation\u003e\u003c/location\u003e \u003cuid\u003e604f4792-eb89-478b-a14f-dd34d3cc6c21-1234360800\u003c/uid\u003e \u003cstate\u003edismissed\u003c/state\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Давайте посмотрим, как мы можем использовать lxml.objectify для воссоздания этого XML:\nfrom lxml import etree, objectify def create_appt(data): \"\"\" Create an appointment XML element \"\"\" appt = objectify.Element(\"appointment\") appt.begin = data[\"begin\"] appt.uid = data[\"uid\"] appt.alarmTime = data[\"alarmTime\"] appt.state = data[\"state\"] appt.location = data[\"location\"] appt.duration = data[\"duration\"] appt.subject = data[\"subject\"] return appt def create_xml(): \"\"\" Create an XML file \"\"\" xml = '''\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003czAppointments\u003e \u003c/zAppointments\u003e ''' root = objectify.fromstring(xml) root.set(\"reminder\", \"15\") appt = create_appt({\"begin\":1181251680, \"uid\":\"040000008200E000\", \"alarmTime\":1181572063, \"state\":\"\", \"location\":\"\", \"duration\":1800, \"subject\":\"Bring pizza home\"} ) root.append(appt) uid = \"604f4792-eb89-478b-a14f-dd34d3cc6c21-1234360800\" appt = create_appt({\"begin\":1234360800, \"uid\":uid, \"alarmTime\":1181572063, \"state\":\"dismissed\", \"location\":\"\", \"duration\":1800, \"subject\":\"Check MS Office website for updates\"} ) root.append(appt) # remove lxml annotation objectify.deannotate(root) etree.cleanup_namespaces(root) # create the xml string obj_xml = etree.tostring(root, pretty_print=True, xml_declaration=True) try: with open(\"example.xml\", \"wb\") as xml_writer: xml_writer.write(obj_xml) except IOError: pass if __name__ == \"__main__\": create_xml() Давайте немного разберемся в этом. Начнем с функции create_xml. В ней мы создаем корневой объект XML с помощью функции fromstring модуля objectify. Корневой объект будет содержать zAppointment в качестве своего тега. Мы устанавливаем атрибут reminder корня, а затем вызываем функцию create_appt, используя в качестве аргумента словарь. В функции create_appt мы создаем экземпляр элемента (технически, это ObjectifiedElement), который мы присваиваем нашей переменной appt. Здесь мы используем dot-notation для создания тегов для этого элемента. Наконец, мы возвращаем элемент appt обратно и добавляем его к нашему root объекту. Мы повторяем процесс для второго экземпляра назначения.\nВ следующем разделе функции create_xml мы удалим аннотацию lxml. Если вы этого не сделаете, ваш XML будет выглядеть следующим образом:\n\u003c?xml version=\"1.0\" ?\u003e \u003czAppointments py:pytype=\"TREE\" reminder=\"15\"\u003e \u003cappointment py:pytype=\"TREE\"\u003e \u003cbegin py:pytype=\"int\"\u003e1181251680\u003c/begin\u003e \u003cuid py:pytype=\"str\"\u003e040000008200E000\u003c/uid\u003e \u003calarmTime py:pytype=\"int\"\u003e1181572063\u003c/alarmTime\u003e \u003cstate py:pytype=\"str\"/\u003e \u003clocation py:pytype=\"str\"/\u003e \u003cduration py:pytype=\"int\"\u003e1800\u003c/duration\u003e \u003csubject py:pytype=\"str\"\u003eBring pizza home\u003c/subject\u003e \u003c/appointment\u003e\u003cappointment py:pytype=\"TREE\"\u003e \u003cbegin py:pytype=\"int\"\u003e1234360800\u003c/begin\u003e \u003cuid py:pytype=\"str\"\u003e604f4792-eb89-478b-a14f-dd34d3cc6c21-1234360800\u003c/uid\u003e \u003calarmTime py:pytype=\"int\"\u003e1181572063\u003c/alarmTime\u003e \u003cstate py:pytype=\"str\"\u003edismissed\u003c/state\u003e \u003clocation py:pytype=\"str\"/\u003e \u003cduration py:pytype=\"int\"\u003e1800\u003c/duration\u003e \u003csubject py:pytype=\"str\"\u003eCheck MS Office website for updates\u003c/subject\u003e \u003c/appointment\u003e \u003c/zAppointments\u003e Чтобы удалить всю эту ненужную аннотацию, мы вызываем следующие две функции:\nobjectify.deannotate(root) etree.cleanup_namespaces(root) Последняя часть головоломки - заставить lxml генерировать сам XML. Здесь мы используем модуль lxml’s etree для выполнения тяжелой работы:\nobj_xml = etree.tostring(root, pretty_print=True, xml_declaration=True) Функция tostring вернет красивую строку XML, а если вы установите pretty_print в True, она обычно возвращает XML в красивом формате. Аргумент xml_declaration указывает модулю etree, включать или нет первую строку декларации (т.е. \u003c?xml version=\"1.0\" ?\u003e).\nПодведение итогов Теперь вы знаете, как использовать модули lxml etree и objectify для разбора XML. Вы также знаете, как использовать objectify для создания XML. Знание того, как использовать несколько модулей для выполнения одной и той же задачи, может быть полезно для того, чтобы увидеть, как подойти к одной и той же проблеме с разных сторон. Это также поможет вам выбрать тот инструмент, с которым вам удобнее всего работать.\n","description":"Python 101","title":"31. Парсинг XML с помощью lxml","uri":"/ru/docs/python101/chapter31_lxml/"},{"content":"Анализ кода Python может быть тяжелой темой, но он может быть очень полезен для улучшения ваших программ. Существует несколько анализаторов кода Python, которые вы можете использовать для проверки вашего кода на соответствие стандартам. pylint, вероятно, является самым популярным. Он очень конфигурируемый, настраиваемый и подключаемый. Он также проверяет ваш код на соответствие PEP8, официальному руководству по стилю Python Core, и ищет ошибки программирования.\nОбратите внимание, что pylint проверяет ваш код на соответствие большинству, но не всем стандартам PEP8. Мы уделим немного времени изучению другого пакета анализа кода, который называется pyflakes.\nНачало работы с pylint Пакет pylint не входит в состав Python, поэтому для его загрузки необходимо обратиться к индексу пакетов Python (PyPI) или на веб-сайт пакета. Вы можете использовать следующую команду, чтобы сделать всю работу за вас:\npip install pylint Если все идет по плану, у вас должен быть установлен pylint, и мы готовы продолжить.\nАнализ вашего кода После установки pylint вы можете запустить его в командной строке, без каких либо аргументов, что бы увидеть, какие опции он принимает. Если это не сработало, можете прописать полный путь, вот так:\nc:\\Python34\\Scripts\\pylint Теперь нам нужен код для анализа. Вот фрагмент кода, в котором есть четыре ошибки. Сохраните его в файл с именем crummy_code.py:\nimport sys class CarClass: \"\"\"\"\"\" def __init__(self, color, make, model, year): \"\"\"Constructor\"\"\" self.color = color self.make = make self.model = model self.year = year if \"Windows\" in platform.platform(): print(\"You're using Windows!\") self.weight = self.getWeight(1, 2, 3) def getWeight(this): \"\"\"\"\"\" return \"2000 lbs\" Можете ли вы обнаружить ошибки без выполнения кода? Давайте посмотрим, сможет ли pylint найти проблемы!\npylint crummy_code.py При выполнении этой команды на экран будет выведено много данных. Вот неполный пример:\nc:\\py101\u003ec:\\Python34\\Scripts\\pylint crummy_code.py No config file found, using default configuration ************* Module crummy_code C: 2, 0: Trailing whitespace (trailing-whitespace) C: 5, 0: Trailing whitespace (trailing-whitespace) C: 12, 0: Trailing whitespace (trailing-whitespace) C: 15, 0: Trailing whitespace (trailing-whitespace) C: 17, 0: Trailing whitespace (trailing-whitespace) C: 1, 0: Missing module docstring (missing-docstring) C: 3, 0: Empty class docstring (empty-docstring) C: 3, 0: Old-style class defined. (old-style-class) E: 13,24: Undefined variable 'platform' (undefined-variable) E: 16,36: Too many positional arguments for function call (too-many-function-args) C: 18, 4: Invalid method name \"getWeight\" (invalid-name) C: 18, 4: Empty method docstring (empty-docstring) E: 18, 4: Method should have \"self\" as first argument (no-self-argument) R: 18, 4: Method could be a function (no-self-use) R: 3, 0: Too few public methods (1/2) (too-few-public-methods) W: 1, 0: Unused import sys (unused-import) Давайте немного притормозим и разберемся. Сначала нам нужно понять, что означают буквы: С – конвенция (convention), R – рефакторинг (refactor), W – предупреждение (warning), E – ошибка (error). Наш pylint нашел 3 ошибки, 4 проблемы с конвенцией, 2 строки, которые нуждаются в рефакторинге и одно предупреждение. Предупреждение и 3 ошибки – это как раз то, что я искал. Мы попытаемся исправить этот код и устранить ряд проблем. Для начала мы наведем порядок в импортах, и изменить функцию getWeight на get_weight, в связи с тем, что camelCase не используется в названиях методов. Нам также нужно исправить вызов get_weight, чтобы он передавал правильное количество аргументов и исправить его, чтобы “self” выступал в качестве первого аргумента. Взглянем на новый код:\n# crummy_code_fixed.py import platform class CarClass: \"\"\"\"\"\" def __init__(self, color, make, model, year): \"\"\"Constructor\"\"\" self.color = color self.make = make self.model = model self.year = year if \"Windows\" in platform.platform(): print(\"You're using Windows!\") self.weight = self.get_weight(3) def get_weight(self, this): \"\"\"\"\"\" return \"2000 lbs\" Давайте запустим этот новый код в pylint и посмотрим, насколько мы улучшили результаты. Для краткости мы снова покажем только первую секцию:\nc:\\py101\u003ec:\\Python34\\Scripts\\pylint crummy_code_fixed.py No config file found, using default configuration ************* Module crummy_code_fixed C: 1,0: Missing docstring C: 4,0:CarClass: Empty docstring C: 21,4:CarClass.get_weight: Empty docstring W: 21,25:CarClass.get_weight: Unused argument 'this' R: 21,4:CarClass.get_weight: Method could be a function R: 4,0:CarClass: Too few public methods (1/2) Это очень помогло! Если бы мы добавили докстринги, мы могли бы вдвое сократить количество проблем. Теперь мы готовы взглянуть на pyflakes!\nНачало работы с pyflakes Проект pyflakes является частью проекта Divmod. Pyflakes не выполняет код, который он проверяет, так же как pylint не выполняет код, который он анализирует. Вы можете установить pyflakes с помощью pip, easy_install или из исходников.\nМы начнем с запуска pyflakes в изначальной версии той же части кода, которую мы использовали для проверки pylint. Вот и он:\nimport sys class CarClass: \"\"\"\"\"\" def __init__(self, color, make, model, year): \"\"\"Constructor\"\"\" self.color = color self.make = make self.model = model self.year = year if \"Windows\" in platform.platform(): print(\"You're using Windows!\") self.weight = self.getWeight(1, 2, 3) def getWeight(this): \"\"\"\"\"\" return \"2000 lbs\" Как мы отмечали в предыдущем разделе, в этом поломанном коде четыре ошибки, три из которых препятствуют работе программы. Давайте посмотрим, что же pyflakes может найти. Попытайтесь запустить данную команду и на выходе вы должны получить следующее:\nc:\\py101\u003ec:\\Python34\\Scripts\\pyflakes.exe crummy_code.py crummy_code.py:1: 'sys' imported but unused crummy_code.py:13: undefined name 'platform' Хотя pyflakes очень быстро вернул этот результат, он не нашел всех ошибок. Вызов метода getWeight передает слишком много аргументов, а сам метод getWeight определен неверно, поскольку у него нет аргумента self. На самом деле, вы можете называть первый аргумент как угодно, но по традиции его обычно называют self. Если бы вы исправили свой код в соответствии с тем, что сказал вам pyflakes, ваш код все равно не работал бы.\nПодведение итогов Следующим шагом будет попытка запустить pylint и pyflakes в вашем собственном коде, либо же в пакете Python, вроде SQLAlchemy, и посмотреть, что вы получите на выходе. С помощью этих инструментов можно многое узнать о собственном коде. pylint интегрирован во многие популярные IDE для Python, такие как Wingware, Editra и PyDev. Некоторые предупреждения от pylint могут показаться вам раздражающими или вообще неприменимыми. Есть способы подавить такие вещи, как предупреждения об устаревании, с помощью опций командной строки. Или вы можете использовать команду -generate-rcfile для создания примера конфигурационного файла, который поможет вам контролировать pylint. Обратите внимание, что pylint и pyflakes не импортируют ваш код, поэтому вам не нужно беспокоиться о нежелательных побочных эффектах.\n","description":"Python 101","title":"32. Анализ кода Python","uri":"/ru/docs/python101/chapter32_pylint/"},{"content":"Модели хранилища Службы хранилища Службы хранилища Azure предоставляются учетными записями хранения. Доступ к учетным записям хранения в основном осуществляется через REST API. Учетная запись хранения должна иметь уникальное имя, являющееся частью DNS-имени \u003cStorage Account name\u003e.core.windows.net. Различные варианты репликации и шифрования. Находится в группе ресурсов Мы можем создать нашу группу хранения, просто выполнив поиск группы хранения в строке поиска в верхней части портала Azure.\nЗатем мы можем выполнить шаги по созданию нашей учетной записи хранения, помня, что это имя должно быть уникальным, а также оно должно быть написано строчными буквами, без пробелов, но может включать цифры.\nМы также можем выбрать уровень избыточности, который мы хотели бы использовать для нашей учетной записи хранения и всего, что мы здесь храним. Чем дальше по списку, тем дороже вариант, но также и распространение ваших данных.\nДаже опция избыточности по умолчанию дает нам 3 копии наших данных.\nAzure Storage Redundancy\nКонцепции из ссылки выше:\nЛокально-избыточное хранилище — трижды реплицирует ваши данные в пределах одного центра обработки данных в основном регионе.\nГеоизбыточное хранилище — трижды синхронно копирует ваши данные в одном физическом расположении в основном регионе с помощью LRS.\nХранилище с избыточностью в пределах зоны — синхронно реплицирует данные службы хранилища Azure в трех зонах доступности Azure в основном регионе.\nХранилище с избыточностью в геозонах — сочетает в себе высокую доступность, обеспечиваемую избыточностью в зонах доступности, с защитой от региональных сбоев, обеспечиваемой георепликацией. Данные в учетной записи хранения GZRS копируются в три зоны доступности Azure в основном регионе, а также реплицируются во второй географический регион для защиты от региональных аварий.\nПросто возвращаюсь к параметрам производительности. У нас есть Стандарт и Премиум на выбор. В нашем пошаговом руководстве мы выбрали «Стандартный», но «Премиум» дает вам некоторые специфические опции. Затем в раскрывающемся списке вы можете увидеть, что у нас есть эти три варианта на выбор. Для учетной записи хранения доступно множество дополнительных параметров, но пока нам не нужно вдаваться в это. Эти параметры связаны с шифрованием и защитой данных.\nУправляемые диски Доступ к хранилищу можно получить несколькими способами.\nАутентифицированный доступ через:\nОбщий ключ для полного контроля. Shared Access Signature для делегированного, детализированного доступа. Azure Active Directory (где доступно) Публичный доступ:\nОбщий доступ также может быть предоставлен для включения анонимного доступа, в том числе через HTTP. — Примером этого может быть размещение базового контента и файлов в блочном BLOB-объекте, чтобы браузер мог просматривать и скачивать эти данные. Если вы получаете доступ к своему хранилищу из другой службы Azure, трафик остается в Azure.\nКогда дело доходит до производительности хранилища, у нас есть два разных типа:\nStandard - Максимальное количество операций ввода-вывода в секунду Premium - Гарантированное количество операций ввода-вывода в секунду Существует также разница между неуправляемыми и управляемыми дисками, которую следует учитывать при выборе правильного хранилища для поставленной задачи.\nХранилище виртуальной машины Диски ОС виртуальной машины обычно хранятся в постоянном хранилище. Некоторым рабочим нагрузкам без сохранения состояния не требуется постоянное хранилище, и уменьшение задержки является большим преимуществом. Существуют виртуальные машины, поддерживающие эфемерные управляемые диски ОС, созданные в локальном хранилище узла. Их также можно использовать с масштабируемыми наборами виртуальных машин. Управляемые диски — это надежное блочное хранилище, которое можно использовать с виртуальными машинами Azure. Вы можете иметь Ultra Disk Storage, Premium SSD, Standard SSD, Standard HDD. Они также несут некоторые характеристики.\nПоддержка снимков и изображений Простое перемещение между SKU Лучшая доступность в сочетании с наборами доступности Плата взимается в зависимости от размера диска, а не от использованного хранилища. Хранилище архивов Cool Tier — доступен классный уровень хранилища для блокировки и добавления больших двоичных объектов. Более низкая стоимость хранения Более высокая стоимость сделки. Archive Tier* — Архивное хранилище доступно для блочных больших двоичных объектов. Это настраивается для каждого BLOB-объекта. Более низкая стоимость, более длительная задержка поиска данных. Такая же надежность данных, как и в обычном хранилище Azure. Пользовательские уровни данных могут быть включены по мере необходимости. Общий доступ к файлам Из вышеописанного создания нашей учетной записи хранения теперь мы можем создавать общие файловые ресурсы.\nЭто обеспечит файловые ресурсы SMB2.1 и 3.0 в Azure.\nМожно использовать в Azure и извне через SMB3 и порт 445, открытый для Интернета.\nПредоставляет общее хранилище файлов в Azure.\nМожно сопоставить с помощью стандартных клиентов SMB в дополнение к REST API.\nВы также можете почитать Azure NetApp Files (SMB и NFS)\nСлужбы кэширования и мультимедиа Сеть доставки содержимого Azure предоставляет кэш статического веб-содержимого с местоположениями по всему миру.\nСлужбы мультимедиа Azure предоставляют технологии транскодирования мультимедиа в дополнение к службам воспроизведения.\nМодели баз данных Microsoft Azure Еще в День 28 мы рассмотрели различные варианты обслуживания. Одним из них была PaaS (Platform as a Service) (платформа как услуга), где вы абстрагируете большую часть инфраструктуры и операционной системы, и вам остается контролировать приложение или, в данном случае, модели базы данных.\nРеляционные базы данных База данных SQL Azure предоставляет реляционную базу данных как службу на основе Microsoft SQL Server.\nЭто SQL, работающий с последней веткой SQL с доступным уровнем совместимости базы данных, где требуется конкретная версия функциональности.\nЕсть несколько вариантов того, как это можно настроить: мы можем предоставить единую базу данных, которая предоставляет одну базу данных в экземпляре, в то время как эластичный пул позволяет использовать несколько баз данных, которые совместно используют пул емкости и совместно масштабируются.\nДоступ к этим экземплярам базы данных можно получить как к обычным экземплярам SQL.\nДополнительные управляемые предложения для MySQL, PostgreSQL и MariaDB.\nРешения NoSQL Azure Cosmos DB — это реализация NoSQL, не зависящая от схемы.\n99,99% SLA\nГлобально распределенная база данных с однозначными задержками на 99-м процентиле в любой точке мира с автоматическим возвратом в исходное положение.\nКлюч раздела, используемый для разделения/разбиения/распределения данных.\nПоддерживает различные модели данных (документы, ключ-значение, график, удобный для столбцов)\nПоддерживает различные API (DocumentDB SQL, MongoDB, Azure Table Storage и Gremlin).\nДоступны различные модели согласованности, основанные на теореме CAP.\nКэширование Не вдаваясь в подробности о системах кэширования, таких как Redis, я хотел добавить, что у Microsoft Azure есть служба под названием Azure Cache for Redis.\nКэш Azure для Redis предоставляет хранилище данных в памяти на основе программного обеспечения Redis.\nЭто реализация Redis Cache с открытым исходным кодом. Размещенный безопасный экземпляр кэша Redis. Доступны разные уровни Приложение должно быть обновлено, чтобы использовать кеш. Предназначен для приложения, которое имеет высокие требования к чтению по сравнению с записью. На основе хранилища ключей-значений. Я ценю, что за последние несколько дней было много заметок и теории о Microsoft Azure, но я хотел охватить строительные блоки, прежде чем мы перейдем к практическим аспектам того, как эти компоненты объединяются и работают.\nУ нас есть еще немного теории, связанной с сетью, прежде чем мы сможем запустить и запустить некоторые основанные на сценариях развертывания сервисов. Мы также хотим взглянуть на некоторые различные способы взаимодействия с Microsoft Azure по сравнению с порталом, который мы использовали до сих пор.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course ","description":"Модели хранилища Microsoft Azure","title":"32. Модели хранилища Microsoft Azure","uri":"/ru/docs/90daysofdevops/day32/"},{"content":"Пакет requests - это более питоническая замена для собственного urllib в Python. Вы обнаружите, что API пакета requests намного проще в работе. Вы можете установить библиотеку requests с помощью pip или easy_install или из исходников.\nИспользование requests Давайте рассмотрим несколько примеров использования пакета requests. Мы будем использовать серию небольших фрагментов кода, чтобы помочь объяснить, как использовать эту библиотеку.\n\u003e\u003e\u003e r = requests.get(\"http://www.google.com\") Этот пример возвращает объект Response. Вы можете использовать методы объекта Response, чтобы узнать много нового о том, как можно использовать запросы. Давайте воспользуемся функцией dir в Python, чтобы посмотреть, какие методы нам доступны:\n\u003e\u003e\u003e dir(r) ['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'iter_content', 'iter_lines', 'json', 'links', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url'] Если вы запустите следующий метод, вы сможете увидеть исходный код веб-страницы:\n\u003e\u003e\u003e r.content() Вывод этой команды слишком длинный, чтобы включать его в книгу, поэтому обязательно попробуйте сами. Если вы хотите взглянуть на заголовки веб-страниц, вы можете выполнить следующее:\n\u003e\u003e\u003e r.headers Обратите внимание, что атрибут headers возвращает диктоподобный объект и не является вызовом функции. Мы не показываем вывод, так как заголовки веб-страниц имеют тенденцию быть слишком широкими, чтобы правильно отображаться в книге. В объекте Response есть множество других замечательных функций и атрибутов. Например, вы можете получить cookies, ссылки на странице и status_code, который вернула страница.\nПакет requests поддерживает следующие типы HTTP-запросов: POST, GET, PUT, DELETE, HEAD и OPTIONS. Если страница возвращает json, вы можете получить к нему доступ, вызвав метод json объекта Response. Давайте рассмотрим практический пример.\nКак отправить веб-форму В этом разделе мы сравним отправку веб-формы с помощью requests и urllib. Давайте начнем с изучения того, как отправить веб-форму. Мы будем выполнять веб-поиск на сайте duckduckgo.com по термину python и сохранять результат в виде HTML-файла. Мы начнем с примера, в котором используется urllib:\nimport urllib.request import urllib.parse import webbrowser data = urllib.parse.urlencode({'q': 'Python'}) url = 'http://duckduckgo.com/html/' full_url = url + '?' + data response = urllib.request.urlopen(full_url) with open(\"results.html\", \"wb\") as f: f.write(response.read()) webbrowser.open(\"results.html\") Первое, что вам нужно сделать, когда вы хотите отправить веб-форму, - это выяснить, как называется форма и каков url, на который вы будете отправлять сообщение. Если вы перейдете на сайт duckduckgo и просмотрите источник, вы заметите, что его действие указывает на относительную ссылку “/html”. Таким образом, наш url будет “http://duckduckgo.com/html\". Поле ввода имеет имя “q”, поэтому, чтобы передать duckduckgo поисковый запрос, мы должны конкатенировать url с полем “q”. Результаты считываются и записываются на диск. Теперь давайте выясним, чем отличается этот процесс при использовании пакета requests.\nПакет requests выполняет отправку форм немного более элегантно. Давайте посмотрим:\nimport requests url = 'https://duckduckgo.com/html/' payload = {'q':'python'} r = requests.get(url, params=payload) with open(\"requests_results.html\", \"wb\") as f: f.write(r.content) При использовании запросов вам просто нужно создать словарь с именем поля в качестве ключа и поисковым термином в качестве значения. Затем вы используете requests.get для выполнения поиска. Наконец, вы используете полученный объект requests, “r”, и обращаетесь к его свойству content, которое сохраняете на диске.\nПодведение итогов Теперь вы знаете основы пакета requests. Я рекомендую прочитать документацию по пакету в Интернете, так как в ней есть много дополнительных примеров, которые вы можете найти полезными. Я лично считаю, что этот модуль более интуитивно понятен в использовании, чем аналог стандартной библиотеки.\n","description":"Python 101","title":"33. Пакет requests","uri":"/ru/docs/python101/chapter33_requests/"},{"content":"Мы рассмотрим сетевые модели в Microsoft Azure и некоторые варианты управления для Azure. До сих пор мы использовали только платформу Azure, но упомянули и другие области, которые можно использовать для управления и создания наших ресурсов на платформе.\nСетевые модели Azure Виртуальные сети Виртуальная сеть — это конструкция, созданная в Azure. Виртуальной сети назначен один или несколько диапазонов IP-адресов. Виртуальные сети живут в рамках подписки внутри региона. В виртуальной сети создаются виртуальные подсети для разбиения сетевого диапазона. Виртуальные машины размещаются в виртуальных подсетях. Все виртуальные машины в виртуальной сети могут обмениваться данными. 65 536 частных IP-адресов на виртуальную сеть. Платите только за исходящий трафик из региона. (данные покидают регион) Поддерживаются IPv4 и IPv6. IPv6 для общедоступных и внутри виртуальных сетей. Мы можем сравнить виртуальные сети Azure с AWS VPC. Однако следует отметить некоторые отличия:\nВ AWS создается виртуальная сеть по умолчанию, чего нет в Microsoft Azure, вам необходимо создать свою первую виртуальную сеть в соответствии с вашими требованиями. Все виртуальные машины в Azure по умолчанию имеют доступ к Интернету через NAT. Нет шлюзов NAT в соответствии с AWS. В Microsoft Azure нет понятия частных или общедоступных подсетей. Общедоступные IP-адреса — это ресурс, который может быть назначен виртуальным сетевым адаптерам или балансировщикам нагрузки. Виртуальная сеть и подсети имеют свои собственные списки управления доступом, позволяющие делегировать уровень подсети. Подсети в зонах доступности, тогда как в AWS у вас есть подсети для каждой зоны доступности. У нас также есть виртуальный сетевой пиринг. Пиринг между виртуальными сетями позволяет эффективно соединить две Виртуальные сети Azure. После создания пиринговой связи две виртуальные сети выглядят как одна сеть в плане подключения. Точно так же трафик между виртуальными машинами в одноранговых виртуальных сетях использует магистральную инфраструктуру Майкрософт. Как и трафик между виртуальными машинами в одной сети, трафик направляется только через частную сеть корпорации Майкрософт.\nКонтроль доступа Azure использует группы безопасности сети, они сохраняют состояние. Разрешить создавать правила, а затем назначать их группе безопасности сети. Группы безопасности сети применяются к подсетям или виртуальным машинам. При применении к подсети он по-прежнему применяется к сетевой карте виртуальной машины и не является “Edge” устройством. Правила объединены в группу безопасности сети. В зависимости от приоритета возможны гибкие конфигурации. Более низкий номер приоритета означает высокий приоритет. Большая часть логики построена на IP-адресах, но также могут использоваться некоторые теги и метки. Description Priority Source Address Source Port Destination Address Destination Port Action Inbound 443 1005 * * * 443 Allow ILB 1010 Azure LoadBalancer * * 10000 Allow Deny All Inbound 4000 * * * * DENY У нас также есть группы безопасности приложений (Application Security Groups) (ASG) .\nГде журналы потоков групп безопасности) (NSG) (Network Security Groups) сети сосредоточены на диапазонах IP-адресов, которые может быть сложно поддерживать для растущих сред. ASG позволяют определять настоящие имена (моникеры) для различных ролей приложений (веб-серверы, серверы БД, WebApp1 и т. д.). Сетевая карта виртуальной машины становится членом одной или нескольких групп ASG. Затем группы ASG можно использовать в правилах, которые являются частью групп безопасности сети, для управления потоком связи и по-прежнему могут использовать функции NSG, такие как теги обслуживания.\nAction Name Source Destination Port Allow AllowInternettoWeb Internet WebServers 443(HTTPS) Allow AllowWebToApp WebServers AppServers 443(HTTPS) Allow AllowAppToDB AppServers DbServers 1443 (MSSQL) Deny DenyAllinbound Any Any Any Балансировщики нагрузки Load Balancing. В Microsoft Azure есть два отдельных решения для балансировки нагрузки. (От Microsoft Azure и сторонние на маркетплейсе) Оба могут работать с внешними или внутренними конечными ендпоинтами.\nБалансировщик нагрузки (Layer 4), поддерживающий распределение на основе хэшей и переадресацию портов. Шлюз приложений (Layer 7) поддерживает такие функции, как разгрузка SSL, сопоставление сеансов на основе файлов cookie и маршрутизация контента на основе URL-адресов. Кроме того, с помощью шлюза приложений вы можете дополнительно использовать компонент брандмауэра веб-приложения.\nСредства управления Azure Мы потратили большую часть нашего теоретического времени на изучение портала Azure, я бы предположил, что когда дело доходит до следования культуре DevOps и обработки многих этих задач, особенно связанных с подготовкой, будет выполняться через API или инструмент командной строки. Я хотел коснуться некоторых из тех других инструментов управления, которые у нас есть, поскольку нам нужно знать это, когда мы автоматизируем подготовку наших сред Azure.\nПортал Azure Портал Microsoft Azure — это веб-консоль, которая представляет собой альтернативу инструментам командной строки. Вы можете управлять своими подписками на портале Azure. Создавайте, управляйте и контролируйте все, от простого веб-приложения до сложных облачных развертываний. Еще одна вещь, которую вы найдете на портале, — это хлебные крошки. JSON, как упоминалось ранее, является основой всех ресурсов Azure. Возможно, вы начнете с портала, чтобы понять функции, службы и функциональные возможности, а затем позже поймете JSON внизу, чтобы включить в ваши автоматизированные рабочие процессы.\nСуществует также портал Azure Preview, который можно использовать для просмотра и тестирования новых и предстоящих услуг и улучшений.\nPowerShell Прежде чем мы перейдем к Azure PowerShell, стоит сначала познакомиться с PowerShell. PowerShell — это среда автоматизации задач и управления конфигурацией, оболочка командной строки и язык сценариев. Мы могли бы и осмелились сказать это, сравнив это с тем, что мы рассмотрели в разделе Linux, посвященном сценариям оболочки. PowerShell впервые появился в ОС Windows, но теперь он кроссплатформенный.\nAzure PowerShell — это набор командлетов для управления ресурсами Azure непосредственно из командной строки PowerShell.\nПри желании мы можеем подключиться к подписке с помощью команды PowerShell «Connect-AzAccount».\nЗатем, если мы хотим найти некоторые конкретные команды, связанные с виртуальными машинами Azure, мы можем запустить следующую команду. Вы можете потратить часы на изучение и понимание этого языка программирования PowerShell. Microsoft предлагает отличные краткие руководства по началу работы и подготовке служб из PowerShell здесь\nVisual Studio Code Visual Studio Code — это бесплатный редактор исходного кода, созданный Microsoft для Windows, Linux и macOS.\nВ Visual Studio Code встроено множество интеграций и инструментов, которые вы можете использовать для взаимодействия с Microsoft Azure и службами внутри. Cloud Shell Azure Cloud Shell — это интерактивная, аутентифицированная, доступная через браузер оболочка для управления ресурсами Azure. Это обеспечивает гибкость выбора оболочки, которая лучше всего подходит для вашей работы.\nКак видно из рисунка ниже, когда мы впервые запускаем Cloud Shell на портале, мы можем выбирать между Bash и PowerShell.\nЧтобы использовать облачную оболочку, вам нужно будет предоставить немного места в своей подписке.\nКогда вы выбираете использование облачной оболочки, она запускает компьютер, эти компьютеры являются временными, но ваши файлы сохраняются двумя способами; через образ диска и подключенный файловый обменник.\nCloud Shell работает на временном хосте, предоставляемом для каждого сеанса и каждого пользователя. Время ожидания Cloud Shell истекает через 20 минут без интерактивной активности. Cloud Shell требует подключения общего файлового ресурса Azure. — Cloud Shell использует один и тот же файловый ресурс Azure как для Bash, так и для PowerShell. Cloud Shell назначается по одному компьютеру для каждой учетной записи пользователя. Cloud Shell сохраняет $HOME, используя образ размером 5 ГБ, хранящийся в вашей общей папке. Разрешения установлены как у обычного пользователя Linux в Bash Подробнее о Cloud Shell\nAzure CLI Azure CLI можно установить в Windows, Linux и macOS. После установки вы можете ввести «az», а затем другие команды для создания, обновления, удаления и просмотра ресурсов Azure.\nКогда я впервые приступил к изучению Azure, меня немного смутило наличие Azure PowerShell и Azure CLI.\nЯ также хотел бы получить отзывы от сообщества по этому поводу. Но я вижу, что Azure PowerShell — это модуль, добавленный в Windows PowerShell или PowerShell Core (также доступен в других ОС, но не во всех), тогда как Azure CLI — это кроссплатформенная программа командной строки, которая подключается к Azure и выполняет эти команды. .\nОбе эти опции имеют разный синтаксис, хотя, насколько я вижу и что я сделал, они могут выполнять очень похожие задачи.\nНапример, для создания виртуальной машины из PowerShell будет использоваться командлет New-AzVM, а в Azure CLI — az VM create.\nРанее вы видели, что в моей системе установлен модуль Azure PowerShell, но затем у меня также установлен Azure CLI, который можно вызывать через PowerShell на моем компьютере с Windows.\nВывод здесь, как мы уже упоминали, заключается в выборе правильного инструмента. Azure работает на основе автоматизации. Каждое действие, которое вы совершаете внутри портала, где-то преобразуется в код, выполняемый для чтения, создания, изменения или удаления ресурсов.\nСравнение Azure CLI Кроссплатформенный интерфейс командной строки, устанавливаемый на Windows, macOS, Linux Работает в Windows PowerShell, Cmd или Bash и других оболочках Unix. Azure PowerShell Кроссплатформенный модуль PowerShell, работает на Windows, macOS, Linux Требуется Windows PowerShell или PowerShell Если по какой-то причине вы не можете использовать PowerShell в своей среде, но можете использовать .mdor bash, тогда Azure CLI будет вашим выбором.\nЗавтра попробуем создать несколько сценариев и приступим к работе в Azure.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course AWS Basics for Beginners - Full Course ","description":"Сетевые модели Microsoft Azure + Управление Azure","title":"33. Сетевые модели Microsoft Azure + Управление Azure","uri":"/ru/docs/90daysofdevops/day33/"},{"content":"SQLAlchemy обычно называют объектно-реляционным маппером (Object Relational Mapper - ORM), хотя он гораздо более полнофункциональный, чем любой другой ORM для Python, который я использовал, например, SqlObject или тот, который встроен в Django. SQLAlchemy был создан парнем по имени Майкл Байер. Поскольку я помешан на музыке, мы создадим простую базу данных для хранения информации об альбомах. База данных не является базой данных без некоторых отношений, поэтому мы создадим две таблицы и соединим их. Вот несколько других вещей, которые мы будем изучать:\nДобавление данных в каждую таблицу\nИзменение данных\nУдаление данных\nБазовые запросы\nНо сначала нам нужно создать базу данных, поэтому именно с этого мы и начнем наше путешествие. Чтобы следовать этому руководству, вам потребуется установить SQLAlchemy. Для этого мы будем использовать pip:\npip install sqlalchemy Теперь мы готовы приступить к работе!\nКак создать базу данных Создать базу данных с помощью SQLAlchemy очень просто. SQLAlchemy использует метод Declarative для создания баз данных. Мы напишем некоторый код для создания базы данных, а затем объясним, как он работает. Если вам нужен способ просмотра базы данных SQLite, я бы рекомендовал плагин SQLite Manager для Firefox. Вот некоторый код для создания таблиц нашей базы данных:\n# table_def.py from sqlalchemy import create_engine, ForeignKey from sqlalchemy import Column, Date, Integer, String from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import relationship, backref engine = create_engine('sqlite:///mymusic.db', echo=True) Base = declarative_base() class Artist(Base): \"\"\"\"\"\" __tablename__ = \"artists\" id = Column(Integer, primary_key=True) name = Column(String) class Album(Base): \"\"\"\"\"\" __tablename__ = \"albums\" id = Column(Integer, primary_key=True) title = Column(String) release_date = Column(Date) publisher = Column(String) media_type = Column(String) artist_id = Column(Integer, ForeignKey(\"artists.id\")) artist = relationship(\"Artist\", backref=backref(\"albums\", order_by=id)) # create tables Base.metadata.create_all(engine) Если вы запустите этот код, вы должны увидеть что-то похожее на следующий результат:\n2014-04-03 09:43:57,541 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"artists\") 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine PRAGMA table_info(\"albums\") 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine CREATE TABLE artists ( id INTEGER NOT NULL, name VARCHAR, PRIMARY KEY (id) ) 2014-04-03 09:43:57,551 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,661 INFO sqlalchemy.engine.base.Engine COMMIT 2014-04-03 09:43:57,661 INFO sqlalchemy.engine.base.Engine CREATE TABLE albums ( id INTEGER NOT NULL, title VARCHAR, release_date DATE, publisher VARCHAR, media_type VARCHAR, artist_id INTEGER, PRIMARY KEY (id), FOREIGN KEY(artist_id) REFERENCES artists (id) ) 2014-04-03 09:43:57,661 INFO sqlalchemy.engine.base.Engine () 2014-04-03 09:43:57,741 INFO sqlalchemy.engine.base.Engine COMMIT Почему это произошло? Потому что когда мы создали объект engine, мы установили его параметр echo в True. Engine - это место, где находится информация о подключении к базе данных, и в нем есть все материалы DBAPI, которые делают возможным взаимодействие с вашей базой данных. Вы заметите, что мы создаем базу данных SQLite. Начиная с Python 2.5, SQLite поддерживается языком. Если вы хотите подключиться к какой-либо другой базе данных, то вам нужно будет отредактировать строку подключения. На всякий случай, если вы не понимаете, о чем идет речь, вот код:\nengine = create_engine('sqlite:///mymusic.db', echo=True) Строка sqlite:///mymusic.db - это наша строка подключения. Далее мы создаем экземпляр декларативной базы, на которой мы будем основывать наши классы таблиц. Далее у нас есть два класса, Artist и Album, которые определяют, как будут выглядеть наши таблицы базы данных. Вы заметите, что у нас есть Columns, но нет имен столбцов. SQLAlchemy фактически использует имена переменных в качестве имен столбцов, если вы специально не укажете их в определении Column. Обратите внимание, что мы используем поле id Integer в качестве первичного ключа в обоих классах. Это поле будет автоинкрементным. Остальные столбцы не требуют пояснений, пока вы не дойдете до ForeignKey. Здесь вы увидите, что мы связываем artist_id с id в таблице Artist. Директива relationship указывает SQLAlchemy связать класс/таблицу Album с таблицей Artist. Благодаря тому, как мы установили ForeignKey, директива отношения сообщает SQLAlchemy, что это отношение “многие к одному”, что нам и нужно. Много альбомов к одному исполнителю. Вы можете прочитать больше об отношениях между таблицами здесь.\nПоследняя строка сценария создаст таблицы в базе данных. Если вы запустите этот сценарий несколько раз, он не сделает ничего нового после первого раза, поскольку таблицы уже созданы. Однако вы можете добавить еще одну таблицу, и тогда будет создана новая.\nКак вставлять/добавлять данные в таблицы База данных не очень полезна, если в ней нет данных. В этом разделе мы покажем вам, как подключиться к базе данных и добавить некоторые данные в две таблицы. Гораздо проще посмотреть на код и затем объяснить его, так что давайте сделаем это!\n# add_data.py import datetime from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from table_def import Album, Artist engine = create_engine('sqlite:///mymusic.db', echo=True) # create a Session Session = sessionmaker(bind=engine) session = Session() # Create an artist new_artist = Artist(name=\"Newsboys\") new_artist.albums = [Album(title=\"Read All About It\", release_date=datetime.date(1988,12,1), publisher=\"Refuge\", media_type=\"CD\")] # add more albums more_albums = [Album(title=\"Hell Is for Wimps\", release_date=datetime.date(1990,7,31), publisher=\"Star Song\", media_type=\"CD\"), Album(title=\"Love Liberty Disco\", release_date=datetime.date(1999,11,16), publisher=\"Sparrow\", media_type=\"CD\"), Album(title=\"Thrive\", release_date=datetime.date(2002,3,26), publisher=\"Sparrow\", media_type=\"CD\")] new_artist.albums.extend(more_albums) # Add the record to the session object session.add(new_artist) # commit the record the database session.commit() # Add several artists session.add_all([ Artist(name=\"MXPX\"), Artist(name=\"Kutless\"), Artist(name=\"Thousand Foot Krutch\") ]) session.commit() Сначала нам нужно импортировать определения наших таблиц из предыдущего сценария. Затем мы подключаемся к базе данных с помощью нашего движка и создаем нечто новое - объект Session. Сессия - это наш манипулятор к базе данных, позволяющий нам взаимодействовать с ней. Мы используем его для создания, изменения и удаления записей, а также используем сессии для запросов к базе данных. Далее мы создаем объект Artist и добавляем альбом. Вы заметите, что для добавления альбома достаточно создать список объектов Album и установить свойство “albums” объекта artist в этот список или расширить его, как показано во второй части примера. В конце сценария мы добавляем еще трех исполнителей с помощью add_all. Как вы уже, наверное, заметили, для записи данных в базу данных необходимо использовать метод commit объекта session. Теперь пришло время перейти к изменению данных.\nКак изменять записи с помощью SQLAlchemy Что произойдет, если вы сохранили плохие данные. Например, вы неправильно ввели название своего любимого альбома или ошиблись с датой выхода фанатского издания, которым вы владеете? Тогда вам нужно узнать, как изменить эту запись! Это будет нашей отправной точкой в изучении запросов SQLAlchemy, поскольку вам нужно найти запись, которую нужно изменить, это значит, что вам нужно написать запрос к ней. Вот код, который покажет нам этот путь:\n# modify_data.py from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from table_def import Album, Artist engine = create_engine('sqlite:///mymusic.db', echo=True) # create a Session Session = sessionmaker(bind=engine) session = Session() # querying for a record in the Artist table res = session.query(Artist).filter(Artist.name==\"Kutless\").first() print(res.name) # changing the name res.name = \"Beach Boys\" session.commit() # editing Album data artist, album = session.query(Artist, Album).filter( Artist.id==Album.artist_id).filter(Album.title==\"Thrive\").first() album.title = \"Step Up to the Microphone\" session.commit() Наш первый запрос ищет артиста по имени, используя метод filter. Функция .first() сообщает SQLAlchemy, что нам нужен только первый результат. Мы могли бы использовать .all(), если бы думали, что результатов будет несколько и нам нужны все из них. В любом случае, этот запрос возвращает объект Artist, которым мы можем манипулировать. Как вы видите, мы изменили name с Kutless на Beach Boys, а затем зафиксировали изменения.\nЗапрос к объединенной таблице немного сложнее. На этот раз мы написали запрос, который запрашивает обе наши таблицы. Он фильтрует по идентификатору исполнителя и названию альбома. Он возвращает два объекта: исполнителя и альбом. Получив их, мы можем легко изменить название альбома. Разве это не просто? На этом этапе, вероятно, стоит отметить, что если мы ошибочно добавили что-то в сессию, мы можем откатить наши изменения/добавления/удаления с помощью session.rollback(). Кстати, об удалении, давайте разберемся с этим вопросом!\nКак удалять записи в SQLAlchemy Иногда вам просто необходимо удалить запись. Неважно, потому что вы вовлечены в тайну или потому что вы не хотите, чтобы люди знали о вашей любви к музыке Бритни Спирс, вам просто нужно избавиться от улик. В этом разделе мы покажем вам, как это сделать! К счастью для нас, SQLAlchemy позволяет удалять записи очень просто. Просто взгляните на следующий код!\n# deleting_data.py from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from table_def import Album, Artist engine = create_engine('sqlite:///mymusic.db', echo=True) # create a Session Session = sessionmaker(bind=engine) session = Session() res = session.query(Artist).filter(Artist.name==\"MXPX\").first() session.delete(res) session.commit() Как видите, все, что вам нужно было сделать, это создать еще один SQL-запрос, чтобы найти запись, которую вы хотите удалить, а затем вызвать session.delete(res). В данном случае мы удалили нашу запись MXPX. Мы уже видели запросы в действии, но давайте рассмотрим их подробнее и посмотрим, сможем ли мы узнать что-то новое.\nОсновные SQL-запросы SQLAlchemy SQLAlchemy предоставляет все запросы, которые могут вам понадобиться. Мы потратим немного времени на рассмотрение нескольких основных из них, таких как пара простых SELECT, JOINed SELECT и использование запроса LIKE. Вы также узнаете, где можно найти информацию о других типах запросов. А пока давайте посмотрим на код:\n# queries.py from sqlalchemy import create_engine from sqlalchemy.orm import sessionmaker from table_def import Album, Artist engine = create_engine('sqlite:///mymusic.db', echo=True) # create a Session Session = sessionmaker(bind=engine) session = Session() # how to do a SELECT * (i.e. all) res = session.query(Artist).all() for artist in res: print(artist.name) # how to SELECT the first result res = session.query(Artist).filter(Artist.name==\"Newsboys\").first() # how to sort the results (ORDER_BY) res = session.query(Album).order_by(Album.title).all() for album in res: print(album.title) # how to do a JOINed query qry = session.query(Artist, Album) qry = qry.filter(Artist.id==Album.artist_id) artist, album = qry.filter(Album.title==\"Step Up to the Microphone\").first() # how to use LIKE in a query res = session.query(Album).filter(Album.publisher.like(\"S%a%\")).all() for item in res: print(item.publisher) Первый запрос, который мы выполним, возьмет всех исполнителей в базе данных (SELECT *) и выведет каждое из полей с их именами. Далее вы увидите, как просто выполнить запрос для конкретного исполнителя и вернуть только первый результат. Третий запрос показывает, как выполнить SELECT * для таблицы Album и упорядочить результаты по названию альбома. Четвертый запрос - это тот же запрос (запрос на JOIN), который мы использовали в разделе редактирования, только мы разбили его на части, чтобы он лучше соответствовал стандартам PEP8 в отношении длины строки. Еще одна причина разбивать длинные запросы - они становятся более читабельными и их легче исправить, если вы что-то напутали. В последнем запросе используется LIKE, который позволяет нам искать по образцу или искать то, что “похоже” на заданную строку. В данном случае мы хотели найти все записи, в которых издательство начиналось с заглавной буквы “S”, какого-либо символа, буквы “a”, а затем чего-либо еще. Таким образом, это будет соответствовать, например, издателям Sparrow и Star.\nSQLAlchemy также поддерживает IN, IS NULL, NOT, AND, OR и все другие ключевые слова фильтрации, которые используют большинство DBA. SQLAlchemy также поддерживает литеральный SQL, скаляры и т.д. и т.п.\nПодведение итогов На данном этапе вы должны знать SQLAlchemy достаточно хорошо, чтобы уверенно приступить к ее использованию. Проект также имеет отличную документацию, с помощью которой вы сможете найти ответы практически на все вопросы. Если вы застряли, группа пользователей SQLAlchemy / список рассылки очень отзывчива к новым пользователям, и даже главные разработчики готовы помочь вам разобраться во всем.\n","description":"Python 101","title":"34. Пакет SQLAlchemy","uri":"/ru/docs/python101/chapter34_sqlalchemy/"},{"content":"Практические скрипты Microsoft Azure Последние 6 дней были сосредоточены на Microsoft Azure и общедоступном облаке в целом, большая часть этой основы должна была содержать много теории, чтобы понять строительные блоки Azure, но также это будет хорошо перенесено на других крупных облачных провайдеров. .\nВ самом начале я упомянул о базовых знаний об общедоступном облаке и выборе одного провайдера, по крайней мере, для начала. Если вы танцуете между разными облаками, я считаю, что вы можете довольно легко заблудиться, тогда как выбрав одно, вы поймете основы. и когда они у вас есть, довольно легко прыгнуть в другие облака и ускорить свое обучение.\nНа этом заключительном занятии я буду выбирать свои практические скрипты с этой страницы, которая является справочной информацией, созданной Microsoft и используемой для подготовки к AZ-104 Администратор Microsoft Azure\nЗдесь есть некоторые из них, такие как контейнеры и Kubernetes, которые мы еще не рассмотрели подробно, поэтому я не хочу пока вдаваться в них.\nВ предыдущих постах мы создали большинство модулей 1,2 и 3.\nВиртуальная сеть Мы пройдем пройти модуль 04:\nЯ прошел по инструкции и изменил несколько названий на #90DaysOfDevOps. Я также вместо использования Cloud Shell вошел в систему с моим новым пользователем, созданным в предыдущие дни с помощью Azure CLI на моем компьютере с Windows.\nВы можете сделать это, используя az login, который откроет браузер и позволит вам аутентифицировать свою учетную запись.\nЗатем я создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для выполнения некоторых из приведенных ниже задач. Вы можете найти связанные файлы в этой папке. (Облако\\01Виртуальная сеть)\nMod04_90DaysOfDevOps-vms-loop-parameters.json { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"value\": \"Standard_D2s_v3\" }, \"adminUsername\": { \"value\": \"Student\" }, \"adminPassword\": { \"value\": \"Pa55w.rd1234\" } } } Mod04_90DaysOfDevOps-vms-loop-template.json { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"type\": \"string\", \"defaultValue\": \"Standard_D2s_v3\", \"metadata\": { \"description\": \"VM size\" } }, \"vmName\": { \"type\": \"string\", \"defaultValue\": \"90day-vm\", \"metadata\": { \"description\": \"VM name Prefix\" } }, \"vmCount\": { \"type\": \"int\", \"defaultValue\": 2, \"metadata\": { \"description\": \"Number of VMs\" } }, \"adminUsername\": { \"type\": \"string\", \"metadata\": { \"description\": \"Admin username\" } }, \"adminPassword\": { \"type\": \"securestring\", \"metadata\": { \"description\": \"Admin password\" } }, \"virtualNetworkName\": { \"type\": \"string\", \"defaultValue\": \"90daysofdevops\", \"metadata\": { \"description\": \"Virtual network name\" } } }, \"variables\": { \"nic\": \"90daysofdevops\", \"virtualNetworkName\": \"[parameters('virtualNetworkName')]\", \"subnetName\": \"subnet\", \"subnet0Name\": \"subnet0\", \"subnet1Name\": \"subnet1\", \"computeApiVersion\": \"2018-06-01\", \"networkApiVersion\": \"2018-08-01\" }, \"resources\": [ { \"name\": \"[concat(parameters('vmName'),copyIndex())]\", \"copy\": { \"name\": \"VMcopy\", \"count\": \"[parameters('vmCount')]\" }, \"type\": \"Microsoft.Compute/virtualMachines\", \"apiVersion\": \"[variables('computeApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Creating VMs\", \"dependsOn\": [ \"[concat(variables('nic'),copyIndex())]\" ], \"properties\": { \"osProfile\": { \"computerName\": \"[concat(parameters('vmName'),copyIndex())]\", \"adminUsername\": \"[parameters('adminUsername')]\", \"adminPassword\": \"[parameters('adminPassword')]\", \"windowsConfiguration\": { \"provisionVmAgent\": \"true\" } }, \"hardwareProfile\": { \"vmSize\": \"[parameters('vmSize')]\" }, \"storageProfile\": { \"imageReference\": { \"publisher\": \"MicrosoftWindowsServer\", \"offer\": \"WindowsServer\", \"sku\": \"2019-Datacenter\", \"version\": \"latest\" }, \"osDisk\": { \"createOption\": \"fromImage\" }, \"dataDisks\": [] }, \"networkProfile\": { \"networkInterfaces\": [ { \"properties\": { \"primary\": true }, \"id\": \"[resourceId('Microsoft.Network/networkInterfaces', concat(variables('nic'),copyIndex()))]\" } ] } } }, { \"type\": \"Microsoft.Network/virtualNetworks\", \"name\": \"[variables('virtualNetworkName')]\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Virtual Network\", \"properties\": { \"addressSpace\": { \"addressPrefixes\": [ \"10.40.0.0/22\" ] }, \"subnets\": [ { \"name\": \"[variables('subnet0Name')]\", \"properties\": { \"addressPrefix\": \"10.40.0.0/24\" } }, { \"name\": \"[variables('subnet1Name')]\", \"properties\": { \"addressPrefix\": \"10.40.1.0/24\" } } ] } }, { \"name\": \"[concat(variables('nic'),copyIndex())]\", \"copy\":{ \"name\": \"nicCopy\", \"count\": \"[parameters('vmCount')]\" }, \"type\": \"Microsoft.Network/networkInterfaces\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Primary NIC\", \"dependsOn\": [ \"[concat('Microsoft.Network/virtualNetworks/', variables('virtualNetworkName'))]\" ], \"properties\": { \"ipConfigurations\": [ { \"name\": \"ipconfig1\", \"properties\": { \"subnet\": { \"id\": \"[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), concat(variables('subnetName'),copyIndex()))]\" }, \"privateIPAllocationMethod\": \"Dynamic\" } } ] } } ], \"outputs\": {} } Module4_90DaysOfDevOps.ps1 $rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-parameters.json Убедитесь, что вы изменили расположение файла в скрипте в соответствии с вашей средой.\nНа этом первом этапе у нас нет виртуальной сети или виртуальных машин, созданных в нашей среде, у меня есть только место хранения облачной оболочки, настроенное в моей группе ресурсов.\nСначала я запускаю свой скрипт в PowerShell\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\01VirtualNetworking\\Mod04_90DaysOfDevOps-vms-loop-parameters.json Задача 1: Создать и настроить виртуальную сеть\nЗадача 2. Развернуть виртуальные машины в виртуальной сети.\nЗадача 3. Настройка частных и общедоступных IP-адресов виртуальных машин Azure.\nЗадача 4: Настройка групп безопасности сети\nЗадача 5. Настройка Azure DNS для внутреннего разрешения имен. Управление сетевым трафиком Переходим к модулю 06:\nДля этого практического занятия я создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для создания некоторых из приведенных ниже задач.\nЗадача 1: Обеспечение лабораторной среды Запустим PowerShell скрипт\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\02TrafficManagement\\Mod06_90DaysOfDevOps-vms-loop-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\02TrafficManagement\\Mod06_90DaysOfDevOps-vms-loop-parameters.json $location = (Get-AzResourceGroup -ResourceGroupName $rgName).location $vmNames = (Get-AzVM -ResourceGroupName $rgName).Name foreach ($vmName in $vmNames) { Set-AzVMExtension ` -ResourceGroupName $rgName ` -Location $location ` -VMName $vmName ` -Name 'networkWatcherAgent' ` -Publisher 'Microsoft.Azure.NetworkWatcher' ` -Type 'NetworkWatcherAgentWindows' ` -TypeHandlerVersion '1.4' } Задача 2. Настройка топологии узловой сети Задача 3. Проверка транзитивности пиринга виртуальной сети.\nДля этого моя группа 90DaysOfDevOps не имела доступа к Network Watcher из-за разрешений, я ожидаю, что это связано с тем, что Network Watcher — это один из тех ресурсов, которые не привязаны к группе ресурсов, где наш RBAC был покрыт для этого пользователя. Я добавил в группу 90DaysOfDevOps роль участника Network Watcher из восточной части США.\nЭто ожидаемо, поскольку виртуальные сети с двумя лучами не связаны друг с другом (пиринг виртуальных сетей не является транзитивным).\nЗадача 4. Настройка маршрутизации в топологии «концентратор-луч». У меня была еще одна проблема: моя учетная запись не могла запустить скрипт от имени моего пользователя в группе 90DaysOfDevOps, в чем я не уверен, поэтому я вернулся в свою основную учетную запись администратора. Группа 90DaysOfDevOps является владельцем всего в группе ресурсов 90DaysOfDevOps, поэтому хотелось бы понять, почему я не могу запустить команду внутри виртуальной машины?\nTask 5: Подключаем Azure Load Balancer Task 6: Подключаем Azure Application Gateway Хранищиле Azure Переходим к модулю 07:\nДля этого практического занятия я также создал сценарий PowerShell и несколько ссылок из модуля, чтобы использовать их для создания некоторых из приведенных ниже задач.\nЗадача 1: Обеспечение лабораторной среды Сначала запускаем PowerShell script\n$rgName = '90DaysOfDevOps' New-AzResourceGroupDeployment ` -ResourceGroupName $rgName ` -TemplateFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\03Storage\\Mod07_90DaysOfDevOps-vm-template.json ` -TemplateParameterFile C:\\Users\\micha\\demo\\90DaysOfDevOps\\Days\\Cloud\\03Storage\\Mod07_90DaysOfDevOps-vm-parameters.json ` -AsJob Файл `Mod07_90DaysOfDevOps-vm-template.json` ``` { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"type\": \"string\", \"defaultValue\": \"Standard_D2s_v3\", \"metadata\": { \"description\": \"Virtual machine size\" } }, \"adminUsername\": { \"type\": \"string\", \"metadata\": { \"description\": \"Admin username\" } }, \"adminPassword\": { \"type\": \"securestring\", \"metadata\": { \"description\": \"Admin password\" } } }, \"variables\": { \"vmName\": \"90Days-vm0\", \"nicName\": \"90Days-nic0\", \"virtualNetworkName\": \"90Days-vnet0\", \"publicIPAddressName\": \"90Days-pip0\", \"nsgName\": \"90Days-nsg0\", \"vnetIpPrefix\": \"10.70.0.0/22\", \"subnetIpPrefix\": \"10.70.0.0/24\", \"subnetName\": \"subnet0\", \"subnetRef\": \"[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), variables('subnetName'))]\", \"computeApiVersion\": \"2018-06-01\", \"networkApiVersion\": \"2018-08-01\" }, \"resources\": [ { \"name\": \"[variables('vmName')]\", \"type\": \"Microsoft.Compute/virtualMachines\", \"apiVersion\": \"[variables('computeApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"dependsOn\": [ \"[variables('nicName')]\" ], \"properties\": { \"osProfile\": { \"computerName\": \"[variables('vmName')]\", \"adminUsername\": \"[parameters('adminUsername')]\", \"adminPassword\": \"[parameters('adminPassword')]\", \"windowsConfiguration\": { \"provisionVmAgent\": \"true\" } }, \"hardwareProfile\": { \"vmSize\": \"[parameters('vmSize')]\" }, \"storageProfile\": { \"imageReference\": { \"publisher\": \"MicrosoftWindowsServer\", \"offer\": \"WindowsServer\", \"sku\": \"2019-Datacenter\", \"version\": \"latest\" }, \"osDisk\": { \"createOption\": \"fromImage\" }, \"dataDisks\": [] }, \"networkProfile\": { \"networkInterfaces\": [ { \"properties\": { \"primary\": true }, \"id\": \"[resourceId('Microsoft.Network/networkInterfaces', variables('nicName'))]\" } ] } } }, { \"type\": \"Microsoft.Network/virtualNetworks\", \"name\": \"[variables('virtualNetworkName')]\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Virtual Network\", \"properties\": { \"addressSpace\": { \"addressPrefixes\": [ \"[variables('vnetIpPrefix')]\" ] }, \"subnets\": [ { \"name\": \"[variables('subnetName')]\", \"properties\": { \"addressPrefix\": \"[variables('subnetIpPrefix')]\" } } ] } }, { \"name\": \"[variables('nicName')]\", \"type\": \"Microsoft.Network/networkInterfaces\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Primary NIC\", \"dependsOn\": [ \"[variables('publicIpAddressName')]\", \"[variables('nsgName')]\", \"[variables('virtualNetworkName')]\" ], \"properties\": { \"ipConfigurations\": [ { \"name\": \"ipconfig1\", \"properties\": { \"subnet\": { \"id\": \"[variables('subnetRef')]\" }, \"privateIPAllocationMethod\": \"Dynamic\", \"publicIpAddress\": { \"id\": \"[resourceId('Microsoft.Network/publicIpAddresses', variables('publicIpAddressName'))]\" } } } ], \"networkSecurityGroup\": { \"id\": \"[resourceId('Microsoft.Network/networkSecurityGroups', variables('nsgName'))]\" } } }, { \"name\": \"[variables('publicIpAddressName')]\", \"type\": \"Microsoft.Network/publicIpAddresses\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Public IP for Primary NIC\", \"properties\": { \"publicIpAllocationMethod\": \"Dynamic\" } }, { \"name\": \"[variables('nsgName')]\", \"type\": \"Microsoft.Network/networkSecurityGroups\", \"apiVersion\": \"[variables('networkApiVersion')]\", \"location\": \"[resourceGroup().location]\", \"comments\": \"Network Security Group (NSG) for Primary NIC\", \"properties\": { \"securityRules\": [ { \"name\": \"default-allow-rdp\", \"properties\": { \"priority\": 1000, \"sourceAddressPrefix\": \"*\", \"protocol\": \"Tcp\", \"destinationPortRange\": \"3389\", \"access\": \"Allow\", \"direction\": \"Inbound\", \"sourcePortRange\": \"*\", \"destinationAddressPrefix\": \"*\" } } ] } } ], \"outputs\": {} } ``` Файл `Mod07_90DaysOfDevOps-vm-parameters.json` ``` { \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"vmSize\": { \"value\": \"Standard_D2s_v3\" }, \"adminUsername\": { \"value\": \"Student\" }, \"adminPassword\": { \"value\": \"Pa55w.rd1234\" } } } ``` Задача 2. Создание и настройка учетных записей хранения Azure. Задача 3. Управление хранилищем BLOB-объектов Задача 4. Управление проверкой подлинности и авторизацией для службы хранилища Azure. Я был немного нетерпелив, ожидая, что это все сработает, но в конце концов это сработало.\nЗадача 5. Создание и настройка общих папок Azure Files. В команде запуска это не сработает с michael.cade@90DaysOfDevOps.com, поэтому я использовал свою учетную запись с повышенными правами.\nЗадача 6. Управление сетевым доступом для службы хранилища Azure. Serverless (внедрение веб-приложений) Переходим к модулю 09a:\nЗадача 1. Создание веб-приложения Azure. Задача 2. Создание промежуточного слота развертывания. Задача 3. Настройка параметров развертывания веб-приложений. Задача 4. Развертывание кода в промежуточном слоте развертывания. Задача 5: Поменять промежуточные слоты местами Задача 6. Настройка и тестирование автоматического масштабирования веб-приложения Azure. $rgName = '90DaysOfDevOps' $webapp = Get-AzWebApp -ResourceGroupName $rgName #The following following will start an infinite loop that sends the HTTP requests to the web app while ($true) { Invoke-WebRequest -Uri $webapp.DefaultHostName } На этом мы завершаем раздел о Microsoft Azure и public cloud в целом.\nРесурсы Hybrid Cloud and MultiCloud Microsoft Azure Fundamentals Google Cloud Digital Leader Certification Course Далее мы углубимся в системы контроля версий, особенно в git, а затем также рассмотрим обзоры репозиториев кода, и мы выберем GitHub, так как это мой предпочтительный вариант.\n","description":"Практические скрипты Microsoft Azure","title":"34. Практические скрипты Microsoft Azure","uri":"/ru/docs/90daysofdevops/day34/"},{"content":"Общая картина: Git — контроль версий Прежде чем мы перейдем к git, нам нужно понять, что такое контроль версий? В этой статье мы рассмотрим, что такое контроль версий и основы git.\nЧто такое контроль версий? Git — не единственная система контроля версий, поэтому рассмотрим, какие варианты и какие методологии доступны для контроля версий.\nНаиболее очевидным и большим преимуществом контроля версий является возможность отслеживать историю проекта. Мы можем посмотреть на этот репозиторий с помощью git log и увидеть, что у нас есть много коммитов и много комментариев, а также то, что произошло на данный момент в проекте. Не волнуйтесь, мы перейдем к командам позже. А теперь подумайте, если бы это был настоящий программный проект, полный исходного кода, и несколько человек в разное время принимают участие в нашем программном обеспечении, разные авторы, а затем и рецензенты, все регистрируются здесь, чтобы мы знали, что произошло, когда, кем и кто рецензировал.\nУправление версиями, прежде чем это стало крутым, было чем-то вроде ручного создания копии вашей версии, прежде чем вы вносили изменения. Возможно, вы также закомментируете старый бесполезный код на всякий случай.\nТем не менее, Управление версиями не является резервной копией!\nЕще одним преимуществом контроля версий является возможность управления несколькими версиями проекта. Давайте создадим пример, у нас есть бесплатное приложение, доступное во всех операционных системах, а затем у нас есть платное приложение, также доступное во всех операционных системах. БОльшая часть кода используется обоими приложениями. Мы могли бы копировать и вставлять наш код при каждом коммите в каждое приложение, но это будет очень грязно, особенно если вы масштабируете свою разработку более чем на одного человека, а также будут допущены ошибки.\nВ премиум-приложении у нас будут дополнительные функции, назовем их премиальными коммитами, бесплатная версия будет содержать только обычные коммиты.\nСпособ, которым это достигается в системе управления версиями, — это ветвление (branching).\nВетвление позволяет использовать два потока кода для одного и того же приложения, как мы указали выше. Но мы по-прежнему хотим, чтобы новые функции, которые появляются в нашей бесплатной версии исходного кода, были в нашей премиум-версии, и для этого у нас есть то, что называется слиянием.\nТеперь это такое же простое, но слияние может быть сложным, потому что у вас может быть команда, работающая над бесплатной версией, и другая команда, работающая над платной премиальной версией, и что, если обе они изменят код, который влияет на аспекты общего кода. Может быть, переменная обновляется и что-то ломает. Тогда у вас есть конфликт, который нарушает одну из функций. Контроль версий не может устранить конфликты, которые зависят от вас. Но контроль версий позволяет легко управлять этим.\nОсновная причина, по которой вы до сих пор не взялись за управление версиями, — это возможность совместной работы. Возможность делиться кодом между разработчиками, и когда я говорю код, как я уже говорил раньше, все чаще и чаще мы видим гораздо больше вариантов использования по другим причинам для использования системы управления версиями, может быть, это совместная презентация, над которой вы работаете с коллегой, или вызов 90DaysOfDevOps. где у вас есть сообщество, предлагающее свои исправления и обновления на протяжении всего проекта.\nБез контроля версий, как команды разработчиков программного обеспечения вообще справлялись с этим? Когда я работаю над своими проектами, мне достаточно трудно следить за вещами. Я ожидаю, что они разделят код на каждый функциональный модуль. Возможно, небольшая часть головоломки заключалась в том, чтобы собрать воедино кусочки, а затем решить проблемы и проблемы, прежде чем что-либо было выпущено.\nС контролем версий у нас есть единственный источник правды. Мы все еще можем работать над разными модулями, но это позволяет нам лучше взаимодействовать.\nЕще одна вещь, которую следует упомянуть здесь, это то, что не только разработчики могут извлечь выгоду из контроля версий. Все члены команды должны иметь представление, но также и инструменты управления проектом и т.д. У нас также может быть build машина, например Jenkins, о которой мы поговорим в другом модуле. Зада подобных инструментов - создать и упаковывать систему, автоматизируя тесты и предоставляя метрики.\nЧто такое Git? Git — это инструмент, который отслеживает изменения в исходном коде или любом файле, или мы могли бы также сказать, что Git — это распределенная система контроля версий с открытым исходным кодом.\nЕсть много способов, которыми git можно использовать в наших системах, чаще всего или, по крайней мере, для меня я видел его в командной строке, но у нас также есть графические пользовательские интерфейсы и инструменты, такие как Visual Studio Code, которые имеют операции с поддержкой git, которые мы может воспользоваться.\nТеперь мы пройдемся по общему обзору еще до того, как установим Git на нашу локальную машину.\nВозьмем папку, которую мы создали ранее.\nЧтобы использовать эту папку с контролем версий, нам сначала нужно инициировать этот каталог с помощью команды `git init. А пока представьте, что эта команда помещает наш каталог в качестве репозитория в базу данных где-то на нашем компьютере.\nТеперь мы можем создать несколько файлов и папок, и наш исходный код может начаться, или, может быть, он уже есть, и у нас уже есть что-то здесь. Мы можем использовать команду git add ., которая помещает все файлы и папки в нашем каталоге в снимок, но мы еще ничего не зафиксировали в этой базе данных. Мы просто говорим, что все файлы с . готовы к добавлению.\nЗатем мы хотим продолжить и зафиксировать наши файлы, мы делаем это с помощью команды git commit -m \"My First Commit\". Мы можем указать причину нашей фиксации, и это предлагается, чтобы мы знали, что произошло для каждой фиксации.\nТеперь мы можем увидеть, что произошло в истории проекта. С помощью команды git log.\nМы также можем проверить состояние нашего репозитория с помощью git status, это показывает, что нам нечего коммитить, и мы можем добавить новый файл с именем samplecode.ps1. Если мы затем запустим тот же статус `git, вы увидите, что мы файл для фиксации.\nДобавьте наш новый файл с помощью команды git add samplecode.ps1, а затем мы снова запустим git status и увидим, что наш файл готов к фиксации.\nЗатем выполните команду git commit -m “My Second Commit”.\nДругой git status теперь показывает, что все снова чисто.\nЗатем мы можем использовать команду git log, которая показывает последние изменения и первую фиксацию.\nЕсли мы хотим увидеть изменения между нашими коммитами, то есть какие файлы были добавлены или изменены, мы можем использовать git diff b8f8 709a\nЗатем отображается то, что изменилось, в нашем случае мы добавили новый файл.\nМы также можем, и мы углубимся в это позже, но мы можем прыгать вокруг наших коммитов, то есть мы можем путешествовать во времени! Используя наш номер фиксации, мы можем использовать команду git checkout 709a, чтобы вернуться назад во времени, не теряя наш новый файл.\nНо в равной степени мы также захотим двигаться вперед, и мы можем сделать это таким же образом с номером коммита, или вы можете видеть здесь, что мы используем команду git switch -, чтобы отменить нашу операцию.\nTLDR;\nОтслеживание истории проектов Управление несколькими версиями проекта Обмен кодом между разработчиками и более широкий круг команд и инструментов Координация работы в команде Это могло показаться прыжком, но, надеюсь, вы можете увидеть, даже не зная, что команды использовали возможности и общую картину, лежащую в основе контроля версий.\nДалее мы установим и настроим git на вашем локальном компьютере и немного углубимся в некоторые другие варианты использования и команды, которые мы можем реализовать в Git.\nРесурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Git — контроль версий","title":"35. Git — контроль версий","uri":"/ru/docs/90daysofdevops/day35/"},{"content":"Виртуальные среды могут быть очень удобны для тестирования программного обеспечения. Это верно и в кругах программистов. Ян Бикинг создал проект virtualenv, который является инструментом для создания изолированных сред Python. Вы можете использовать эти среды для тестирования новых версий вашего программного обеспечения, новых версий пакетов, от которых вы зависите, или просто в качестве “песочницы” для опробования нового пакета в целом. Вы также можете использовать virtualenv в качестве рабочей среды, когда вы не можете скопировать файлы в пакеты сайта, потому что он находится на общем хосте. Когда вы создаете виртуальную среду с помощью virtualenv, он создает папку и копирует в нее Python вместе с папкой site-packages и несколькими другими. Он также устанавливает pip. Как только ваша виртуальная среда станет активной, вы будете использовать обычный Python. А когда вы закончите, вы можете просто удалить папку для очистки. Никакой суеты, никакой суеты. Кроме того, вы можете продолжать использовать его для разработки.\nВ этой главе мы потратим некоторое время на знакомство с virtualenv и на то, как использовать его для создания собственной магии.\nУстановка Прежде всего, вам, вероятно, потребуется установить virtualenv. Вы можете использовать pip или easy_install для его установки или скачать файл virtualenv.py с их сайта и установить его из исходников с помощью сценария setup.py.\nЕсли у вас Python 3.4, вы обнаружите, что у вас есть модуль venv, который использует API, очень похожий на пакет virtualenv. Однако в этой главе речь пойдет только о пакете virtualenv.\nСоздание виртуальной среды Создать виртуальную песочницу с помощью пакета virtualenv довольно просто. Все, что вам нужно сделать, это следующее:\npython virtualenv.py FOLDER_NAME Где FOLDER_NAME* - это имя папки, в которую вы хотите поместить вашу песочницу. На моей машине Windows 7 путь к папке C:\\Python34\\Scripts добавлен, поэтому я могу просто вызвать virtualenv.py FOLDER_NAME без части python. Если вы не передадите ему ничего, то получите список опций, выведенный на экран. Допустим, мы создадим проект под названием sandbox. Как мы будем его использовать? Ну, нам нужно активировать его. Вот как:\nВ Posix вы сделаете source bin/activate, а в Windows вы сделаете .\\path\\to\\env\\Scripts\\activate. в командной строке. Давайте проделаем эти шаги. Мы создадим папку “песочница” на рабочем столе, чтобы вы могли увидеть пример. Вот как это выглядит на моей машине:\nC:\\Users\\mdriscoll\\Desktop\u003evirtualenv sandbox New python executable in sandbox\\Scripts\\python.exe Installing setuptools................done. Installing pip...................done. C:\\Users\\mdriscoll\\Desktop\u003esandbox\\Scripts\\activate (sandbox) C:\\Users\\mdriscoll\\Desktop\u003e Как только ваша виртуальная среда будет активирована, вы увидите, что ваше приглашение изменится и будет включать префикс имени папки, которую вы создали, в данном случае это sandbox. Это дает вам знать, что вы используете свою песочницу. Теперь вы можете использовать pip для установки других пакетов в вашу виртуальную среду. Когда вы закончите, просто вызовите сценарий deactivate, чтобы выйти из среды.\nЕсть несколько флагов, которые вы можете передать virtualenv при создании виртуальной среды, о которых вам следует знать. Например, вы можете использовать -system-site-packages, чтобы унаследовать пакеты от пакетов сайта Python по умолчанию. Если вы хотите использовать distribute, а не setuptools, вы можете передать virtualenv флаг -distribute.\nvirtualenv также предоставляет возможность просто установить библиотеки, но использовать для их запуска сам системный Python. Согласно документации, для этого достаточно создать специальный скрипт.\nЕсть также изящный (и экспериментальный) флаг -relocatable, который можно использовать, чтобы сделать папку перемещаемой. Однако на момент написания этой статьи он НЕ работает в Windows, поэтому я не смог его проверить.\nНаконец, есть флаг -extra-search-dir, который можно использовать для сохранения виртуальной среды в автономном режиме. По сути, он позволяет добавить каталог в путь поиска дистрибутивов, из которых pip или easy_install могут устанавливать. Таким образом, вам не нужно иметь доступ к интернету для установки пакетов.\nПодведение итогов На данном этапе вы должны уметь использовать virtualenv самостоятельно. На этом этапе стоит упомянуть еще пару проектов. Это библиотека virtualenvwrapper Дуга Хеллмана, которая еще больше упрощает создание, удаление и управление виртуальными окружениями, а также zc.buildout, который, вероятно, является ближайшим конкурентом virtualenv. Я рекомендую ознакомиться с ними обеими, поскольку они могут помочь вам в ваших приключениях в программировании.\n","description":"Python 101","title":"35. virtualenv","uri":"/ru/docs/python101/chapter35_virtualenv/"},{"content":"Создание модулей Python - это то, что большинство программистов Python делают каждый день, даже не задумываясь об этом. Каждый раз, когда вы сохраняете новый сценарий Python, вы создаете новый модуль. Вы можете импортировать свой модуль в другие модули. Пакет - это коллекция связанных модулей. То, что вы импортируете в свои сценарии из стандартной библиотеки, является модулями или пакетами. В этой главе мы узнаем, как создавать модули и пакеты. Мы уделим больше времени пакетам, поскольку они сложнее модулей.\nКак создать модуль Python Мы начнем с создания суперпростого модуля. Этот модуль будет предоставлять нам базовую арифметику и не будет обрабатывать ошибки. Вот наш первый пример:\ndef add(x, y): return x + y def division(x, y): return x / y def multiply(x, y): return x * y def subtract(x, y): return x - y У этого кода, конечно, есть проблемы. Отсутствует проверка ошибок при делении на ноль или смешивании строк и чисел. Но дело не в этом. Дело в том, что если вы сохраните этот код, у вас будет полностью квалифицированный модуль. Назовем его arithmetic.py. Что можно сделать с модулем? Вы можете импортировать его и использовать любую из определенных функций или классов, которые находятся внутри него. А можно сделать его исполняемым, немного подправить и отполировать. Давайте сделаем и то, и другое!\nСначала мы напишем небольшой скрипт, который импортирует наш модуль и запускает функции в нем. Сохраните следующий файл под именем math_test.py:\nimport arithmetic print(arithmetic.add(5, 8)) print(arithmetic.subtract(10, 5)) print(arithmetic.division(2, 7)) print(arithmetic.multiply(12, 6)) Теперь давайте изменим исходный скрипт так, чтобы его можно было запускать из командной строки. Вот один из самых простых способов сделать это:\ndef add(x, y): return x + y def division(x, y): return x / y def multiply(x, y): return x * y def subtract(x, y): return x - y if __name__ == \"__main__\": import sys print(sys.argv) v = sys.argv[1].lower() valOne = int(sys.argv[2]) valTwo = int(sys.argv[3]) if v == \"a\": print(add(valOne, valTwo)) elif v == \"d\": print(division(valOne, valTwo)) elif v == \"m\": print(multiply(valOne, valTwo)) elif v == \"s\": print(subtract(valOne, valTwo)) else: pass Правильным способом выполнения этого сценария было бы использование модуля Python optparse (pre-2.7) или argparse (2.7+). Вам следует потратить некоторое время, чтобы разобраться с одним из этих модулей в качестве учебного упражнения. А пока мы перейдем к пакетам!\nКак создать пакет Python Основное различие между модулем и пакетом заключается в том, что пакет - это набор модулей И у него есть файл init.py. В зависимости от сложности пакета, он может иметь более одного init.py. Давайте рассмотрим простую структуру папок, чтобы сделать это более очевидным, а затем создадим простой код, который будет следовать структуре, которую мы определили.\nmymath/ __init__.py adv/ __init__.py sqrt.py add.py subtract.py multiply.py divide.py Теперь нам просто нужно повторить эту структуру в нашем собственном пакете. Давайте попробуем это сделать! Создайте каждый из этих файлов в дереве папок, как показано в примере выше. Для файлов сложения, вычитания, умножения и деления можно использовать функции, которые мы создали в предыдущем примере. Для модуля sqrt.py мы будем использовать следующий код.\n# sqrt.py import math def squareroot(n): return math.sqrt(n) Вы можете оставить оба файла init.py пустыми, но тогда вам придется писать код типа mymath.add.add(x,y), что довольно некрасиво, поэтому мы добавим следующий код во внешний init.py, чтобы облегчить понимание и использование нашего пакета.\n# outer __init__.py from . add import add from . divide import division from . multiply import multiply from . subtract import subtract from .adv.sqrt import squareroot Теперь мы должны иметь возможность использовать наш модуль, когда он находится в пути к Python. Для этого вы можете скопировать папку в папку site-packages вашего Python. В Windows она находится в следующем общем месте: C:\\Python34\\Lib\\site-packages. В качестве альтернативы вы можете отредактировать путь на лету в коде теста. Давайте посмотрим, как это делается:\nimport sys # modify this path to match your environment sys.path.append('C:\\Users\\mdriscoll\\Documents') import mymath print(mymath.add(4,5)) print(mymath.division(4, 2)) print(mymath.multiply(10, 5)) print(mymath.squareroot(48)) Обратите внимание, что мой путь НЕ включает папку mymath. Вы хотите добавить родительскую папку, в которой находится ваш новый модуль, а не саму папку модуля. Если вы сделаете это, то приведенный выше код будет работать.\nВы также можете создать сценарий setup.py и установить ваш пакет в режиме разработки. Вот пример скрипта setup.py:\n#!/usr/bin/env python from setuptools import setup # This setup is suitable for \"python setup.py develop\". setup(name='mymath', version='0.1', description='A silly math package', author='Mike Driscoll', author_email='mike@mymath.org', url='http://www.mymath.org/', packages=['mymath', 'mymath.adv'], ) Сохраните этот сценарий на один уровень выше папки mymath. Чтобы установить пакет в режиме разработки, выполните следующие действия:\npython setup.py develop Это установит файл ссылки в папку site-packages, который будет указывать на то место, где находится ваш пакет. Это удобно для тестирования без фактической установки пакета.\nПоздравляем! Вы только что создали пакет Python!\nПодведение итогов Вы только что узнали, как создавать свои собственные модули и пакеты. Вы обнаружите, что чем больше вы пишете, тем чаще вы создаете программы, в которых есть части, которые вы хотите использовать повторно. Эти многократно используемые части кода можно объединить в модули. В конце концов, у вас будет достаточно связанных модулей, и вы захотите объединить их в пакет. Теперь у вас есть инструменты, чтобы сделать это!\n","description":"Python 101","title":"36. Создание модулей и пакетов","uri":"/ru/docs/python101/chapter36_creating_modules_and_packages/"},{"content":"Установка и настройка Git Git — это кроссплатформенный инструмент с открытым исходным кодом для контроля версий. Если я нравлюсь вам, вы используете Ubuntu или большинство сред Linux, вы можете обнаружить, что у вас уже установлен git, но мы собираемся выполнить установку и настройку.\nДаже если у вас уже установлен git в вашей системе, также рекомендуется убедиться, что мы в курсе последних событий.\nУстановка Git Мы будем работать с Windows и Linux, но вы также можете найти macOS в списке здесь\nДля Windows мы можем загрузить наши установщики с официального сайта.\nВы также можете использовать winget на своем компьютере с Windows, думайте об этом как о своем диспетчере пакетов приложений Windows.\nПрежде чем мы что-либо установим, давайте посмотрим, какая версия у нас есть на нашей машине с Windows. Откройте окно PowerShell и запустите git --version\nМы также можем проверить нашу версию Git для Ubuntu.\nЗагружаем последнюю версию установщика. Важно отметить, что git удалит предыдущие версии перед установкой последней.\nЭто означает, что процесс, показанный ниже, по большей части такой же, как если бы вы устанавливали не из git.\nЭто очень простая установка. После загрузки дважды щелкните и начните. Прочтите лицензионное соглашение GNU. Но помните, что это бесплатное программное обеспечение с открытым исходным кодом.\nТеперь мы можем выбрать дополнительные компоненты, которые мы хотели бы также установить, но также связать с git. В Windows я всегда устанавливаю Git Bash, так как это позволяет нам запускать сценарии bash в Windows.\nЗатем мы можем выбрать, какой исполняемый файл SSH мы хотим использовать. IN оставьте это как пакетный OpenSSH, который вы могли видеть в разделе Linux.\nЗатем у нас есть экспериментальные функции, которые мы можем захотеть включить, мне они не нужны, поэтому я не включаю, вы всегда можете вернуться во время установки и включить их позже.\nУстановка завершена, теперь мы можем открыть Git Bash или последние примечания к выпуску.\nПоследняя проверка — посмотреть в нашем окне PowerShell, какая у нас сейчас версия git.\nСупер простые вещи, и теперь мы на последней версии. На нашей машине с Linux мы немного отстали, поэтому мы также можем пройти этот процесс обновления.\nЯ просто запускаю команду sudo apt-get install git.\nВы также можете запустить следующее, которое добавит репозиторий git для установки программного обеспечения.\nsudo add-apt-repository ppa:git-core/ppa -y sudo apt-get update sudo apt-get install git -y git --version Настройка Git Когда мы впервые используем git, нам нужно определить некоторые настройки,\nИмя Эл. адрес Редактор по умолчанию Окончание строки Это можно сделать на трех уровнях\nSystem = Все пользователи Global = все репозитории текущего пользователя Local = текущий репозиторий Пример:\ngit config --global user.name \"My Name\" git config --global user.email email@example.com\" В зависимости от вашей операционной системы будет определять текстовый редактор по умолчанию. На моей машине с Ubuntu без настройки следующая команда использует Тano. Приведенная ниже команда изменит это на код Visual Studio.\ngit config --global core.editor \"code --wait\"\nЧтобы увидеть всю конфигурацию git, мы можем использовать команду git config --global -e\nНа любом компьютере этот файл будет называться .gitconfig, на моем компьютере с Windows вы найдете его в каталоге своей учетной записи пользователя. Теория Git Я упомянул во вчерашнем посте, что существуют и другие типы контроля версий, и мы можем разделить их на два разных типа. Один клиент-сервер, а другой распределенный.\nКлиент-серверный контроль версий До появления git клиент-сервер был де-факто методом контроля версий. Примером этого может быть Apache Subversion, которая представляет собой систему управления версиями с открытым исходным кодом, основанную в 2000 году.\nВ этой модели управления версиями клиент-сервер на первом этапе разработчик загружает исходный код, фактические файлы с сервера. Это не устраняет конфликты, но устраняет сложность конфликтов и способы их разрешения.\nТеперь, например, скажем, у нас есть два разработчика, работающих над одними и теми же файлами, и один из них выигрывает гонку и первым фиксирует или загружает свой файл обратно на сервер со своими новыми изменениями. Когда второй разработчик идет на обновление, у них возникает конфликт.\nИтак, теперь разработчику нужно вывести первое изменение кода разработчика рядом с его проверкой, а затем зафиксировать, как только эти конфликты будут урегулированы.\nРаспределенный контроль версий Git — не единственная распределенная система контроля версий. Но это очень де-факто.\nНекоторые из основных преимуществ Git:\nБыстрый Гибкий Безопасный и надежный В отличие от модели управления версиями клиент-сервер, каждый разработчик загружает исходный репозиторий, то есть все. История коммитов, все ветки и т.д. и т.п.\nРесурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Установка и настройка Git","title":"36. Установка и настройка Git","uri":"/ru/docs/90daysofdevops/day36/"},{"content":"В предыдущей главе мы создали пакет под названием mymath. В этой главе мы узнаем, как разместить его на Python Packaging Index (PyPI). Для этого нам сначала нужно узнать, как создать файл setup.py Для справки, вот наша текущая иерархия папок:\nmymath/ __init__.py adv/ __init__.py sqrt.py add.py subtract.py multiply.py divide.py Это означает, что у вас есть папка mymath со следующими файлами в ней: init.py, add.py, subtract.py, multiply.py и divide.py. Внутри папки mymath также есть папка adv. В папке adv у вас будет два файла: init.py и sqrt.py.\nСоздание файла setup.py Мы начнем с создания очень простого скрипта setup.py. Вот самый простой из них:\nfrom distutils.core import setup setup(name='mymath', version='0.1', packages=['mymath', 'mymath.adv'], ) Это то, что вы можете написать для внутреннего пакета. Для загрузки в PyPI вам нужно будет указать немного больше информации:\nfrom distutils.core import setup setup(name='mymath', version='0.1', description='A silly math package', author='Mike Driscoll', author_email='mike@mymath.org', url='http://www.mymath.org/', packages=['mymath', 'mymath.adv'], ) Теперь, когда мы закончили с этим, мы должны протестировать наш сценарий. Вы можете создать виртуальную среду, используя указания из главы 35, или просто установить ваш код в вашу установку Python, вызвав следующую команду:\npython setup.py install В качестве альтернативы вы можете использовать метод, описанный в конце прошлой главы, в которой вы создали специальный setup.py, который установили в режиме разработки. Обратите внимание, что в прошлой главе мы использовали setuptools, а в этой - distutils. Причина в том, что в setuptools есть команда develop, а в distutils - нет.\nТеперь нам нужно зарегистрировать наш пакет в PyPI!\nРегистрация пакетов Зарегистрировать пакет очень просто. Поскольку это ваш первый пакет, вы захотите зарегистрироваться на тестовом сервере PyPI, а не на реальном. Вам может понадобиться создать файл .pypirc и ввести адрес сервера Test PyPI. Смотрите следующий раздел для получения дополнительной информации. Как только вы это сделаете, вам просто нужно будет выполнить следующую команду:\npython setup.py register Вы получите список опций, в которых предлагается войти в систему, зарегистрироваться, попросить сервер выслать вам пароль или выйти из системы. Если имя пользователя и пароль сохранены на вашем компьютере, вы не увидите этого сообщения. Если вы уже зарегистрированы, вы можете войти в систему, и метаданные вашего пакета будут загружены.\nЗагрузка пакетов в PyPI Вы, вероятно, захотите начать с тестирования на тестовом сервере PyPI, который находится по адресу https://testpypi.python.org/pypi. Вам придется зарегистрироваться, так как он использует другую базу данных, в отличии от основного сайта. Как только вы это сделаете, вы, возможно, захотите создать файл .pypirc где-нибудь в пути вашей операционной системы. В Linux вы можете использовать $HOME, чтобы найти его, а в Windows - переменную окружения HOME. Этот путь является местом сохранения файла. Ниже приведен пример того, что может быть в файле pypirc с сайта https://wiki.python.org/moin/TestPyPI:\n[distutils] index-servers= pypi test [test] repository = https://testpypi.python.org/pypi username = richard password = \u003cyour password goes here\u003e [pypi] repository = http://pypi.python.org/pypi username = richard password = \u003cyour password goes here\u003e Я настоятельно рекомендую вам подробно ознакомиться с документацией, чтобы понять все опции, которые вы можете добавить в этот конфигурационный файл.\nЧтобы загрузить некоторые файлы в PyPI, вам нужно будет создать несколько дистрибутивов.\npython setup.py sdist bdist_wininst upload Когда вы выполните приведенную выше команду, она создаст папку dist. Команда sdist создаст архивный файл (zip в Windows, tarball в Linux). Команда bdist_wininst создаст простой исполняемый файл установщика для Windows. Команда upload загрузит эти два файла на PyPI.\nВ файле setup.py вы можете добавить поле long_description, которое будет использоваться PyPI для создания домашней страницы вашего пакета на PyPI. Вы можете использовать reStructuredText для форматирования вашего описания. Или вы можете не добавлять описание и принять форматирование PyPI по умолчанию.\nЕсли вам нужен полный список команд, которые вы можете использовать в setup.py, попробуйте выполнить следующую команду:\npython setup.py --help-commands Вы также должны добавить файл README.txt, который объясняет, как установить и использовать ваш пакет. Он также может содержать раздел “Спасибо”, если у вас много вкладчиков.\nПодведение итогов Теперь вы знаете основы добавления вашего пакета в Python Packaging Index. Если вы хотите добавить Python-яйцо в PyPI, вам нужно будет использовать easy_install вместо distutils. Когда вы выпустите свою следующую версию, вы, возможно, захотите добавить файл CHANGES.txt, в котором перечислены изменения в вашем коде. Существует отличный сайт под названием The Hitchhiker’s Guide to Packaging, на котором вы можете найти дополнительную информацию по этой интересной теме. Кроме того, вы можете ознакомиться с этим руководством Скотта Торборга, чтобы взглянуть на процесс с другой стороны.\nСсылки https://pylint.pycqa.org/en/latest\n","description":"Python 101","title":"37. Как добавить пакет в PyPI","uri":"/ru/docs/python101/chapter37_pypi_packaging/"},{"content":"Знакомство с Git В последних двух постах мы узнали о системах контроля версий и некоторых основных рабочих процессах git как системы контроля версий День 35. Затем мы установили git в нашу систему, обновили и настроили. Мы также немного углубились в теорию между системой контроля версий клиент-сервер и Git, которая является распределенной системой контроля версий День 36.\nТеперь мы пройдемся по некоторым командам и вариантам использования, которые мы все обычно видим в git.\nГде получить помощь по git? Будут времена, когда вы просто не сможете вспомнить или просто не знаете команду, которая вам нужна для работы с git. Вам понадобится помощь.\nСамо собой разумеется, что Google или любая другая поисковая система, вероятно, будет вашим первым портом захода при поиске помощи.\nВо-вторых, следующим местом будет официальный сайт git и документация. git-scm.com/docs Здесь вы найдете не только подробные ссылки на все доступные команды, но и множество различных ресурсов.\nМы также можем получить доступ к этой же документации, которая очень полезна, если у вас нет подключения к терминалу. Например, если мы выбрали команду git add, мы можем запустить git add --help, и мы увидим ниже руководство.\nМы также можем в оболочке использовать git add -h, который даст нам краткий обзор доступных опций.\nМифы Git «У Git нет контроля доступа» — вы можете уполномочить “лидера” поддерживать исходный код.\n«Git слишком тяжелый» — у Git есть возможность предоставлять неглубокие репозитории, что в основном означает меньший объем истории, если у вас большие проекты.\nНедостатки Не идеально подходит для двоичных файлов. Отлично подходит для исходного кода, но не подходит, например, для исполняемых файлов или видео.\nGit не удобен для пользователя, тот факт, что нам приходится тратить время на обсуждение команд и функций инструмента, вероятно, является ключевым признаком этого.\nВ целом, git сложно освоить, но легко использовать.\nЭкосистема git Я хочу кратко рассказать об экосистеме вокруг git, но не углубляться в некоторые из этих областей, но я думаю, что важно отметить их здесь на высоком уровне.\nПочти все современные инструменты разработки поддерживают Git.\nИнструменты разработчика. Мы уже упоминали код Visual Studio, но вы найдете плагины git и интеграции в возвышенный текст и другие текстовые редакторы и IDE.\nКомандные инструменты. Также упоминаются такие инструменты, как Jenkins с точки зрения CI/CD, Slack из среды обмена сообщениями и Jira для управления проектами и отслеживания проблем.\nОблачные провайдеры. Все крупные облачные провайдеры поддерживают git, Microsoft Azure, Amazon AWS, Google Cloud Platform.\nСервисы на основе Git. Затем у нас есть GitHub, GitLab и BitBucket, о которых мы поговорим более подробно позже. Я слышал об этих сервисах как о социальной сети для кода!\nШпаргалка по Git Мы не рассмотрели большинство этих команд, но просмотрев некоторые шпаргалки, доступные в Интернете, я хотел задокументировать некоторые из команд git и их назначение. Нам не нужно запоминать все это, и с большей практикой и использованием вы выберете, по крайней мере, основы git.\nОсновы Git Command Example Description git init git init \u003cdirectory\u003e создает пустой репозиторий git в указанном каталоге. git clone git clone \u003crepo\u003e клонирует репозиторий, расположенный в , на локальный компьютер. git config git config user.name определяет имя автора, которое будет использоваться для всех коммитов в текущем репозитории, system, global, local флаг для установки параметров конфигурации. git add git add \u003cdirectory\u003e он подготовит все изменения в для следующего коммита. Мы также можем добавить и \u003c.\u003e для добавления всех изменененных файлов всего. git commit -m git commit -m \"\u003cmessage\u003e\" фиксирует промежуточный коммит, запишет , чтобы подробно описать, что точно сохраняем. git status git status выведит список файлов, которые помещены в архив, не помещены в архив и не отслеживаются. git log git log Отображение всей истории коммитов в формате по умолчанию. У этой команды есть дополнительные параметры. git diff git diff Показать неустановленные изменения между вашим индексом и рабочим каталогом. Git Отмена изменений Command Example Description git revert git revert \u003ccommit\u003e создает новую фиксацию, которая отменяет все изменения, сделанные в , а затем примените ее к текущей ветке. git reset git reset \u003cfile\u003e убрать из индекса коммита (изменения не теряются). git clean git clean -n увидеть, какие файлы являются лишними, перед их непосредственным удалением git clean git clean -f удалить неотслеживаемые файлы и папки из рабочей копии git clean git clean -fd удалить их Git переписать историю Command Example Description git commit git commit --amend Заменяет последний коммит поэтапными изменениями и последним коммитом. Используйте без статуса stage, чтобы отредактировать сообщение последнего коммита. git rebase git rebase \u003cbase\u003e Перебазировать текущую ветку на . может быть идентификатором фиксации, именем ветки, тегом или относительной ссылкой на HEAD. git reflog git reflog Показать журнал изменений в HEAD локального репозитория. Добавьте флаг –relative-date для отображения информации о дате или –all для отображения всех ссылок. Git Branches Command Example Description git branch git branch Перечислите все ветки в вашем репо. Добавьте аргумент , чтобы создать новую ветку с именем . git checkout git checkout -b \u003cbranch\u003e Создайте и извлеките новую ветку с именем . Отбросьте флаг -b, чтобы проверить существующую ветку. git merge git merge \u003cbranch\u003e Объединить ветку с текущей веткой. Git Remote Repositories Command Example Description git remote add git remote add \u003cname\u003e \u003curl\u003e Создайте новое подключение к удаленному репозиторию. После добавления пульта вы можете использовать в качестве ярлыка для в других командах. git fetch git fetch \u003cremote\u003e \u003cbranch\u003e Выбирает конкретную \u003cветку\u003e из репозитория. Оставьте , чтобы получить все удаленные ссылки. git pull git pull \u003cremote\u003e Получить указанную удаленную копию текущей ветки и немедленно объединить ее с локальной копией. git push git push \u003cremote\u003e \u003cbranch\u003e Отправьте ветку на вместе с необходимыми коммитами и объектами. Создает именованную ветку в удаленном репо, если она не существует. Git Diff Command Example Description git diff HEAD git diff HEAD Показать разницу между рабочим каталогом и последним коммитом. git diff –cached git diff --cached Показать разницу между поэтапными изменениями и последней фиксацией Git Config Command Example Description git config –global user.name \u003cимя\u003e git config --global user.name \u003cимя\u003e Определите имя автора, которое будет использоваться для всех коммитов текущим пользователем. git config –global user.email git config --global user.email \u003cemail\u003e Определите адрес электронной почты автора, который будет использоваться для всех коммитов текущего пользователя. git config –global alias \u003cалиас-имя\u003e git config --global alias \u003calias-name\u003e \u003cgit-command\u003e Создать ярлык для команды git. git config –system core.editor \u003cредактор\u003e git config --system core.editor \u003cредактор\u003e Установите текстовый редактор, который будет использоваться командами для всех пользователей на машине. Аргумент должен быть командой, запускающей нужный редактор. git config –global –edit git config --global --edit Откройте файл глобальной конфигурации в текстовом редакторе для редактирования вручную. Git Rebase Command Example Description git rebase -i git rebase -i \u003cbase\u003e Интерактивно перебазировать текущую ветку на . Запускает редактор для ввода команд того, как каждый коммит будет перенесен в новую базу. Git Pull Command Example Description git pull –rebase git pull --rebase \u003cremote\u003e Получить удаленную копию текущей ветки и перебазировать ее в локальную копию. Использует git rebase вместо слияния для интеграции веток. Git Reset Command Example Description git reset git reset Сбросьте промежуточную область, чтобы она соответствовала самой последней фиксации, но оставьте рабочий каталог без изменений. git reset –hard git reset --hard Сбросить промежуточную область и рабочий каталог, чтобы они соответствовали самой последней фиксации, и перезаписать все изменения в рабочем каталоге git reset git reset \u003ccommit\u003e Переместите конец текущей ветки назад к , сбросьте промежуточную область, чтобы она соответствовала, но оставьте рабочий каталог в покое git reset –hard git reset --hard \u003ccommit\u003e То же, что и предыдущее, но сбрасывает и промежуточную область, и рабочий каталог, чтобы они совпадали. Удаляет незафиксированные изменения и все фиксации после . Git Push Command Example Description git push –force git push \u003cremote\u003e --force Делает git push, даже если это приводит к слиянию без быстрой перемотки вперед. Не используйте флаг –force, если вы абсолютно не уверены, что знаете, что делаете. git push –all git push \u003cremote\u003e --all Переместите все свои локальные ветки на указанный удаленный сервер. git push –tags git push \u003cremote\u003e --tags Теги не добавляются автоматически при отправке ветки или использовании флага –all. Флаг –tags отправляет все ваши локальные теги в удаленное репо. Ресурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"Знакомство с Git","title":"37. Шпаргалка по Git","uri":"/ru/docs/90daysofdevops/day37/"},{"content":"Python egg - это старый формат распространения Python. Новый формат называется Python wheel, который мы рассмотрим в следующей главе. Файл egg - это, по сути, zip-файл с другим расширением. Python может импортироваться непосредственно из egg. Для работы с eggs вам понадобится пакет SetupTools. SetupTools - это оригинальный основной метод загрузки и установки пакетов Python из PyPI и других источников через командную строку, что-то вроде apt-get для Python. Существовал форк SetupTools под названием distribute, который в итоге был объединен обратно в SetupTools. Я упоминаю об этом только потому, что вы можете встретить ссылки на этот форк, если будете много читать о Python eggs вне этой книги.\nНесмотря на то, что от формата eggs сейчас отказываются, вам все еще нужно знать о нем, поскольку существует множество пакетов, распространяемых с помощью этой технологии. Возможно, пройдут годы, прежде чем все перестанут использовать eggs. Давайте научимся создавать свои собственные!\nСоздание egg\nВы можете думать об egg как об альтернативе исходному дистрибутиву или исполняемому файлу Windows, но следует отметить, что для eggs чистого Python файл egg является полностью кроссплатформенным. Мы рассмотрим, как создать собственное egg, используя пакет, который мы создали в предыдущей главе о модулях и пакетах. Чтобы приступить к созданию egg, вам нужно создать новую папку и поместить в нее папку mymath. Затем создайте файл setup.py в родительском каталоге папки mymath со следующим содержимым:\nfrom setuptools import setup, find_packages setup( name = \"mymath\", version = \"0.1\", packages = find_packages() ) В Python есть собственный пакет для создания дистрибутивов, который называется distutils. Однако вместо использования функции установки distutils в Python, мы используем функцию установки setuptools. Мы также используем функцию find_packages от setuptools, которая будет автоматически искать любые пакеты в текущем каталоге и добавлять их в egg. Чтобы создать egg, вам нужно выполнить следующее из командной строки:\nc:\\Python34\\python.exe setup.py bdist_egg Это приведет к появлению большого количества выходных данных, но когда все будет готово, вы увидите, что у вас есть три новые папки: build, dist и mymath.egg-info. Нам важна только папка dist, в которой вы найдете файл egg, mymath-0.1-py3.4.egg. Обратите внимание, что на моей машине я заставил программу запускаться на Python 3.4, чтобы она создала egg на этой версии Python. Сам файл egg - это, по сути, zip-файл. Если вы измените расширение на “zip”, вы сможете заглянуть внутрь и увидеть, что в нем есть две папки: mymath и EGG-INFO. Теперь вы можете указать easy_install на egg в вашей файловой системе, и он установит ваш пакет.\nПодведение итогов Теперь настала ваша очередь. Зайдите в индекс пакетов Python и найдите несколько модулей чистого Python для загрузки. Затем попробуйте создать eggs, используя приемы, которые вы изучили в этой главе. Если вы хотите установить egg, вы можете использовать easy_install. Удалить egg немного сложнее. Вам придется перейти к месту его установки и удалить папку и/или файл egg, которые оно установило, а также удалить запись о пакете из файла easy-install.pth. Все эти элементы можно найти в папке site-packages вашего Python.\n","description":"Python 101","title":"38. Python egg","uri":"/ru/docs/python101/chapter38_eggs/"},{"content":"Working directory Git - это система трёх основных стадий: working directory, staging area и repository. Пройдем поэтапно каждую стадию.\nСоздадим пустую папку.\nmkdir my_fodler cd my_folder Сделаем инициализацию git проекта.\ngit init После инициализации git репозитория создается скрытая папка .git Здесь хранятся сведения о репозитории git, а также информация о наших ветках и коммитах.\nStaging/Stage Сейчас у нас пустая папка. Создадим пустой файл README.md и выполним команду\ngit status Git знает о новом файле, но этот файл еще не зафиксирован в staging. Текущее расположение файла - Working directory, директория, где проиниализирован .git проект.\nstaging - это хранилище для файлов с изменениями, информация о которых попадет в единый коммит\nЧтобы файл перешел в staging, необходимо его добавить. Для этого выполним команду\ngit add README.md После добавления файла в staging area, цвет поменялся на зеленый\nМожно добавить все измененные файлы с помощью команды\ngit add . Знак . означает, что мы хотим добавить все обновленные файлы и папки.\nДалее необходимо зафиксировать изменения в репозитории. Для этого выполним команду\ngit commit -m \"Add README.md (или другой значимый комментарий)\" Коммит изменений В процессе работы мы добавляем много различных файлов. Если мы захотим добавить более длинный и осмысленный коммит, то можно запусть команду без комментария\ngit commit Откроется стандартный редактор текста. Записываем комментарий и сохраняем. Проверим результат\ngit status Требования к именам коммитов У каждой компании/проекта есть свои требования к именам коммитов. В компании может быть несколько проектов, каждый из которых должен иметь свои требования к именам коммитов. В проекте может быть несколько веток, каждая из которых должна иметь свои требования к именам коммитов.\nСуществует гайдлайн, на который можно ориентироваться. Такой подход точно будет понятен для всех новых проектов. Некоторые проекты, соблюдабщие данную конвенцию: angular, electron\nКоммит:\nДолжен использоваться present tense (“add feature” not “added feature”) Должен использоваться imperative mood (“move cursor to…” not “moves cursor to…”) Примеры имен коммитов init: - используется для начала проекта/таска. Примеры:\ninit: start youtube-task init: start mentor-dashboard task feat: - это реализованная новая функциональность из технического задания (добавил поддержку зумирования, добавил footer, добавил карточку продукта). Примеры:\nfeat: add basic page layout feat: implement search box feat: implement request to youtube API feat: implement swipe for horizontal list feat: add additional navigation button feat: add banner feat: add social links feat: add physical security section feat: add real social icons fix: - исправил ошибку в ранее реализованной функциональности. Примеры:\nfix: implement correct loading data from youtube fix: change layout for video items to fix bugs fix: relayout header for firefox fix: adjust social links for mobile refactor: - новой функциональности не добавлял / поведения не менял. Файлы в другие места положил, удалил, добавил. Изменил форматирование кода (white-space, formatting, missing semi-colons, etc). Улучшил алгоритм, без изменения функциональности. Примеры:\nrefactor: изменение структуры проекта refactor: переименование переменных для лучшей читабельности refactor: применить eslint refactor: применить prettier docs: - используется при работе с документацией/readme проекта. Примеры:\ndocs: обновить readme с дополнительной информацией docs: обновить описание метода run() Пропуск Staging Area Можно сразу добавить коммит, добавим параметр -a в git commit:\nУдаление файлов Фиксация удаления как и добавления файлов происхоит через комит\nСоздадим файл -\u003e Добавим в stage -\u003e Удалим файл\ntouch old_file.txt git add old_file.txt git commit -m \"add old_file to be removed\" Удаляем файл\ngit rm old_file.txt git status Переименование/Перемещение файлов Мы можем переименовывать или перемещать файлы в проекте средствами операционной системы. Таке это можно делать командами git.\nПример:\ngit mv old_file.txt new_file.txt Пропуск/игнорирование файлов В Git это можно сделать рзличными способами:\nИгнорировать изменения в неотслеченных файлах с помощью .gitignore файла Игнорировать изменения в неотслеченных файлах с помощью exclude файла Остановка отслеживания файла и пропуск изменений с помощью git update-index Остановка отслеживания файла и пропуск изменений с помощью git rm .gitignore Достаточно в файл .gitignore добавить путь до файлов или папок, которые необходимо игнорировать\nПосле обновления файл переходит в категорию Untracked files\nЕсли файлы уже добавлены в stage, но нужно убрать файл, то можно использовать команду git rm --cached\nStatus сокращенно git status -s Ресурсы What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial ","description":"Git Staging и Изменение файлов","title":"38. Staging и Изменения","uri":"/ru/docs/90daysofdevops/day38/"},{"content":"Первым распространенным форматом упаковки Python был файл .egg. Теперь в городе появился новый формат под названием wheel (.whl). Согласно описанию в Python Packaging Index, wheel предназначен для содержания всех файлов для установки, совместимой с PEP 376, в формате, очень близком к формату на диске. В этой главе мы узнаем, как создать wheel и затем установить его в virtualenv.\nНачало работы Рекомендуемый способ работы с wheels - использование pip. Убедитесь, что вы установили последнюю версию pip, так как более ранние версии не поддерживают формат wheel. Если вы не уверены, что у вас установлена последняя версия pip, вы можете выполнить следующую команду:\npip install --upgrade pip Если у вас нет последней версии, то эта команда обновит pip. Теперь мы готовы к созданию wheel!\nСоздание wheel Прежде всего, вам нужно установить пакет wheel:\npip install wheel Это было легко! Далее мы будем использовать пакет unidecode для создания нашего первого wheel, так как на момент написания статьи он еще не был создан, и я сам использовал этот пакет в нескольких проектах. Пакет unidecode берет строку текста и пытается заменить любой юникод на его эквивалент ASCII. Это очень удобно, когда нужно очистить данные, предоставленные пользователем, от странных аномалий. Вот команда, которую нужно выполнить, чтобы создать wheel для этого пакета:\npip wheel --wheel-dir=my_wheels Unidecode Вот скриншот вывода, который я получил при запуске этой программы:\nТеперь у вас должно быть wheel с именем Unidecode-0.04.14-py26-none-any.whl в папке my_wheels. Давайте узнаем, как установить наше новое wheel!\nУстановка wheel Python Давайте создадим virtualenv для тестирования. Для создания виртуальной среды тестирования мы используем следующую команду:\nvirtualenv test Это предполагает, что virtualenv находится в вашем системном пути. Если вы получите ошибку unrecognized command, то вам, вероятно, придется указать полный путь (например, c:\\Python34\\Scripts\\virtualenv). Выполнение этой команды создаст для нас виртуальную песочницу, в которой будет работать pip. Обязательно запустите скрипт activate из папки Scripts папки test, чтобы включить virtuanenv, прежде чем продолжить. Ваш virtualenv не включает wheel, поэтому вам придется установить wheel снова:\npip install wheel После этого мы можем установить наше wheel с помощью следующей команды:\npip install --use-wheel --no-index --find-links=path/to/my_wheels Unidecode Чтобы проверить, что это сработало, запустите Python из папки Scripts в вашем виртуальном окружении и попробуйте импортировать unidecode. Если он импортируется, значит, вы успешно установили wheel!\nФайл *.whl похож на *.egg тем, что это, по сути, замаскированный файл *.zip. Если вы переименуете расширение с *.whl на *.zip, вы сможете открыть его с помощью выбранного вами приложения zip и изучить файлы и папки внутри по своему усмотрению.\nПодведение итогов Теперь вы должны быть готовы к созданию собственных wheels. Это хороший способ создать локальный репозиторий зависимостей для вашего проекта (проектов), который можно быстро установить. Вы можете создать несколько различных репозиториев wheel, чтобы легко переключаться между различными наборами версий для тестирования. В сочетании с virtualenv вы получаете действительно простой способ увидеть, как новые версии зависимостей могут повлиять на ваш проект, без необходимости загружать их несколько раз.\n","description":"Python 101","title":"39. Python wheels","uri":"/ru/docs/python101/chapter39_wheels/"},{"content":"GIT - Просмотр, удаление, отмена и восстановление Просмотр файлов в Stagig area и Working area Если некоторые файлы/папки уже добавлены в staging area, то можно просмотреть их рахницу по отношению в главной ветке комадой: git diff --staged\nЭто покажет нам все внесенные изменения и все новые файлы, которые мы добавили или удалили.\nИзменения в измененных файлах обозначаются символами --- или +++ Вы можете видеть ниже, что мы только что добавили +add some text, что означает, что это новые строки.\nМы также можем запустить git diff, чтобы сравнить наш staging area с нашим рабочим каталогом. Если мы внесем некоторые изменения в наш только что добавленный файл code.txt и добавим несколько строк текста.\nИнструменты для визуального отображения Вот несколько инструментов для визуального сравнения коммитов и веток:\nKDiff3 P4Merge WinMerge (только для Windows) VSCode Если запустим git difftool то запустится визуальный инструмент сравнения по умолчанию. Проверить текущие настройки git config --global -e Чтобы установить инструмент в git, выполним следующую команду git config --global diff.tool vscode. Теперь при запуске git difftool откроется vscode После этого открывается редактор VScode на странице diff и сравнивает их, мы изменили только один файл, добавив строку кода с правой стороны. Можем использовать git difftool --staged для сравнения файлов в staging area с “прокомиченными” файлами. VScode, как и большинство IDE, имеют встроенную функциональность, поэтому очень редко вам понадобится запускать эти команды из терминала, хотя это полезно, если у вас по какой-то причине не установлена IDE.\nПросмотр истории изменений Просмотреть историю изменений в Git можно командой git log\nКаждый коммит имеет свою шестнадцатеричную строку, уникальную для репозитория. Здесь вы можете увидеть, над какой веткой мы работаем, а также автора, дату и комментарий коммита.\nУ нас также есть git log --oneline, и это даёт нам гораздо меньшую версию шестнадцатеричной строки, которую мы можем использовать в других командах diff.\nЧтобы просмотреть коммиты с самого первого, а не послденего, как по умолчанию, запустим git log --oneline --reverse, и теперь мы видим наш первый коммит в верхней части страницы.\nПросмотр коммита Можно просмотреть данные ко конкретном коммите более детально: git show или git show \u003ccommit ID\u003e\nМы также можем использовать git show HEAD~1, где 1 - это количество шагов назад от текущей версии, к которой мы хотим вернуться.\nЭто отличный вариант, если вам нужна подробная информация о файлах, но если мы хотим получить список всех файлов в дереве для всего каталога снимков. Мы можем добиться этого, используя команду git ls-tree HEAD~1, снова вернувшись на один снимок назад от последнего коммита. Ниже мы видим два пятна, которые обозначают файлы, в то время как дерево обозначает каталог. В этой информации вы также можете увидеть коммиты и теги.\nПроверим коммит\nUnstaging Бывают случаи, когда вы, возможно, использовали git add ., но на самом деле есть файлы, которые вы пока не хотите фиксировать в этом снапшоте. В этом примере ниже я добавил newfile.txt в область staging, но я не готов зафиксировать этот файл, поэтому я собираюсь использовать git restore --staged newfile.txt, чтобы отменить шаг git add.\nМы также можем сделать то же самое с изменёнными файлами, такими как main.js, и снять фиксацию, см. выше у нас есть greem M для modified, а ниже мы снимаем фиксацию этих изменений.\nЯ нашел эту команду весьма полезной во время 90DaysOfDevOps, поскольку иногда я работаю заранее, когда чувствую, что хочу сделать заметки для следующего дня, но не хочу фиксировать и выкладывать в публичный репозиторий GitHub.\nОтмена локальных изменений Иногда мы можем вносить изменения, но эти изменения нас не устраивают, и мы хотим их отбросить. Мы снова воспользуемся командой git restore и сможем восстановить файлы из наших снимков или предыдущих версий. Мы можем запустить команду git restore . для нашего каталога, и мы восстановим все из нашего снимка, но обратите внимание, что наш неотслеживаемый файл все еще присутствует. Нет предыдущего отслеживаемого файла под названием newfile.txt.\nТеперь, чтобы удалить newfile.txt или любой другой неотслеживаемый файл. Мы можем использовать git clean, но получим только предупреждение.\nИли, если мы знаем о последствиях, мы можем запустить git clean -fd, чтобы принудительно удалить все каталоги.\nВосстановление файла до более ранней версии Как мы уже упоминали, большая часть того, чем может помочь Git, - это возможность восстановления копий файлов из снимков (это не резервное копирование, но это очень быстрая точка восстановления). Я советую вам также сохранять копии вашего кода в других местах, используя для этого решение для резервного копирования.\nВ качестве примера давайте удалим наш самый важный файл в каталоге, обратите внимание, что мы используем команды на базе unix для удаления этого файла из каталога, а не команды git.\nТеперь у нас нет readme.mdin в нашей рабочей директории. Мы могли бы использовать git rm readme.md и тогда это было бы отражено в нашей базе данных git. Давайте также удалим его отсюда, чтобы имитировать его полное удаление.\nТеперь зафиксируем это с сообщением и докажем, что у нас больше нет ничего в рабочем каталоге или в области постановки.\nБыла допущена ошибка, и теперь нам нужно вернуть этот файл!\nМы можем использовать команду git undo, которая отменит последний коммит, но что если это было давно? Мы можем использовать команду git log, чтобы найти наши коммиты, и тогда мы обнаружим, что наш файл находится в последнем коммите, но мы не хотим, чтобы все эти коммиты были отменены, поэтому мы можем использовать эту команду git restore --source=HEAD~1 README.md, чтобы найти файл и восстановить его из нашего снимка.\nВы можете видеть, что с помощью этого процесса мы вернули файл в наш рабочий каталог.\nТеперь у нас есть новый неотслеживаемый файл, и мы можем использовать наши команды, упомянутые ранее, для отслеживания, этапа и фиксации наших файлов и изменений.\nRebase / Merge Это, кажется, самая большая головная боль, когда речь заходит о Git и о том, когда использовать rebase, а когда использовать merge в ваших git-репозиториях.\nПрежде всего, нужно знать, что и git rebase, и git merge решают одну и ту же задачу. Оба они интегрируют изменения из одной ветки в другую. Однако они делают это по-разному.\nДавайте начнем с новой функции в новой выделенной ветке. Основная ветку продолжает работу с новыми коммитами.\nПростой вариант здесь - использовать git merge feature main, который объединит основную ветку с веткую feature.\nСлияние простое, потому что оно неразрушающее. Существующие ветви никак не изменяются. Однако это также означает, что функциональная ветку будет иметь неактуальный коммит слияния каждый раз, когда вам нужно будет включить изменения, внесённые выше по течению. Если main очень занят или активен, это может привести к загрязнению истории функциональной ветви.\nВ качестве альтернативного варианта мы можем перебазировать функциональную ветку на основную ветку с помощью команды\ngit checkout feature git rebase main Это перемещает ветку feature (всю ветку feature), эффективно включая все новые коммиты в main. Но вместо использования коммита слияния, rebasing переписывает историю проекта, создавая совершенно новые коммиты для каждого коммита в исходной ветке.\nСамым большим преимуществом ребасинга является гораздо более чистая история проекта. Это также устраняет ненужные коммиты слияния. и если сравнить последние два изображения, то можно увидеть, что история проекта намного чище.\nХотя это еще не окончательный вывод, потому что выбор более чистой истории также связан с компромиссами. Если вы не будете следовать The Golden rule of rebasing, переписывание истории проекта может стать потенциально катастрофой для вашего рабочего процесса совместной работы. И, что менее важно, при пересборке теряется контекст, предоставляемый коммитом слияния - вы не можете увидеть, когда изменения, внесенные выше по течению, были включены в функцию.\nСсылки What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet Exploring the Git command line – A getting started guide ","description":"Просмотр, удаление, отмена и восстановление версий в Git","title":"39. Просмотр, удаление, отмена и восстановление","uri":"/ru/docs/90daysofdevops/day39/"},{"content":"DevOps и Agile Вы знаете разницу между DevOps и Agile? Они формировались как самостоятельные понятия. Но теперь эти два термина сливаются.\nВ этом посте мы рассмотрим важные различия между Agile и DevOps и выясним, почему они так тесно связаны.\nЯ думаю, что хорошее место для начала — это немного больше узнать об общем подходе, который я увидел в изучении этой области, а именно о DevOps и Agile, даже несмотря на то, что у них схожие цели и процессы. В этом разделе я, надеюсь, мы разберемся с этим.\nНачнем с определений.\nРазработка Agile Agile — это подход, который фокусируется на более быстром получении небольших результатов, а не на выгрзуке (релизе) одного большого обновления продукта; программное обеспечение разрабатывается итерациями (неболшими изменениями). Команда выпускает новую версию каждую неделю или месяц с дополнительными обновлениями. Итоговая цель Agile — предоставить конечным пользователям оптимальный опыт.\nDevOps В течение последних нескольких дней мы освещали это несколькими различными способами описания конечных целей DevOps. DevOps обычно описывает разработку программного обеспечения и методы доставки, основанные на сотрудничестве между разработчиками программного обеспечения и специалистами по эксплуатации. Основными преимуществами DevOps являются упрощение процесса разработки и минимизация недопонимания.\nВ чем разница между Agile и DevOps Разница в основном в заботах. У Agile и DevOps разные интересы, но они помогают друг другу. Agile требует коротких итераций, что возможно только с автоматизацией, которую обеспечивает DevOps. Agile хочет, чтобы клиент попробовал конкретную версию и быстро дал отзыв, что возможно только в том случае, если DevOps упростит создание новой среды.\nРазные участники Agile фокусируется на оптимизации взаимодействия между конечными пользователями и разработчиками, в то время как DevOps нацелен на разработчиков и членов операционной группы. Можно сказать, что Agile ориентирован на клиентов, тогда как DevOps — это набор внутренних практик.\nКоманда Agile обычно применяется к разработчикам программного обеспечения и руководителям проектов. Компетенции DevOps-инженеров лежат на стыке разработки, QA (обеспечения качества) и операций, поскольку они участвуют во всех этапах цикла продукта и являются частью Agile-команды.\nПрикладные фреймворки В Agile есть много сред управления для достижения гибкости и прозрачности: Scrum \u003e Kanban \u003e Lean \u003e Extreme \u003e Crystal \u003e Dynamic \u003e Feature-Driven. DevOps фокусируется на подходе к разработке в сотрудничестве, но не предлагает конкретных методологий. Тем не менее, DevOps продвигает такие практики, как инфраструктура как код, архитектура как код, мониторинг, самовосстановление, сквозная автоматизация тестирования… Но сама по себе это не структура, а практика.\nОбратная связь В Agile основным источником обратной связи является конечный пользователь, тогда как в DevOps более высокий приоритет имеет обратная связь от заинтересованных сторон и самой команды.\nЦелевые области Agile фокусируется на разработке программного обеспечения больше, чем на развертывании и обслуживании. DevOps также фокусируется на разработке программного обеспечения, но его ценности и инструменты также охватывают этапы развертывания и после выпуска, такие как мониторинг, высокая доступность, безопасность и защита данных.\nДокументация Agile отдает предпочтение гибкости и поставленным задачам, а не документации и мониторингу. С другой стороны, DevOps рассматривает проектную документацию как один из основных компонентов проекта.\nРиски Риски Agile вытекают из гибкости методологии. Гибкие проекты трудно предсказать или оценить, поскольку приоритеты и требования постоянно меняются.\nРиски DevOps возникают из-за неправильного понимания термина и отсутствия подходящих инструментов. Некоторые люди рассматривают DevOps как набор программного обеспечения для развертывания и непрерывной интеграции, не способного изменить базовую структуру процесса разработки.\nИспользуемые инструменты Agile-инструменты ориентированы на совместную управленческую коммуникацию, метрики и обработку отзывов. К наиболее популярным agile-инструментам относятся JIRA, Trello, Slack, Zoom, SurveyMonkey и другие.\nDevOps использует инструменты для командного общения, разработки программного обеспечения, развертывания и интеграции, такие как Jenkins, GitHub Actions, BitBucket и т. д. Несмотря на то, что Agile и DevOps имеют несколько разные фокусы и области действия, ключевые значения почти идентичны, поэтому вы можете комбинировать их.\nСобрать все вместе… хорошая идея или нет? Обсуждать? Сочетание Agile и DevOps дает следующие преимущества:\nГибкое управление и мощные технологии. Практики Agile помогают командам DevOps более эффективно сообщать о своих приоритетах. Стоимость автоматизации, которую вы должны заплатить за свои методы DevOps, оправдана вашим гибким требованием быстрого и частого развертывания. Это приводит к укреплению: команда, внедряющая agile-практики, улучшит сотрудничество, повысит мотивацию команды и снизит текучесть кадров. В результате вы получаете лучшее качество продукции. Agile позволяет вернуться к предыдущим этапам разработки продукта, чтобы исправить ошибки и предотвратить накопление технического долга. Принять Agile и DevOps одновременно просто выполните 7 шагов:\nОбъедините команды разработки и эксплуатации. Создайте команды сборки и запуска, все проблемы, связанные с разработкой и эксплуатацией, обсуждаются всей командой DevOps. Измените свой подход к спринтам и назначьте рейтинги приоритета, чтобы предлагать задачи DevOps, которые имеют такое же значение, как задачи разработки. Поощряйте команды разработчиков и эксплуатации обмениваться мнениями о рабочем процессе других команд и возможных проблемах. Включите контроль качества на все этапы разработки. Выбирайте правильные инструменты. Автоматизируйте все, что можете. Измеряйте и контролируйте, используя материальные числовые результаты. Что вы думаете? У вас разные взгляды? Я хочу услышать от разработчиков, специалистов по эксплуатации, QA или кого-либо, кто лучше разбирается в Agile и DevOps, которые могут поделиться комментариями и отзывами по этому поводу?\nИсточники DevOps for Developers – Day in the Life: DevOps Engineer in 2021 3 Things I wish I knew as a DevOps Engineer How to become a DevOps Engineer feat. Shawn Powers До встречи в День 5\n","description":"DevOps и Agile","title":"4. DevOps и Agile","uri":"/ru/docs/90daysofdevops/day04/"},{"content":"В каждом компьютерном языке есть хотя бы один условный оператор. Чаще всего этот оператор представляет собой структуру if/elif/else.\nВ Python 3.10 добавилась структура match/case\nУсловный оператор проверяет, является ли утверждение истинным или ложным. Это, собственно, все, что он делает. Также рассмотрим следующие булевы операции: and, or и not. Эти операции могут изменять поведение условного оператора простыми и сложными способами, в зависимости от проекта.\nОператор if Оператор if в Python довольно прост в использовании. Давайте потратим несколько минут на рассмотрение нескольких примеров, чтобы лучше познакомиться с этой конструкцией.\n\u003e\u003e\u003e if 2 \u003e 1: print(\"This is a True statement!\") This is a True Statement! `` Это условие проверяет \"правдивость\" следующего утверждения: 2 \u003e 1. Поскольку это утверждение оценивается как True, оно приведет к печати последней строки примера на экран или в **стандартный выход** (stdout). **Python заботится о пробелах** Язык Python очень заботится о пробелах. Вы заметили, что в нашем условном выражении выше мы отступили от кода внутри оператора if на четыре пробела. Это очень важно! Если вы не сделаете отступы между блоками кода должным образом, код не будет выполняться правильно. Он может вообще не выполниться. Также **не** смешивайте табуляцию и пробелы. IDLE будет жаловаться, что с файлом что-то не так, и вам будет трудно понять, в чем дело. Рекомендуемое количество пробелов для отступа в блоке кода - четыре. На самом деле вы можете отступать от текста на любое количество пробелов, если вы последовательны. Однако правило 4 пробелов рекомендовано в Руководстве по стилю Python, и именно его придерживаются разработчики кода Python. Давайте рассмотрим другой пример: ```python \u003e\u003e\u003e var1 = 1 \u003e\u003e\u003e var2 = 3 \u003e\u003e\u003e if var1 \u003e var2: print(\"This is also True\") В этой статье мы сравниваем две переменные, которые отвечают на вопрос: 1 \u003e 3? Очевидно, что 1 не больше 3, поэтому ничего не выводится. Но что, если мы хотим, чтобы он что-то вывел? Вот тут-то и приходит на помощь оператор else. Давайте изменим условие, чтобы добавить этот элемент:\nif var1 \u003e var2: print(\"This is also True\") else: print(\"That was False!\") Если вы запустите этот код, он выведет строку, которая следует за оператором else. Давайте сменим передачу и получим немного информации от пользователя, чтобы сделать это поинтереснее. В Python 3.x тоже есть встроенная функция input, но она пытается выполнить то, что введено как выражение Python.\nvalue = input(\"How much is that doggy in the window? \\n\") value = int(value) if value \u003c 10: print(\"That's a great deal!\") elif 10 \u003c= value \u003c= 20: print(\"I'd still pay that...\") else: print(\"Wow! That's too much!\") Давайте немного разложим всё это по полочкам. Первая строка запрашивает у пользователя сумму. В следующей строке он преобразует введенный пользователем результат в целое число. Так что если вы введете число с плавающей запятой, например 1.23, оно будет усечено до 1. Если вы введете не число, то получите исключение. Мы рассмотрим, как обрабатывать исключения в следующей главе, поэтому пока просто введите целое число.\nВ следующих нескольких строках вы увидите, как мы проверяем 3 различных случая: меньше 10, больше или равно 10, но меньше или равно 20 или что-то еще. Для каждого из этих случаев выводится своя строка. Попробуйте поместить этот код в IDLE и сохранить его. Затем запустите его несколько раз с разными входными данными, чтобы посмотреть, как он работает.\nВы можете добавить несколько операторов elif ко всему условию. Оператор else необязателен, но является хорошим вариантом по умолчанию.\nmatch/case color = \"yellow\" match color: case \"red\": print(\"The color is red\") case \"yellow\": print(\"Wow, you picked yellow\") case \"green\": print(\"We are using a green color\") case \"blue\": print(\"Blue like the sea...\") match command.split(): case [\"quit\"]: print(\"Goodbye!\") quit_game() case [\"look\"]: current_room.describe() case [\"get\", obj]: character.get(obj, current_room) case [\"go\", direction]: current_room = current_room.neighbor(direction) or/and/not Теперь мы готовы к изучению булевых операций (and, or, not). Согласно документации Python, их порядок приоритета таков: сначала or, затем and, затем not. Вот как они работают:\nor означает, что если любое условие, которое “перечислено” вместе, равно True, то выполняется следующее утверждение and означает, что для выполнения следующего утверждения все утверждения должны быть True not означает, что если условие оценивается как False, то оно является True. На мой взгляд, это самый запутанный вариант. Давайте рассмотрим несколько примеров каждого из них. Мы начнем с or.\nx = 10 y = 20 if x \u003c 10 or y \u003e 15: print(\"This statement was True!\") Здесь мы создаем пару переменных и проверяем, если одна из них меньше десяти, а другая больше 15. Поскольку последняя больше 15, выполняется оператор print. Как видите, если одно или оба утверждения равны True, то выполняется оператор print. Давайте посмотрим, как работает end:\nx = 10 y = 10 if x == 10 and y == 15: print(\"This statement was True\") else: print(\"The statement was False!\") Если вы выполните приведенный выше код, вы увидите, что первое утверждение не выполняется. Вместо него выполняется оператор под else. Почему так? Потому что мы проверяем, что x и y равны 10 и 15 соответственно. В данном случае это не так, поэтому мы переходим к else. Таким образом, когда вы соединяете два оператора вместе, оба оператора должны иметь значение True, чтобы выполнить следующий код. Также обратите внимание, что для проверки равенства в Python необходимо использовать двойной знак равенства. Одинарный знак равенства известен как оператор присваивания и предназначен только для присвоения значения переменной. Если бы вы попытались выполнить приведенный выше код с одним из операторов, имеющим только один знак равенства, вы бы получили сообщение о неправильном синтаксисе.\nОбратите внимание, что вы также можете использовать or и and более чем два оператора вместе. Однако я не рекомендую этого делать, так как чем больше утверждений, тем сложнее их понять и отладить.\nТеперь мы готовы рассмотреть операцию not.\nmy_list = [1, 2, 3, 4] x = 10 if x not in my_list: print(\"'x' is not in the list, so this is True!\") В этом примере мы создаем список, содержащий четыре целых числа. Затем мы пишем тест, который спрашивает, нет ли “x” в этом списке. Поскольку “x” равно 10, оператор оценивается как True, и сообщение выводится на экран. Другим способом проверки на not является использование восклицательного знака, например, так:\nx = 10 if x != 11: print(\"x is not equal to 11!\") При желании вы можете комбинировать операцию not с двумя другими для создания более сложных условных операторов. Вот простой пример:\nmy_list = [1, 2, 3, 4] x = 10 z = 11 if x not in my_list and z != 10: print(\"This is True!\") Проверка на ничто (None) Поскольку мы говорим об утверждениях, которые оцениваются в True, нам, вероятно, нужно рассказать о том, что оценивается в False. В Python есть ключевое слово False, которое я уже несколько раз упоминал. Однако пустая строка, кортеж или список также оцениваются как False. Есть также еще одно ключевое слово, которое в основном оценивается как False и называется None. Значение None используется для обозначения отсутствия значения. Это своего рода аналог Null, который можно встретить в базах данных. Давайте посмотрим на код, чтобы лучше понять, как все это работает:\nempty_list = [] empty_tuple = () empty_string = \"\" nothing = None if empty_list == []: print(\"It's an empty list!\") if empty_tuple: print(\"It's not an empty tuple!\") if not empty_string: print(\"This is an empty string!\") if not nothing: print(\"Then it's nothing!\") Первые четыре строки задают четыре переменные. Далее мы создаем четыре условия для их проверки. Первое проверяет, действительно ли empty_list пуст. Второе условие проверяет, есть ли что-то в empty_tuple. Да, вы все правильно поняли, второе условие имеет значение True, только если кортеж не пуст! Последние два условия делают противоположное второму. Третье проверяет, является ли строка пустой, а четвертое - действительно ли переменная nothing является None.\nОператор not означает, что мы проверяем противоположное значение. Другими словами, мы проверяем, является ли значение НЕ True. Поэтому в третьем примере мы проверяем, является ли пустая строка ПО НАСТОЯЩЕМУ пустой. Вот другой способ написать то же самое:\nif empty_string == \"\": print(\"This is an empty string!\") Чтобы действительно закрепить это, давайте установим переменную empty_string, чтобы она действительно содержала что-то:\n\u003e\u003e\u003e empty_string = \"something\" \u003e\u003e\u003e if empty_string == \"\": print(\"This is an empty string!\") Если вы выполните это, то увидите, что ничего не будет выведено, так как мы выведем что-то только в том случае, если переменная является пустой строкой.\nОбратите внимание, что ни одна из этих переменных не равна другой. Они просто оцениваются одинаково. Чтобы доказать это, мы рассмотрим пару быстрых примеров:\n\u003e\u003e\u003e empty_list == empty_string False \u003e\u003e\u003e empty_string == nothing False Как видите, они не равны друг другу. В реальном мире вы часто будете проверять свои структуры данных на наличие данных. Некоторые программисты предпочитают просто обернуть свои структуры в обработчик исключений, и если они окажутся пустыми, они поймают исключение. Другие предпочитают использовать вышеупомянутую стратегию, когда вы действительно проверяете структуру данных на наличие в ней данных. Обе стратегии являются правильными.\nЯ нахожу оператор not немного запутанным и не использую его часто. Но время от времени он может оказаться полезным.\nСпециальные символы Строки могут содержать специальные символы, такие как табуляция или новая строка. Мы должны знать о них, поскольку иногда они могут появляться и вызывать проблемы. Например, символ новой строки определяется как \\n, а символ табуляции - как \\t. Давайте рассмотрим несколько примеров, чтобы вы лучше поняли, что они делают:\n\u003e\u003e\u003e print(\"I have a \\n new line in the middle\") I have a new line in the middle \u003e\u003e\u003e print(\"This sentence is \\ttabbed!\") This sentence is tabbed! Был ли вывод таким, как вы ожидали? В первом примере в середине предложения стоит буква “n”, что заставляет вывести новую строку. Поскольку у нас есть пробел после символа новой строки, вторая строка отделена пробелом. Второй пример показывает, что происходит, когда внутри предложения есть символ табуляции.\nИногда в строке необходимо использовать управляющие символы, например, обратную косую черту. Чтобы использовать экранирующие символы, необходимо использовать обратную косую черту, поэтому в случае с обратной косой чертой необходимо ввести две обратные косые черты. Давайте посмотрим:\n\u003e\u003e\u003e print(\"This is a backslash \\\") Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e EOL while scanning string literal: \u003cstring\u003e, line 1, pos 30 \u003e\u003e\u003e print(\"This is a backslash \\\\\") This is a backslash \\ Вы заметите, что первый пример сработал не очень хорошо. Python думал, что мы экранируем двойную кавычку, поэтому он не мог определить, где находится конец строки (EOL), и выдавал ошибку. Во втором примере обратная косая черта экранирована должным образом.\nif name == “main” Вы увидите очень распространенный условный оператор, используемый во многих примерах Python. Вот как он выглядит\nif __name__ == \"__main__\": # do something! Располагается в конце файла. Это говорит Python, что вы хотите выполнить следующий код, только если эта программа будет выполнена как отдельный файл. Я часто использую эту конструкцию, чтобы проверить, что мой код работает так, как я ожидаю. Мы обсудим это позже в книге, но всякий раз, когда вы создаете сценарий Python, вы создаете модуль Python. Если вы напишете его хорошо, вы можете захотеть импортировать его в другой модуль. Когда вы импортируете модуль, он не будет выполнять код, находящийся под условным обозначением, потому что name больше не будет равен \"main\".\n","description":"Python 101","title":"4. Условия","uri":"/ru/docs/python101/chapter4_conditionals/"},{"content":"Социальная сеть для кода Изучение GitHub | GitLab | BitBucket\nСегодня я хочу рассказать о некоторых сервисах на основе git, о которых мы, вероятно, все слышали и ожидаем, что будем использовать их ежедневно.\nGitHub Наиболее распространенным, по крайней мере для меня, является GitHub, GitHub — это веб-хостинг для git. Чаще всего он используется разработчиками программного обеспечения для хранения своего кода. Управление исходным кодом с функциями контроля версий git, а также множеством дополнительных функций. Это позволяет командам или открытым участникам легко общаться и обеспечивает социальный аспект кодирования. (отсюда и название социальной сети) С 2018 года GitHub является частью Microsoft.\nGitHub существует уже довольно давно и был основан в 2007-2008 годах. Сегодня на платформе более 40 миллионов пользователей.\nОсновные возможности GitHub\nCode Repository Pull Requests Project Management toolset - Issues CI / CD Pipeline - GitHub Actions С точки зрения ценообразования GitHub предлагает различные уровни ценообразования для своих пользователей. Дополнительную информацию можно найти на странице Цены.\nДля этого мы рассмотрим бесплатный уровень.\nЯ собираюсь использовать свою уже созданную учетную запись GitHub во время этого пошагового руководства, если у вас нет учетной записи, то на открывающейся странице GitHub есть вариант регистрации и несколько простых шагов для настройки.\nGitHub opening page Когда вы впервые входите в свою учетную запись GitHub, вы получаете страницу, содержащую множество виджетов, дающих вам варианты того, где и что вы хотели бы увидеть или сделать. Во-первых, у нас есть «All Activity», это даст вам представление о том, что происходит с вашими репозиториями или действиями в целом, связанными с вашей организацией или учетной записью.\nЗатем у нас есть наши репозитории кода, либо наши собственные, либо репозитории, с которыми мы недавно взаимодействовали. Мы также можем быстро создавать новые репозитории или репозитории поиска.\nЗатем у нас есть наша недавняя активность, для меня это проблемы и pull requests, которые я недавно создал или в которых участвовал.\nВ правой части страницы есть несколько ссылок на репозитории, которые могут нас заинтересовать, скорее всего, на основе вашей недавней активности или собственных проектов.\nЧестно говоря, я очень редко бываю на своей домашней странице, которую мы только что видели и описали, хотя теперь я вижу, что лента может быть действительно полезной, чтобы помочь взаимодействовать с сообществом немного лучше в определенных проектах.\nДалее, если мы хотим зайти в наш профиль на GitHub, мы можем перейти в правый верхний угол, и на вашем изображении будет выпадающий список, который позволит вам перемещаться по вашему аккаунту. Отсюда для доступа к своему профилю выберите “Ваш профиль”\nДалее появится страница вашего профиля, по умолчанию, если вы не измените свою конфигурацию, вы не увидите того, что есть у меня, я добавил некоторые функции, которые показывают мои последние записи в блоге на vZilla, а также мои последние видео на моем канале YouTube.\nЛично вы не собираетесь тратить много времени на просмотр своего профиля, но это хорошая страница профиля, которой можно поделиться со своей сетью, чтобы они могли увидеть крутые проекты, над которыми вы работаете.\nЗатем мы можем перейти к основному элементу GitHub - репозиториям. Здесь вы увидите свои собственные репозитории, а если у вас есть частные репозитории, они также будут показаны в этом длинном списке.\nПоскольку этот репозиторий так важен для GitHub, позвольте мне выбрать довольно загруженный в последнее время и просмотреть некоторые основные функции, которые мы можем использовать здесь, в дополнение ко всему, что я уже использую, когда дело доходит до редактирования нашего кода в git. моя локальная система.\nПрежде всего, в предыдущем окне я выбрал репозиторий 90DaysOfDevOps, и мы видим это представление. Вы можете видеть из этого представления, что у нас есть много информации, у нас есть наша основная структура кода в середине, показывающая наши файлы и папки, которые хранятся в нашем репозитории. Наш файл readme.md отображается внизу. Справа от страницы у нас есть раздел о репозитории, где у репозитория есть описание и назначение. Затем у нас есть много информации под этим, показывающей, сколько людей отметили проект, разветвились и смотрят.\nЕсли мы прокрутим вниз немного дальше, вы также увидите, что у нас есть Releases, они относятся к части задачи golang. У нас нет никаких пакетов в нашем проекте, здесь перечислены наши соавторы. Затем у нас есть используемые языки, опять же из разных разделов задачи.\nВ верхней части страницы вы увидите список вкладок. Они могут различаться, и их можно изменить, чтобы отображались только те, которые вам нужны. Вы увидите здесь, что я не использую все это, и я должен удалить их, чтобы убедиться, что весь мой репозиторий в порядке.\nВо-первых, у нас была вкладка кода, которую мы только что обсуждали, но эти вкладки всегда доступны при навигации по репозиторию, что очень полезно, так что мы можем быстро и легко переходить между разделами. Далее у нас есть вкладка вопросов.\nПроблемы позволяют отслеживать вашу работу на GitHub, где происходит разработка. В этом конкретном репозитории вы можете увидеть, что у меня есть некоторые проблемы, связанные с добавлением диаграмм или опечаток, но также у нас есть проблема, указывающая на необходимость или требование для китайской версии репозитория.\nЕсли это был репозиторий кода, то это отличное место, чтобы сообщить о проблемах или проблемах с сопровождающими, но помните, будьте внимательны и подробны в отношении того, о чем вы сообщаете, давайте как можно больше подробностей.\nСледующая вкладка — Pull Requests. Pull Requests позволяют вам сообщать другим об изменениях, которые вы отправили в ветку в репозитории. Здесь кто-то мог разветвить ваш репозиторий, внести изменения, такие как исправления ошибок или улучшения функций, или просто опечататься во многих случаях в этом репозитории.\nМы рассмотрим разветвление позже.\nЯ считаю, что следующая вкладка совершенно новая? Но я подумал, что для такого проекта, как #90DaysOfDevOps, это может действительно помочь направить контент, а также помочь сообществу, когда они проходят свой собственный путь обучения. Я создал несколько дискуссионных групп для каждого раздела задачи, чтобы люди могли присоединиться и обсудить.\nВкладка “Actions” позволит вам создавать, тестировать и развертывать код и многое другое прямо из GitHub. GitHub Actions будет чем-то, что мы рассмотрим в разделе задачи, посвященном CI/CD, но именно здесь мы можем установить некоторую конфигурацию, чтобы автоматизировать шаги для нас.\nВ моем основном профиле GitHub я использую GitHub Actions для получения последних сообщений в блогах и видео на YouTube, чтобы обновлять информацию на этом домашнем экране.\nЯ уже говорил о том, что GitHub - это не только хранилище исходного кода, но и инструмент управления проектами. Вкладка “Проект” позволяет нам создавать проектные таблицы типа канбан, чтобы мы могли связывать проблемы и PR для лучшего сотрудничества над проектом и иметь видимость этих задач. Я знаю, что проблемы, как мне кажется, являются хорошим местом для регистрации запросов о возможностях, и это так, но страница вики позволяет составить полную дорожную карту проекта с указанием текущего состояния и в целом лучше документировать ваш проект, будь то устранение неполадок или контент типа how-to.\nНе совсем применимо к этому проекту, но вкладка Security действительно существует для того, чтобы убедиться, что участники проекта знают, как обращаться с определенными задачами, здесь мы можем определить политику, а также дополнения для сканирования кода, чтобы убедиться, что ваш код, например, не содержит секретных переменных окружения.\nДля меня вкладка insights очень важна, она предоставляет так много информации о репозитории, начиная от того, сколько активности происходило и заканчивая коммитами и проблемами, а также сообщает о посещаемости репозитория. В левой части вы можете увидеть список, который позволяет вам подробно ознакомиться с метриками репозитория.\nНаконец, у нас есть вкладка Settings, где мы можем подробно описать, как мы управляем нашим репозиторием, в настоящее время я единственный сопровождающий репозитория, но мы можем разделить эту ответственность. Здесь мы можем определить интеграции и другие подобные задачи.\nЭто был очень быстрый обзор GitHub, я думаю, что есть еще несколько областей, которые я, возможно, упомянул и которые нуждаются в более подробном объяснении. Как уже упоминалось, GitHub содержит миллионы репозиториев, в которых в основном хранится исходный код, и они могут быть общедоступными или частными.\nForking Я собираюсь больше рассказать об Open-Source на завтрашней сессии, но большая часть любого репозитория кода — это возможность сотрудничать с сообществом. Давайте подумаем о сценарии: мне нужна копия репозитория, потому что я хочу внести в него некоторые изменения, может быть, я хочу исправить ошибку или, может быть, я хочу что-то изменить, чтобы использовать его для моего варианта использования, который, возможно, не был предполагаемый вариант использования для первоначального сопровождающего кода. Это то, что мы бы назвали разветвлением репозитория. Форк — это копия репозитория. Разветвление репозитория позволяет вам свободно экспериментировать с изменениями, не затрагивая исходный проект.\nПозвольте мне вернуться на начальную страницу после входа в систему и увидеть один из предложенных репозиториев.\nЕсли мы нажмем на этот репозиторий, мы получим тот же вид, что и репозиторий 90DaysOfDevOps.\nЕсли мы обратим внимание, ниже у нас есть 3 варианта: watch, fork и star.\nWatch - обновление, когда что-то происходит с хранилищем. Fork - копия репозитория. Star - “Я думаю, что ваш проект крутой”. Учитывая наш сценарий, когда нам нужна копия репозитория для работы, мы воспользуемся опцией fork. Если вы являетесь членом нескольких организаций, то вам придётся выбрать, где будет происходить форк, я выберу свой профиль.\nТеперь у нас есть собственная копия репозитория, над которой мы можем свободно работать и изменять по своему усмотрению. Это начало процесса подачи запросов на исправление, о котором мы уже вкратце упоминали, но более подробно рассмотрим завтра. Хорошо, я слышу, как вы говорите, но как мне внести изменения в этот репозиторий и код, если он находится на веб-сайте, ну, вы можете просматривать и редактировать на веб-сайте, но это не будет таким же, как использование вашей любимой IDE в вашей локальной системе. с вашей любимой цветовой темой. Чтобы получить копию этого репозитория на нашем локальном компьютере, мы выполним клонирование репозитория. Это позволит нам работать над вещами локально, а затем отправлять наши изменения обратно в нашу разветвленную копию репозитория.\nУ нас есть несколько вариантов получения копии этого кода, как вы можете видеть ниже.\nДоступна локальная версия GitHub Desktop, которая дает вам визуальное настольное приложение для отслеживания изменений и отправки и получения изменений между локальным и github.\nДля этой небольшой демонстрации я буду использовать URL-адрес HTTPS, который мы видим там.\nТеперь на нашей локальной машине я перейду в каталог, в который я хочу загрузить этот репозиторий, а затем выполню команду git clone url.\nТеперь мы можем обратиться к VScode, чтобы действительно внести некоторые изменения.\nТеперь давайте сделаем некоторые изменения, я хочу изменить все эти ссылки и заменить их на что-то другое.\nТеперь, если мы вернемся на GitHub и найдем наш readme.mdin в этом репозитории, вы сможете увидеть несколько изменений, которые я внес в файл.\nНа данном этапе это может быть завершено, и мы можем быть довольны нашим изменением, поскольку мы единственные люди, которые будут использовать наше новое изменение, но, возможно, это было изменение ошибки, и если это так, то мы захотим внести свой вклад через Pull Request чтобы уведомить сопровождающих исходного репозитория о наших изменениях и посмотреть, примут ли они наши изменения.\nМы можем сделать это, используя кнопку вклада, выделенную ниже. Я расскажу об этом подробнее завтра, когда мы рассмотрим рабочие процессы с открытым исходным кодом.\nЯ долго просматривал GitHub и слышал, как некоторые из вас плачут, но как насчет других вариантов!\nНу, есть, и я собираюсь найти некоторые ресурсы, которые охватывают основы для некоторых из них. В своих путешествиях вы столкнетесь с GitLab и BitBucket, и хотя они основаны на git, у них есть свои отличия.\nВы также столкнетесь с размещенными вариантами. Чаще всего здесь я видел GitLab как размещенную версию по сравнению с GitHub Enterprise (не верите, что есть бесплатный размещенный GitHub?)\nРесурсы Learn GitLab in 3 Hours | GitLab Complete Tutorial For Beginners BitBucket Tutorials Playlist What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"Обзор онлайн репозиториев для Git","title":"40. GitHub | GitLab | BitBucket","uri":"/ru/docs/90daysofdevops/day40/"},{"content":"Проект py2exe раньше был основным способом создания исполняемых файлов Windows из ваших приложений Python. На PyPI лежит версия, которая будет работать и с Python 2 и 3.\nУ вас есть несколько вариантов для приложения. Вы можете создать программу, которая будет работать только в терминале, вы можете создать графический интерфейс пользователя (GUI) для рабочего стола или создать веб-приложение. Мы создадим очень простой настольный интерфейс, который ничего не делает, кроме отображения формы, которую пользователь может заполнить. Мы будем использовать инструментарий wxPython GUI, чтобы продемонстрировать, как py2exe может подбирать пакеты без нашего указания.\nСоздание простого графического интерфейса Вам нужно перейти на сайт wxPython (www.wxpython.org) и загрузить копию, соответствующую вашей версии Python. Если у вас 32-битный Python, убедитесь, что вы скачали 32-битный wxPython. Вы не сможете использовать easy_install или pip для установки wxPython, если только вы не получите самую современную версию wxPython от Phoenix, поэтому вам придется взять копию, предварительно собранную для вашей системы, либо с сайта wxPython, либо из менеджера пакетов вашей системы. Я рекомендую использовать по крайней мере wxPython 2.9 или выше.\nДавайте напишем немного кода!\nimport wx class DemoPanel(wx.Panel): \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" wx.Panel.__init__(self, parent) labels = [\"Name\", \"Address\", \"City\", \"State\", \"Zip\", \"Phone\", \"Email\", \"Notes\"] mainSizer = wx.BoxSizer(wx.VERTICAL) lbl = wx.StaticText(self, label=\"Please enter your information here:\") lbl.SetFont(wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD)) mainSizer.Add(lbl, 0, wx.ALL, 5) for lbl in labels: sizer = self.buildControls(lbl) mainSizer.Add(sizer, 1, wx.EXPAND) self.SetSizer(mainSizer) mainSizer.Layout() def buildControls(self, label): \"\"\" Put the widgets together \"\"\" sizer = wx.BoxSizer(wx.HORIZONTAL) size = (80,40) font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD) lbl = wx.StaticText(self, label=label, size=size) lbl.SetFont(font) sizer.Add(lbl, 0, wx.ALL|wx.CENTER, 5) if label != \"Notes\": txt = wx.TextCtrl(self, name=label) else: txt = wx.TextCtrl(self, style=wx.TE_MULTILINE, name=label) sizer.Add(txt, 1, wx.ALL, 5) return sizer class DemoFrame(wx.Frame): \"\"\" Frame that holds all other widgets \"\"\" def __init__(self): \"\"\"Constructor\"\"\" wx.Frame.__init__(self, None, wx.ID_ANY, \"Py2Exe Tutorial\", size=(600,400) ) panel = DemoPanel(self) self.Show() if __name__ == \"__main__\": app = wx.App(False) frame = DemoFrame() app.MainLoop() Если вы выполните приведенный выше код, вы должны увидеть что-то вроде следующего:\nДавайте немного разложим это по полочкам. Мы создаем два класса, DemoPanel и DemoFrame. В wxPython объект wx.Frame используется для создания реального “окна”, которое вы видите в большинстве случаев. Вы добавляете wx.Panel, чтобы придать вашему приложению соответствующий вид и ощущение, а также добавить табуляцию между полями. Родителем объекта панели является фрейм. Фрейм, будучи виджетом верхнего уровня, не имеет родителя. Панель содержит все остальные виджеты в этом примере. Для компоновки виджетов мы используем сайзеры. Сайзеры позволяют разработчику создавать виджеты, размер которых будет изменяться соответствующим образом при изменении размера самого окна. Вы также можете разместить виджеты на панели с помощью абсолютного позиционирования, что не рекомендуется. В конце мы вызываем метод MainLoop объекта wx.App, чтобы запустить цикл событий, который позволяет wxPython реагировать на события мыши и клавиатуры (такие как щелчок, ввод текста и т.д.).\nТеперь мы готовы узнать, как упаковать это приложение в исполняемый файл!\nФайл py2exe setup.py Ключевым элементом любого скрипта py2exe является файл setup.py. Этот файл определяет, что будет включено или исключено, как сильно мы будем сжимать и упаковывать, и многое другое! Вот простейшая установка, которую мы можем использовать с приведенным выше скриптом wx:\nfrom distutils.core import setup import py2exe setup(windows=['sampleApp.py']) Как вы видите, мы импортируем метод setup из distutils.core, а затем импортируем py2exe. Далее мы вызываем setup с параметром ключевого слова windows и передаем ему имя главного файла внутри объекта python list. Если бы вы создавали проект без графического интерфейса, то вместо windows вы бы использовали клавишу console. Чтобы запустить этот фрагмент, сохраните его в той же папке, что и ваш скрипт wxPython, откройте командную строку и перейдите в то место, где вы сохранили эти два файла. Затем введите python setup.py py2exe, чтобы запустить его. Если все идет хорошо, вы увидите много вывода, заканчивающегося примерно так:\nЕсли вы используете Python 2.6, вы можете получить ошибку MSVCP90.dll не найден. Если вы увидите эту ошибку, вам, вероятно, придется найти Microsoft Visual C++ 2008 Redistributable Package и установить его, чтобы DLL стала доступна в вашей системе. Иногда бывает так, что вы создаете исполняемый файл, а затем, когда вы его запускаете, он просто не загружается правильно. Обычно при этом создается файл журнала, который можно использовать для выяснения причины. Я также нашел инструмент под названием Dependency Walker, который можно запустить против вашего исполняемого файла, и он может рассказать вам о недостающих элементах, не относящихся к Python (например, DLL и т.д.).\nЯ хотел бы отметить, что файл setup.py не включает wxPython в явном виде. Это означает, что py2exe был достаточно умен, чтобы включить пакет wxPython автоматически. Давайте потратим немного времени, чтобы узнать немного больше о включении и исключении пакетов.\nСоздание расширенного файла setup.py Давайте посмотрим, какие еще возможности дает нам py2exe для создания двоичных файлов, создав более сложный файл setup.py.\nfrom distutils.core import setup import py2exe includes = [] excludes = ['_gtkagg', '_tkagg', 'bsddb', 'curses', 'email', 'pywin.debugger', 'pywin.debugger.dbgcon', 'pywin.dialogs', 'tcl', 'Tkconstants', 'Tkinter'] packages = [] dll_excludes = ['libgdk-win32-2.0-0.dll', 'libgobject-2.0-0.dll', 'tcl84.dll', 'tk84.dll'] setup( options = {\"py2exe\": {\"compressed\": 2, \"optimize\": 2, \"includes\": includes, \"excludes\": excludes, \"packages\": packages, \"dll_excludes\": dll_excludes, \"bundle_files\": 3, \"dist_dir\": \"dist\", \"xref\": False, \"skip_archive\": False, \"ascii\": False, \"custom_boot_script\": '', } }, windows=['sampleApp.py'] ) Это довольно понятно, но все же давайте разберемся. Сначала мы создадим несколько списков, которые мы передадим в параметр options функции setup.\nСписок includes предназначен для специальных модулей, которые вам нужно включить. Иногда py2exe не может найти определенные модули, поэтому их нужно указать вручную. Список excludes - это список модулей, которые нужно исключить из вашей программы. В данном случае нам не нужен Tkinter, так как мы используем wxPython. Этот список исключений GUI2Exe будет исключать по умолчанию. Список packages - это список конкретных пакетов для включения. Опять же, иногда py2exe просто не может что-то найти. Мне уже приходилось включать сюда email, PyCrypto или lxml. Обратите внимание, что если список excludes содержит что-то, что вы пытаетесь включить в списки packages или includes, py2exe может продолжать исключать это. dll_excludes - исключает dll, которые не нужны в нашем проекте. В словаре options у нас есть еще несколько опций, на которые стоит обратить внимание. Ключ compressed указывает py2exe, сжимать или нет zip-файл, если он установлен. Ключ optimize задает уровень оптимизации. Ноль - это отсутствие оптимизации, а 2 - самый высокий уровень. Установив optimize на 2, мы можем уменьшить размер папки примерно на один мегабайт. Ключ bundle_files связывает dlls в zip-файл или exe. Допустимыми значениями для bundle_files являются:\n1 = упаковывать все, включая интерпретатор Python. 2 = упаковывать все, кроме интерпретатора Python. 3 = не упаковывать (по умолчанию). Несколько лет назад, когда я только начинал изучать py2exe, я спросил в их списке рассылки, какой вариант лучше, потому что у меня были проблемы с вариантом bundle 1. Мне ответили, что вариант 3, вероятно, самый стабильный. Я перешел на него и перестал испытывать случайные проблемы, поэтому сейчас я рекомендую именно его. Если вам не нравится распространять более одного файла, заархивируйте их или создайте программу установки. Единственный вариант, который я использую в этом списке, это dist_dir. Я использую его для экспериментов с различными вариантами сборки или для создания пользовательских сборок, когда я не хочу перезаписывать свою основную хорошую сборку. Обо всех остальных опциях вы можете прочитать на сайте py2exe.\nПакет py2exe не поддерживает включение eggs Python в свои двоичные файлы, поэтому если вы установили пакет, от которого зависит ваше приложение, как egg, то при создании исполняемого файла он не будет работать. Вам придется убедиться, что ваши зависимости установлены нормально.\nСуществует несколько альтернатив py2exe, таких как bbfreeze, cx_freeze и PyInstaller. Создание исполняемых файлов может быть нелегким делом, но наберитесь терпения и настойчиво пройдите через это.\n","description":"Python 101","title":"40. py2exe","uri":"/ru/docs/python101/chapter40_py2exe/"},{"content":"Пакет bbfreeze также позволяет нам создавать двоичные файлы, но только в Linux и Windows. Когда вы создаете двоичный файл в Linux, результат будет работать только на машинах, имеющих ту же аппаратную архитектуру и версию libc, что ограничивает его полезность в Linux. Также следует отметить, что bbfreeze работает только с Python версий 2.4 - 2.7. Вы можете использовать easy_install или pip для установки пакета bbfreeze в вашу систему. Пакет bbfreeze включает поддержку egg, поэтому он может включать зависимости eggs в ваши двоичные файлы, в отличие от py2exe. Вы также можете замораживать несколько скриптов одновременно, включать интерпретатор Python и многое другое.\nНачало работы с bbfreeze Вы можете использовать easy_install для загрузки и установки bbfreeze или просто загрузить его исходники или файл egg непосредственно из Python Package Index (PyPI). В этой статье мы попробуем использовать его на простом скрипте генератора конфигурационных файлов, а также опробуем его на программе wxPython из главы py2exe.\n# config_1.py import configobj def createConfig(configFile): \"\"\" Create the configuration file \"\"\" config = configobj.ConfigObj() inifile = configFile config.filename = inifile config['server'] = \"http://www.google.com\" config['username'] = \"mike\" config['password'] = \"dingbat\" config['update interval'] = 2 config.write() def getConfig(configFile): \"\"\" Open the config file and return a configobj \"\"\" return configobj.ConfigObj(configFile) def createConfig2(path): \"\"\" Create a config file \"\"\" config = configobj.ConfigObj() config.filename = path config[\"Sony\"] = {} config[\"Sony\"][\"product\"] = \"Sony PS3\" config[\"Sony\"][\"accessories\"] = ['controller', 'eye', 'memory stick'] config[\"Sony\"][\"retail price\"] = \"$400\" config.write() if __name__ == \"__main__\": createConfig2(\"sampleConfig2.ini\") В этом скрипте есть несколько функций, которые довольно бессмысленны, но мы оставим их для примера. Согласно документации bbfreeze, мы должны быть в состоянии создать двоичный файл со следующей строкой, введенной в командную строку:\nbb-freeze config_1.py Это предполагает, что в вашем пути есть C:\\Python27\\Scripts. Если у вас его нет, вам придется ввести полный путь (например, C:\\Python27\\Scripts\\bb-freeze config_1.py). Если вы запустите его, вы должны увидеть, как создается папка с именем dist. Вот как выглядела моя папка после запуска config_1.exe:\nВы заметите, что при запуске исполняемого файла он создает файл конфигурации sampleconfig2.ini. Вы можете увидеть предупреждение о том, что пакет pywin32 не установлен. Вы можете проигнорировать это предупреждение или загрузить и установить pywin32.\nТеперь мы готовы двигаться дальше и попытаться создать исполняемый файл из кода, использующего wxPython!\nПродвинутой расширенной конфигурации bbfreeze На странице PyPI для bbfreeze (которая также является его домашней страницей) очень мало документации. Однако там говорится, что предпочтительный способ использования bbfreeze - это небольшие скрипты. Мы попробуем создать двоичный файл с помощью примера wxPython, упомянутого ранее. Вот код wx:\nimport wx class DemoPanel(wx.Panel): \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" wx.Panel.__init__(self, parent) labels = [\"Name\", \"Address\", \"City\", \"State\", \"Zip\", \"Phone\", \"Email\", \"Notes\"] mainSizer = wx.BoxSizer(wx.VERTICAL) lbl = wx.StaticText(self, label=\"Please enter your information here:\") lbl.SetFont(wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD)) mainSizer.Add(lbl, 0, wx.ALL, 5) for lbl in labels: sizer = self.buildControls(lbl) mainSizer.Add(sizer, 1, wx.EXPAND) self.SetSizer(mainSizer) mainSizer.Layout() def buildControls(self, label): \"\"\" Put the widgets together \"\"\" sizer = wx.BoxSizer(wx.HORIZONTAL) size = (80,40) font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD) lbl = wx.StaticText(self, label=label, size=size) lbl.SetFont(font) sizer.Add(lbl, 0, wx.ALL|wx.CENTER, 5) if label != \"Notes\": txt = wx.TextCtrl(self, name=label) else: txt = wx.TextCtrl(self, style=wx.TE_MULTILINE, name=label) sizer.Add(txt, 1, wx.ALL, 5) return sizer class DemoFrame(wx.Frame): \"\"\" Frame that holds all other widgets \"\"\" def __init__(self): \"\"\"Constructor\"\"\" wx.Frame.__init__(self, None, wx.ID_ANY, \"Py2Exe Tutorial\", size=(600,400) ) panel = DemoPanel(self) self.Show() if __name__ == \"__main__\": app = wx.App(False) frame = DemoFrame() app.MainLoop() Теперь давайте создадим простой скрипт freezing!\n# bb_setup.py from bbfreeze import Freezer f = Freezer(distdir=\"bb-binary\") f.addScript(\"sampleApp.py\") f() Прежде всего, мы импортируем класс Freezer из пакета bbfreeze. Freezer принимает три аргумента: папку назначения, итерабельную переменную includes и итерабельную переменную excludes (т.е. кортеж или список). Чтобы посмотреть, насколько хорошо работает bbfreeze с настройками по умолчанию, мы опустим кортежи/списки include и excludes. Как только у вас есть объект Freezer, вы можете добавить свой сценарий(и), вызвав метод addScript имени объекта Freezer. Затем вам нужно просто вызвать объект (например, f() ).\nПримечание: Вы можете увидеть предупреждение о том, что bb_freeze не может найти “MSVCP90.dll” или что-то подобное. Если вы увидите такое сообщение, возможно, вам придется включить его явно или добавить в качестве зависимости при создании программы установки. О том, как создать программу установки, мы узнаем в одной из следующих глав.\nЧтобы запустить этот сценарий, нужно сделать примерно следующее:\npython bb_setup.py Когда я запустил этот скрипт, он создал папку с именем bb-binary, содержащую 19 файлов размером 17,2 МБ. Когда я запустил файл sampleApp.exe, он прекрасно запустился и был правильно оформлен, однако у него также был экран консоли. Нам придется немного отредактировать наш сценарий, чтобы исправить это:\n# bb_setup2.py from bbfreeze import Freezer includes = [] excludes = ['_gtkagg', '_tkagg', 'bsddb', 'curses', 'email', 'pywin.debugger', 'pywin.debugger.dbgcon', 'pywin.dialogs', 'tcl', 'Tkconstants', 'Tkinter'] bbFreeze_Class = Freezer('dist', includes=includes, excludes=excludes) bbFreeze_Class.addScript(\"sampleApp.py\", gui_only=True) bbFreeze_Class.use_compression = 0 bbFreeze_Class.include_py = True bbFreeze_Class() Если вы запустите его, то в итоге получите папку dist с примерно 19 файлами, но немного другого размера - 19,6 МБ. Обратите внимание, что мы добавили второй аргумент в метод addScript: gui_only=True. Благодаря этому раздражающая консоль исчезнет. Мы также установили сжатие на ноль (без сжатия) и включили интерпретатор Python. Включение сжатия только уменьшило результат до 17,2 МБ.\nПакет bbfreeze также работает с “рецептами” и включает несколько примеров, однако они не очень хорошо документированы. Не стесняйтесь изучить их самостоятельно в качестве упражнения.\nПодведение итогов Теперь вы должны знать основы использования bbfreeze для создания двоичных файлов из ваших программ. Я заметил, что когда я запускал bbfreeze на своей машине, он значительно медленнее создавал исполняемый файл wxPython по сравнению с py2exe. Это одна из тех вещей, с которыми вам придется экспериментировать, когда вы будете определять, какой инструмент использовать для создания двоичных файлов.\n","description":"Python 101","title":"41. bbfreeze","uri":"/ru/docs/python101/chapter41_bb_freeze/"},{"content":"Рабочий процесс с открытым исходным кодом Когда мы изучали основы GitHub, мы проходили процесс форка произвольного проекта и внесения изменений в наш локальный репозиторий. Здесь мы хотим сделать еще один шаг вперед и внести свой вклад в проект с открытым исходным кодом. Помните, что вклад не обязательно должен заключаться в исправлении ошибок, кодировании функций, это может быть и документация. Каждая мелочь помогает, и это также позволит вам поработать с некоторыми функциями git, которые мы рассмотрели.\nФорк проекта Первое, что нам нужно сделать, это найти проект, в который мы можем внести свой вклад. Я недавно выступал с презентациями в Kanister Project и хотел бы поделиться своими презентациями, которые теперь есть на YouTube, с основным readme.mdf-файлом проекта.\nПрежде всего, нам нужно форкнуть проект. Давайте проделаем этот процесс. Я собираюсь перейти по ссылке, указанной выше, и форкнуть репозиторий.\nТеперь у нас есть наша копия всего репозитория.\nДля справки в файле Readme.mdfile в списке оригинальных Presenations указаны только эти два, поэтому нам нужно исправить это в нашем процессе.\nКлонирование на локальную машину Теперь у нас есть собственный форк, который мы можем перенести на локальную машину и начать вносить правки в файлы. Используя кнопку code на нашем репозитории, мы можем получить URL, а затем использовать git clone url в каталоге, куда мы хотим поместить репозиторий.\nВносим изменения У нас есть локальный проект, поэтому мы можем открыть VSCode или IDE или текстовый редактор по вашему выбору, чтобы добавить свои изменения.\nФайл readme.mdfile написан на языке markdown, и поскольку я изменяю чужой проект, я собираюсь следовать существующему форматированию проекта для добавления нашего содержимого.\nТестируем свои изменения В качестве лучшей практики мы должны тестировать наши изменения, это совершенно логично, если бы это было изменение кода приложения, вы бы хотели убедиться, что приложение продолжает функционировать после изменения кода, но мы также должны убедиться, что документация отформатирована и выглядит правильно.\nВ VScode у нас есть возможность добавить множество плагинов, одним из которых является возможность предварительного просмотра страниц в формате markdown.\nВерните изменения в наш форкнутый репозиторий У нас нет аутентификации, чтобы отправить наши изменения непосредственно в репозиторий Kanister, поэтому мы должны пойти этим путем. Теперь, когда я доволен нашими изменениями, мы можем выполнить некоторые из этих хорошо известных команд git.\nТеперь мы возвращаемся в GitHub, чтобы еще раз проверить изменения и затем внести вклад в мастер-проект.\nТеперь мы можем вернуться в верхнюю часть нашего форкнутого репозитория для Kanister и увидеть, что мы на 1 коммит опережаем ветку kanisterio:master.\nДалее мы нажимаем на кнопку “Внести вклад”, выделенную выше. Мы видим опцию “Open Pull Request”.\nOpen a pull request На следующем изображении происходит довольно много всего: слева вверху вы видите, что мы находимся в оригинальном или основном репозитории. Затем вы можете увидеть, что мы сравниваем, а это оригинальный основной и наш форкнутый репозиторий. Затем у нас есть кнопка создания запроса на притяжение, к которой мы скоро вернёмся. У нас есть единственный коммит, но если бы изменений было больше, то здесь могло бы быть несколько коммитов. Затем у нас есть изменения, которые мы внесли в readme.mdfile.\nМы просмотрели вышеуказанные изменения и готовы создать pull request, нажав на зеленую кнопку.\nЗатем, в зависимости от того, как мейнтейнер проекта настроил функциональность Pull Request в своём репозитории, у вас может быть или не быть шаблона, который даст вам указания на то, что хочет видеть мейнтейнер.\nЗдесь вам снова нужно составить содержательное описание того, что вы сделали, четкое и краткое, но достаточно подробное. Вы можете видеть, что я сделал простой обзор изменений и отметил документацию.\nСоздайте запрос на исправление Теперь мы готовы к созданию запроса на исправление. После нажатия кнопки “Create Pull Request” в верхней части страницы вы получите краткое описание вашего запроса.\nПрокручивая страницу вниз, вы, вероятно, увидите, что происходит автоматизация, в данном случае нам требуется рецензия, и происходят некоторые проверки. Мы видим, что Travis CI находится в процессе и началась сборка, которая проверит наше обновление и убедится, что перед тем, как что-то будет слито, мы не сломаем что-то своими добавлениями.\nЕще одна вещь, которую следует отметить, это то, что красный цвет на снимке экрана выше, может выглядеть немного пугающе и выглядеть так, как будто вы совершили ошибки! Не волнуйтесь, вы ничего не нарушили, мой главный совет - этот процесс поможет вам и сопровождающим проекта. Если вы допустили ошибку, по крайней мере, по моему опыту, сопровождающий свяжется с вами и посоветует, что делать дальше.\nЭтот запрос на исправление теперь общедоступен для всех added Kanister presentation/resource #1237.\nЯ собираюсь опубликовать это до того, как слияние и запрос на исправление будут приняты, так что, возможно, мы сможем получить небольшой приз для тех, кто всё ещё следит за развитием событий и сможет добавить картинку к успешному PR?\nФоркните этот репозиторий на свой собственный аккаунт GitHub Добавьте свою картинку и, возможно, текст Внесите изменения в свой форкнутый репозиторий. Создайте PR, который я увижу и одобрю. Я придумаю какой-нибудь приз. На этом мы завершаем знакомство с Git и GitHub, далее мы погружаемся в контейнеры, что начинается с рассмотрения общей картины того, как, почему контейнеры, а также с рассмотрения виртуализации и того, как мы к ней пришли.\nРесурсы Learn GitLab in 3 Hours | GitLab Complete Tutorial For Beginners BitBucket Tutorials Playlist What is Version Control? Types of Version Control System Git Tutorial for Beginners Git for Professionals Tutorial Git and GitHub for Beginners - Crash Course Complete Git and GitHub Tutorial Git cheatsheet ","description":"","title":"41. Рабочий процесс с открытым исходным кодом","uri":"/ru/docs/90daysofdevops/day41/"},{"content":"В этой главе мы познакомимся с cx_Freeze, кроссплатформенным набором скриптов, предназначенных для freeze скриптов Python в исполняемые файлы, подобно py2exe, PyInstaller и т.д. Мы заморозим один консольный скрипт и один оконный (т.е. GUI) скрипт, используя примеры из предыдущей главы. Инструмент cx_Freeze - единственный инструмент создания двоичных файлов, который на данный момент может работать как с Python 2.x, так и с 3.x на различных операционных системах. В этой главе мы будем использовать его с Python 2.7 только потому, что хотим сравнить его с другими инструментами создания двоичных файлов.\nВы можете установить cx_Freeze с помощью одного из их инсталляторов для Windows, через предоставленные ими RPM для Linux, через исходный RPM или непосредственно из исходного кода. Вы также можете использовать pip для установки cx_Freeze.\nПримечание: Я тестировал на Windows 7, используя Python 2.7.3, wxPython 2.9.4.0 (classic) и cx_Freeze 4.3.2.\nНачало работы с cx_Freeze Как указано на сайте cx_Freeze, существует три способа использования этого скрипта. Первый - просто использовать прилагаемый скрипт cxfreeze; второй - создать установочный скрипт distutils (думаю о py2exe), который вы можете сохранить для дальнейшего использования; и третий - работать с внутренними компонентами cxfreeze. Мы сосредоточимся на первых двух способах использования cx_Freeze. Начнем с консольного скрипта:\n# config_1.py import configobj def createConfig(configFile): \"\"\" Create the configuration file \"\"\" config = configobj.ConfigObj() inifile = configFile config.filename = inifile config['server'] = \"http://www.google.com\" config['username'] = \"mike\" config['password'] = \"dingbat\" config['update interval'] = 2 config.write() def getConfig(configFile): \"\"\" Open the config file and return a configobj \"\"\" return configobj.ConfigObj(configFile) def createConfig2(path): \"\"\" Create a config file \"\"\" config = configobj.ConfigObj() config.filename = path config[\"Sony\"] = {} config[\"Sony\"][\"product\"] = \"Sony PS3\" config[\"Sony\"][\"accessories\"] = ['controller', 'eye', 'memory stick'] config[\"Sony\"][\"retail price\"] = \"$400\" config.write() if __name__ == \"__main__\": createConfig2(\"sampleConfig2.ini\") Все, что делает этот скрипт, это создает действительно простой конфигурационный файл, используя модуль configobj Майкла Фоорда. Вы можете настроить его и на чтение конфигурации, но для данного примера мы это пропустим. Давайте узнаем, как собрать бинарник с помощью cx_Freeze! Согласно документации, для этого достаточно ввести в командную строку следующую строку (при условии, что вы находитесь в правильной директории):\ncxfreeze config_1.py --target-dir dirName Это предполагает, что в вашем пути есть C:\\PythonXX\\Scripts. Если это не так, вам придется либо исправить это, либо ввести полный путь. В любом случае, если скрипт cxfreeze запущен правильно, у вас должна быть папка со следующим содержимым:\nКак вы можете видеть, общий размер файла должен составлять около 5 мегабайт. Это было довольно просто. Он даже подхватил модуль configobj без нашей просьбы. Есть 18 аргументов командной строки, которые вы можете передать cx_Freeze, чтобы управлять его действиями. Они варьируются от того, какие модули включать или исключать, оптимизировать, сжимать, включать zip-файл, манипулировать путями и многое другое.\nТеперь давайте попробуем кое-что более продвинутое.\nПродвинутый cx_Freeze - использование файла setup.py Прежде всего, нам нужен скрипт, который мы будем использовать. Мы будем использовать пример формы wxPython из предыдущих глав.\nimport wx class DemoPanel(wx.Panel): \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" wx.Panel.__init__(self, parent) labels = [\"Name\", \"Address\", \"City\", \"State\", \"Zip\", \"Phone\", \"Email\", \"Notes\"] mainSizer = wx.BoxSizer(wx.VERTICAL) lbl = wx.StaticText(self, label=\"Please enter your information here:\") lbl.SetFont(wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD)) mainSizer.Add(lbl, 0, wx.ALL, 5) for lbl in labels: sizer = self.buildControls(lbl) mainSizer.Add(sizer, 1, wx.EXPAND) self.SetSizer(mainSizer) mainSizer.Layout() def buildControls(self, label): \"\"\" Put the widgets together \"\"\" sizer = wx.BoxSizer(wx.HORIZONTAL) size = (80,40) font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD) lbl = wx.StaticText(self, label=label, size=size) lbl.SetFont(font) sizer.Add(lbl, 0, wx.ALL|wx.CENTER, 5) if label != \"Notes\": txt = wx.TextCtrl(self, name=label) else: txt = wx.TextCtrl(self, style=wx.TE_MULTILINE, name=label) sizer.Add(txt, 1, wx.ALL, 5) return sizer class DemoFrame(wx.Frame): \"\"\" Frame that holds all other widgets \"\"\" def __init__(self): \"\"\"Constructor\"\"\" wx.Frame.__init__(self, None, wx.ID_ANY, \"Py2Exe Tutorial\", size=(600,400) ) panel = DemoPanel(self) self.Show() if __name__ == \"__main__\": app = wx.App(False) frame = DemoFrame() app.MainLoop() Теперь давайте создадим файл setup.py в стиле cx_Freeze:\n# setup.py from cx_Freeze import setup, Executable setup( name = \"wxSampleApp\", version = \"0.1\", description = \"An example wxPython script\", executables = [Executable(\"sampleApp.py\")] ) Как вы можете видеть, это довольно просто. Мы импортируем пару классов из cx_Freeze и передаем в них некоторые параметры. В данном случае мы даем классу setup имя, версию, описание и класс Executable. Класс Executable также получает один параметр - имя скрипта, который он будет использовать для создания бинарного файла.\nВ качестве альтернативы вы можете создать простой setup.py с помощью команды quickstart cx_Freeze (если она находится в пути вашей системы) в той же папке, что и ваш код:\ncxfreeze-quickstart\nЧтобы заставить setup.py собрать двоичный файл, вам нужно сделать следующее в командной строке:\npython setup.py build После запуска у вас должны появиться следующие папки: buildexe.win32-2.7. Внутри последней папки у меня оказалось 15 файлов общим размером 16,6 МБ. Когда вы запустите файл sampleApp.exe, вы заметите, что мы что-то испортили. В дополнение к нашему графическому интерфейсу загружается окно консоли! Чтобы исправить это, нам нужно немного изменить наш установочный файл. Взгляните на наш новый файл:\nfrom cx_Freeze import setup, Executable exe = Executable( script=\"sampleApp.py\", base=\"Win32GUI\", ) setup( name = \"wxSampleApp\", version = \"0.1\", description = \"An example wxPython script\", executables = [exe] ) Во-первых, мы отделили класс Executable от класса setup и присвоили класс Executable переменной. Мы также добавили второй параметр к классу Executable, который является ключевым. Этот параметр называется base. Установив base=“Win32GUI”, мы можем подавить консольное окно. В документации на сайте cx_Freeze показано множество других параметров, которые принимает класс Executable.\nПодведение итогов Теперь вы должны знать, как создавать двоичные файлы с помощью cx_Freeze. Это довольно просто сделать, и в моем тестировании он работал намного быстрее, чем bbfreeze. Если у вас есть необходимость создавать двоичные файлы для Python 2.x и 3.x на всех основных платформах, то этот инструмент для вас!\n","description":"Python 101","title":"42. cx_Freeze","uri":"/ru/docs/python101/chapter42_cx_freeze/"},{"content":"Контейнеры Этот раздел будет посвящен контейнерам. Будем рассматривать Docker, вникая в некоторые ключевые области, чтобы понять больше о контейнерах.\nЯ также попытаюсь провести практические занятия по созданию контейнера, который мы сможем использовать не только в этом разделе, но и в последующих.\nПочему другой способ запуска приложений? Первое, на что мы должны обратить внимание, - зачем нам нужен другой способ запуска программ или приложений? Просто выбор велик, мы можем запускать наши приложения в разных формах, мы можем видеть приложения, развернутые на физическом оборудовании с операционной системой и одним приложением, мы можем видеть виртуальную машину или облачные IaaS экземпляры, запускающие наше приложение, которое затем интегрируется в базу данных снова в виртуальной машине или как PaaS предложение в публичном облаке. Или мы можем увидеть наши приложения, работающие в контейнерах.\nНи один из перечисленных вариантов не является неправильным или правильным, но у каждого из них есть свои причины для существования, и я также твердо уверен, что ни один из них не исчезнет. Я видел много материалов, в которых обсуждаются контейнеры и виртуальные машины, и на самом деле здесь не должно быть спора, поскольку это больше похоже на спор между яблоками и грушами, где они оба являются фруктами (способы запуска наших приложений), но это не одно и то же.\nЯ бы также сказал, что если вы начинаете и разрабатываете приложение, вам следует склониться к контейнерам просто потому, что мы рассмотрим некоторые из этих областей позже, но речь идет об эффективности, скорости и размере. Но за это тоже приходится платить, если вы не имеете представления о контейнерах, то вам придется учиться, чтобы понять, зачем это нужно, и вжиться в этот образ мышления. Если вы разрабатывали свои приложения особым образом или вы не работаете в новой среде, то у вас может быть больше болевых точек, с которыми нужно справиться, прежде чем рассматривать контейнеры.\nУ нас есть много различных вариантов, когда нужно загрузить ту или иную часть программного обеспечения, есть множество различных операционных систем, которые мы можем использовать. И конкретные инструкции о том, что нам нужно сделать, чтобы установить наши приложения.\nВ последнее время я все чаще замечаю, что приложения, для которых раньше требовалась полноценная серверная ОС, виртуальная машина, физический или облачный экземпляр, теперь выпускают версии своего программного обеспечения на основе контейнеров. Я нахожу это интересным, поскольку это открывает мир контейнеров и Kubernetes для всех, а не только для разработчиков приложений.\nКак вы уже, наверное, поняли, я не собираюсь утверждать, что ответ - это контейнеры, в чем вопрос! Но я хотел бы обсудить, что это еще один вариант, о котором мы должны знать при развертывании наших приложений.\nУ нас уже давно существует контейнерная технология, так почему же именно сейчас, за последние 10 лет, она стала популярной, я бы сказал, даже более популярной в последние 5 лет. У нас были контейнеры в течение десятилетий. Все сводится к вызову контейнеров или, лучше сказать, образов, тому, как мы распространяем наше программное обеспечение, потому что если у нас будет только контейнерная технология, то у нас останется много тех же проблем, которые были с управлением программным обеспечением.\nЕсли мы подумаем о Docker как об инструменте, то причина его взлета заключается в экосистеме образов, которые легко найти и использовать. Их легко установить на свои системы и запустить в работу. Важной частью этого является согласованность во всем пространстве, во всех этих различных проблемах, с которыми мы сталкиваемся при работе с программным обеспечением. Неважно, MongoDB это или nodeJS, процесс запуска любого из них будет одинаковым. Процесс остановки любого из них одинаков. Все эти проблемы будут существовать, но самое приятное, что когда мы объединяем хорошие технологии контейнеров и образов, у нас появляется единый набор инструментов для решения всех этих различных проблем. Некоторые из этих проблем перечислены ниже:\nСначала нам нужно найти программное обеспечение в Интернете. Затем мы должны загрузить это программное обеспечение. Доверяем ли мы источнику? Нужна ли нам лицензия? Какая лицензия? Совместима ли она с различными платформами? Что представляет собой пакет? Бинарный? Исполняемый? Менеджер пакетов? Как сконфигурировать программу? Зависимости? Были ли они учтены при загрузке или они нам тоже нужны? Зависимости зависимостей? Как нам запустить приложение? Как мы остановим приложение? Будет ли оно автозапускаться? Запускаться при загрузке? Конфликты ресурсов? Конфликтующие библиотеки? Конфликты портов Безопасность программного обеспечения? Обновления программного обеспечения? Как удалить программное обеспечение? Мы можем разделить вышеперечисленное на 3 области сложности программного обеспечения, с которыми помогают справиться контейнеры и образы.\nРаспространение Установка Эксплуатация Найти Установить Запустить Скачать Конфигурация Безопасность Лицензия Деинсталляция Порты Пакет Зависимости Конфликты с ресурсами Доверие Платформа Автоперезагрузка Поиск Библиотеки Обновления Контейнеры и образы помогут нам устранить некоторые из этих проблем, с которыми мы сталкиваемся при работе с другими программами и приложениями.\nНа высоком уровне мы можем перенести установку и эксплуатацию в один список: образы помогут нам с точки зрения распространения, а контейнеры помогут с установкой и эксплуатацией.\nХорошо, возможно, звучит здорово и захватывающе, но нам все еще нужно понять, что такое контейнер, и теперь я упомянул образы, поэтому давайте рассмотрим эти области далее.\nЕще одна вещь, которую вы могли часто видеть, когда мы говорили о контейнерах для разработки программного обеспечения, - это аналогия с морскими контейнерами: морские контейнеры используются для перевозки различных товаров по морю с помощью больших судов.\nКакое отношение это имеет к нашей теме о контейнерах? Подумайте о коде, который пишут разработчики программного обеспечения, как мы можем перенести этот код с одной машины на другую?\nЕсли мы подумаем о том, что мы уже говорили о распространении программного обеспечения, установке и операциях, то теперь мы начнем выстраивать это в визуальную среду. У нас есть аппаратное обеспечение и операционная система, на которой вы будете запускать несколько приложений. Например, nodejs имеет определенные зависимости и нуждается в определенных библиотеках. Если вы хотите установить MySQL, то ему нужны необходимые библиотеки и зависимости. Каждое программное приложение будет иметь свою библиотеку и зависимость. Нам может крупно повезти, и у нас не будет конфликтов между приложениями, где определенные библиотеки и зависимости сталкиваются, вызывая проблемы, но чем больше приложений, тем больше вероятность или риск конфликтов. Однако речь не идет об одном развертывании, когда все исправления ваших программных приложений будут обновлены, и тогда мы также можем столкнуться с этими конфликтами.\nКонтейнеры могут помочь решить эту проблему. Контейнеры помогают создать ваше приложение, отправить приложение, развернуть и масштабировать эти приложения с легкостью самостоятельно. Давайте рассмотрим архитектуру, у вас есть аппаратное обеспечение и операционная система, а поверх них - контейнерный движок, такой как docker, который мы рассмотрим позже. Программное обеспечение контейнерного движка помогает создавать контейнеры, которые упаковывают библиотеки и зависимости вместе с ними, так что вы можете легко перемещать этот контейнер с одной машины на другую, не беспокоясь о библиотеках и зависимостях, поскольку они поставляются как часть пакета, который является ничем иным, как контейнером, так что вы можете иметь различные контейнеры, которые можно перемещать между системами, не беспокоясь о базовых зависимостях, которые необходимы приложению. потому что все, что нужно приложению для работы, упаковано как контейнер, который можно перемещать.\nПреимущества контейнеров Контейнеры помогают упаковать все зависимости внутри контейнера и изолировать его.\nКонтейнерами легко управлять\nВозможность перехода от одной системы к другой.\nКонтейнеры помогают упаковать программное обеспечение, и вы можете легко отправить его без каких-либо дублирующих усилий.\nКонтейнеры легко масштабируются.\nИспользуя контейнеры, вы можете масштабировать независимые контейнеры и использовать балансировщик нагрузки или сервис, который поможет разделить трафик, и вы сможете масштабировать приложения горизонтально. Контейнеры обеспечивают большую гибкость и облегчают управление приложениями.\nЧто такое контейнер? Когда мы запускаем приложения на нашем компьютере, это может быть веб-браузер или VScode, который вы используете для чтения этого сообщения. Это приложение работает как процесс или то, что известно как процесс. На наших ноутбуках или системах мы обычно запускаем несколько приложений или, как мы сказали, процессов. Когда мы открываем новое приложение или нажимаем на значок приложения, это приложение, которое мы хотим запустить, иногда это приложение может быть службой, которую мы просто хотим запустить в фоновом режиме, наша операционная система полна служб, которые работают в фоновом режиме, предоставляя вам возможность пользоваться системой.\nЗначок приложения представляет собой ссылку на исполняемый файл в файловой системе, после чего операционная система загружает этот файл в память. Интересно, что этот исполняемый файл иногда называют образом, когда речь идет о процессе.\nКонтейнеры - это процессы, а контейнер - это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, чтобы приложение быстро и надежно работало в разных вычислительных средах.\nКонтейнерное программное обеспечение всегда будет работать одинаково, независимо от инфраструктуры. Контейнеры изолируют программное обеспечение от его окружения и обеспечивают его единообразную работу, несмотря на различия, например, между разработкой и постановкой на хранение.\nЯ упоминал образы в последнем разделе, когда речь шла о том, как и почему контейнеры и образы вместе сделали контейнеры популярными в нашей экосистеме.\nЧто такое образ? Образ контейнера - это легкий, автономный, исполняемый пакет программного обеспечения, который включает все необходимое для запуска приложения: код, время выполнения, системные инструменты, системные библиотеки и настройки. Образы контейнеров становятся контейнерами во время выполнения.\nЧто такое контейнер? Когда мы запускаем приложения на нашем компьютере, это может быть веб-браузер или VScode, который вы используете для чтения этого сообщения. Это приложение работает как процесс или то, что известно как процесс. На наших ноутбуках или системах мы склонны запускать несколько приложений или, как мы сказали, процессов. Когда мы открываем новое приложение или нажимаем на значок приложения, это приложение, которое мы хотели бы запустить, иногда это приложение может быть службой, которую мы просто хотим запустить в фоновом режиме, наша операционная система полна служб, которые работают в фон, предоставляющий вам пользовательский опыт, который вы получаете с вашей системой.\nЭтот значок приложения представляет собой ссылку на исполняемый файл где-то в вашей файловой системе, затем операционная система загружает этот исполняемый файл в память. Интересно, что этот исполняемый файл иногда называют образом, когда мы говорим о процессе.\nКонтейнеры — это процессы. Контейнер — это стандартная единица программного обеспечения, которая упаковывает код и все его зависимости, чтобы приложение быстро и надежно запускалось из одной вычислительной среды в другую.\nКонтейнерное программное обеспечение всегда будет работать одинаково, независимо от инфраструктуры. Контейнеры изолируют программное обеспечение от его среды и обеспечивают его единую работу, несмотря на различия, например, между разработкой и промежуточной стадией.\nЯ упомянул изображения в предыдущем разделе, когда речь шла о том, как и почему сочетание контейнеров и изображений сделало контейнеры популярными в нашей экосистеме.\nСсылки TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers ","description":"Контенеры Docker для запуска приложений","title":"42. Контейнеры","uri":"/ru/docs/90daysofdevops/day42/"},{"content":"PyInstaller - это последний инструмент, который мы рассмотрим для создания двоичных файлов. Он поддерживает Python 2.4 - 2.7. Мы продолжим использовать наши простые консольные и wxPython GUI скрипты для тестирования. PyInstaller должен работать на Windows, Linux, Mac, Solaris и AIX. Поддержка Solaris и AIX является экспериментальной. PyInstaller поддерживает подпись кода (Windows), eggs, скрытый импорт, один исполняемый файл, один каталог и многое другое!\nНачало работы с PyInstaller Чтобы установить PyInstaller, вы можете скачать исходный код в tarball или zip архиве, распаковать его и запустить его файл setup.py:\npython setup.py install Вы также можете установить PyInstaller с помощью pip. Мы начнем с нашего маленького кусочка кода создания конфигурации:\n# config_1.py import configobj def createConfig(configFile): \"\"\" Create the configuration file \"\"\" config = configobj.ConfigObj() inifile = configFile config.filename = inifile config['server'] = \"http://www.google.com\" config['username'] = \"mike\" config['password'] = \"dingbat\" config['update interval'] = 2 config.write() def getConfig(configFile): \"\"\" Open the config file and return a configobj \"\"\" return configobj.ConfigObj(configFile) def createConfig2(path): \"\"\" Create a config file \"\"\" config = configobj.ConfigObj() config.filename = path config[\"Sony\"] = {} config[\"Sony\"][\"product\"] = \"Sony PS3\" config[\"Sony\"][\"accessories\"] = ['controller', 'eye', 'memory stick'] config[\"Sony\"][\"retail price\"] = \"$400\" config.write() if __name__ == \"__main__\": createConfig2(\"sampleConfig2.ini\") Теперь давайте попробуем создать исполняемый файл! Вам должно быть достаточно сделать это, чтобы PyInstaller заработал:\npyinstaller config_1.py Когда я запустил это, я получил следующую ошибку:\nError: PyInstaller for Python 2.6+ on Windows needs pywin32. Please install from http://sourceforge.net/projects/pywin32/ Чтобы использовать PyInstaller в Windows, вам нужно сначала установить PyWin32! После установки PyWin32 попробуйте повторно запустить эту команду. Вы должны увидеть много вывода на экран, а также две папки рядом с вашим скриптом: build и dist. Если вы перейдете в папку *dist, а затем в ее папку config_1, вы должны увидеть что-то вроде этого:\nКогда я запустил исполняемый файл, он создал файл конфигурации, как и должен был. Вы заметите, что PyInstaller смог захватить configobj без вашего указания.\nPyInstaller и wxPython Теперь давайте попробуем создать двоичный файл из простого скрипта wxPython. Вот код wxPython, который мы использовали в предыдущих главах:\nimport wx class DemoPanel(wx.Panel): \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" wx.Panel.__init__(self, parent) labels = [\"Name\", \"Address\", \"City\", \"State\", \"Zip\", \"Phone\", \"Email\", \"Notes\"] mainSizer = wx.BoxSizer(wx.VERTICAL) lbl = wx.StaticText(self, label=\"Please enter your information here:\") lbl.SetFont(wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD)) mainSizer.Add(lbl, 0, wx.ALL, 5) for lbl in labels: sizer = self.buildControls(lbl) mainSizer.Add(sizer, 1, wx.EXPAND) self.SetSizer(mainSizer) mainSizer.Layout() def buildControls(self, label): \"\"\" Put the widgets together \"\"\" sizer = wx.BoxSizer(wx.HORIZONTAL) size = (80,40) font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD) lbl = wx.StaticText(self, label=label, size=size) lbl.SetFont(font) sizer.Add(lbl, 0, wx.ALL|wx.CENTER, 5) if label != \"Notes\": txt = wx.TextCtrl(self, name=label) else: txt = wx.TextCtrl(self, style=wx.TE_MULTILINE, name=label) sizer.Add(txt, 1, wx.ALL, 5) return sizer class DemoFrame(wx.Frame): \"\"\" Frame that holds all other widgets \"\"\" def __init__(self): \"\"\"Constructor\"\"\" wx.Frame.__init__(self, None, wx.ID_ANY, \"Py2Exe Tutorial\", size=(600,400) ) panel = DemoPanel(self) self.Show() if __name__ == \"__main__\": app = wx.App(False) frame = DemoFrame() app.MainLoop() Если вы выполните команду pyinstaller против этого сценария, вы увидите, что на экран будет выводиться все больше данных. Будет создано 23 файла общим размером 19,4 МБ. Вы также заметите, что когда вы запускаете sampleApp.exe, он показывает консольное окно в дополнение к вашему графическому интерфейсу, а это не то, что мы хотим. Самый простой способ исправить это - вызвать PyInstaller с командой -w, которая говорит PyInstaller подавить консольное окно:\npyinstaller -w sampleApp.py Пакет PyInstaller имеет множество опций командной строки, которые вы можете использовать, чтобы изменить способ обработки PyInstaller вашей программы. Каждый раз, когда вы запускаете PyInstaller, он создает файл spec, который он использует для обработки вашей программы. Если вы хотите сохранить копию файла спецификации, чтобы лучше понять, что делает PyInstaller, вы можете сделать это с помощью следующей команды:\npyi-makespec sampleApp.py Вы можете передать pyi-makespec те же команды, что и PyInstaller, который изменит спецификацию соответствующим образом. Вот содержимое спецификации, созданной с помощью предыдущей команды:\n# -*- mode: python -*- a = Analysis(['sampleApp.py'], pathex=['c:\\\\py101\\\\wxpy'], hiddenimports=[], hookspath=None, runtime_hooks=None) pyz = PYZ(a.pure) exe = EXE(pyz, a.scripts, exclude_binaries=True, name='sampleApp.exe', debug=False, strip=None, upx=True, console=False ) coll = COLLECT(exe, a.binaries, a.zipfiles, a.datas, strip=None, upx=True, name='sampleApp') В ранних версиях PyInstaller вы должны были создать файл спецификации и редактировать его напрямую. Теперь, если вам не нужно что-то действительно особенное, вы можете сгенерировать нужную спецификацию, просто используя флаги. Обязательно прочитайте документацию для получения полной информации, так как флагов много и их описание выходит за рамки этой главы.\nПодведение итогов На этом наш краткий экскурс по PyInstaller закончен. Я надеюсь, что вы нашли это полезным в ваших начинаниях по созданию бинарных файлов Python. Проект PyInstaller довольно хорошо задокументирован и стоит того, чтобы потратить на него свое время.\n","description":"Python 101","title":"43. PyInstaller","uri":"/ru/docs/python101/chapter43_pyinstaller/"},{"content":"Что такое Docker и его установка В предыдущей статье я хотя бы раз упомянул Docker, и это потому, что Docker действительно является новатором в создании популярности контейнеров, несмотря на то, что они существуют уже очень давно.\nЗдесь мы будем использовать и объяснять docker, но мы также должны упомянуть [Open Container Initiative (OCI)] (https://www.opencontainers.org/), которая является организацией по отраслевым стандартам, поощряющей инновации и избегающей опасности блокировки поставщиков. Благодаря OCI у нас есть выбор при выборе инструментария для контейнеров, включая Docker, CRI-O, Podman, LXC и другие.\nDocker - это программная среда для создания, запуска и управления контейнерами. Термин “docker” может относиться как к инструментам (командам и демону), так и к формату файлов Dockerfile.\nМы будем использовать Docker Personal, который является бесплатным (для образования и обучения). Он включает в себя все самое необходимое, что нам нужно для получения хорошего фундамента знаний о контейнерах и инструментах.\nВозможно, стоит разделить некоторые инструменты “docker”, которые мы будем использовать и для чего они нужны. Термин docker может относиться к проекту docker в целом, который является платформой для разработчиков и администраторов для разработки, доставки и запуска приложений. Также это может быть ссылка на процесс docker daeemon, запущенный на хосте, который управляет образами и контейнерами и называется Docker Engine.\nDocker Engine Docker Engine - это технология контейнеризации с открытым исходным кодом для создания и контейнеризации приложений. Docker Engine действует как клиент-серверное приложение:\nСервер с долго работающим процессом-демоном dockerd. API, определяющие интерфейсы, которые программы могут использовать для общения и обучения демона Docker. Клиент docker с интерфейсом командной строки (CLI). Вышеизложенное было взято из официальной документации Docker и конкретного Docker Engine Overview\nDocker Desktop У нас есть рабочий стол docker для систем Windows и macOS. Простая в установке, легковесная среда разработки docker. Нативное приложение для ОС, использующее возможности виртуализации на хостовой операционной системе.\nЭто лучшее решение, если вы хотите создавать, отлаживать, тестировать, упаковывать и отправлять Docker-приложения на Windows или macOS.\nНа Windows мы также можем воспользоваться преимуществами WSL2 и Microsoft Hyper-V. Мы рассмотрим некоторые преимущества WSL2 по ходу дела.\nБлагодаря интеграции с возможностями гипервизора на хостовой операционной системе docker предоставляет возможность запускать ваши контейнеры с операционными системами Linux.\nDocker Compose Docker compose - это инструмент, позволяющий запускать более сложные приложения в нескольких контейнерах. Преимуществом является возможность использования одного файла и команды для запуска приложения.\nDocker Hub Централизованный ресурс для работы с Docker и его компонентами. Чаще всего он известен как реестр для размещения образов Docker. Но здесь есть множество дополнительных сервисов, которые можно использовать для автоматизации или интеграции в GitHub, а также для сканирования безопасности.\nDockerfile Dockerfile - это текстовый файл, содержащий команды, которые обычно выполняются вручную для создания образа docker. Docker может собирать образы автоматически, читая инструкции, которые содержатся в нашем dockerfile.\nУстановка Docker Desktop Документация docker documenation просто потрясающая, и если вы только начинаете в нее погружаться, то вам стоит ее просмотреть и прочитать. Мы будем использовать Docker Desktop на Windows с WSL2. Я уже выполнил установку на своей машине, которую мы используем здесь.\nОбратите внимание перед установкой на системные требования, Install Docker Desktop on Windows, если вы используете macOS, включая архитектуру процессора на базе M1, вы также можете взглянуть на Install Docker Desktop on macOS.\nЯ проведу установку Docker Desktop для Windows на другой машине Windows и запишу процесс ниже.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started ","description":"","title":"43. Установка Docker","uri":"/ru/docs/90daysofdevops/day43/"},{"content":"В этой главе мы проведем вас через процесс создания исполняемого файла и его последующей упаковки в программу установки. Для создания исполняемого файла мы будем использовать очень аккуратный пользовательский интерфейс GUI2Exe, написанный Андреа Гаваной. Он основан на wxPython, поэтому для его использования вам потребуется его установить. GUI2Exe поддерживает py2exe, bbfreeze, cx_Freeze, PyInstaller и py2app. После создания папки dist мы используем Inno Setup для создания нашего инсталлятора.\nМы снова будем использовать следующий код:\n# sampleApp.py import wx class DemoPanel(wx.Panel): \"\"\"\"\"\" def __init__(self, parent): \"\"\"Constructor\"\"\" wx.Panel.__init__(self, parent) labels = [\"Name\", \"Address\", \"City\", \"State\", \"Zip\", \"Phone\", \"Email\", \"Notes\"] mainSizer = wx.BoxSizer(wx.VERTICAL) lbl = wx.StaticText(self, label=\"Please enter your information here:\") lbl.SetFont(wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD)) mainSizer.Add(lbl, 0, wx.ALL, 5) for lbl in labels: sizer = self.buildControls(lbl) mainSizer.Add(sizer, 1, wx.EXPAND) self.SetSizer(mainSizer) mainSizer.Layout() def buildControls(self, label): \"\"\" Put the widgets together \"\"\" sizer = wx.BoxSizer(wx.HORIZONTAL) size = (80,40) font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.BOLD) lbl = wx.StaticText(self, label=label, size=size) lbl.SetFont(font) sizer.Add(lbl, 0, wx.ALL|wx.CENTER, 5) if label != \"Notes\": txt = wx.TextCtrl(self, name=label) else: txt = wx.TextCtrl(self, style=wx.TE_MULTILINE, name=label) sizer.Add(txt, 1, wx.ALL, 5) return sizer class DemoFrame(wx.Frame): \"\"\" Frame that holds all other widgets \"\"\" def __init__(self): \"\"\"Constructor\"\"\" wx.Frame.__init__(self, None, wx.ID_ANY, \"Py2Exe Tutorial\", size=(600,400) ) panel = DemoPanel(self) self.Show() if __name__ == \"__main__\": app = wx.App(False) frame = DemoFrame() app.MainLoop() Давайте начнем!\nНачало работы с GUI2Exe Чтобы использовать GUI2Exe, нужно просто зайти на его сайт (http://code.google.com/p/gui2exe/) и скачать релиз. Затем распаковать его и запустить скрипт, который называется GUI2Exe.py. Проект GUI2Exe основан на wxPython, поэтому убедитесь, что он у вас тоже установлен. Я успешно запустил свой проект с wxPython 2.9. Вот как его можно вызвать:\npython GUI2Exe.py При успешном выполнении вы должны увидеть экран, похожий на этот:\nТеперь перейдите в меню Файл -\u003e Новый проект и дайте проекту имя. В данном случае я назвал проект wxForm. Если вы хотите, вы можете добавить вымышленное название компании, авторские права и дать ему название программы. Не забудьте также найти ваш основной Python-скрипт (т.е. sampleApp.py). Согласно сайту Андреа, вы должны установить значение Optimize на 2, Compressed на 2 и Bundled Files на 1. В большинстве случаев это работает, но у меня было несколько ошибок, которые, похоже, возникли из-за установки последнего значения на 1. На самом деле, по словам одного из моих знакомых из списка рассылки py2exe, опция bundle должна быть установлена на 3, чтобы минимизировать ошибки. Приятно, что при установке bundle в “1” получается всего один файл, но поскольку я собираюсь свернуть его с Inno, я собираюсь использовать вариант 3, чтобы убедиться, что моя программа работает хорошо.\nПосле того, как все будет сделано так, как вы хотите, нажмите кнопку Compile в правом нижнем углу. Это создаст все файлы, которые вы хотите распространять, в папке dist, если вы не изменили название, установив dist checkbox и отредактировав последующее текстовое поле. После завершения компиляции GUI2Exe спросит вас, хотите ли вы протестировать ваш исполняемый файл. Нажимайте “Yes”. Если вы получите какие-либо ошибки о недостающих модулях, вы можете добавить их в раздел Python Modules или Python Packages в зависимости от ситуации. В данном примере такой проблемы возникнуть не должно.\nТеперь мы готовы к изучению создания программы установки!\nДавайте создадим программу установки! Теперь, когда у нас есть исполняемый файл и куча зависимостей, как нам сделать программу установки? В этой главе мы будем использовать Inno Setup, но вы также можете использовать NSIS или фирменную программу установки Microsoft. Вам нужно будет перейти на их сайт (http://www.jrsoftware.org/isdl.php), скачать программу и установить ее. Затем запустите программу. Вы должны увидеть главную программу со следующим диалоговым окном поверх нее:\nВыберите опцию Create a new script using the Script Wizard и нажмите кнопку OK. Нажмите кнопку Next, и вы должны увидеть что-то вроде этого:\nЗаполните его, как вам нравится, и нажмите кнопку Next (я назвал свой скрипт wxForm). На следующем экране вы можете выбрать место установки приложения по умолчанию. По умолчанию это *Program Files(), что вполне подходит. Нажмите кнопку Next. Теперь вы должны увидеть следующее окно:\nПерейдите к созданному исполняемому файлу, чтобы добавить его. Затем нажмите кнопку **Add file(s)… **, чтобы добавить остальные. Вы можете выбрать все файлы, кроме exe, и нажать OK. Вот как получилось у меня:\nТеперь вы готовы нажать кнопку Next. Убедитесь, что папка меню Пуск имеет правильное имя (в данном случае wxForm) и продолжайте. Вы можете проигнорировать следующие два экрана или поэкспериментировать с ними, если хотите. Однако я не использую лицензию и не помещаю информационные файлы для отображения пользователю. Последний экран перед завершением работы позволяет выбрать каталог, в который будет помещен вывод. Я оставил это поле пустым, так как по умолчанию оно указывает на место расположения исполняемого файла, что вполне подходит для данного примера. Нажмите кнопку Next, Next и Finish. Будет создан полноценный файл .iss, который Inno Setup использует для превращения вашего приложения в программу установки. Он спросит вас, хотите ли вы продолжить компиляцию скрипта сейчас. Сделайте это. Затем он спросит, хотите ли вы сохранить сценарий в формате .iss. Это хорошая идея, поэтому сделайте и это. Надеюсь, вы не получили никаких ошибок и можете опробовать новую программу установки.\nЕсли вам интересно узнать о языке сценариев Inno, не стесняйтесь читать документацию Inno. Вы можете сделать с его помощью довольно много. Если вы случайно внесли изменения в сценарий сборки, вы можете пересобрать программу установки, перейдя в меню build и выбрав пункт меню compile.\nПодведение итогов Теперь вы знаете, как создать настоящий, живой инсталлятор, который можно использовать для установки вашего приложения и любых файлов, необходимых для его работы. Это особенно удобно, когда у вас есть множество пользовательских значков для панелей инструментов или база данных по умолчанию, файл конфигурации и т.д., которые нужно распространять вместе с приложением. Вернитесь и попробуйте создать программу установки снова, но выберите другие варианты, чтобы посмотреть, что еще можно сделать. Экспериментирование - отличный способ обучения. Только убедитесь, что у вас всегда есть резервная копия на случай, если что-то пойдет не так!\n","description":"Python 101","title":"44. Создание программы установки","uri":"/ru/docs/python101/chapter44_creating_an_installer/"},{"content":"Образы Docker и практическая работа с Docker Desktop Теперь у нас в системе установлен Docker Desktop. (Если вы используете Linux, у вас все еще есть опции, но нет графического интерфейса, но docker, очевидно, работает на Linux)Install Docker Engine on Ubuntu (Другие дистрибутивы также доступны).\nВ этом посте мы собираемся начать с развертывания некоторых образов в нашей среде. Напомним, что такое образ Docker - образ Docker - это файл, используемый для выполнения кода в контейнере Docker. Образы Docker действуют как набор инструкций для создания контейнера Docker, как шаблон. Образы Docker также служат отправной точкой при использовании Docker.\nСейчас самое время пойти и создать свой аккаунт на DockerHub\nDockerHub - это централизованный ресурс для работы с Docker и его компонентами. Наиболее известен как реестр для размещения образов докеров. Но здесь есть множество дополнительных сервисов, которые можно использовать для автоматизации или интеграции в GitHub, а также для сканирования безопасности.\nЕсли вы прокрутите вниз после входа в систему, вы увидите список образов контейнеров, вы можете увидеть образы баз данных для mySQL, hello-world и т.д. и т.п. Рассматривайте их как отличные базовые образы, или вам может понадобиться просто образ базы данных, и вам лучше всего использовать официальный образ, что означает, что вам не нужно создавать свой собственный.\nМы можем углубиться в просмотр доступных изображений и осуществлять поиск по категориям, операционным системам и архитектурам. Единственное, что я выделил ниже, это Office Image, это должно дать вам уверенность в происхождении этого образа контейнера.\nМы также можем искать конкретное изображение, например, wordpress может быть хорошим базовым изображением, которое нам нужно, мы можем сделать это в верхней части и найти все изображения контейнеров, связанные с wordpress. Ниже обратите внимание, что у нас также есть проверенный издатель.\nОфициальные образы - Официальные образы Docker - это курируемый набор открытых исходных кодов Docker и репозиториев решений “drop-in”.\nПроверенный издатель - высококачественный контент Docker от проверенных издателей. Эти продукты публикуются и поддерживаются непосредственно коммерческой организацией.\nИзучение Docker Desktop У нас в системе установлен Docker Desktop, и если открыть его, то, если он у вас еще не установлен, вы увидите нечто похожее на изображение ниже. Как вы можете видеть, у нас нет запущенных контейнеров, но наш движок docker запущен.\nПоскольку это была не свежая установка для меня, у меня есть некоторые изображения, которые уже загружены и доступны в моей системе. Скорее всего, здесь вы ничего не увидите.\nВ разделе удаленных репозиториев вы найдете все образы контейнеров, которые хранятся в вашем хабе docker. Ниже показано, что у меня нет никаких образов.\nМы также можем уточнить это на нашем сайте dockerhub и подтвердить, что у нас там нет репозиториев.\nДалее у нас есть вкладка Volumes, если у вас есть контейнеры, которым требуется постоянство, то здесь мы можем добавить эти тома в вашу локальную файловую систему или общую файловую систему.\nНа момент написания статьи также существует вкладка Dev Environments, которая поможет вам сотрудничать с вашей командой вместо того, чтобы перемещаться между различными ветками git. Мы не будем ее рассматривать.\nВернувшись на первую вкладку, вы увидите, что там есть команда, которую мы можем запустить - это контейнер для запуска. Давайте запустим docker run -d -p 80:80 docker/getting-started в нашем терминале.\nЕсли мы снова проверим окно рабочего стола docker, то увидим, что у нас есть запущенный контейнер.\nВы могли заметить, что я использую WSL2, и для того, чтобы вы могли использовать его, вам нужно убедиться, что он включен в настройках.\nЕсли теперь мы снова перейдем на вкладку Images, вы должны увидеть используемый образ под названием docker/getting-started.\nВернитесь на вкладку Containers/Apps, нажмите на ваш запущенный контейнер. По умолчанию вы увидите журналы, а в верхней части есть несколько опций на выбор, в нашем случае я уверен, что это будет веб-страница, запущенная в этом контейнере, поэтому мы выберем опцию “Открыть в браузере”.\nКогда мы нажмем на кнопку выше, конечно же, откроется веб-страница на вашем локальном хосте и отобразится что-то похожее на то, что показано ниже.\nЭтот контейнер также содержит более подробную информацию о том, что такое контейнеры и изображения.\nТеперь мы запустили наш первый контейнер. Пока ничего страшного. А что если мы захотим вытащить один из образов контейнера из DockerHub? Может быть, там есть докер-контейнер hello world, который мы могли бы использовать.\nЯ остановил начальный контейнер, не то чтобы он занимал много ресурсов, но для аккуратности, пока мы проходим еще несколько шагов.\nВернемся в терминал и выполним команду docker run hello-world и посмотрим, что произойдет.\nВы можете видеть, что у нас не было локального образа, поэтому мы стянули его, а затем получили сообщение, записанное в образ контейнера, с информацией о том, что он сделал, чтобы запуститься, и некоторые ссылки на точки отсчета.\nОднако, если мы посмотрим в Docker Desktop, у нас нет запущенных контейнеров, но есть вышедший контейнер, который использовал сообщение hello-world, то есть он появился, передал сообщение и затем завершился.\nИ в последний раз, давайте просто проверим вкладку images и увидим, что у нас есть новый образ hello-world локально в нашей системе, что означает, что если мы снова выполним команду docker run hello-world в нашем терминале, нам не придется ничего вытаскивать, если только версия не изменится.\nВ сообщении от контейнера hello-world была поставлена задача запустить что-то более амбициозное.\nВызов принят!\nЗапустив docker run -it ubuntu bash в нашем терминале, мы собираемся запустить контейнерную версию Ubuntu, а не полную копию операционной системы. Вы можете узнать больше об этом конкретном образе на DockerHub.\nВы можете видеть ниже, когда мы выполним команду, у нас появится интерактивная подсказка (-it) и мы запустим оболочку bash в нашем контейнере.\nУ нас есть оболочка bash, но у нас не так много больше, поэтому образ этого контейнера занимает менее 30 мб.\nНо мы все еще можем использовать этот образ, и мы все еще можем установить программное обеспечение, используя наш менеджер пакетов apt, мы можем обновить наш образ контейнера и обновить также.\nИли, может быть, мы хотим установить какое-то программное обеспечение в наш контейнер, я выбрал очень плохой пример, поскольку pinta - это редактор изображений, и его размер превышает 200мб, но, надеюсь, вы поняли, к чему я веду. Это значительно увеличит размер нашего контейнера, но все же мы будем находиться в мб, а не в гб.\nЯ хотел, чтобы вы получили общее представление о Docker Desktop и не таком уж страшном мире контейнеров, когда вы разбиваете его на простые сценарии использования, но нам нужно рассказать о некоторых сетевых возможностях, безопасности и других вариантах, которые у нас есть по сравнению с просто загрузкой образов контейнеров и их использованием таким образом. К концу раздела мы хотим создать что-то, загрузить в наш репозиторий DockerHub и иметь возможность развернуть это.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started ","description":"","title":"44. Установка образов Docker в Docker Desktop","uri":"/ru/docs/90daysofdevops/day44/"},{"content":" Как хостить телеграм-бота (и другие скрипты на Python) на Repl.it бесплатно 24/7 ","description":"Python 101","title":"45. Хостинг Python приложения","uri":"/ru/docs/python101/chapter45_hosting/"},{"content":"Анатомия образа Docker На прошлом занятии мы рассмотрели некоторые основы использования Docker Desktop в сочетании с DockerHub для развертывания и запуска некоторых проверенных образов. Вкратце о том, что такое образ, вы не забудете, если я продолжу упоминать.\nОбраз Docker - это шаблон, доступный только для чтения, содержащий набор инструкций для создания контейнера, который может работать на платформе Docker. Это удобный способ упаковки приложений и предварительно сконфигурированных серверных сред, которые вы можете использовать для личного пользования или публично делиться ими с другими пользователями Docker. Образы Docker также являются отправной точкой для тех, кто впервые использует Docker.\nЧто произойдет, если мы захотим создать свой собственный образ Docker? Для этого мы создадим Dockerfile. Вы видели, как мы могли взять образ контейнера Ubuntu и добавить наше программное обеспечение, и у нас получился образ контейнера с программным обеспечением, которое мы хотели, и все хорошо, но если этот контейнер выключить или выбросить, то все эти обновления и установки программного обеспечения пропадут, и не будет повторяющейся версии того, что мы сделали. Это отлично подходит для демонстрации возможностей, но не помогает при транспортировке образов в несколько сред с одним и тем же набором программного обеспечения, устанавливаемого при каждом запуске контейнера.\nЧто такое Dockerfile Dockerfile - это текстовый файл, содержащий команды, которые обычно выполняются вручную для создания образа docker. Docker может собирать образы автоматически, читая инструкции, содержащиеся в нашем dockerfile.\nКаждый из файлов, составляющих образ docker, называется слоем. Эти слои образуют серию образов, поэтапно создаваемых друг над другом. Каждый слой зависит от слоя, расположенного непосредственно под ним. Порядок расположения слоев является ключевым фактором эффективности управления жизненным циклом образов docker.\nМы должны расположить слои, которые меняются чаще всего, как можно выше в стеке, потому что при внесении изменений в слой образа Docker перестраивает не только этот слой, но и все слои, созданные на его основе. Поэтому изменение слоя на самом верху требует наименьшего объема работы по пересборке всего образа.\nКаждый раз, когда docker запускает контейнер из образа (как мы делали вчера), он добавляет слой, доступный для записи, известный как слой контейнера. В нем хранятся все изменения, вносимые в контейнер в течение всего времени его работы. Этот слой - единственное различие между работающим контейнером и исходным образом. Любое количество подобных контейнеров может иметь общий доступ к одному и тому же базовому образу, сохраняя при этом свое индивидуальное состояние.\nВернемся к примеру, который мы использовали вчера с образом Ubuntu. Мы можем выполнить одну и ту же команду несколько раз и на первый контейнер установить pinta, а на второй - figlet. Это два разных приложения, разного назначения, разного размера и т.д. и т.п.. Каждый контейнер, который мы установили, имеет один и тот же образ, но не одно и то же состояние, и это состояние исчезает, когда мы удаляем контейнер.\nВ приведенном выше примере используется образ Ubuntu, но также существует множество других готовых образов контейнеров, доступных на DockerHub и в других сторонних репозиториях. Эти образы обычно называют родительским образом. Это фундамент, на котором строятся все остальные слои, и базовые строительные блоки для наших контейнерных сред.\nНаряду с набором отдельных файлов слоев, образ Docker также включает дополнительный файл, известный как манифест. Это, по сути, описание образа в формате JSON, содержащее такую информацию, как теги образа, цифровая подпись и подробные сведения о том, как настроить контейнер для различных типов хост-платформ.\nКак создать образ docker Есть два способа создания образа docker. Мы можем сделать это на лету, используя процесс, который мы начали вчера, мы выбираем наш базовый образ, раскручиваем контейнер, устанавливаем все программное обеспечение и депенансы, которые мы хотим иметь на нашем контейнере.\nЗатем мы можем использовать команду docker commit container name, после чего у нас будет локальная копия этого образа в разделе docker images и на вкладке docker desktop images.\nСупер просто, я бы не рекомендовал этот метод, если вы не хотите понять процесс, будет очень сложно управлять жизненным циклом таким образом и много ручной настройки/переконфигурации. Но это самый быстрый и простой способ создания образа docker. Отлично подходит для тестирования, устранения неполадок, проверки зависимостей и т.д.\nМы собираемся создать наш образ с помощью dockerfile. Это дает нам чистый, компактный и повторяемый способ создания образов. Намного проще управлять жизненным циклом и легко интегрировать в процессы непрерывной интеграции и непрерывной доставки. Но, как вы уже поняли, это немного сложнее, чем первый упомянутый процесс.\nИспользование метода dockerfile гораздо больше соответствует реальным развертываниям контейнеров корпоративного уровня.\nСоздание dockerfile - это трехэтапный процесс, в ходе которого вы создаете dockerfile и добавляете команды, необходимые для сборки образа.\nВ следующей таблице приведены некоторые из утверждений dockerfile, которые мы будем использовать или которые вы, скорее всего, будете использовать.\nКоманда Задача FROM Чтобы указать родительский образ WORKDIR Чтобы задать рабочий каталог для всех последующих команд в Dockerfile. RUN Для установки любых приложений и пакетов, необходимых для контейнера. COPY Для копирования файлов или каталогов из определенного места. ADD Как COPY, но также может работать с удаленными URL и распаковывать сжатые файлы. ENTRYPOINT Команда, которая всегда будет выполняться при запуске контейнера. Если она не указана, по умолчанию используется /bin/sh -c. Аргументы, передаваемые точке входа. Если ENTRYPOINT не задан (по умолчанию /bin/sh -c), .md будут командами, которые выполняет контейнер. EXPOSE Для определения порта, через который будет осуществляться доступ к вашему контейнерному приложению. LABEL Чтобы добавить метаданные к образу. Теперь у нас есть подробная информация о том, как создать наш первый dockerfile, мы можем создать рабочий каталог и создать наш dockerfile. Я создал рабочий каталог в этом репозитории, где вы можете увидеть файлы и папки, которые мне предстоит пройти. Containers\nВ этом каталоге я собираюсь создать файл .dockerignore, аналогичный .gitignore, который мы использовали в предыдущем разделе. В этом файле будут перечислены все файлы, которые могут быть созданы в процессе сборки Docker и которые вы хотите исключить из окончательной сборки.\nПомните, что все, что связано с контейнерами, - это компактность, максимальная скорость и отсутствие лишнего объема.\nСоздадим простой Dockerfile с приведенной ниже схемой, которую также можно найти в папке по ссылке выше.\n# Use the official Ubuntu 18.04 as base FROM ubuntu:18.04 # Install nginx and curl RUN apt-get update \u0026\u0026 apt-get upgrade -y RUN apt-get install -y nginx curl RUN rm -rf /var/lib/apt/lists/* Перейдите в этот каталог в терминале, а затем выполните команду docker build -t 90daysofdevops:0.1 . мы используем -t, а затем задаем имя и тег изображения.\nТеперь, когда мы создали наш образ, мы можем запустить его с помощью Docker Desktop или командной строки docker. Я использовал Docker Desktop Я запустил контейнер, и вы можете видеть, что у нас есть curl, доступный нам в cli контейнера.\nВ Docker Desktop также есть возможность использовать пользовательский интерфейс для выполнения некоторых других задач с этим новым образом.\nМы можем проинспектировать наш образ, при этом очень хорошо виден dockerfile и строки кода, которые мы хотели запустить в нашем контейнере.\nУ нас есть опция pull, теперь она не работает, потому что это изображение нигде не размещено, поэтому мы получим ошибку. Однако у нас есть Push to hub, который позволит нам отправить наш образ на DockerHub.\nЕсли вы используете ту же docker build, которую мы запустили ранее, то это тоже не сработает, вам понадобится команда сборки docker build -t {{username}}/{{imagename}}:{{version}}.\nЕсли мы посмотрим на наш репозиторий DockerHub, то увидим, что мы только что выложили новый образ. Теперь в Docker Desktop мы сможем использовать эту вкладку pull.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image ","description":"","title":"45. Что из себя представляет оьбраз Docker","uri":"/ru/docs/90daysofdevops/day45/"},{"content":"Docker Compose Возможность запуска одного контейнера может быть отличной, если у вас есть самодостаточный образ, в котором есть все, что вам нужно для одного случая использования, но все становится интересным, когда вы ищете возможность создания нескольких приложений между различными образами контейнеров. Например, если у меня есть фронт-энд сайта, но есть потребность в базе данных бэкенда, я могу поместить все в один контейнер, но лучше и эффективнее было бы иметь собственный контейнер для базы данных.\nИменно здесь на помощь приходит Docker compose - инструмент, позволяющий запускать более сложные приложения в нескольких контейнерах. Преимущество заключается в том, что для запуска приложения можно использовать один файл и команду. Пример, который я собираюсь рассмотреть в этой заметке, взят из [Docker QuickStart sample apps (Quickstart: Compose and WordPress)] (https://docs.docker.com/samples/wordpress/).\nВ этом первом примере мы собираемся:\nИспользовать Docker compose для создания WordPress и отдельного экземпляра MySQL. Использовать YAML файл, который будет называться docker-compose.yml. Соберите проект Настроить WordPress через браузер Выключение и очистка Установка Docker Compose Как уже упоминалось, Docker Compose - это инструмент, если вы работаете на macOS или Windows, то compose включен в вашу установку Docker Desktop. Однако вы можете захотеть запустить свои контейнеры на сервере Windows или Linux, и в этом случае вы можете установить их, используя эти инструкции Install Docker Compose.\nЧтобы убедиться, что docker-compose установлен в нашей системе, мы можем открыть терминал и просто ввести приведенную выше команду.\nDocker-Compose.yml (YAML) Следующее, о чем нужно поговорить, это docker-compose.yml, который вы можете найти в папке container репозитория. Но что более важно, нам нужно немного обсудить YAML в целом.\nYAML можно было бы посвятить отдельную сессию, поскольку вы можете встретить его в самых разных местах. Но по большей части\n“YAML - это удобный для человека язык сериализации данных для всех языков программирования”.\nОн обычно используется для файлов конфигурации и в некоторых приложениях, где данные хранятся или передаются. Вы, несомненно, сталкивались с XML-файлами, которые обычно предлагают тот самый файл конфигурации. YAML предоставляет минимальный синтаксис, но нацелен на те же случаи использования.\nYAML Ain’t Markup Language (YAML) - это язык сериализации, популярность которого неуклонно растет в течение последних нескольких лет. Возможности сериализации объектов делают его реальной заменой таким языкам, как JSON.\nАббревиатура YAML была сокращением от Yet Another Markup Language. Но сопровождающие переименовали его в YAML Ain’t Markup Language, чтобы сделать больший акцент на его функциях, ориентированных на данные.\nВ любом случае, вернемся к файлу docker-compose.yml. Это файл конфигурации того, что мы хотим сделать, когда речь идет о развертывании нескольких контейнеров на нашей единой системе.\nПрямо из приведенного выше руководства вы можете увидеть, что содержимое файла выглядит следующим образом:\nversion: \"3.9\" services: db: image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - wordpress_data:/var/www/html ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress volumes: db_data: {} wordpress_data: {} Мы объявляем версию, а затем большая часть этого файла docker-compose.yml состоит из наших служб, у нас есть служба db и служба wordpress. Вы можете видеть, что для каждого из них определено изображение, с которым связан тег версии. В отличие от наших первых прохождений, сейчас мы также вводим состояние в нашу конфигурацию, но теперь мы собираемся создать тома, чтобы мы могли хранить там наши базы данных.\nЗатем у нас есть некоторые переменные окружения, такие как пароли и имена пользователей. Очевидно, что эти файлы могут стать очень сложными, но конфигурационный файл YAML упрощает то, как они выглядят в целом.\nСборка проекта Далее мы можем вернуться в терминал и использовать некоторые команды с помощью нашего инструмента docker-compose. Перейдите в каталог, где находится ваш файл docker-compose.yml.\nВ терминале мы можем просто выполнить команду docker-compose up -d, которая запустит процесс извлечения образов и создания вашего многоконтейнерного приложения.\nСимвол -d в этой команде означает отделенный режим, что означает, что команда Run выполняется или будет выполняться в фоновом режиме.\nЕсли теперь мы выполним команду docker ps, вы увидите, что у нас запущено 2 контейнера, один из которых - wordpress, а другой - mySQL.\nДалее мы можем проверить, что у нас запущен WordPress, открыв браузер и перейдя по адресу http://localhost:8000, вы должны увидеть страницу установки wordpress.\nМы можем выполнить настройку WordPress, а затем начать создавать наш сайт по своему усмотрению в консоли ниже.\nЕсли мы откроем новую вкладку и перейдем по тому же адресу, что и раньше http://localhost:8000, то увидим простую тему по умолчанию с названием нашего сайта “90DaysOfDevOps”, а затем образец поста.\nПрежде чем мы сделаем какие-либо изменения, откройте Docker Desktop и перейдите на вкладку volumes, здесь вы увидите два тома, связанных с нашими контейнерами, один для wordpress и один для db.\nМоя текущая тема для wordpress - “Twenty Twenty-Two”, и я хочу изменить ее на “Twenty Twenty” Вернувшись в панель управления, мы можем внести эти изменения.\nЯ также собираюсь добавить новый пост на свой сайт, и здесь ниже вы видите последнюю версию нашего нового сайта.\nОчищать или нет Если мы сейчас используем команду docker-compose down, это приведет к остановке наших контейнеров. Но наши тома останутся на месте.\nМы можем просто подтвердить в Docker Desktop, что наши тома все еще там.\nЕсли мы захотим вернуть все обратно, мы можем выполнить команду docker up -d из той же директории, и наше приложение снова будет запущено.\nЗатем мы переходим в браузере по тому же адресу http://localhost:8000 и замечаем, что наш новый пост и смена темы все еще на месте.\nЕсли мы хотим избавиться от контейнеров и этих томов, то выполнение команды docker-compose down --volumes также уничтожит тома.\nТеперь, когда мы снова используем docker-compose up -d, мы начнем все сначала, однако образы все еще будут локальными в нашей системе, поэтому вам не нужно будет повторно брать их из репозитория DockerHub.\nЯ знаю, что когда я начал погружаться в docker-compose и его возможности, я был в замешательстве относительно того, где он находится рядом с инструментами оркестровки контейнеров, такими как Kubernetes, ну, все, что мы сделали здесь в этой короткой демонстрации, сосредоточено на одном хосте, у нас есть wordpress и db, запущенные на локальной настольной машине. У нас нет нескольких виртуальных машин или нескольких физических машин, у нас также нет возможности легко увеличивать и уменьшать требования нашего приложения.\nВ следующем разделе мы рассмотрим Kubernetes, но сначала у нас есть еще несколько дней, посвященных контейнерам в целом.\nЭто также отличный ресурс для примеров приложений docker compose с множеством интеграций. Awesome-Compose.\nВ вышеупомянутом репозитории есть отличный пример, который развернет Elasticsearch, Logstash и Kibana (ELK) на одном узле.\nЯ загрузил файлы в папку Containers Когда у вас есть эта папка локально, перейдите туда и вы можете просто использовать docker-compose up -d.\nЗатем мы можем проверить наличие запущенных контейнеров с помощью docker ps.\nТеперь мы можем открыть браузер для каждого из контейнеров:\nЧтобы удалить все, мы можем использовать команду docker-compose down.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute ","description":"","title":"46. Docker Compose","uri":"/ru/docs/90daysofdevops/day46/"},{"content":"Docker Networking \u0026 Security Во время этой сессии по контейнерам мы уже кое-что сделали, но не рассмотрели, как все работает за кулисами с точки зрения сетевых технологий, а также не затронули безопасность, поэтому мы планируем эту сессию.\nОсновы сетевого взаимодействия Docker Откройте терминал и введите команду docker network - это основная команда для настройки и управления сетями контейнеров.\nНиже показано, как мы можем использовать эту команду и все доступные подкоманды. Мы можем создавать новые сети, составлять список существующих, проверять и удалять сети.\nДавайте посмотрим на существующие сети, которые у нас есть с момента установки, поэтому из коробки Docker networking выглядит как использование команды docker network list.\nКаждая сеть получает уникальный ID и NAME. Каждая сеть также связана с одним драйвером. Обратите внимание, что сеть “bridge” и сеть “host” имеют те же имена, что и их соответствующие драйверы.\nДалее мы можем более детально рассмотреть наши сети с помощью команды docker network inspect.\nЗапустив команду docker network inspect bridge, я могу получить все детали конфигурации конкретного имени сети. Сюда входят имя, ID, драйверы, подключенные контейнеры и, как вы можете видеть, многое другое.\nDocker: Bridge Networking Как вы видели выше, стандартная установка Docker Desktop дает нам предварительно созданную сеть под названием bridge Если вы обратитесь к команде docker network list, то увидите, что сеть под названием bridge связана с драйвером bridge. То, что у них одинаковое имя, не означает, что это одно и то же. Связаны, но не одно и то же.\nВывод выше также показывает, что сеть bridge имеет локальную привязку. Это означает, что сеть существует только на этом хосте Docker. Это справедливо для всех сетей, использующих драйвер моста - драйвер моста обеспечивает работу сети на одном хосте.\nВсе сети, созданные с помощью драйвера моста, основаны на мосте Linux (он же виртуальный коммутатор).\nПодключение контейнера По умолчанию новым контейнерам назначается сеть bridge, то есть, если вы не укажете сеть, все контейнеры будут подключены к сети bridge.\nДавайте создадим новый контейнер командой docker run -dt ubuntu sleep infinity.\nКоманда sleep выше просто будет поддерживать работу контейнера в фоновом режиме, чтобы мы могли возиться с ним.\nЕсли мы затем проверим нашу сеть моста с помощью docker network inspect bridge, вы увидите, что у нас есть контейнер, соответствующий тому, что мы только что развернули, потому что мы не указали сеть.\nМы также можем погрузиться в контейнер, используя docker exec -it 3a99af449ca2 bash, вам придется использовать docker ps, чтобы получить идентификатор контейнера.\nОтсюда наш образ не имеет ничего для пинга, поэтому нам нужно выполнить следующую команду.apt-get update \u0026\u0026 apt-get install -y iputils-ping затем пингуем внешний адрес интерфеса. ping -c5 www.90daysofdevops.com\nЧтобы устранить эту проблему, мы можем запустить docker stop 3a99af449ca2 и снова использовать docker ps для поиска ID вашего контейнера, но это приведет к удалению нашего контейнера.\nНастройте NAT для внешнего подключения На этом шаге мы запустим новый контейнер NGINX и назначим порт 8080 на хосте Docker на порт 80 внутри контейнера. Это означает, что трафик, поступающий на хост Docker по порту 8080, будет передаваться на порт 80 внутри контейнера.\nЗапустите новый контейнер на основе официального образа NGINX, выполнив команду docker run --name web1 -d -p 8080:80 nginx.\nПросмотрите состояние контейнера и сопоставление портов, выполнив команду docker ps.\nВерхняя строка показывает новый контейнер web1, запущенный NGINX. Обратите внимание на команду, которую запускает контейнер, а также на сопоставление портов - 0.0.0.0:8080-\u003e80/tcp сопоставляет порт 8080 на всех интерфейсах хоста с портом 80 внутри контейнера web1. Это сопоставление портов делает веб-сервис контейнера доступным из внешних источников (через IP-адрес хоста Docker на порту 8080).\nТеперь нам нужен IP-адрес нашего реального хоста, мы можем сделать это, зайдя в терминал WSL и используя команду ip addr.\nЗатем мы можем взять этот IP, открыть браузер и перейти по адресу http://172.25.218.154:8080/ Ваш IP может быть другим. Это подтверждает, что NGINX доступен.\nЯ взял эти инструкции с этого сайта с далекого 2017 DockerCon, но они актуальны и сегодня. Однако остальная часть руководства посвящена Docker Swarm, и я не собираюсь рассматривать его здесь. Docker Networking - DockerCon 2017\nОбеспечение безопасности контейнеров Контейнеры обеспечивают безопасную среду для рабочих нагрузок по сравнению с полной конфигурацией сервера. Они позволяют разбить ваши приложения на более мелкие, слабо связанные компоненты, изолированные друг от друга, что помогает уменьшить поверхность атаки в целом.\nНо они не застрахованы от хакеров, которые хотят использовать системы в своих целях. Нам по-прежнему необходимо понимать подводные камни безопасности этой технологии и придерживаться лучших практик.\nОткажитесь от прав root Все контейнеры, которые мы развернули, использовали права root для процессов внутри контейнеров. Это означает, что они имеют полный административный доступ к вашим контейнерам и хост-средам. Теперь для целей прохождения мы знали, что эти системы не будут работать долго. Но вы видели, как легко их запустить.\nМы можем добавить несколько шагов к нашему процессу, чтобы дать возможность не root-пользователям быть предпочтительной лучшей практикой. При создании нашего dockerfile мы можем создать учетные записи пользователей. Вы можете найти этот пример также в папке containers в репозитории.\n# Используем официальную версию Ubuntu 18.04 в качестве базовой FROM ubuntu:18.04 RUN apt-get update \u0026\u0026 apt-get upgrade -y RUN groupadd -g 1000 basicuser \u0026\u0026 useradd -r -u 1000 -g basicuser basicuser пользователь basicuser Мы также можем использовать docker run --user 1009 ubuntu Команда Docker run переопределяет любого пользователя, указанного в вашем Dockerfile. Поэтому в следующем примере ваш контейнер всегда будет запускаться с наименьшими привилегиями при условии, что идентификатор пользователя 1009 также имеет самый низкий уровень прав.\nОднако этот метод не устраняет основной недостаток безопасности самого образа. Поэтому лучше указать в Dockerfile пользователя, не являющегося root, чтобы ваши контейнеры всегда запускались безопасно.\nЧастный репозитории Еще одна область, которую мы активно используем, - это публичные реестры в DockerHub, а частный реестр образов контейнеров, созданный вашей организацией, означает, что вы можете размещать их там, где пожелаете, или же для этого существуют управляемые сервисы, но в целом это дает вам полный контроль над образами, доступными для вас и вашей команды.\nDockerHub отлично подходит для создания базового уровня, но он предоставляет только базовый сервис, где вам придется во многом доверять издателю образа.\nLean \u0026 Clean Мы уже упоминали об этом, хотя это и не связано с безопасностью. Но размер вашего контейнера также может влиять на безопасность с точки зрения поверхности атаки, если у вас есть ресурсы, которые вы не используете в своем приложении, то они не нужны в вашем контейнере.\nЭто также является моей основной проблемой при использовании последних образов, потому что это может принести много лишнего в ваши образы. DockerHub показывает сжатый размер для каждого образа в хранилище.\ndocker image - отличная команда для просмотра размера ваших образов.\nРесурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute ","description":"","title":"47. Сетевое взаимодействие Docker и безопасность","uri":"/ru/docs/90daysofdevops/day47/"},{"content":"Альтернативы Docker В самом начале этого раздела я говорил, что мы будем использовать Docker, просто потому, что ресурсов очень много, а сообщество очень большое, но также именно с него начался толчок к популярности контейнеров. Я бы посоветовал вам пойти и посмотреть немного истории о Docker и о том, как он появился, я нашел это очень полезным.\nНо, как я уже упоминал, существуют и другие альтернативы Docker. Если мы подумаем о том, что такое Docker и что мы уже рассмотрели. Это платформа для разработки, тестирования, развертывания и управления приложениями.\nЯ хочу выделить несколько альтернатив Docker, которые вы можете увидеть или увидите в будущем.\nPodman Что такое Podman? Podman - это контейнерный движок без демонов для разработки, управления и запуска OCI-контейнеров в вашей системе Linux. Контейнеры могут быть запущены от имени root или в режиме rootless.\nЯ буду рассматривать это с точки зрения Windows, но знаю, что, как и в случае с Docker, здесь не требуется виртуализация, поскольку он будет использовать базовую ОС, чего нельзя сделать в мире Windows.\nPodman может быть запущен под WSL2, хотя и не так гладко, как в случае с Docker Desktop. Существует также удаленный клиент Windows, с помощью которого можно подключиться к виртуальной машине Linux, где будут запущены ваши контейнеры.\nМой Ubuntu на WSL2 - это версия 20.04. Следуя следующим шагам, вы сможете установить Podman на свой экземпляр WSL.\necho \"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_20.04/ /\" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list Добавим ключ GPG\ncurl -L \"https://download.opensuse.org/repositories/devel:/kubic:\\ /libcontainers:/stable/xUbuntu_20.04/Release.key\" | sudo apt-key add - Запустите обновление системы с помощью команды sudo apt-get update \u0026\u0026 sudo apt-get upgrade. Наконец, мы можем установить podman с помощью команды sudo apt install podman.\nТеперь мы можем использовать многие из тех же команд, которые мы использовали для docker, однако обратите внимание, что у нас нет красивого пользовательского интерфейса рабочего стола docker. Вы можете видеть ниже, я использовал podman images и у меня ничего не появилось после установки, затем я использовал podman pull ubuntu для извлечения образа контейнера ubuntu.\nЗатем мы можем запустить наш образ Ubuntu с помощью podman run -dit ubuntu и podman ps, чтобы увидеть наш запущенный образ.\nЧтобы попасть в этот контейнер, мы можем выполнить команду podman attach dazzling_darwin, имя вашего контейнера, скорее всего, будет другим.\nЕсли вы переходите от docker к podman, то обычно также необходимо изменить ваш конфигурационный файл на alias docker=podman, тогда любая команда, запущенная с помощью docker, будет использовать podman.\nLXC LXC - это механизм контейнеризации, который позволяет пользователям снова создавать несколько изолированных контейнерных сред Linux. В отличие от Docker LXC действует как гипервизор для создания нескольких Linux-машин с отдельными системными файлами, сетевыми функциями. Появился еще до Docker, а затем сделал короткое возвращение из-за недостатков Docker.\nLXC такой же легкий, как и docker, и легко развертывается.\nContainerd Автономная среда выполнения контейнеров. Containerd обеспечивает простоту и надежность, а также, конечно, переносимость. Ранее Containerd был инструментом, работающим как часть контейнерных сервисов Docker, пока Docker не решил вывести свои компоненты в самостоятельные.\nПроект в Cloud Native Computing Foundation, что ставит его в один ряд с такими популярными контейнерными инструментами, как Kubernetes, Prometheus и CoreDNS.\nДругие инструменты Docker Мы могли бы также упомянуть инструменты и опции вокруг Rancher, VirtualBox, но мы можем рассказать о них более подробно в другой раз.\nGradle\nСканирование сборки позволяет командам совместно отлаживать свои скрипты и отслеживать историю всех сборок. Опции выполнения дают командам возможность непрерывной сборки так, чтобы при каждом вводе изменений задание выполнялось автоматически. Настраиваемый макет репозитория дает командам возможность рассматривать любую структуру файловых каталогов как хранилище артефактов. Packer\nВозможность параллельного создания нескольких машинных образов для экономии времени разработчиков и повышения эффективности. Команды могут легко отлаживать сборки с помощью отладчика Packer, который проверяет сбои и позволяет командам опробовать решения перед перезапуском сборки. Поддержка многих платформ с помощью плагинов, что позволяет командам настраивать свои сборки. Logspout\nИнструмент для ведения логов - настраиваемость инструмента позволяет командам отправлять одни и те же логи в несколько мест назначения. Команды могут легко управлять своими файлами, поскольку инструмент требует только доступа к сокету Docker. Полностью с открытым исходным кодом и прост в развертывании. Logstash\nНастройте свой конвейер с помощью подключаемой структуры Logstash. Легко анализируйте и преобразуйте данные для анализа и повышения ценности бизнеса. Разнообразие выходов Logstash позволяет направлять данные туда, куда вам нужно. Portainer\nИспользуйте готовые шаблоны или создавайте свои собственные для развертывания приложений. Создавайте команды и назначайте роли и разрешения для членов команды. Узнайте, что запущено в каждой среде, используя приборную панель инструмента. Ресурсы TechWorld with Nana - Docker Tutorial for Beginners Programming with Mosh - Docker Tutorial for Beginners Docker Tutorial for Beginners - What is Docker? Introduction to Containers WSL 2 with Docker getting started Blog on gettng started building a docker image Docker documentation for building an image YAML Tutorial: Everything You Need to Get Started in Minute Podman | Daemonless Docker | Getting Started with Podman LXC - Guide to building a LXC Lab ","description":"","title":"48. Альтернативы Docker","uri":"/ru/docs/90daysofdevops/day48/"},{"content":"Общая картина: Kubernetes В предыдущем разделе мы рассмотрели контейнеры. Контейнеры не справляются с задачей масштабирования и оркестровки. Лучшее, что мы можем сделать, это использовать docker-compose для объединения нескольких контейнеров. Когда речь заходит о Kubernetes, который является оркестратором контейнеров, это дает нам возможность масштабирования в автоматическом режиме или в зависимости от нагрузки ваших приложений и сервисов.\nКак платформа Kubernetes предлагает возможность оркестровки контейнеров в соответствии с вашими требованиями и желаемым состоянием. Мы рассмотрим Kubernetes в этом разделе, поскольку она быстро развивается как следующая волна инфраструктуры. С точки зрения DevOps, Kubernetes - это лишь одна из платформ, базовое понимание которой вам понадобится. Вам также потребуется понимание “голого металла”, виртуализации и, скорее всего, облачных сервисов. Kubernetes - это просто еще один вариант запуска наших приложений.\nЧто такое оркестровка контейнеров? Я упомянул Kubernetes и упомянул оркестровку контейнеров, Kubernetes - это технология, а оркестровка контейнеров - это концепция или процесс, стоящий за технологией. Kubernetes - не единственная платформа для оркестровки контейнеров, у нас также есть Docker Swarm, HashiCorp Nomad и другие. Но Kubernetes набирает силу, поэтому я хочу рассказать о Kubernetes, но хочу сказать, что она не единственная.\nЧто такое Kubernetes? Первое, что вам следует прочитать, если вы новичок в Kubernetes, - это официальная документация. Мой опыт глубокого погружения в Kubernetes чуть больше года назад показал, что это будет крутая кривая обучения. Будучи выходцем из сферы виртуализации и хранения данных, я думал о том, насколько пугающим это кажется.\nНо на самом деле сообщество, бесплатные учебные ресурсы и документация просто потрясающие. Kubernetes.io\nKubernetes - это портативная, расширяемая платформа с открытым исходным кодом для управления контейнерными рабочими нагрузками и сервисами, которая облегчает как декларативную конфигурацию, так и автоматизацию. Она имеет большую, быстро развивающуюся экосистему. Услуги, поддержка и инструменты Kubernetes широко доступны.\nВажные моменты, которые следует отметить из вышеприведенного цитаты: Kubernetes является открытым исходным кодом с богатой историей, восходящей к Google, который передал проект в фонд Cloud Native computing Foundation (CNCF), и в настоящее время он развивается сообществом открытого исходного кода, а также крупными корпоративными поставщиками, которые внесли свой вклад, чтобы сделать Kubernetes тем, чем он является сегодня.\nЯ уже упоминал, что контейнеры - это здорово, и в предыдущем разделе мы говорили о том, как контейнеры и образы контейнеров изменили и ускорили внедрение облачных нативных систем. Но сами по себе контейнеры не дадут вам готового к производству опыта, который необходим вашему приложению. Kubernetes дает нам следующее:\nОбнаружение сервисов и балансировка нагрузки Kubernetes может открыть контейнер, используя DNS-имя или собственный IP-адрес. Если трафик на контейнер высок, Kubernetes может сбалансировать нагрузку и распределить сетевой трафик так, чтобы развертывание было стабильным.\nОркестровка хранилищ Kubernetes позволяет автоматически монтировать системы хранения по вашему выбору, например, локальные хранилища, общедоступные облачные провайдеры и многое другое.\nАвтоматизированное развертывание и откат Вы можете описать желаемое состояние для развернутых контейнеров с помощью Kubernetes, и он может изменить фактическое состояние на желаемое с контролируемой скоростью. Например, вы можете автоматизировать Kubernetes для создания новых контейнеров для развертывания, удаления существующих контейнеров и переноса всех их ресурсов в новый контейнер.\nАвтоматическая упаковка контейнеров Вы предоставляете Kubernetes кластер узлов, которые он может использовать для выполнения контейнерных задач. Вы сообщаете Kubernetes, сколько процессора и памяти (RAM) требуется каждому контейнеру. Kubernetes может разместить контейнеры на ваших узлах, чтобы наилучшим образом использовать ваши ресурсы.\nСамовосстановление Kubernetes перезапускает вышедшие из строя контейнеры, заменяет контейнеры, уничтожает контейнеры, которые не отвечают на заданную пользователем проверку работоспособности, и не рекламирует их клиентам, пока они не будут готовы к обслуживанию.\nУправление секретами и конфигурациями Kubernetes позволяет хранить и управлять конфиденциальной информацией, такой как пароли, токены OAuth и ключи SSH. Вы можете развертывать и обновлять секреты и конфигурацию приложений, не перестраивая образы контейнеров и не раскрывая секреты в конфигурации стека.\nKubernetes предоставляет вам основу для отказоустойчивого запуска распределенных систем.\nContainer Orchestration управляет развертыванием, размещением и жизненным циклом контейнеров.\nНа нее также возложено множество других обязанностей:\nУправление кластером объединяет узлы в одну цель.\nУправление расписанием распределяет контейнеры по узлам с помощью планировщика.\nОбнаружение сервисов знает, где находятся контейнеры, и распределяет между ними запросы клиентов.\nРепликация обеспечивает наличие необходимого количества узлов и контейнеров для требуемой рабочей нагрузки.\nУправление здоровьем обнаруживает и заменяет нездоровые контейнеры и узлы.\nОсновные компоненты Kubernetes Kubernetes - это контейнерный оркестратор для обеспечения, управления и масштабирования приложений. Вы можете использовать его для управления жизненным циклом контейнерных приложений в кластере узлов, который представляет собой набор рабочих машин, таких как виртуальные машины или физические машины.\nДля работы вашим приложениям может понадобиться множество других ресурсов, таких как тома, сети и секреты, которые помогут вам подключаться к базам данных, общаться с бэкграундом и защищать ключи. С помощью Kubernetes вы можете добавить эти ресурсы в свое приложение. Инфраструктурные ресурсы, необходимые вашим приложениям, управляются декларативно.\nКлючевой парадигмой Kubernetes является ее декларативная модель. Вы предоставляете нужное вам состояние, а Kubernetes его реализует. Если вам нужно пять экземпляров, вы не запускаете пять отдельных экземпляров самостоятельно. Вместо этого вы сообщаете Kubernetes, что вам нужно пять экземпляров, и Kubernetes автоматически согласовывает состояние. Если с одним из ваших экземпляров что-то пойдет не так и он выйдет из строя, Kubernetes все равно будет знать нужное вам состояние и создаст экземпляры на доступном узле.\nУзел План управления\nКаждый кластер Kubernetes требует наличия узла Control Plane, компоненты которого принимают глобальные решения относительно кластера (например, планирование), а также обнаруживают и реагируют на события кластера.\nРабочий узел Рабочая машина, на которой выполняются рабочие нагрузки Kubernetes. Это может быть физическая (bare metal) машина или виртуальная машина (VM). На каждом узле может размещаться один или несколько стручков. Узлы Kubernetes управляются плоскостью управления\nСуществуют и другие типы узлов, но я не буду их здесь рассматривать.\nkubelet\nАгент, который запускается на каждом узле кластера. Он следит за тем, чтобы контейнеры запускались в Pod.\nКуплет принимает набор PodSpecs, которые предоставляются через различные механизмы, и гарантирует, что контейнеры, описанные в этих PodSpecs, запущены и здоровы. Куплет не управляет контейнерами, которые не были созданы Kubernetes.\nkube-proxy\nkube-proxy - это сетевой прокси, который работает на каждом узле вашего кластера, реализуя часть концепции Kubernetes Service.\nkube-proxy поддерживает сетевые правила на узлах. Эти сетевые правила позволяют сетевое взаимодействие с вашими Pods из сетевых сессий внутри или вне вашего кластера.\nkube-proxy использует уровень фильтрации пакетов операционной системы, если он есть и доступен. В противном случае kube-proxy сам перенаправляет трафик.\nВремя выполнения контейнера\nВремя выполнения контейнеров - это программное обеспечение, которое отвечает за запуск контейнеров.\nKubernetes поддерживает несколько сред выполнения контейнеров: Docker, containerd, CRI-O и любую реализацию Kubernetes CRI (Container Runtime Interface).\n​\nКластер Кластер - это группа узлов, где узлом может быть физическая машина или виртуальные машины. На каждом из узлов будет установлена среда выполнения контейнеров (Docker), а также будет запущен сервис kubelet, который является агентом, принимающим команды от главного контроллера (подробнее об этом позже), и прокси, который используется для прокси-соединений с Pods от другого компонента (сервисы, которые мы рассмотрим позже).\nНа нашей плоскости управления, которую можно сделать высокодоступной, будет несколько уникальных ролей по сравнению с рабочими узлами, самой важной из них будет сервер kube API, именно с ним будет происходить любое взаимодействие для получения информации или отправки информации в наш кластер Kubernetes.\nKube API-Server\nСервер API Kubernetes проверяет и настраивает данные для объектов api, которые включают стручки, сервисы, контроллеры репликации и другие. API-сервер обслуживает REST-операции и предоставляет фронтенд к общему состоянию кластера, через который взаимодействуют все остальные компоненты.\nПланировщик\nПланировщик Kubernetes - это процесс в плоскости управления, который назначает Pods узлам. Планировщик определяет, какие узлы являются допустимыми для размещения каждого Pod в очереди планирования в соответствии с ограничениями и доступными ресурсами. Затем планировщик ранжирует каждый допустимый узел и привязывает Pod к подходящему узлу.\nМенеджер контроллера\nМенеджер контроллеров Kubernetes - это демон, который встраивает основные контуры управления, поставляемые с Kubernetes. В приложениях робототехники и автоматизации контур управления - это не завершающийся цикл, который регулирует состояние системы. В Kubernetes контроллер - это контур управления, который следит за общим состоянием кластера через apiserver и вносит изменения, пытаясь переместить текущее состояние в желаемое.\netcd.\nПоследовательное и высокодоступное хранилище значений ключей, используемое в качестве резервного хранилища Kubernetes для всех данных кластера.\nkubectl\nДля управления этим с точки зрения CLI у нас есть kubectl, kubectl взаимодействует с сервером API.\nИнструмент командной строки Kubernetes, kubectl, позволяет выполнять команды для кластеров Kubernetes. Вы можете использовать kubectl для развертывания приложений, проверки и управления ресурсами кластера, а также для просмотра журналов.\nPods Pod - это группа контейнеров, которые образуют логическое приложение. Например, если у вас есть веб-приложение, в котором запущен контейнер NodeJS, а также контейнер MySQL, то оба этих контейнера будут находиться в одном Pod. Pod также может иметь общие тома данных, а также разделять одно и то же сетевое пространство имен. Помните, что Pods являются эфемерными и могут быть подняты и опущены главным контроллером. Kubernetes использует простое, но эффективное средство идентификации Pods с помощью концепции Labels (имя - значения).\nПодсистемы управляют томами, секретами и конфигурацией контейнеров.\nПодсистемы являются эфемерными. Они предназначены для автоматического перезапуска после смерти.\nPods реплицируются при горизонтальном масштабировании приложения с помощью ReplicationSet. Каждый Pod будет выполнять один и тот же код контейнера.\nPods живут на рабочих узлах (Worker Nodes).\nРазвертывания Вы можете просто решить запустить Pods, но когда они умирают, они умирают.\nРазвертывание позволит вашему стручку работать непрерывно.\nРазвертывания позволяют вам обновлять работающее приложение без простоя.\nРазвертывания также определяют стратегию перезапуска стручков, когда они умирают\nReplicaSets Развертывание также может создать набор реплик.\nReplicaSet гарантирует, что ваше приложение имеет необходимое количество Pods.\nReplicaSets будет создавать и масштабировать Pods на основе развертывания\nРазвертывание, наборы реплик, подсистемы не являются исключительными, но могут быть\nStatefulSets Требуется ли вашему приложению хранить информацию о его состоянии?\nБаза данных нуждается в состоянии\nПодсистемы StatefulSet не являются взаимозаменяемыми.\nКаждый Pod имеет уникальный постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nКаждый Pod имеет уникальный, постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nDaemonSets DaemonSets предназначены для непрерывного процесса.\nОни запускают по одному Pod на узел.\nКаждый новый узел, добавленный в кластер, получает запущенный pod.\nПолезны для фоновых задач, таких как мониторинг и сбор логов.\nКаждый Pod имеет уникальный, постоянный идентификатор, который контроллер сохраняет при любом перепланировании.\nСервисы единая конечная точка для доступа к Pods\nунифицированный способ маршрутизации трафика к кластеру и, в конечном итоге, к списку Pods.\nИспользуя сервис, Pods можно поднимать и опускать, не затрагивая ничего.\nЭто лишь краткий обзор и заметки о фундаментальных строительных блоках Kubernetes, мы можем использовать эти знания и добавить некоторые другие области, такие как Storage и Ingress, чтобы улучшить наши приложения, но у нас также есть большой выбор, где будет работать наш кластер Kubernetes. Следующая сессия будет посвящена этим вариантам, где я могу запустить кластер Kubernetes, а также изучению некоторых особенностей хранения данных.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"49. Основы Kubernetes","uri":"/ru/docs/90daysofdevops/day49/"},{"content":"Сегодня мы сосредоточимся на отдельных шагах от начала до конца и на непрерывном цикле приложения в мире DevOps.\nПлан Все начинается с процесса планирования, когда команда разработчиков собирается вместе и выясняет, какие типы функций и исправлений ошибок они собираются внедрить в следующем спринте. Это возможность для вас как инженера DevOps принять участие в этом и узнать, какие вещи будут происходить на вашем пути, с которыми вам нужно участвовать, а также повлиять на их решения или их путь и как бы помочь им работать с инфраструктура, которую вы построили, или направьте их к чему-то, что будет работать лучше для них, если они не на этом пути, и поэтому одна ключевая вещь, на которую здесь следует указать, это то, что разработчики или команда разработчиков программного обеспечения являются вашим клиентом как DevOps инженер, так что это ваша возможность поработать с вашим клиентом до того, как он пойдет по плохому пути.\nCode Теперь, как только эта сессия планирования будет завершена, разработчики начинают писать код, в разработку котоого вы можете быть вовлечены, предоставляя информацю об инфрастуктуре, микросеврисах, если таковые имеются, и т.д. Когда разработчики заканчивают писать код/часть кода, они объединяют (merge) все измененияю и выгруат в репозиторий.\nBuild Здесь мы начнем первый из наших процессов автоматизации, потому что мы “возьмем” их код и построим (скомпилируем, “сбилдим”) его в зависимости от того, какой язык они используют, это может быть транспиляция или компиляция, а может создать образ докера из этого кода в любом случае, мы собираемся пройти этот процесс, используя наш cicd pipeline (“пайплайн”)\nTesting После того, как мы его скомпилировали проект, мы проведем на нем несколько тестов. Команда разработчиков обычно пишет тесты. У вас может быть некоторый вклад в то, какие тесты пишутся, но нам нужно запустить эти тесты. Тестирование — это способ провериь и свести к минимуму появление проблем в рабочей среде. И хотя это не гарантирует полной проверки, но мы хотим максимально точно быть уверенными, что одна из новых функций не создает новых ошибок, а две другие не ломают то, что раньше работало.\nRelease Как только эти тесты пройдены, мы собираемся выполнить процесс выпуска, и, опять же, в зависимости от того, над каким типом приложения вы работаете, это может быть поэтапным. Код может просто находиться в репозитории GitHub или репозитории git или где-то еще, а также это может быть процесс зарузки вашего скомпилированного кода или созданного образа докера и помещения его в реестр или репозиторий, где он находится.\nDeploy Следующее, что мы собираемся сделать - это “деплой” (публикация/развертывание). Развертывание похоже на конечный результат процесса. Потому что после развертывания приложения, когда мы запускаем код в производство, наш бизнес действительно осознает ценность всех временных усилий и тяжелой работы, которые вы и команда разработчиков программного обеспечения вложили в этот продукт до этого момента.\nOperate После того, как код выгружен скомпилирован, мы собираемся эксплуатировать его, и эксплуатация может включать в себя что-то вроде того, что вы начинаете получать звонки от своих клиентов, которые все раздражены тем, что сайт работает медленно или их приложение работает медленно, поэтому вам нужно выяснить, почему это так. А а затем, возможно, создать автоматическое масштабирование, которое связано с увеличением количества серверов, доступных в пиковые периоды, и уменьшением количества серверов в непиковые периоды.\nMonitor Все вышеперечисленные части ведут к последнему шагу - мониторингу, что важно особенно в отношении проблем, возникающих в рельном времени, автоматического масштабирования, устранения неполадок. Во время мониторига мы сохраняем данные об использовании памяти, использовании ЦП на диске, времени отклика, скорость отклика и т.д. Большая часть этого также является журналами. Журналы дают разработчикам возможность видеть, что происходит, без доступа к производственным системам.\nRince \u0026 Repeat Once that’s in place you go right back to the beginning to the planning stage and go through the whole thing again\nContinuous Многие инструменты помогают нам достичь вышеуказанного непрерывного процесса, весь этот код и конечная цель полной автоматизации облачной инфраструктуры или любой среды часто описывается как непрерывная интеграция/непрерывная доставка/непрерывное развертывание или сокращенно «CI/CD». Позже, в течение 90 дней, мы посвятим целую неделю CI/CD с некоторыми примерами и пошаговыми руководствами, чтобы понять основы.\nContinuous Delivery Continuous Delivery = Plan \u003e Code \u003e Build \u003e Test\nContinuous Integration Непрерывная интеграция - это результат описанных выше этапов непрерывной “доставки” и результат этапа выпуска. Это относится как к неудаче, так и к успеху, но это возвращается в непрерывную доставку или перемещается в непрерывное развертывание.\nContinuous Integration = Plan \u003e Code \u003e Build \u003e Test \u003e Release\nContinuous Deployment Если у вас есть успешный релиз, перейдите к непрерывному развертыванию, которое включает следующие этапы.\nВыпуск CI выполнен успешно = непрерывное развертывание = развертывание \u003e эксплуатация \u003e мониторинг\nВы можете рассматривать эти три понятия выше как простой набор фаз жизненного цикла DevOps.\nЭтот последний фрагмент был для меня чем-то вроде подведения итогов третьего дня, но думаю, что на самом деле это проясняет для меня ситуацию.\nИсточники DevOps for Developers – Software or DevOps Engineer? Techworld with Nana -DevOps Roadmap 2022 - How to become a DevOps Engineer? What is DevOps? How to become a DevOps Engineer in 2021 - DevOps Roadmap До встречи в День 6\n","description":"Plan \u003e Code \u003e Build \u003e Testing \u003e Release \u003e Deploy \u003e Operate \u003e Monitor","title":"5. Plan \u003e Code \u003e Build \u003e Testing \u003e Release \u003e Deploy \u003e Operate \u003e Monitor","uri":"/ru/docs/90daysofdevops/day05/"},{"content":"В каждом языке программирования, который я пробовал, есть какая-то конструкция циклов. В большинстве из них их больше одного. В мире Python есть два типа циклов:\nцикл for и цикл while Вы увидите, что цикл for является самым популярным. Циклы используются, когда вы хотите сделать что-то много раз. Обычно вам нужно выполнить какую-то операцию или набор операций над фрагментом данных снова и снова. Вот здесь-то и приходят на помощь циклы. С их помощью очень легко применять подобную логику к вашим данным.\nДавайте начнем изучать, как работают эти забавные структуры!\nЦикл for Как упоминалось выше, цикл используется, когда вы хотите выполнить итерацию по чему-либо n-ное количество раз. Это будет немного проще понять, если мы рассмотрим пример. Давайте воспользуемся встроенной в Python функцией range. Функция range создаст список длиной n.\n\u003e\u003e\u003e range(5) range(0, 5) Как видите, вышеприведенная функция range принимает целое число и возвращает объект range. Функция range также принимает начальное значение, конечное значение и значение шага. Вот еще два примера:\n\u003e\u003e\u003e range(5,10) range(5, 10) \u003e\u003e\u003e list(range(1, 10, 2)) [1, 3, 5, 7, 9] Первый пример демонстрирует, что вы можете передать начальное и конечное значение, и функция range вернет числа от начального значения до конечного, но не включая его. Таким образом, в случае 5-10 мы получим 5-9. Второй пример показывает, как использовать функцию list, чтобы заставить функцию range возвращать каждый второй элемент от 1 до 10. Таким образом, она начинает с единицы, пропускает два и т.д. Теперь вам, наверное, интересно, какое отношение это имеет к циклам. Один из простых способов показать, как работает цикл, - это использовать функцию range! Посмотрите:\n\u003e\u003e\u003e for number in range(5): print(number) 0 1 2 3 4 Что здесь произошло? Давайте прочитаем слева направо, чтобы понять это. Для каждого числа в диапазоне 5 выведите это число. Мы знаем, что если вызвать range со значением 5, то он вернет список из 5 элементов. Поэтому каждый раз, проходя через цикл, он выводит каждый из элементов. Приведенный выше цикл for был бы эквивалентен следующему:\n\u003e\u003e\u003e for number in [0, 1, 2, 3, 4]: print(number) Функция range просто делает его немного меньше. Цикл for может выполнять цикл над любым итератором Python. Мы уже видели, как он может выполнять итерацию над списком. Давайте посмотрим, может ли он также выполнять итерацию над словарем\n\u003e\u003e\u003e a_dict = {\"one\":1, \"two\":2, \"three\":3} \u003e\u003e\u003e for key in a_dict: print(key) three two one Когда вы используете цикл for со словарем, вы увидите, что он автоматически перебирает ключи. Нам не нужно было говорить for key в a_dict.keys() (хотя это тоже сработало бы). Python просто сделал все правильно за нас. Вам возможно интересно, почему ключи выводятся в другом порядке, чем они были определены в словаре. Как вы помните из главы 3, словари неупорядочены, поэтому при итерации по ним ключи могут располагаться в любом порядке.\nТеперь, если вы знаете, что ключи можно отсортировать, вы можете сделать это до того, как начнете итерацию по ним. Давайте немного изменим словарь, чтобы посмотреть, как это работает.\n\u003e\u003e\u003e a_dict = {1:\"one\", 2:\"two\", 3:\"three\"} \u003e\u003e\u003e keys = a_dict.keys() \u003e\u003e\u003e keys = sorted(keys) \u003e\u003e\u003e for key in keys: print(key) 1 2 3 Давайте немного разберемся, что делает этот код. Во-первых, мы создаем словарь, в котором ключами являются целые числа, а не строки. Затем мы извлекаем ключи из словаря. Каждый раз, когда вы вызываете метод keys(), он возвращает неупорядоченный список ключей. Если вы выведите их и обнаружите, что они расположены в порядке возрастания, то это просто случайность. Теперь у нас есть представление ключей словаря, которые хранятся в переменной keys. Мы сортируем ее, а затем с помощью цикла for перебираем ее.\nТеперь мы готовы сделать все немного интереснее. Мы собираемся перебирать диапазон, но хотим вывести только четные числа. Для этого мы хотим использовать условный оператор вместо параметра step диапазона. Вот один из способов сделать это:\n\u003e\u003e\u003e for number in range(10): if number % 2 == 0: print(number) 0 2 4 6 8 Вы, вероятно, задаетесь вопросом, что здесь происходит. Что случилось со знаком процента? В Python знак % называется оператором модуляции. Когда вы используете оператор модуляции, он возвращает остаток. При делении четного числа на два остатка нет, поэтому мы выводим эти числа. Вы, скорее всего, не будете часто использовать оператор modulus, но я думаю он может быть полезным время от времени.\nТеперь мы готовы к изучению цикла while.\nЦикл while Цикл while также используется для повторения участков кода, но вместо того, чтобы повторять цикл n раз, он будет повторяться только до тех пор, пока не будет выполнено определенное условие. Давайте рассмотрим очень простой пример:\n\u003e\u003e\u003e i = 0 \u003e\u003e\u003e while i \u003c 10: print(i) i = i + 1 Цикл while - это что-то вроде условного оператора. Вот что означает этот код: пока переменная i меньше десяти, выведите это значение. Затем в конце мы увеличиваем значение i на единицу. Если вы запустите этот код, он должен вывести 0-9, каждый на своей строке, а затем остановиться. Если вы удалите ту часть, где мы увеличиваем значение i, то в итоге у вас получится бесконечный цикл. Это обычно плохо. Бесконечных циклов следует избегать, они известны как логические ошибки.\nСуществует другой способ выйти из цикла. Использованием встроенной функции break. Давайте посмотрим, как это работает:\n\u003e\u003e\u003e while i \u003c 10: print(i) if i == 5: break i += 1 0 1 2 3 4 5 В этом фрагменте кода мы добавляем условие, чтобы проверить, равна ли переменная i 5 когда-либо. Если да, то мы выходим из цикла. Как видно из примера вывода, как только значение i достигает 5, код останавливается, несмотря на то, что мы сказали циклу while продолжать цикл, пока значение не достигнет 10. Вы также заметите, что мы изменили способ увеличения значения, использовав +=. Это удобное сокращение, которое можно использовать и для других математических операций, таких как вычитание (-=) и умножение (*=).\nВстроенная функция break известна как инструмент управления потоком. Есть еще одна, называемая continue, которая используется для пропуска итерации или продолжения следующей итерации. Вот один из способов её использования:\ni = 0 while i \u003c 10: if i == 3: i += 1 continue print(i) if i == 5: break i += 1 Немного запутано, не так ли? По сути, мы добавили второе условие, которое проверяет, равно ли i 3. Если да, то мы увеличиваем переменную и продолжаем следующий цикл, который фактически пропускает вывод значения 3 на экран. Как и раньше, когда мы достигаем значения 5, мы выходим из цикла.\nЕсть еще одна тема, которую мы должны рассмотреть в отношении циклов, и это оператор else.\nДля чего нужно else в циклах Оператор else в циклах выполняется только в случае успешного завершения цикла. В основном оператор else используется для поиска элементов:\nmy_list = [1, 2, 3, 4, 5] for i in my_list: if i == 3: print(\"Item found!\") break print(i) else: print(\"Item not found!\") В этом коде мы выходим из цикла, когда i становится равным 3. В результате оператор else будет пропущен. Если вы хотите поэкспериментировать, вы можете изменить условие так, чтобы оно искало значение, которого нет в списке, что приведет к выполнению оператора else. Честно говоря, за все годы работы программистом я ни разу не видел, чтобы кто-то использовал эту структуру. Большинство примеров, которые я видел, это блоггеры, пытающиеся объяснить, для чего она используется. Я видел несколько примеров, когда она используется для выдачи ошибки, если элемент не найден в итерабельной таблице, где был поиск. Вы можете прочитать довольно подробную статью одного из разработчиков ядра Python здесь.\nПодведение итогов Надеюсь, теперь вы видите ценность циклов Python. Они упрощают повторение и довольно просты для понимания. Скорее всего, вы будете видеть цикл for гораздо чаще, чем цикл while. На самом деле, мы рассмотрим еще один способ использования цикла for в следующей главе, когда будем изучать генераторы! Если вы все еще не совсем понимаете, как все работает, возможно, вам стоит перечитать эту главу, прежде чем продолжать.\n","description":"Python 101","title":"5. Циклы","uri":"/ru/docs/python101/chapter5_loops/"},{"content":"Выбор платформы Kubernetes Я хотел бы использовать эту сессию для разбора некоторых платформ или, может быть, дистрибутивов - более подходящий термин для этого, одна вещь, которая была проблемой в мире Kubernetes - это устранение сложности.\nKubernetes the hard way рассказывает о том, как построить из ничего полноценный функциональный кластер Kubernetes, очевидно, что это крайность, но все больше и больше людей, по крайней мере, тех, с кем я общаюсь, хотят устранить эту сложность и запустить управляемый кластер Kubernetes. Проблема в том, что это стоит больше денег, но преимущества могут быть следующими: если вы используете управляемый сервис, действительно ли вам нужно знать архитектуру узлов и то, что происходит с точки зрения плоскости управления узлов, когда обычно у вас нет к этому доступа.\nЗатем у нас есть локальные дистрибутивы для разработки, которые позволяют нам использовать наши собственные системы и запускать локальную версию Kubernetes, чтобы разработчики могли иметь полную рабочую среду для запуска своих приложений на платформе, для которой они предназначены.\nОбщая основа всех этих концепций заключается в том, что все они являются разновидностью Kubernetes, что означает, что мы должны иметь возможность свободно мигрировать и перемещать наши рабочие нагрузки туда, куда нам нужно, в соответствии с нашими требованиями.\nВо многом наш выбор будет зависеть от того, какие инвестиции были сделаны. Я уже упоминал об опыте разработчиков, но некоторые из локальных сред Kubernetes, в которых работают наши ноутбуки, отлично подходят для ознакомления с технологией без затрат денег.\nBare-Metal Clusters Вариантом для многих может быть запуск ОС Linux прямо на нескольких физических серверах для создания кластера, это также может быть Windows, но я не слышал о темпах внедрения Windows, контейнеров и Kubernetes. Очевидно, что если вы - компания, и вы приняли решение о покупке физических серверов, то это может быть способом создания кластера Kubernetes, но управление и администрирование здесь означает, что вам придется создавать и управлять всем с нуля.\nВиртуализация Независимо от тестовых и учебных сред или готовых корпоративных кластеров Kubernetes виртуализация является отличным способом продвижения, обычно это возможность запускать виртуальные машины в качестве узлов и затем объединять их в кластер. Вы получаете базовую архитектуру, эффективность и скорость виртуализации, а также возможность эффективно использовать существующие затраты. Например, VMware предлагает отличное решение для виртуальных машин и Kubernetes в различных вариантах.\nМой первый кластер Kubernetes был создан на основе виртуализации с использованием Microsoft Hyper-V на старом сервере, который был способен запускать несколько виртуальных машин в качестве узлов.\nВарианты локального рабочего стола Существует несколько вариантов запуска локального кластера Kubernetes на вашем настольном компьютере или ноутбуке. Как уже говорилось ранее, это дает разработчикам возможность увидеть, как будет выглядеть их приложение, без необходимости создавать несколько дорогостоящих или сложных кластеров. Лично я часто использую этот кластер, в частности, я использую minikube. Он обладает отличной функциональностью и дополнениями, которые меняют способ создания и запуска приложений.\nKubernetes Managed Services Я уже упоминал о виртуализации, и это может быть достигнуто с помощью гипервизоров локально, но мы знаем из предыдущих разделов, что мы также можем использовать виртуальные машины в публичном облаке в качестве узлов. Я говорю об управляемых сервисах Kubernetes - это предложения, которые мы видим у крупных гипермасштабирующих компаний, а также у MSP, которые убирают уровни управления и контроля от конечного пользователя; это может быть удаление плоскости управления от конечного пользователя, что происходит с Amazon EKS, Microsoft AKS и Google Kubernetes Engine. (GKE)\nНепреодолимый выбор Выбор - это здорово, но есть момент, когда он становится чрезмерным, и это не глубокий обзор всех вариантов в каждой из перечисленных выше категорий. В дополнение к вышеперечисленному у нас есть OpenShift от Red Hat, и этот вариант действительно может быть использован во всех вышеперечисленных вариантах у всех основных облачных провайдеров и, вероятно, сегодня обеспечивает наилучшее общее удобство для администраторов независимо от того, где развернуты кластеры.\nИтак, с чего вы начнете свое обучение, как я уже сказал, я начал с пути виртуализации, но это было потому, что у меня был доступ к физическому серверу, который я мог использовать для этой цели, я ценю и фактически с тех пор у меня больше нет такой возможности.\nСейчас я бы посоветовал использовать Minikube в качестве первого варианта или Kind (Kubernetes в Docker), но Minikube дает нам некоторые дополнительные преимущества, которые почти абстрагируют сложность, так как мы можем просто использовать дополнительные модули и быстро создавать вещи, а затем разрушать их, когда мы закончим, мы можем запускать несколько кластеров, мы можем запускать их почти везде, кросс-платформенные и аппаратно-агностические.\nЯ проделал небольшой путь в изучении Kubernetes, поэтому я собираюсь оставить выбор платформы и конкретику здесь, чтобы перечислить варианты, которые я пробовал, чтобы дать мне лучшее понимание платформы Kubernetes и того, где она может работать. Что я мог бы сделать с нижеприведенными записями в блоге, так это еще раз взглянуть на них, обновить их и перенести сюда, вместо того, чтобы они были ссылками на записи в блоге.\nРесурсы Kubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone ","description":"","title":"50. Выбор платформы Kubernetes для проекта","uri":"/ru/docs/90daysofdevops/day50/"},{"content":"Развертывание первого кластера Kubernetes В этом посте мы собираемся запустить кластер Kubernetes на нашей локальной машине с помощью minikube, это даст нам базовый кластер Kubernetes для остальной части раздела Kubernetes, хотя позже мы рассмотрим развертывание кластера Kubernetes и в VirtualBox. Причина, по которой мы выбрали этот метод, а не развертывание управляемого кластера Kubernetes в публичном облаке, заключается в том, что это будет стоить денег даже при бесплатном уровне, однако я поделился некоторыми блогами, если вы захотите развернуть такую среду в предыдущем разделе День 50.\nЧто такое Minikube? Minikube быстро создает локальный кластер Kubernetes на macOS, Linux и Windows.\nДля начала, независимо от ОС вашей рабочей станции, вы можете запустить minikube. Сначала перейдите на страницу проекта. Первая опция, которая у вас есть, это выбор метода установки. Я не использовал этот метод, но вы можете выбрать мой способ (о моем способе речь впереди).\nНиже упоминается, что вам необходимо иметь “Менеджер контейнеров или виртуальных машин, такой как: Docker, Hyperkit, Hyper-V, KVM, Parallels, Podman, VirtualBox или VMware” - это то, где будет работать MiniKube, и это простой вариант, и если не указано в репозитории, я использую Docker. Вы можете установить Docker на свою систему, используя следующую ссылку.\nПонятное руководство по установке minikube\nМой способ установки minikube Я уже некоторое время использую arkade, чтобы получить все эти инструменты Kubernetes и CLI, вы можете посмотреть шаги установки на этом github репозитории для начала работы с Arkade. Я также упоминал об этом в других записях блога, когда мне нужно было что-то установить. Простота установки: достаточно нажать arkade get и посмотреть, доступен ли ваш инструмент или cli, очень удобна. В разделе Linux мы говорили о менеджере пакетов и процессе получения нашего программного обеспечения, вы можете думать об Arkade как о рынке для всех ваших приложений и clis для Kubernetes. Очень удобный инструмент, который нужно иметь в своих системах, написанный на Golang и кроссплатформенный.\nВ длинном списке доступных приложений в arkade minikube является одним из них, поэтому с помощью простой команды arkade get minikube мы загружаем бинарник и можем приступать.\nНам также понадобится kubectl как часть нашего инструментария, поэтому вы можете получить его через arkade или, как я полагаю, в документации по minikube он представлен как часть команд curl, упомянутых выше. Подробнее о kubectl мы расскажем позже в этом посте.\nПолучение и запуск кластера Kubernetes В этом конкретном разделе я хочу рассказать о доступных нам вариантах запуска кластера Kubernetes на вашей локальной машине. Мы можем просто выполнить следующую команду, и она запустит кластер для использования.\nminikube используется в командной строке, и, проще говоря, после того как вы все установили, вы можете выполнить команду minikube start для развертывания вашего первого кластера Kubernetes. Ниже вы увидите, что драйвер Docker по умолчанию является местом, где мы будем запускать наш вложенный узел виртуализации. В начале статьи я упомянул о других доступных опциях, которые помогут вам расширить вид локального кластера Kubernetes.\nОдин кластер Minikube будет состоять из одного контейнера docker, в котором будут находиться узел плоскости управления и рабочий узел в одном экземпляре. Обычно вы разделяете эти узлы по отдельности. Об этом мы расскажем в следующем разделе, где мы рассмотрим домашние лабораторные среды Kubernetes, но немного ближе к производственной архитектуре.\nЯ уже несколько раз говорил об этом, мне очень нравится minikube из-за доступных дополнений, возможность развернуть кластер с помощью простой команды, включающей все необходимые дополнения с самого начала, действительно помогает мне каждый раз развертывать одну и ту же необходимую установку.\nНиже представлен список этих аддонов, я обычно использую аддоны csi-hostpath-driver и volumesnapshots, но вы можете увидеть длинный список ниже. Конечно, эти аддоны могут быть развернуты с помощью Helm, о чем мы расскажем позже в разделе Kubernetes, но это значительно упрощает работу.\nЯ также определяю в нашем проекте некоторые дополнительные конфигурации, apiserver установлен на 6433 вместо случайного порта API, я определяю время выполнения контейнера также на containerd, однако docker используется по умолчанию, и CRI-O также доступен. Я также устанавливаю определенную версию Kubernetes.\nТеперь мы готовы развернуть наш первый кластер Kubernetes с помощью minikube. Я уже упоминал, что вам также понадобится kubectl для взаимодействия с вашим кластером. Вы можете установить kubectl с помощью arkade, выполнив команду arkade get kubectl.\nили вы можете загрузить кросс-платформенную версию со следующих сайтов\nLinux macOS Windows После установки kubectl мы можем взаимодействовать с нашим кластером с помощью простой команды kubectl get nodes.\nЧто такое kubectl? Теперь у нас есть наш кластер minikube | Kubernetes, и я попросил вас установить Minikube, где я объяснил, что он делает, но я не объяснил, что такое kubectl и что он делает.\nkubectl - это программа, которая используется или позволяет вам взаимодействовать с кластерами Kubernetes, мы используем ее здесь для взаимодействия с нашим кластером minikube, но мы также используем kubectl для взаимодействия с нашими корпоративными кластерами в публичном облаке.\nМы используем kubectl для развертывания приложений, проверки и управления ресурсами кластера. Гораздо лучший Обзор kubectl можно найти здесь, в официальной документации Kubernetes.\nkubectl взаимодействует с сервером API, расположенным на узле Control Plane, о котором мы вкратце рассказывали в одном из предыдущих постов.\nkubectl шпаргалка Наряду с официальной документацией я также обнаружил, что при поиске команд kubectl у меня постоянно открыта эта страница. Unofficial Kubernetes\nListing Resources kubectl get nodes List all nodes in cluster kubectl get namespaces List all namespaces in cluster kubectl get pods List all pods in default namespace cluster kubectl get pods -n name List all pods in “name” namespace kubectl get pods -n name List all pods in “name” namespace Creating Resources kubectl create namespace name Create a namespace called “name” kubectl create -f [filename] Create a resource from a JSON or YAML file: Editing Resources kubectl edit svc/servicename To edit a service More detail on Resources kubectl describe nodes display the state of any number of resources in detail, Delete Resources kubectl delete pod Remove resources, this can be from stdin or file Вы захотите узнать краткие названия некоторых команд kubectl, например, -n - это краткое название для namespace, что облегчает ввод команды, а также, если вы пишете скрипты, вы можете получить гораздо более аккуратный код.\nShort name Full name csr certificatesigningrequests cs componentstatuses cm configmaps ds daemonsets deploy deployments ep endpoints ev events hpa horizontalpodautoscalers ing ingresses limits limitranges ns namespaces no nodes pvc persistentvolumeclaims pv persistentvolumes po pods pdb poddisruptionbudgets psp podsecuritypolicies rs replicasets rc replicationcontrollers quota resourcequotas sa serviceaccounts svc services В заключение хочу добавить, что я создал еще один проект на основе minikube, чтобы помочь мне быстро развернуть демонстрационные среды для демонстрации сервисов данных и защиты этих рабочих нагрузок с помощью Kasten K10, Project Pace можно найти там и буду рад вашим отзывам или взаимодействию, он также показывает или включает некоторые автоматизированные способы развертывания кластеров minikube и создания различных приложений сервисов данных.\nДалее мы перейдем к развертыванию нескольких узлов в виртуальные машины с помощью VirtualBox, но здесь мы будем действовать проще, как мы делали в разделе Linux, где мы использовали vagrant для быстрого запуска машин и развертывания нашего программного обеспечения, как мы хотим.\nЯ добавил этот список к вчерашнему посту, который представляет собой блоги с описанием развертывания различных кластеров Kubernetes.\nKubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone Ресурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"51. Установка minikube","uri":"/ru/docs/90daysofdevops/day51/"},{"content":"Настройка многоузлового кластера Kubernetes Я хотел назвать эту статью “Настройка многоузлового кластера Kubernetes с помощью Vagrant”, но подумал, что это будет слишком длинно!\nНа вчерашней сессии мы использовали классный проект для развертывания нашего первого кластера Kubernetes и немного поработали с самым важным инструментом CLI, с которым вы столкнетесь при использовании Kubernetes (kubectl).\nЗдесь мы будем использовать VirtualBox в качестве основы, но, как мы уже говорили о Vagrant в разделе Linux, мы можем использовать любой гипервизор или инструмент виртуализации. Это был День 14, когда мы прошли и развернули машину Ubuntu для раздела Linux.\nКраткая информация о Vagrant Vagrant - это утилита CLI, которая управляет жизненным циклом ваших виртуальных машин. Мы можем использовать vagrant для запуска и разворачивания виртуальных машин на различных платформах, включая vSphere, Hyper-v, Virtual Box и Docker. У него есть и другие поставщики, но мы будем придерживаться этого, мы используем Virtual Box, так что все готово.\nЯ собираюсь использовать базовый уровень этого блога и репозитория, чтобы пройтись по конфигурации. Однако я бы посоветовал, если вы впервые развертываете кластер Kubernetes, посмотреть, как это делается вручную, и тогда вы хотя бы будете знать, как это выглядит. Хотя я должен сказать, что эти операции и усилия дня 0 становятся все более эффективными с каждым выпуском Kubernetes. Я сравниваю это с временами VMware и ESX, когда для развертывания 3 серверов ESX требовался по меньшей мере день, а теперь мы можем сделать это за час. Мы движемся в этом направлении, когда речь идет о Kubernetes\".\nЛабораторная среда Kubernetes Я загрузил в папку Kubernetes vagrantfile, который мы будем использовать для создания нашей среды. Возьмите его и перейдите в этот каталог в терминале. Я снова использую Windows, поэтому я буду использовать PowerShell для выполнения команд рабочей станции с vagrant. Если у вас нет vagrant, вы можете использовать arkade, о котором мы говорили вчера при установке minikube и других инструментов. Простая команда arkade get vagrant должна заставить вас загрузить и установить последнюю версию vagrant.\nКогда вы окажетесь в своей директории, вы можете просто запустить vagrant up, и если все настроено правильно, вы должны увидеть в терминале следующее.\nВ терминале вы увидите ряд шагов, но тем временем давайте посмотрим, что мы на самом деле создаем.\nИз приведенного выше изображения видно, что мы собираемся создать 3 виртуальные машины, у нас будет узел плоскости управления и два рабочих узла. Если вы вернетесь к День 49, вы увидите более подробное описание этих областей, которые мы видим на изображении.\nТакже на изображении мы указываем, что наш доступ к kubectl будет происходить извне кластера и попадать в kube apiserver, в то время как на самом деле в рамках инициализации vagrant мы развертываем kubectl на каждом из этих узлов, чтобы мы могли получить доступ к кластеру изнутри каждого из наших узлов.\nПроцесс создания этой лаборатории может занять от 5 до 30 минут в зависимости от вашей установки.\nЯ собираюсь в ближайшее время рассказать о скриптах, но если вы посмотрите в файл vagrant, то заметите, что мы вызываем 3 скрипта как часть развертывания, и именно здесь создается кластер. Мы видели, как легко использовать vagrant для развертывания наших виртуальных машин и установки ОС с помощью боксов vagrant, но возможность запуска скрипта оболочки как часть процесса развертывания - это то, что становится довольно интересным в автоматизации этих лабораторных сборок.\nПосле завершения мы можем подключиться по ssh к одному из наших узлов vagrant ssh master из терминала должен получить доступ, имя пользователя и пароль по умолчанию - vagrant/vagrant.\nВы также можете использовать vagrant ssh node01 и vagrant ssh node02 для получения доступа к рабочим узлам, если хотите.\nТеперь мы находимся на одном из вышеуказанных узлов нашего нового кластера, мы можем выдать команду kubectl get nodes, чтобы показать наш 3-узловой кластер и его статус.\nНа данный момент у нас есть запущенный 3-узловой кластер, с 1 узлом плоскости управления и 2 рабочими узлами.\nVagrantfile и Shell Script walkthrough Если мы посмотрим на наш vagrantfile, вы увидите, что мы определяем количество рабочих узлов, сетевые IP-адреса для мостовой сети в VirtualBox, а также некоторые именования. Еще вы заметите, что мы также вызываем некоторые скрипты, которые мы хотим запустить на определенных хостах.\nNUM_WORKER_NODES=2 IP_NW=\"10.0.0.\" IP_START=10 Vagrant.configure(\"2\") do |config| config.vm.provision \"shell\", inline: \u003c\u003c-SHELL apt-get update -y echo \"$IP_NW$((IP_START)) master-node\" \u003e\u003e /etc/hosts echo \"$IP_NW$((IP_START+1)) worker-node01\" \u003e\u003e /etc/hosts echo \"$IP_NW$((IP_START+2)) worker-node02\" \u003e\u003e /etc/hosts SHELL config.vm.box = \"bento/ubuntu-21.10\" config.vm.box_check_update = true config.vm.define \"master\" do |master| master.vm.hostname = \"master-node\" master.vm.network \"private_network\", ip: IP_NW + \"#{IP_START}\" master.vm.provider \"virtualbox\" do |vb| vb.memory = 4048 vb.cpus = 2 vb.customize [\"modifyvm\", :id, \"--natdnshostresolver1\", \"on\"] end master.vm.provision \"shell\", path: \"scripts/common.sh\" master.vm.provision \"shell\", path: \"scripts/master.sh\" end (1..NUM_WORKER_NODES).each do |i| config.vm.define \"node0#{i}\" do |node| node.vm.hostname = \"worker-node0#{i}\" node.vm.network \"private_network\", ip: IP_NW + \"#{IP_START + i}\" node.vm.provider \"virtualbox\" do |vb| vb.memory = 2048 vb.cpus = 1 vb.customize [\"modifyvm\", :id, \"--natdnshostresolver1\", \"on\"] end node.vm.provision \"shell\", path: \"scripts/common.sh\" node.vm.provision \"shell\", path: \"scripts/node.sh\" end end end Давайте разберем эти выполняемые скрипты. У нас есть три скрипта, перечисленные в вышеуказанном VAGRANTFILE для запуска на определенных узлах.\nmaster.vm.provision \"shell\", path: \"scripts/common.sh\"\nПриведенный выше скрипт будет направлен на подготовку узлов, он будет запущен на всех трех наших узлах и удалит все существующие компоненты Docker и переустановит Docker и ContainerD, а также kubeadm, kubelet и kubectl. Этот скрипт также обновит существующие пакеты программного обеспечения в системе.\nmaster.vm.provision \"shell\", path: \"scripts/master.sh\"\nСкрипт master.sh будет выполняться только на узле плоскости управления, этот скрипт создаст кластер Kubernetes с помощью команд kubeadm. Он также подготовит контекст конфигурации для доступа к этому кластеру, о чем мы расскажем далее.\nnode.vm.provision \"shell\", path: \"scripts/node.sh\"\nЭто просто возьмет конфиг, созданный мастером, и присоединит наши узлы к кластеру Kubernetes, этот процесс присоединения снова использует kubeadm и другой скрипт, который можно найти в папке config.\nДоступ к кластеру Kubernetes Теперь у нас есть два развернутых кластера: кластер minikube, который мы развернули в предыдущем разделе, и новый 3-узловой кластер, который мы только что развернули на VirtualBox.\nТакже в этом конфигурационном файле, к которому у вас будет доступ на машине, с которой вы запускали vagrant, описано, как мы можем получить доступ к нашему кластеру с нашей рабочей станции.\nПрежде чем мы покажем это, позвольте мне коснуться контекста.\nКонтекст важен, необходима возможность доступа к кластеру Kubernetes с рабочего стола или ноутбука. Существует множество различных вариантов, и люди используют различные операционные системы в качестве повседневных драйверов.\nПо умолчанию клиент Kubernetes CLI (kubectl) использует папку C:\\Users\\username.kube\\config для хранения информации о кластере Kubernetes, такой как конечная точка и учетные данные. Если вы развернули кластер, вы сможете увидеть этот файл в этом месте. Но если вы до сих пор использовали главный узел для выполнения всех команд kubectl через SSH или другими способами, то эта статья, надеюсь, поможет вам освоить возможность подключения к рабочей станции.\nЗатем нам нужно получить файл kubeconfig из кластера или мы также можем получить его из нашего файла конфигурации после развертывания, получить содержимое этого файла либо через SCP, либо просто открыть консольный сеанс на главном узле и скопировать на локальную машину windows.\nЗатем мы хотим взять копию этого файла конфигурации и переместить в место $HOME/.kube/config.\nТеперь с локальной рабочей станции вы сможете запустить kubectl cluster-info и kubectl get nodes, чтобы убедиться, что у вас есть доступ к вашему кластеру.\nЭто не только обеспечивает подключение и управление с вашей windows-машины, но и позволяет нам выполнить проброс портов для доступа к определенным сервисам с нашей windows-машины.\nЕсли вам интересно, как управлять несколькими кластерами на рабочей станции, у меня есть более подробное описание здесь.\nЯ добавил этот список, в котором представлены блоги, посвященные различным развертываемым кластерам Kubernetes.\nKubernetes playground – How to choose your platform Kubernetes playground – Setting up your cluster Getting started with Amazon Elastic Kubernetes Service (Amazon EKS) Getting started with Microsoft Azure Kubernetes Service (AKS) Getting Started with Microsoft AKS – Azure PowerShell Edition Getting started with Google Kubernetes Service (GKE) Kubernetes, How to – AWS Bottlerocket + Amazon EKS Getting started with CIVO Cloud Minikube - Kubernetes Demo Environment For Everyone Ресурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"52. Настройка многоузлового кластера Kubernetes","uri":"/ru/docs/90daysofdevops/day52/"},{"content":"Обзор Rancher - практическое применение В этом разделе мы рассмотрим Rancher, до сих пор все, что мы делали, было в cli и с использованием kubectl, но у нас есть несколько действительно хороших пользовательских интерфейсов и инструментов управления несколькими кластерами, чтобы дать нашим операционным командам хорошую видимость управления кластером.\nRancher, согласно их сайту\nRancher - это полный программный стек для команд, внедряющих контейнеры. Он решает операционные проблемы и проблемы безопасности при управлении несколькими кластерами Kubernetes в любой инфраструктуре, обеспечивая команды DevOps интегрированными инструментами для запуска контейнерных рабочих нагрузок.\nRancher позволяет нам развертывать кластеры Kubernetes производственного уровня практически из любого места, а затем обеспечивает централизованную аутентификацию, контроль доступа и наблюдаемость. Я упоминал в предыдущем разделе, что существует почти непреодолимый выбор, когда речь идет о Kubernetes и о том, где вы должны или можете их запустить, но с Rancher действительно не имеет значения, где они находятся.\nРазвертывание Rancher Первое, что нам нужно сделать, это развернуть Rancher на нашей локальной рабочей станции, есть несколько способов и мест, которые вы можете выбрать для выполнения этого шага, я хочу использовать свою локальную рабочую станцию и запустить Rancher как контейнер docker. Выполнив приведенную ниже команду, мы получим образ контейнера и доступ к пользовательскому интерфейсу rancher.\nДоступны и другие методы развертывания rancher Rancher Quick-Start-Guide sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher.\nКак вы можете видеть на нашем рабочем столе Docker, у нас есть запущенный контейнер rancher.\nДоступ к пользовательскому интерфейсу Rancher Запустив вышеуказанный контейнер, мы должны иметь возможность перейти к нему через веб-страницу. По адресу https://localhost откроется страница входа в систему, как показано ниже.\nСледуйте инструкциям ниже, чтобы получить требуемый пароль. Поскольку я использую Windows, я решил использовать bash для Windows, так как для этого требуется команда grep.\nЗатем мы можем взять указанный выше пароль и войти в систему, на следующей странице мы можем задать новый пароль.\nПосле выполнения вышеуказанных действий мы войдем в систему и увидим наш начальный экран. В рамках развертывания Rancher мы также увидим локальный кластер K3s.\nКраткий экскурс по rancher Первое, на что мы посмотрим, это наш локально развернутый кластер K3S. Вы можете видеть ниже, что мы получаем хорошее представление о том, что происходит внутри нашего кластера. Это развертывание по умолчанию, и мы еще ничего не развертывали в этом кластере. Видно, что он состоит из 1 узла и имеет 5 развертываний. Также вы можете видеть, что есть некоторые статистические данные по стручкам, ядрам и памяти.\nВ меню слева есть вкладка Apps \u0026 Marketplace, которая позволяет нам выбрать приложения, которые мы хотели бы запустить на наших кластерах. Как уже упоминалось ранее, Rancher дает нам возможность запускать и управлять несколькими различными кластерами. С помощью рынка мы можем очень легко развернуть наши приложения.\nЕще одна вещь, о которой стоит упомянуть, это то, что если вам понадобится получить доступ к любому кластеру, управляемому Rancher, в правом верхнем углу есть возможность открыть оболочку kubectl для выбранного кластера.\nСоздание нового кластера На последних двух занятиях мы создали кластер minikube локально и использовали Vagrant с VirtualBox для создания 3-узлового кластера Kubernetes, с помощью Rancher мы также можем создавать кластеры. В папке Rancher Folder вы найдете дополнительные файлы vagrant, которые создадут те же 3 узла, но без шагов по созданию нашего кластера Kubernetes (мы хотим, чтобы Rancher сделал это за нас).\nТем не менее, мы хотим установить docker и обновить ОС, поэтому вы увидите скрипт common.sh, запускаемый на каждом из наших узлов. Это также установит Kubeadm, Kubectl и т.д. Но он не запустит команды Kubeadm для создания и объединения наших узлов в кластер.\nМы можем перейти в папку vagrant и просто запустить vagrant up, и это начнет процесс создания наших 3 виртуальных машин в virtualbox.\nТеперь, когда у нас есть наши узлы или ВМ на месте и готовы, мы можем использовать Rancher для создания нашего нового кластера Kubernetes. Первый экран для создания кластера дает вам несколько вариантов того, где находится ваш кластер, то есть используете ли вы службы Kubernetes, управляемые публичным облаком, vSphere или что-то еще.\nМы выберем “custom”, так как не используем ни одну из интегрированных платформ. На открывшейся странице вы определяете имя вашего кластера (ниже написано local, но вы не можете использовать local, наш кластер называется vagrant). Здесь вы можете определить версии Kubernetes, сетевых провайдеров и некоторые другие параметры конфигурации, чтобы запустить ваш кластер Kubernetes.\nНа следующей странице вы найдете регистрационный код, который необходимо запустить на каждом из узлов и включить соответствующие службы: etcd, controlplane и worker. Для нашего главного узла нам нужны etcd и controlplane, поэтому команду можно увидеть ниже.\nsudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.6.3 --server https://10. 0.0.1 --token mpq8cbjjwrj88z4xmf7blqxcfmwdsmq92bmwjpphdkklfckk5hfwc2 --ca-checksum a81944423cbfeeb92be0784edebba1af799735ebc30ba8cbe5cc5f996094f30b --etcd --controlplane\rЕсли сетевое взаимодействие настроено правильно, то вы должны довольно быстро увидеть следующее на приборной панели rancher, указывающее на то, что первый мастер-узел сейчас регистрируется и кластер создается.\nЗатем мы можем повторить процесс регистрации для каждого из рабочих узлов с помощью следующей команды, и через некоторое время вы получите свой кластер, способный использовать рынок для развертывания приложений.\nsudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.6.3 --server https://10. 0.0.1 --token mpq8cbjjwrj88z4xmf7blqxcfmwdsmq92bmwjpphdkklfckk5hfwc2 --ca-checksum a81944423cbfeeb92be0784edebba1af799735ebc30ba8cbe5cc5f996094f30b --worker\rЗа последние 3 занятия мы использовали несколько различных способов запуска кластера Kubernetes, в оставшиеся дни мы рассмотрим прикладную сторону платформы, вероятно, самую важную. Мы рассмотрим сервисы и возможность предоставления и использования наших сервисов в Kubernetes.\nМне сказали, что требования к загрузке узлов rancher требуют, чтобы эти виртуальные машины имели 4 ГБ оперативной памяти, иначе они будут работать с ошибками, с тех пор я обновил информацию, так как наши рабочие узлы имели 2 ГБ.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"53. Обзор Rancher","uri":"/ru/docs/90daysofdevops/day53/"},{"content":"Развертывание приложений Kubernetes Теперь мы, наконец, переходим к реальному развертыванию некоторых приложений в наших кластерах, некоторые говорят, что именно для этого существует Kubernetes - для доставки приложений.\nИдея заключается в том, что мы можем взять наши образы контейнеров и развернуть их в виде стручков в нашем кластере Kubernetes, чтобы воспользоваться преимуществами Kubernetes как контейнерного оркестратора.\nРазвертывание приложений в Kubernetes Существует несколько способов развертывания наших приложений в кластере Kubernetes, мы рассмотрим два наиболее распространенных подхода - YAML-файлы и диаграммы Helm.\nДля развертывания приложений мы будем использовать кластер minikube. Мы рассмотрим некоторые из ранее упомянутых компонентов или строительных блоков Kubernetes.\nНа протяжении всего этого раздела и раздела о контейнерах мы говорили об образах и преимуществах Kubernetes, а также о том, как мы можем легко справляться с масштабированием на этой платформе.\nВ этом первом шаге мы просто создадим приложение без статических данных в нашем кластере minikube. Мы будем использовать дефакто стандартное приложение без статики в нашей первой демонстрации nginx. Мы настроим Deployment, который предоставит нам наши стручки, а затем мы также создадим службу, которая позволит нам перейти к простому веб-серверу, размещенному в стручке nginx. Все это будет содержаться в пространстве имен.\nСоздание YAML В первом демо мы хотим определить все, что мы делаем с YAML, мы могли бы создать целый раздел о YAML, но я собираюсь пропустить это и оставить некоторые ресурсы в конце, которые расскажут о YAML более подробно.\nМы можем создать следующее как один YAML-файл или разбить его на части для каждого аспекта нашего приложения, то есть это могут быть отдельные файлы для пространства имен, развертывания и создания сервисов, но в этом файле ниже мы разделили их с помощью --- в одном файле. Вы можете найти этот файл, расположенный здесь\napiVersion: v1\rkind: Namespace\rmetadata:\rname: nginx\r\"labels\": {\r\"name\": \"nginx\"\r}\r---\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: nginx-deployment\rnamespace: nginx\rspec:\rselector:\rmatchLabels:\rapp: nginx\rreplicas: 1\rtemplate:\rmetadata:\rlabels:\rapp: nginx\rspec:\rcontainers:\r- name: nginx\rimage: nginx\rports:\r- containerPort: 80\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: nginx-service\rnamespace: nginx\rspec:\rselector:\rapp: nginx-deployment\rports:\r- protocol: TCP\rport: 80\rtargetPort: 80\rПроверка нашего кластера Перед тем как развернуть что-либо, мы должны убедиться, что у нас нет существующих пространств имен с названием nginx. Мы можем сделать это, выполнив команду kubectl get namespace, и как вы можете видеть ниже, у нас нет пространства имен с названием nginx.\nВремя развернуть наше приложение Теперь мы готовы развернуть наше приложение на нашем кластере minikube, этот же процесс будет работать на любом другом кластере Kubernetes.\nНам нужно перейти к расположению нашего yaml файла, а затем мы можем выполнить команду kubectl create -f nginx-stateless-demo.yaml, после чего вы увидите, что было создано 3 объекта, у нас есть пространство имен, развертывание и сервис.\nДавайте снова выполним команду, чтобы увидеть доступные пространства имен в нашем кластере kubectl get namespace, и теперь вы можете увидеть, что у нас есть наше новое пространство имен.\nЕсли мы затем проверим наше пространство имен на наличие стручков с помощью kubectl get pods -n nginx, вы увидите, что у нас есть 1 стручок в готовом и запущенном состоянии.\nМы также можем проверить, что наш сервис создан, выполнив команду kubectl get service -n nginx.\nНаконец, мы можем пойти и проверить наше развертывание, развертывание - это то, где и как мы сохраняем нашу желаемую конфигурацию.\nВыше приведено несколько команд, которые стоит знать, но вы также можете использовать kubectl get all -n nginx, чтобы увидеть все, что мы развернули с помощью одного YAML-файла.\nВы можете заметить, что у нас также есть replicaset, в нашем развертывании мы определяем, сколько копий нашего образа мы хотим развернуть. Изначально мы установили значение 1, но если мы хотим быстро масштабировать наше приложение, мы можем сделать это несколькими способами.\nМы можем отредактировать наш файл с помощью команды kubectl edit deployment nginx-deployment -n nginx, которая откроет текстовый редактор в вашем терминале и позволит вам изменить развертывание.\nПосле сохранения в текстовом редакторе в терминале, если не возникло проблем и было использовано правильное форматирование, вы должны увидеть дополнительное развертывание в вашем пространстве имен.\nМы также можем изменить количество реплик с помощью kubectl и команды kubectl scale deployment nginx-deployment --replicas=10 -n nginx.\nМы также можем использовать этот метод для уменьшения масштаба нашего приложения до 1 снова, если захотим, используя любой метод. Я использовал опцию edit, но вы также можете использовать команду scale выше.\nНадеюсь, здесь вы можете увидеть пример использования: не только все очень быстро запускается и выключается, но у нас есть возможность быстро увеличивать и уменьшать масштаб наших приложений. Если бы это был веб-сервер, мы могли бы увеличивать масштаб в периоды загруженности и уменьшать, когда нагрузка снижается.\nРаскрытие нашего приложения Но как нам получить доступ к нашему веб-серверу?\nЕсли вы посмотрите выше на наш сервис, вы увидите, что там нет внешнего IP, поэтому мы не можем просто открыть веб-браузер и ожидать, что он будет там волшебным образом. Для доступа у нас есть несколько вариантов.\nClusterIP - IP, который вы видите, является кластерным IP, он находится во внутренней сети кластера. Только объекты внутри кластера могут достичь этого IP.\nNodePort - Выставляет службу на один и тот же порт каждого из выбранных узлов в кластере с помощью NAT.\nLoadBalancer - Создает внешний балансировщик нагрузки в текущем облаке, мы используем minikube, но если вы создали свой собственный кластер Kubernetes, т.е. то, что мы сделали в VirtualBox, вам нужно будет развернуть LoadBalancer, такой как metallb, в вашем кластере, чтобы обеспечить эту функциональность.\nPort-Forward - У нас также есть возможность Port Forward, которая позволяет вам получить доступ и взаимодействовать с внутренними процессами кластера Kubernetes с вашего localhost. На самом деле эта опция используется только для тестирования и поиска неисправностей.\nТеперь у нас есть несколько вариантов на выбор, Minikube имеет некоторые ограничения или отличия от полноценного кластера Kubernetes.\nМы можем просто выполнить следующую команду, чтобы перенаправить порт для доступа, используя нашу локальную рабочую станцию.\nkubectl port-forward deployment/nginx-deployment -n nginx 8090:80.\nОбратите внимание, что при выполнении вышеуказанной команды терминал становится непригодным для использования, поскольку он действует как проброс порта на вашу локальную машину и порт.\nНаконец, в новом терминале запустите minikube --profile='mc-demo' service nginx-service --url -n nginx, чтобы создать туннель для нашего сервиса.\nОткройте браузер или программу управления и нажмите на ссылку в терминале.\nHelm Helm - это еще один способ, с помощью которого мы можем развернуть наши приложения. Известен как “менеджер пакетов для Kubernetes”. Вы можете узнать больше здесь.\nHelm - это менеджер пакетов для Kubernetes. Helm можно считать аналогом yum или apt для Kubernetes. Helm развертывает диаграммы, которые можно представить как упакованное приложение. Это чертеж предварительно сконфигурированных ресурсов приложения, которые можно развернуть в виде одной простой в использовании диаграммы. Затем вы можете развернуть другую версию диаграммы с другим набором конфигураций.\nУ компании есть сайт, на котором можно просмотреть все доступные диаграммы Helm и, конечно, создать свою собственную. Документация также понятна и лаконична и не так пугает, как когда я впервые услышал термин Helm среди всех других новых слов в этой области.\nЗапустить или установить Helm очень просто. Просто. Здесь вы можете найти двоичные файлы и ссылки на загрузку практически для всех дистрибутивов, включая устройства RaspberryPi arm64.\nИли вы можете использовать скрипт установщика, преимущество которого в том, что будет загружена и установлена последняя версия Helm.\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3\rchmod 700 get_helm.sh\r./get_helm.sh\rНаконец, есть также возможность использовать менеджер пакетов для менеджера приложений, homebrew для mac, chocolatey для windows, apt с Ubuntu/Debian, snap и pkg также.\nПока что Helm кажется наиболее удобным способом загрузки и установки различных тестовых приложений в кластере.\nХорошим ресурсом для ссылки здесь будет ArtifactHUB, который является ресурсом для поиска, установки и публикации пакетов Kubernetes. Я также порекомендую KubeApps, который представляет собой пользовательский интерфейс для отображения диаграмм штурвала.\nРесурсы Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! ","description":"","title":"54. Развертывание приложений Kubernetes","uri":"/ru/docs/90daysofdevops/day54/"},{"content":"State и Ingress в Kubernetes В этом заключительном разделе, посвященном Kubernetes, мы рассмотрим State и ingress.\nВсе, о чем мы говорили до сих пор, касается stateless, stateless - это когда нашим приложениям не важно, какую сеть они используют, и им не нужно постоянное хранение данных. В то время как приложения с состоянием, например, базы данных, чтобы такое приложение функционировало правильно, вам нужно убедиться, что стручки могут обращаться друг к другу через уникальную идентификацию, которая не меняется (имена хостов, IP… и т.д.). Примерами stateful-приложений являются кластеры MySQL, Redis, Kafka, MongoDB и другие. В принципе, любое приложение, которое хранит данные.\nStateful Application StatefulSets представляют собой набор Pods с уникальными, постоянными идентификаторами и стабильными именами хостов, которые Kubernetes поддерживает независимо от того, где они запланированы. Информация о состоянии и другие устойчивые данные для любого данного StatefulSet Pod хранятся в постоянном дисковом хранилище, связанном с StatefulSet.\nРазвертывание против StatefulSet Репликация stateful-приложений является более сложной задачей. Репликация наших стручков в развертывании (Stateless Application) идентична и взаимозаменяема. Создаем капсулы в случайном порядке со случайными хэшами Один сервис, который балансирует нагрузку на любой стручок. Когда дело доходит до StatefulSets или Stateful Applications, вышеописанное становится сложнее.\nНевозможно одновременно создавать и удалять. Не может быть случайного обращения. реплики Pods не являются идентичными. То, что вы увидите в нашей демонстрации в ближайшее время, заключается в том, что каждая копия имеет свою собственную идентичность. В приложении без статического состояния вы увидите случайные имена. Например, app-7469bbb6d7-9mhxd, в то время как Stateful Application будет иметь имя mongo-0, а затем при масштабировании создаст новую капсулу под названием mongo-1.\nЭти стручки создаются на основе одной и той же спецификации, но они не взаимозаменяемы. Каждая капсула StatefulSet имеет постоянный идентификатор при любом повторном планировании. Это необходимо, потому что когда нам требуются нагрузки с учетом состояния, такие как база данных, где требуется запись и чтение в базу данных, мы не можем иметь две капсулы, пишущие в одно и то же время без осведомленности, так как это приведет к несогласованности данных. Нам нужно убедиться, что в любой момент времени только один из наших стручков записывает данные в базу данных, однако мы можем иметь несколько стручков, читающих эти данные.\nКаждый стручок в StatefulSet будет иметь доступ к своему собственному постоянному тому и копии базы данных для чтения, которая постоянно обновляется с главного сервера. Также интересно отметить, что каждый pod будет хранить свое состояние pod в этом постоянном томе, если mongo-0 умрет, то при инициализации нового pod он возьмет состояние pod, хранящееся в хранилище.\nTLDR; StatefulSets vs Deployments\nPredicatable pod name = mongo-0 Fixed individual DNS name Pod Identity - Retain State, Retain Role Replicating stateful apps is complex There are lots of things you must do: Configure cloning and data synchronisation. Make remote shared storage available. Management \u0026 backup Как сохранять данные в Kubernetes?\nМы упоминали выше, что когда у нас есть приложение с состоянием, нам нужно где-то хранить состояние, и именно здесь возникает необходимость в томе, поскольку из коробки Kubernetes не обеспечивает постоянство данных.\nНам нужен уровень хранения, который не зависит от жизненного цикла стручка. Это хранилище должно быть доступно со всех наших узлов Kubernetes. Хранилище также должно находиться вне кластера Kubernetes, чтобы иметь возможность выжить, даже если кластер Kubernetes потерпит крах.\nПостоянный том Ресурс кластера (например, процессор и оперативная память) для хранения данных. Создается с помощью файла YAML. Требуется реальное физическое хранилище (NAS) Внешняя интеграция в ваш кластер Kubernetes. В вашем хранилище могут быть доступны различные типы хранилищ. PV не имеют пространства имен Локальное хранилище доступно, но оно будет специфично для одного узла в кластере Персистентность базы данных должна использовать удаленное хранилище (NAS) Утверждение о постоянном томе Постоянный том, как описано выше, может существовать и быть доступным, но пока он не заявлен приложением, он не используется.\nСоздается с помощью файла YAML Утверждение постоянного тома используется в конфигурации стручка (атрибут volumes) PVC находятся в том же пространстве имен, что и pod Том монтируется в капсулу Стручки могут иметь несколько различных типов томов (ConfigMap, Secret, PVC). Другой способ представить PVs и PVCs заключается в следующем\nPVs создаются администратором Kubernetes Admin PVC создаются пользователем или разработчиком приложения.\nУ нас также есть два других типа томов, которые мы не будем подробно описывать, но о которых стоит упомянуть:\nConfigMaps | Secrets Конфигурационный файл для вашего стручка. Файл сертификата для вашей капсулы. StorageClass Создается с помощью файла YAML Предоставляет постоянные тома динамически, когда PVC заявляет об этом. Каждый бэкенд хранилища имеет свой собственный провизор Бэкенд хранилища определяется в YAML (через атрибут provisioner) Абстракции базового провайдера хранения Определяет параметры для этого хранилища Время просмотра Во вчерашней сессии мы рассмотрели создание приложения без статических данных, здесь мы хотим сделать то же самое, но использовать наш кластер minikube для развертывания рабочей нагрузки с статическими данными.\nНапомним команду minikube, которую мы используем, чтобы иметь возможность и аддоны для использования персистентности: minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p mc-demo --kubernetes-version=1.21.2.\nЭта команда использует драйвер csi-hostpath-driver, который дает нам наш класс хранилища, что я покажу позже.\nСборка приложения выглядит следующим образом:\nВы можете найти файл конфигурации YAML для этого приложения здесь pacman-stateful-demo.yaml\nКонфигурация класса хранилища Есть еще один шаг, который мы должны выполнить перед началом развертывания нашего приложения, а именно убедиться, что наш класс хранилища (csi-hostpath-sc) является классом по умолчанию. Сначала мы можем проверить это, выполнив команду kubectl get storageclass, но из коробки кластер minikube будет показывать стандартный класс хранения по умолчанию, поэтому мы должны изменить его с помощью следующих команд.\nПервая команда сделает наш класс хранилища csi-hostpath-sc классом по умолчанию.\nkubectl patch storageclass csi-hostpath-sc -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"true\"}}}'}''\nЭта команда удалит аннотацию по умолчанию из стандартного StorageClass.\nkubectl patch storageclass standard -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"false\"}}}'}''\nНачнем с того, что в нашем кластере нет пространства имен pacman. kubectl get namespace\nЗатем мы развернем наш YAML-файл. kubectl create -f pacman-stateful-demo.yaml Из этой команды видно, что мы создаем ряд объектов в нашем кластере Kubernetes.\nТеперь у нас есть наше только что созданное пространство имен.\nИз следующего изображения и команды kubectl get all -n pacman видно, что в нашем пространстве имен происходит несколько вещей. У нас есть pods, запускающий наш NodeJS web front end, у нас есть mongo, запускающий нашу backend базу данных. Есть сервисы для pacman и mongo для доступа к этим стручкам. У нас есть развертывание для pacman и statefulset для mongo.\nУ нас также есть наши постоянные тома и утверждения постоянных томов. Выполнив команду kubectl get pv, мы получим наши постоянные тома, не связанные с именами, а выполнив команду kubectl get pvc -n pacman, мы получим наши утверждения постоянных томов, связанные с именами. Играем в игру | Я имею в виду доступ к нашему критически важному приложению Поскольку мы используем Minikube, как уже упоминалось в приложении без статических данных, нам предстоит преодолеть несколько препятствий, когда дело доходит до доступа к нашему приложению. Однако если бы у нас был доступ к ingress или балансировщику нагрузки в нашем кластере, служба настроена на автоматическое получение IP-адреса от него для получения доступа извне. (Вы можете видеть это выше на изображении всех компонентов в пространстве имен pacman).\nВ данном демонстрационном примере мы будем использовать метод проброса портов для доступа к нашему приложению. Открыв новый терминал и выполнив следующую команду kubectl port-forward svc/pacman 9090:80 -n pacman, открыв браузер, мы получим доступ к нашему приложению. Если вы запускаете это в AWS или в определенных местах, то это также сообщит об облаке и зоне, а также о хосте, который равен вашему стручку в Kubernetes, опять же, вы можете оглянуться назад и увидеть это имя стручка на наших скриншотах выше.\nТеперь мы можем пойти и создать высокий балл, который затем будет сохранен в нашей базе данных.\nХорошо, у нас есть высокий балл, но что произойдет, если мы удалим наш mongo-0 pod? Выполнив команду kubectl delete pod mongo-0 -n pacman, я могу удалить его, и если вы все еще находитесь в приложении, вы увидите, что высокий балл недоступен, по крайней мере, в течение нескольких секунд.\nТеперь, если я вернусь в свою игру, я смогу создать новую игру и увидеть свои высокие баллы. Единственный способ поверить мне в это - попробовать и поделиться в социальных сетях своими высокими результатами!\nС развертыванием мы можем увеличить масштаб с помощью команд, которые мы рассматривали в предыдущей сессии, но в частности здесь, особенно если вы хотите устроить огромную вечеринку pacman, вы можете увеличить масштаб с помощью kubectl scale deployment pacman --replicas=10 -n pacman.\nIngress объяснено Прежде чем мы закончим с Kubernetes, я также хотел бы затронуть важный аспект Kubernetes, и это - ingress.\nЧто такое ingress? До сих пор в наших примерах мы использовали port-forward или определенные команды в minikube, чтобы получить доступ к нашим приложениям, но в производстве это не сработает. Нам нужен лучший способ доступа к нашим приложениям в масштабе с множеством пользователей.\nМы также говорили о возможности использования NodePort, но это опять же должно быть только в тестовых целях.\nIngress дает нам лучший способ открыть наши приложения, он позволяет нам определить правила маршрутизации в нашем кластере Kubernetes.\nДля ingress мы создадим запрос на внутреннюю службу нашего приложения.\nКогда вам нужен ingress? Если вы используете облачный провайдер, управляемое предложение Kubernetes, то, скорее всего, у них будет своя опция ingress для вашего кластера или они предоставят вам свой собственный балансировщик нагрузки. Вам не придется реализовывать это самостоятельно, что является одним из преимуществ управляемого Kubernetes.\nЕсли вы управляете собственным кластером, вам необходимо настроить точку входа.\nНастройка Ingress на Minikube На моем конкретном запущенном кластере под названием mc-demo я могу выполнить следующую команду, чтобы включить ingress на моем кластере.\nminikube --profile='mc-demo' addons enable ingress.\nЕсли теперь мы проверим наши пространства имен, то увидим, что у нас есть новое пространство имен ingress-nginx. kubectl get ns\nТеперь мы должны создать YAML-конфигурацию ingress для запуска нашего сервиса Pacman. Я добавил этот файл в репозиторий pacman-ingress.yaml.\nЗатем мы можем создать его в нашем пространстве имен ingress с помощью kubectl create -f pacman-ingress.yaml.\nЗатем, если мы запустим kubectl get ingress -n pacman\nЗатем мне говорят, что поскольку мы используем minikube, работающий на WSL2 в Windows, мы должны создать туннель minikube, используя minikube tunnel --profile=mc-demo.\nНо я все еще не могу получить доступ к 192.168.49.2 и играть в свою игру pacman.\nЕсли у кого-нибудь есть или есть возможность заставить это работать под Windows и WSL, я буду благодарен за отзывы. Я подниму вопрос об этом в репозитории и вернусь к нему, как только у меня появится время и исправление.\nUPDATE: Мне кажется, что этот блог помогает определить причину того, что игра не работает на WSL Configuring Ingress to run Minikube on WSL2 using Docker runtime\nРесурсы Kubernetes StatefulSet simply explained Kubernetes Volumes explained Kubernetes Ingress Tutorial for Beginners Kubernetes Documentation TechWorld with Nana - Kubernetes Tutorial for Beginners [FULL COURSE in 4 Hours] TechWorld with Nana - Kubernetes Crash Course for Absolute Beginners Kunal Kushwaha - Kubernetes Tutorial for Beginners | What is Kubernetes? Architecture Simplified! На этом мы завершаем раздел Kubernetes. Существует так много дополнительных материалов, которые мы могли бы осветить на тему Kubernetes, и 7 дней дают нам базовые знания, но есть люди, которые проходят 100DaysOfKubernetes, где вы можете погрузиться в самую гущу событий.\nДалее мы рассмотрим инфраструктуру как код и ту важную роль, которую она играет с точки зрения DevOps.\n","description":"","title":"55. State и Ingress в Kubernetes","uri":"/ru/docs/90daysofdevops/day55/"},{"content":"Обзор IaC Люди совершают ошибки! Автоматизация - это путь к успеху!\nКак вы строите свои системы сегодня?\nКаков был бы ваш план, если бы вы потеряли все, физические машины, виртуальные машины, облачные виртуальные машины, облачные PaaS и т.д. и т.п.?\nСколько времени у вас уйдет на замену всего?\nИнфраструктура как код предоставляет решение, позволяющее сделать это и одновременно протестировать, не путайте это с резервным копированием и восстановлением, но что касается вашей инфраструктуры и сред, ваших платформ, мы должны быть в состоянии раскрутить их и обращаться с ними как со скотом и домашними животными.\nTLDR; заключается в том, что мы можем использовать код для восстановления всей нашей среды.\nЕсли мы также вспомним, что с самого начала мы говорили о DevOps в целом - это способ преодоления барьеров для безопасной и быстрой доставки систем в производство.\nInfrastructure as code помогает нам поставлять системы, мы говорили о множестве процессов и инструментов. IaC предлагает нам больше инструментов, с которыми мы должны быть знакомы, чтобы обеспечить эту часть процесса.\nВ этом разделе мы сосредоточимся на инфраструктуре как коде. Вы также можете услышать упоминание этого термина как “инфраструктура из кода” или “конфигурация как код”. Я думаю, что наиболее известным термином является Инфраструктура как код.\nДомашние животные против крупного рогатого скота Если мы посмотрим на до DevOps, то при необходимости создания нового приложения мы должны были подготовить наши серверы вручную.\nРазвернуть виртуальные машины | физические серверы и установить операционную систему Настроить сеть Создать таблицы маршрутизации Установить программное обеспечение и обновления Настроить программное обеспечение Установка базы данных Это ручной процесс, выполняемый системными администраторами. Чем больше приложение, тем больше ресурсов и серверов требуется, тем больше ручных усилий потребуется для создания этих систем. Это потребует огромного количества человеческих усилий и времени, но, кроме того, как компания, вы должны будете заплатить за эти ресурсы, чтобы создать эту среду. Как я уже говорил в начале раздела “Люди совершают ошибки! Автоматизация - это путь к успеху!”.\nПосле вышеупомянутой фазы начальной установки вам предстоит обслуживание этих серверов.\nОбновление версий Развертывание новых релизов Управление данными Восстановление приложений Добавление, удаление и масштабирование серверов Конфигурация сети Добавьте сюда сложность нескольких сред тестирования и разработки.\nИменно здесь на помощь приходит Infrastructure as Code. Выше было время, когда мы заботились об этих серверах, как о домашних животных, люди даже называли их домашними именами или, по крайней мере, давали им какие-то имена, потому что они должны были находиться рядом какое-то время, они должны были стать частью “семьи” на какое-то время.\nС Infrastructure as Code у нас есть возможность автоматизировать все эти задачи от конца до конца. Инфраструктура как код - это концепция, и есть инструменты, которые выполняют автоматическое обеспечение инфраструктуры. На данный момент, если с сервером случается что-то плохое, вы выбрасываете его и запускаете новый. Этот процесс автоматизирован, и сервер точно такой же, как определено в коде. В этот момент нам не важно, как они называются, они находятся в поле и служат своей цели до тех пор, пока их больше нет в поле, и нам нужно заменить их либо из-за сбоя, либо из-за обновления части или всего нашего приложения.\nЭто может быть использовано практически во всех платформах, виртуализации, облачных рабочих нагрузках, а также в облачной нативной инфраструктуре, такой как Kubernetes и контейнеры.\nОбеспечение инфраструктуры Не все IaC охватывают все перечисленное ниже, вы увидите, что инструмент, который мы будем использовать в этом разделе, охватывает только первые две области; Terraform - это тот инструмент, который мы будем рассматривать, и он позволяет нам начать с нуля и определить в коде, как должна выглядеть наша инфраструктура, а затем развернуть ее, он также позволит нам управлять этой инфраструктурой и первоначально развернуть приложение, но в этот момент он потеряет контроль над приложением, и здесь на помощь приходит следующий раздел, и что-то вроде Ansible как инструмент управления конфигурацией может работать лучше на этом фронте.\nБез забегания вперед такие инструменты, как chef, puppet и ansible, лучше всего подходят для начальной установки приложений, а затем для управления этими приложениями и их конфигурацией.\nПервоначальная установка и настройка программного обеспечения\nРазвертывание новых серверов Конфигурация сети Создание балансировщиков нагрузки Конфигурация на уровне инфраструктуры Конфигурация инфраструктуры с провизией Установка приложения на серверы Подготовьте серверы для развертывания приложения. Развертывание приложения Развертывание и управление приложением Этап обслуживания Обновления программного обеспечения Реконфигурация Различия инструментов IaC Декларативный и процедурный\nПроцедурный\nПошаговая инструкция Создайте сервер \u003e Добавьте сервер \u003e Внесите это изменение Декларативный\nобъявить конечный результат 2 сервера Изменяемые (домашние животные) против неизменяемых (крупный рогатый скот)\nМутабельный\nИзменение вместо замены Как правило, долгоживущие Неизменяемые\nЗамена вместо изменения Возможно, недолговечна Именно поэтому у нас есть множество различных вариантов Infrastructure as Code, потому что не существует одного инструмента, который бы управлял всеми.\nМы будем в основном использовать terraform и работать с ним, поскольку это лучший способ начать видеть преимущества инфраструктуры как кода в действии. Практическая работа - это также лучший способ приобрести навыки, так как вы будете писать код.\nДалее мы начнем изучать Terraform со 101-го урока, прежде чем приступим к практическому использованию.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"56. Обзор IaC","uri":"/ru/docs/90daysofdevops/day56/"},{"content":"“Terraform - это инструмент для безопасного и эффективного создания, изменения и управления версиями инфраструктуры”. «Приведенная выше цитата взята из HashiCorp, HashiCorp - это компания, стоящая за Terraform.\n“Terraform - это программный инструмент “инфраструктура как код” с открытым исходным кодом, который обеспечивает последовательный рабочий процесс CLI для управления сотнями облачных сервисов. Terraform кодирует облачные API в декларативные конфигурационные файлы”.\nУ HashiCorp есть отличный ресурс HashiCorp Learn, который охватывает все их продукты и дает несколько отличных демонстрационных примеров, когда вы пытаетесь достичь чего-то с помощью инфраструктуры как кода.\nВсе облачные провайдеры и локальные платформы обычно предоставляют нам доступ к консолям управления, которые позволяют нам создавать наши ресурсы с помощью пользовательского интерфейса, обычно эти платформы также предоставляют доступ к CLI или API для создания тех же ресурсов, но с API у нас есть возможность быстрого предоставления ресурсов.\nИнфраструктура как код позволяет нам подключаться к этим API для развертывания наших ресурсов в нужном состоянии.\nНиже перечислены и другие инструменты, но они не являются исключительными или исчерпывающими. Если у вас есть другие инструменты, пожалуйста, поделитесь с нами через PR.\nCloud Specific Cloud Agnostic AWS CloudFormation Terraform Azure Resource Manager Pulumi Google Cloud Deployment Manager Это еще одна причина, почему мы используем Terraform, мы хотим быть независимыми от облаков и платформ, которые мы хотим использовать для наших демонстраций, а также в целом.\nОбзор Terraform Terraform - это инструмент, ориентированный на обеспечение, Terraform - это CLI, который предоставляет возможности для обеспечения сложных инфраструктурных сред. С помощью Terraform мы можем определить сложные требования к инфраструктуре, существующей локально или удаленно (облако). Terraform позволяет нам не только создавать вещи на начальном этапе, но и поддерживать и обновлять эти ресурсы в течение всего срока их службы.\nЗдесь мы рассмотрим основные моменты, но для получения более подробной информации и множества ресурсов вы можете посетить сайт terraform.io.\nЗапись Terraform позволяет нам создавать декларативные конфигурационные файлы, которые будут создавать наше окружение. Файлы пишутся с помощью языка HashiCorp Configuration Language (HCL), который позволяет кратко описывать ресурсы с помощью блоков, аргументов и выражений. Мы, конечно, будем подробно рассматривать их при развертывании виртуальных машин, контейнеров и в Kubernetes.\nПлан Возможность проверить, что вышеуказанные конфигурационные файлы развернут то, что мы хотим видеть, используя определенные функции terraform cli, чтобы иметь возможность протестировать этот план перед развертыванием чего-либо или изменением чего-либо. Помните, что Terraform - это инструмент для продолжения вашей инфраструктуры, если вы хотите изменить аспект вашей инфраструктуры, вы должны сделать это через terraform, чтобы все это было зафиксировано в коде.\nПрименить Очевидно, что когда вы будете довольны, вы сможете применить эту конфигурацию к множеству провайдеров, доступных в Terraform. Вы можете увидеть большое количество доступных провайдеров здесь.\nЕще одна вещь, о которой следует упомянуть, это то, что также доступны модули, и это похоже на образы контейнеров в том, что эти модули были созданы и выложены в открытый доступ, так что вам не придется создавать их снова и снова, просто используйте лучшую практику развертывания определенного ресурса инфраструктуры одинаковым способом везде. Вы можете найти доступные модули здесь.\nРабочий процесс Terraform выглядит следующим образом: (взято с сайта terraform)\nTerraform vs Vagrant Во время этого испытания мы использовали Vagrant, который является еще одним инструментом с открытым исходным кодом от Hashicorp, сконцентрированным на средах разработки.\nVagrant - это инструмент, ориентированный на управление средами разработки.\nTerraform - это инструмент для создания инфраструктуры.\nОтличное сравнение этих двух инструментов можно найти здесь на официальном сайте Hashicorp\nУстановка Terraform В установке Terraform нет ничего сложного.\nTerraform является кроссплатформенным, и вы можете видеть ниже на моей Linux машине у нас есть несколько вариантов загрузки и установки CLI\nИспользование arkade для установки Terraform, arkade - это удобный инструмент для получения необходимых инструментов, приложений и clis на вашу систему. Простая команда arkade get terraform позволит обновить terraform, если он доступен, или эта же команда также установит Terraform CLI\nМы собираемся больше узнать о HCL, а также начать использовать Terraform для создания некоторых инфраструктурных ресурсов на различных платформах.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"57. Введение в Terraform","uri":"/ru/docs/90daysofdevops/day57/"},{"content":"Язык конфигурации HashiCorp (HCL) Прежде чем мы начнем создавать вещи с помощью Terraform, мы должны немного погрузиться в язык HashiCorp Configuration Language (HCL). До сих пор в ходе нашей задачи мы рассмотрели несколько различных языков скриптов и программирования, и вот еще один. Мы затронули язык программирования Go, затем скрипты bash, мы даже немного затронули python, когда дело дошло до автоматизации сети.\nТеперь мы должны рассмотреть язык конфигурации HashiCorp (HCL), если вы впервые видите этот язык, он может показаться немного пугающим, но он довольно прост и очень мощный.\nПо мере продвижения по этому разделу мы будем использовать примеры, которые мы можем запустить локально на нашей системе, независимо от того, какую ОС вы используете, мы будем использовать virtualbox, хотя и не инфраструктурную платформу, которую вы обычно используете с Terraform. Тем не менее, запуск этого локально, он бесплатный и позволит нам достичь того, что мы ищем в этой заметке. Мы также можем расширить концепцию этого поста на docker или Kubernetes.\nВ целом, вы будете или должны использовать Terraform для развертывания инфраструктуры в публичном облаке (AWS, Google, Microsoft Azure), а также в средах виртуализации, таких как (VMware, Microsoft Hyper-V, Nutanix AHV). В публичном облаке Terraform позволяет нам делать гораздо больше, чем просто автоматическое развертывание виртуальных машин, мы можем создавать всю необходимую инфраструктуру, такую как рабочие нагрузки PaaS, и все необходимые сетевые ресурсы, такие как VPC и группы безопасности.\nВ Terraform есть два важных аспекта: код, который мы рассмотрим в этой статье, и состояние. Оба этих аспекта вместе можно назвать ядром Terraform. Затем у нас есть среда, в которую мы хотим обратиться и развернуть, которая выполняется с помощью провайдеров Terraform, кратко упомянутых на прошлом занятии, но у нас есть провайдеры AWS, есть провайдеры Azure и т.д. Их сотни. Их сотни.\nБазовое использование Terraform Давайте посмотрим на файл Terraform .tf, чтобы увидеть, как они создаются. Первый пример, который мы рассмотрим, будет кодом для развертывания ресурсов на AWS, для этого также потребуется установить AWS CLI на вашей системе и настроить его для вашей учетной записи.\nProviders В верхней части нашей файловой структуры .tf, обычно называемой main.tf, по крайней мере до тех пор, пока мы не сделаем все более сложным. Здесь мы определим провайдеров, о которых мы упоминали ранее. Наш источник провайдера aws, как вы видите, hashicorp/aws, это означает, что провайдер поддерживается или был опубликован самой компанией hashicorp. По умолчанию вы будете ссылаться на провайдеров, доступных в Terraform Registry, у вас также есть возможность написать свои собственные провайдеры и использовать их локально или самостоятельно опубликовать в Terraform Registry.\nterraform {\rrequired_providers {\raws = {\rsource = \"hashicorp/aws\"\rversion = \"~\u003e 3.0\"\r}\r}\r}\rЗдесь мы также можем добавить регион, чтобы определить, какой регион AWS мы хотим предоставить, мы можем сделать это, добавив следующее:\nprovider \"aws\" {\rregion = \"ap-southeast-1\" //region where resources need to be deployed\r}\rResources Другой важный компонент конфигурационного файла terraform, который описывает один или несколько объектов инфраструктуры, таких как EC2, Load Balancer, VPC и т.д.\nБлок ресурсов объявляет ресурс заданного типа (“aws_instance”) с заданным локальным именем (“90daysofdevops”).\nТип ресурса и имя вместе служат идентификатором для данного ресурса.\nresource \"aws_instance\" \"90daysofdevops\" {\rami = data.aws_ami.instance_id.id\rinstance_type = \"t2.micro\"\ravailability_zone = \"us-west-2a\"\rsecurity_groups = [aws_security_group.allow_web.name]\ruser_data = \u003c\u003c-EOF\r#! /bin/bash\rsudo yum update\rsudo yum install -y httpd\rsudo systemctl start httpd\rsudo systemctl enable httpd\recho \"\r\u003ch1\u003eDeployed via Terraform\u003c/h1\u003e\r\" | sudo tee /var/www/html/index.html\rEOF\rtags = {\rName = \"Created by Terraform\"\r}\r}\rИз вышеприведенного видно, что мы также запускаем обновление yum и устанавливаем httpd в наш экземпляр ec2.\nЕсли мы теперь посмотрим на полный файл main.tf, он может выглядеть примерно так.\nterraform {\rrequired_providers {\raws = {\rsource = \"hashicorp/aws\"\rversion = \"~\u003e 3.27\"\r}\r}\rrequired_version = \"\u003e= 0.14.9\"\r}\rprovider \"aws\" {\rprofile = \"default\"\rregion = \"us-west-2\"\r}\rresource \"aws_instance\" \"90daysofdevops\" {\rami = \"ami-830c94e3\"\rinstance_type = \"t2.micro\"\ravailability_zone = \"us-west-2a\"\ruser_data = \u003c\u003c-EOF\r#! /bin/bash\rsudo yum update\rsudo yum install -y httpd\rsudo systemctl start httpd\rsudo systemctl enable httpd\recho \"\r\u003ch1\u003eDeployed via Terraform\u003c/h1\u003e\r\" | sudo tee /var/www/html/index.html\rEOF\rtags = {\rName = \"Created by Terraform\"\rtags = {\rName = \"ExampleAppServerInstance\"\r}\r}\rПриведенный выше код позволит развернуть очень простой веб-сервер в качестве экземпляра ec2 в AWS. Самое замечательное в этой и любой другой подобной конфигурации то, что мы можем повторить ее и каждый раз получать один и тот же результат. Кроме вероятности того, что я испортил код, нет никакого взаимодействия с человеком.\nМы можем рассмотреть суперпростой пример, который вы, скорее всего, никогда не будете использовать, но давайте все равно пошутим. Как и во всех хороших скриптах и языках программирования, мы должны начать со скрипта приветствия мира.\nterraform {\r# This module is now only being tested with Terraform 0.13.x. However, to make upgrading easier, we are setting\r# 0.12.26 as the minimum version, as that version added support for required_providers with source URLs, making it\r# forwards compatible with 0.13.x code.\rrequired_version = \"\u003e= 0.12.26\"\r}\r# website::tag::1:: The simplest possible Terraform module: it just outputs \"Hello, World!\"\routput \"hello_world\" {\rvalue = \"Hello, 90DaysOfDevOps from Terraform\"\r}\rВы найдете этот файл в папке IAC в разделе hello-world, но из коробки он не будет просто работать, есть несколько команд, которые необходимо выполнить, чтобы использовать наш код терраформы.\nВ терминале перейдите в папку, где был создан файл main.tf, он может быть из этого репозитория или вы можете создать новый, используя код выше.\nНаходясь в этой папке, выполните команду terraform init.\nМы должны выполнить эту команду в любой директории, где у нас есть или перед запуском любого кода terraform. Инициализация каталога конфигурации загружает и устанавливает провайдеров, определенных в конфигурации, в данном случае у нас нет провайдеров, но в примере выше это загрузит провайдера aws для этой конфигурации.\nСледующей командой будет terraform plan.\nКоманда terraform plan создает план выполнения, который позволяет вам предварительно просмотреть изменения, которые Terraform планирует внести в вашу инфраструктуру.\nВы можете видеть ниже, что на нашем примере hello-world мы увидим результат, если бы это был экземпляр AWS ec2, мы бы увидели все шаги, которые мы будем создавать.\nНа данном этапе мы инициализировали наш репозиторий, загрузили провайдеров, где это необходимо, запустили тестовый проход, чтобы убедиться, что это то, что мы хотим видеть, теперь мы можем запустить и развернуть наш код.\nКоманда terraform apply позволяет нам это сделать, в нее встроена мера безопасности, и это снова даст вам представление о том, что произойдет, что требует от вас ответа “да”, чтобы продолжить.\nКогда мы вводим “да”, чтобы ввести значение, наш код развертывается. Очевидно, это не так интересно, но вы можете видеть, что у нас есть вывод, который мы определили в нашем коде.\nТеперь мы ничего не развернули, мы ничего не добавили, не изменили и не уничтожили, но если бы мы это сделали, то мы бы увидели, что это также указано выше. Однако если мы что-то развернули и хотим избавиться от всего, что развернули, мы можем использовать команду terraform destroy. Опять же, это имеет ту безопасность, когда вы должны ввести “да”, хотя вы можете использовать --auto-approve в конце ваших команд apply и destroy, чтобы обойти это ручное вмешательство. Но я бы посоветовал использовать это сокращение только в процессе обучения и тестирования, так как все будет исчезать иногда быстрее, чем было создано.\nТаким образом, мы рассмотрели всего 4 команды из Terraform CLI.\nterraform init = подготовить папку проекта с провайдерами terraform plan = показать, что будет создано, изменено во время следующей команды на основе нашего кода. terraform apply = развернет ресурсы, определенные в нашем коде. terraform destroy = уничтожит ресурсы, которые мы создали в нашем проекте. Мы также рассмотрели два важных аспекта наших кодовых файлов.\nproviders = как terraform общается с конечной платформой через API-интерфейсы resources = что именно мы хотим развернуть с помощью кода Еще одна вещь, которую следует отметить, когда мы запускаем terraform init, посмотрите на дерево в папке до и после, чтобы увидеть, что происходит и где мы храним провайдеры и модули.\nTerraform state Нам также необходимо знать о файле состояния, который создается также внутри нашей директории, и для этого примера hello world наш файл состояния прост. Это JSON-файл, который является представлением мира в соответствии с Terraform. Состояние будет радостно демонстрировать ваши конфиденциальные данные, поэтому будьте осторожны и в качестве лучшей практики помещайте файлы .tfstate в папку .gitignore перед загрузкой на GitHub.\nПо умолчанию файл состояния, как вы видите, находится в том же каталоге, что и код вашего проекта, но его можно хранить и удаленно. В производственной среде это, скорее всего, будет общее место, например, ведро S3.\nДругим вариантом может быть Terraform Cloud, это платная управляемая услуга. (Бесплатно до 5 пользователей)\nПлюсы хранения состояния в удаленном месте заключаются в том, что мы получаем:\n{\r\"version\": 4,\r\"terraform_version\": \"1.1.6\",\r\"serial\": 1,\r\"lineage\": \"a74296e7-670d-0cbb-a048-f332696ca850\",\r\"outputs\": {\r\"hello_world\": {\r\"value\": \"Hello, 90DaysOfDevOps from Terraform\",\r\"type\": \"string\"\r}\r},\r\"resources\": []\r}\rРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"58. Язык конфигурации HashiCorp (HCL)","uri":"/ru/docs/90daysofdevops/day58/"},{"content":"Создание виртуальной машины с помощью Terraform и переменных В этой сессии мы будем создавать виртуальную машину или две виртуальные машины с помощью Terraform внутри VirtualBox. Это не совсем обычно, VirtualBox - это вариант виртуализации рабочих станций, и на самом деле это не было бы вариантом использования Terraform, но я сейчас нахожусь на высоте 36 000 футов в воздухе, и как бы я ни развертывал ресурсы публичного облака так высоко в облаках, гораздо быстрее сделать это локально на моем ноутбуке.\nЧисто демонстрационная цель, но концепция та же, мы собираемся иметь наш желаемый код конфигурации состояния, а затем мы собираемся запустить его против провайдера virtualbox. В прошлом мы использовали здесь vagrant, и я рассказал о различиях между vagrant и terraform в начале раздела.\nСоздание виртуальной машины в VirtualBox Первое, что мы сделаем, это создадим новую папку под названием virtualbox, затем мы можем создать файл virtualbox.tf, в котором мы определим наши ресурсы. Приведенный ниже код, который можно найти в папке VirtualBox под названием virtualbox.tf, создаст 2 виртуальные машины в Virtualbox.\nВы можете узнать больше о сообществе провайдера Virtualbox здесь\nterraform {\rrequired_providers {\rvirtualbox = {\rsource = \"terra-farm/virtualbox\"\rversion = \"0.2.2-alpha.1\"\r}\r}\r}\r# В настоящее время нет никаких опций конфигурации для самого провайдера.\rresource \"virtualbox_vm\" \"node\" {\rcount = 2\rname = format(\"node-%02d\", count.index + 1)\rimage = \"https://app.vagrantup.com/ubuntu/boxes/bionic64/versions/20180903.0.0/providers/virtualbox.box\"\rcpus = 2\rmemory = \"512 mib\"\rnetwork_adapter {\rtype = \"hostonly\"\rhost_interface = \"vboxnet1\"\r}\r}\routput \"IPAddr\" {\rvalue = element(virtualbox_vm.node.*.network_adapter.0.ipv4_address, 1)\r}\routput \"IPAddr_2\" {\rvalue = element(virtualbox_vm.node.*.network_adapter.0.ipv4_address, 2)\r}\rТеперь, когда мы определили наш код, мы можем выполнить terraform init для нашей папки, чтобы загрузить провайдер для virtualbox.\nОчевидно, что в вашей системе также должен быть установлен virtualbox. Затем мы можем запустить terraform plan, чтобы посмотреть, что наш код создаст для нас. Затем следует terraform apply. На рисунке ниже показан завершенный процесс.\nТеперь в Virtualbox вы увидите две виртуальные машины.\nИзменение конфигурации Давайте добавим еще один узел в наше развертывание. Мы можем просто изменить строку count, чтобы показать новое желаемое количество узлов. Когда мы запустим нашу terraform apply, она будет выглядеть примерно так, как показано ниже.\nПосле завершения работы в virtualbox вы можете увидеть, что у нас теперь есть 3 узла.\nКогда мы закончим, мы можем очистить все это с помощью команды terraform destroy, и наши машины будут удалены.\nПеременные и выходные данные Мы упоминали о выводах, когда выполняли пример hello-world на прошлом занятии. Но здесь мы можем остановиться на этом более подробно.\nНо есть много других переменных, которые мы можем использовать здесь, также есть несколько различных способов, которыми мы можем определить переменные.\nМы можем вручную ввести наши переменные с помощью команды terraform plan или terraform apply.\nМы можем определить их в .tf-файле внутри блока\nМы можем использовать переменные окружения в нашей системе, используя TF_VAR_NAME в качестве формата.\nЯ предпочитаю использовать файл terraform.tfvars в папке нашего проекта.\nСуществует опция *auto.tfvars файла\nили мы можем определить, когда запускаем terraform plan или terraform apply с помощью var или var-file.\nПорядок определения переменных будет начинаться снизу вверх.\nМы также упоминали, что файл состояния будет содержать конфиденциальную информацию. Мы можем определить нашу чувствительную информацию как переменную и определить ее как чувствительную.\nvariable \"some resource\" {\rdescription = \"something important\"\rtype: string\rsensitive = true\r}\rРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"59. Создание виртуальной машины с помощью Terraform","uri":"/ru/docs/90daysofdevops/day59/"},{"content":"DevOps - Истории компаний DevOps с самого начала считался недосягаемым для многих из нас, поскольку у нас не было среды или требований, подобных Netflix или Fortune 500, но подумайте, что теперь это начинает становиться нормой, когда мы внедряем практику DevOps внутри. любой вид бизнеса.\nПо второй ссылке ниже в справочных материалах вы увидите множество различных отраслей и вертикалей, использующих DevOps и оказывающих огромное положительное влияние на свои бизнес-цели.\nОчевидно, что основным преимуществом здесь является DevOps, если он выполнен правильно, он должен помочь вашему бизнесу повысить скорость и качество разработки программного обеспечения.\nЯ хотел использовать этот день, чтобы посмотреть на успешные компании, которые внедрили практику DevOps, и поделиться некоторыми ресурсами по этому поводу. Приняли ли вы культуру DevOps в своем бизнесе? Был ли он успешным?\nЯ упомянул Netflix выше и коснусь их снова, поскольку это очень хорошая модель, которая даже до сих пор продвинута к тому, что мы обычно видим сегодня, но также упомяну некоторые другие известные бренды, которые, похоже, преуспевают.\nAmazon В 2010 году Amazon переместила свои физические серверы в облако Amazon Web Services (AWS), что позволило им сэкономить ресурсы за счет увеличения и уменьшения емкости с очень небольшими приращениями. Мы также знаем, что это облако AWS продолжит свое существование и будет приносить огромный доход, продолжая управлять розничным филиалом компании Amazon.\nAmazon внедрила в 2011 году (согласно приведенному ниже ресурсу) непрерывный процесс развертывания, при котором их разработчики могли развертывать код в любое время и на любых серверах, которые им нужны. Это позволило Amazon добиться развертывания нового программного обеспечения на производственных серверах в среднем каждые 11,6 секунды!\nNetFlix Кто не пользуется NetFlix? очевидно, это огромный качественный потоковый сервис, который, по крайней мере, лично для всех, обеспечивает отличный пользовательский опыт.\nПочему этот пользовательский опыт так хорош? Что ж, возможность предоставить услугу без воспоминаний, по крайней мере, о сбоях, требует скорости, гибкости и внимания к качеству.\nРазработчики NetFlix могут автоматически встраивать фрагменты кода в развертываемые веб-образы, не полагаясь на ИТ-операции. По мере обновления изображений они интегрируются в инфраструктуру Netflix с помощью специально созданной веб-платформы.\nНепрерывный мониторинг выполняется таким образом, что в случае сбоя развертывания образов новые образы откатываются, а трафик перенаправляется на предыдущую версию.\nНиже приводится отличная беседа, в которой подробно рассказывается о том, что нужно и чего нельзя делать, по которым Netflix живет и умирает в своих командах.\nEtsy Как и у многих из нас и многих компаний, медленные и болезненные развертывания были настоящим испытанием. В том же духе мы могли бы также работать в компаниях, которые имеют много бункеров и команд, которые не очень хорошо работают вместе.\nИз того, что я могу понять, по крайней мере, из чтения об Amazon и Netflix, Etsy, возможно, разрешила разработчикам развертывать свой собственный код примерно в конце 2009 года, что могло быть до двух других упомянутых. (интересный!)\nИнтересный вывод, который я прочитал здесь, заключался в том, что они поняли, что когда разработчики чувствуют ответственность за развертывание, они также берут на себя ответственность за производительность приложения, время безотказной работы и другие цели.\nКультура обучения является ключевой частью DevOps, даже неудача может стать успехом, если извлечь уроки. (не уверен, откуда на самом деле взялась эта цитата, но она имеет смысл!)\nЯ добавил несколько других историй о том, как DevOps изменил правила игры в некоторых из этих чрезвычайно успешных компаний.\nИсточники How Netflix Thinks of DevOps 16 Popular DevOps Use Cases \u0026 Real Life Applications [2021] DevOps: The Amazon Story How Etsy makes DevOps work Adopting DevOps @ Scale Lessons learned at Hertz, Kaiser Permanente and lBM Interplanetary DevOps at NASA JPL Target CIO explains how DevOps took root inside the retail giant Подведем итоги наших первых дней, посвященных DevOps. DevOps — это комбинация разработки и эксплуатации, которая позволяет одной команде управлять всем жизненным циклом разработки приложения, состоящим из разработки, тестирования, развертывания, эксплуатации.\nОсновное внимание и цель DevOps — сократить жизненный цикл разработки, часто предоставляя функции, исправления и функциональные возможности в тесном соответствии с бизнес-целями.\nDevOps — это подход к разработке программного обеспечения, с помощью которого программное обеспечение может поставляться и разрабатываться надежно и быстро. Вы также можете увидеть это как Непрерывная разработка, тестирование, развертывание, мониторинг\nДо встречи в День 7\nНа седьмой день мы погрузимся в язык программирования. Я не стремлюсь быть разработчиком, но хочу понимать, что делают разработчики.\nМожем ли мы достичь этого за неделю? Вероятно, нет, но если мы потратим 7 дней или 7 часов на изучение чего-то, мы будем знать больше, чем когда мы начинали.\n","description":"DevOps - Истории","title":"6. DevOps - Истории","uri":"/ru/docs/90daysofdevops/day06/"},{"content":"В языке Python есть несколько методов создания списков и словарей, которые известны как генераторы. Существует также третий тип генератора для создания набора в Python. В этой главе мы узнаем, как использовать каждый тип генераторов. Вы увидите, что конструкция генератора основываются на знаниях, полученных из предыдущих глав, поскольку они содержат циклы и условия.\nГенераторы списков Генераторы списков в Python очень удобны. Но их также бывает трудно понять, когда и зачем их использовать. Генераторы списков, как правило, сложнее для чтения, чем простое использование цикла for. Возможно, вы захотите просмотреть главу о циклах, прежде чем продолжить.\nЕсли вы готовы, то мы потратим немного времени на рассмотрение того, как строить генераторы списков и узнаем, как их можно использовать. Генератор списка - это, по сути, однострочный цикл for, который создает структуру данных Python в виде списка. Вот простой пример:\n\u003e\u003e\u003e x = [i for i in range(5)] Давайте немного разберемся в этом. В Python есть функция range, которая может возвращать список чисел. По умолчанию она возвращает целые числа, начиная с 0 и заканчивая числом, которое вы ей передали, но не включая его. В данном случае она возвращает список, содержащий целые числа 0-4. Это может быть полезно, если вам нужно быстро создать список. Например, вы разбираете файл и ищете что-то конкретное. Вы можете использовать генератор списка в качестве своеобразного фильтра:\nif [i for i in line if \"SOME TERM\" in i]: # do something Я использовал код, подобный этому, для быстрого просмотра файла, чтобы разобрать определенные строки или разделы файла. Когда вы добавляете функции, вы можете начать делать действительно интересные вещи. Допустим, вы хотите применить функцию к каждому элементу списка, например, вам нужно преобразовать кучу строк в целые числа:\n\u003e\u003e\u003e x = ['1', '2', '3', '4', '5'] \u003e\u003e\u003e y = [int(i) for i in x] \u003e\u003e\u003e y [1, 2, 3, 4, 5] Такое встречается чаще, чем вы думаете. Мне также приходилось обращаться к списку строк и вызывать строковый метод, например, strip, потому что в них были всевозможные ведущие или конечные пробелы:\n\u003e\u003e\u003e myStrings = [s.strip() for s in myStringList] Бывают случаи, когда необходимо создать генерацию вложенного списка. Одна из причин для этого - сглаживание нескольких списков в один. Этот пример взят из документации Python:\n\u003e\u003e\u003e vec = [[1,2,3], [4,5,6], [7,8,9]] \u003e\u003e\u003e [num for elem in vec for num in elem] [1, 2, 3, 4, 5, 6, 7, 8, 9] В документации приведено несколько других интересных примеров для понимания генерации вложенных списков. Я настоятельно рекомендую взглянуть на нее! К этому моменту вы уже должны уметь применять генераторы списков в своем собственном коде и применять их хорошо. Просто используйте свое воображение, и вы начнете видеть много хороших мест, где вы тоже можете их использовать.\nТеперь мы готовы перейти к работе со словарями Python!\nГенераторы словарей Генераторы словарей появились в Python 3.0. Первоначально они были предложены в предложении 274 (PEP 274) по усовершенствованию Python еще в 2001 году. По своей организации они очень похожи на списки.\nЛучший способ понять это - просто сделать один!\n\u003e\u003e\u003e print( {i: str(i) for i in range(5)} ) {0: '0', 1: '1', 2: '2', 3: '3', 4: '4'} Это довольно простой генератор. По сути, он создает целочисленный ключ и строковое значение для каждого элемента в диапазоне. Теперь вы можете задаться вопросом, как можно использовать генерацию словаря в реальной жизни. Марк Пилгрим упомянул, что вы можете использовать это для замены ключей и значений словаря. Например, вот так:\n\u003e\u003e\u003e my_dict = {1:\"dog\", 2:\"cat\", 3:\"hamster\"} \u003e\u003e\u003e print( {value:key for key, value in my_dict.items()} ) {'hamster': 3, 'dog': 1, 'cat': 2} Это будет работать только в том случае, если генераторы словаря имеют неизменяемый тип, например, строку. В противном случае вы вызовете исключение.\nЯ также вижу, что генератор словаря может быть полезен для создания таблицы из переменных класса и их значений. Однако на данный момент мы не рассматривали классы, поэтому я не буду вас в этом запутывать.\nГенератор множеств Генератор множеств создается примерно так же, как и генератор словарей. Множество Python во многом похоже на математическое множество, поскольку в нем нет повторяющихся элементов. Вы можете создать обычное множество следующим образом:\n\u003e\u003e\u003e my_list = [1, 2, 2, 3, 4, 5, 5, 7, 8] \u003e\u003e\u003e my_set = set(my_list) \u003e\u003e\u003e my_set set([1, 2, 3, 4, 5, 7, 8]) Как видно из примера выше, вызов set удалил дубликаты из списка. Теперь давайте перепишем этот код для использования генератора set:\n\u003e\u003e\u003e my_list = [1, 2, 2, 3, 4, 5, 5, 7, 8] \u003e\u003e\u003e my_set = {x for x in my_list} \u003e\u003e\u003e my_set set([1, 2, 3, 4, 5, 7, 8]) Вы заметите, что для создания генератора set мы просто заменили квадратные скобки, которые используются в генераторе списка, на фигурные скобки, которые используются в генераторе словаря.\nПодведение итогов Теперь вы знаете, как использовать различные виды генераторов в Python. Вероятно, поначалу вам покажется, что наиболее полезным и популярным является генератор списка. Если вы начнете использовать свое воображение, я уверен, что вы сможете найти применение всем трем типам генераторов. Теперь мы готовы двигаться дальше и изучать обработку исключений!\nРесурсы https://vegibit.com/python-comprehension-tutorial/ ","description":"Python 101","title":"6. Генераторы в Python","uri":"/ru/docs/python101/chapter6_comprehensions/"},{"content":"Контейнеры и модули Docker Вчера мы развернули виртуальную машину с помощью Terraform в нашей локальной среде FREE virtualbox. В этом разделе мы собираемся развернуть контейнер Docker с некоторой конфигурацией в нашей локальной среде Docker.\nDocker Demo Для начала мы используем приведенный ниже блок кода, суть которого заключается в том, что мы хотим развернуть простое веб-приложение в docker и опубликовать его, чтобы оно было доступно в нашей сети. Мы будем использовать nginx и сделаем его доступным извне на нашем ноутбуке через localhost и порт 8000. Мы используем провайдера docker из сообщества, и вы можете видеть образ docker, который мы используем, также указанный в нашей конфигурации.\nterraform {\rrequired_providers {\rdocker = {\rsource = \"kreuzwerker/docker\"\rversion = \"2.16.0\"\r}\r}\r}\rprovider \"docker\" {}\rresource \"docker_image\" \"nginx\" {\rname = \"nginx:latest\"\rkeep_locally = false\r}\rresource \"docker_container\" \"nginx\" {\rimage = docker_image.nginx.latest\rname = \"tutorial\"\rports {\rinternal = 80\rexternal = 8000\r}\r}\rПервой задачей является использование команды terraform init для загрузки провайдера на нашу локальную машину.\nЗатем мы запускаем команду terraform apply, а затем docker ps, и вы можете увидеть, что у нас есть запущенный контейнер.\nЕсли мы откроем браузер, то перейдем по адресу http://localhost:8000/ и увидим, что у нас есть доступ к нашему контейнеру NGINX.\nВы можете узнать больше информации о Docker Provider.\nВыше приведена очень простая демонстрация того, что можно сделать с помощью Terraform плюс Docker и как мы теперь можем управлять этим в состоянии Terraform. Мы рассматривали docker compose в разделе о контейнерах, и есть небольшое пересечение между этим, инфраструктурой как код, а также Kubernetes.\nДля демонстрации того, как Terraform может справиться с более сложными задачами, мы возьмем файл docker compose для wordpress и mysql, который мы создали с помощью docker compose, и поместим его в Terraform. Вы можете найти docker-wordpress.tf\nterraform {\rrequired_providers {\rdocker = {\rsource = \"kreuzwerker/docker\"\rversion = \"2.16.0\"\r}\r}\r}\rprovider \"docker\" {}\rvariable wordpress_port {\rdefault = \"8080\"\r}\rresource \"docker_volume\" \"db_data\" {\rname = \"db_data\"\r}\rresource \"docker_network\" \"wordpress_net\" {\rname = \"wordpress_net\"\r}\rresource \"docker_container\" \"db\" {\rname = \"db\"\rimage = \"mysql:5.7\"\rrestart = \"always\"\rnetwork_mode = \"wordpress_net\"\renv = [\r\"MYSQL_ROOT_PASSWORD=wordpress\",\r\"MYSQL_PASSWORD=wordpress\",\r\"MYSQL_USER=wordpress\",\r\"MYSQL_DATABASE=wordpress\"\r]\rmounts {\rtype = \"volume\"\rtarget = \"/var/lib/mysql\"\rsource = \"db_data\"\r}\r}\rresource \"docker_container\" \"wordpress\" {\rname = \"wordpress\"\rimage = \"wordpress:latest\"\rrestart = \"always\"\rnetwork_mode = \"wordpress_net\"\renv = [\r\"WORDPRESS_DB_HOST=db:3306\",\r\"WORDPRESS_DB_USER=wordpress\",\r\"WORDPRESS_DB_NAME=wordpress\",\r\"WORDPRESS_DB_PASSWORD=wordpress\"\r]\rports {\rinternal = \"80\"\rexternal = \"${var.wordpress_port}\"\r}\r}\rМы снова помещаем это в новую папку и затем запускаем команду terraform init, чтобы извлечь необходимые нам провайдеры.\nЗатем мы запускаем команду terraform apply и смотрим на вывод docker ps, мы должны увидеть наши только что созданные контейнеры.\nЗатем мы можем перейти к нашему фронт-энду WordPress. Точно так же, как мы проходили этот процесс с docker-compose в разделе о контейнерах, теперь мы можем выполнить установку, и наши посты wordpress будут жить в нашей базе данных MySQL.\nОчевидно, что теперь мы рассмотрели контейнеры и Kubernetes в некоторых деталях, мы, вероятно, знаем, что это подходит для тестирования, но если бы вы действительно собирались запустить веб-сайт, вы бы не стали делать это только с помощью контейнеров и рассмотрели бы использование Kubernetes для достижения этой цели, Далее мы рассмотрим использование Terraform с Kubernetes.\nProvisioners Провайдеры существуют для того, чтобы если что-то не может быть декларировано, у нас был способ разобрать это для нашего развертывания.\nЕсли у вас нет другой альтернативы, и добавление такой сложности в ваш код - это то, что вам нужно, то вы можете сделать это, выполнив что-то похожее на следующий блок кода.\nресурс \"docker_container\" \"db\" { # ...\rprovisioner \"local-exec\" {\rcommand = \"echo The server's IP address is ${self.private_ip}\"\r}\r}\rУдаленный исполнительный провайдер вызывает скрипт на удаленном ресурсе после его создания. Это может быть использовано для чего-то специфического для ОС, или это может быть использовано для обертывания в инструмент управления конфигурацией. Хотя заметьте, что некоторые из них мы уже рассмотрели в собственных провайдерах.\nСредство подготовки удаленных исполняемых файлов вызывает скрипт на удаленном ресурсе после его создания. Это может быть использовано для чего-то определенного для ОС или может быть использовано для включения инструмента управления конфигурацией. Хотя обратите внимание, что у нас есть некоторые из них, покрытые их собственными провизорами. Подробнее о провизорах](https://www.terraform.io/language/resources/provisioners/syntax)\nfile local-exec remote-exec vendor ansible chef puppet Модули Модули - это контейнеры для нескольких ресурсов, которые используются вместе. Модуль состоит из коллекции файлов .tf в одном каталоге.\nМодули - это хороший способ разделить ресурсы инфраструктуры, а также возможность использовать уже созданные сторонние модули, чтобы не изобретать колесо.\nНапример, если бы мы хотели использовать один и тот же проект для создания нескольких виртуальных машин, VPC, групп безопасности, а затем кластера Kubernetes, мы бы, вероятно, захотели разделить наши ресурсы на модули, чтобы лучше определить наши ресурсы и их группировку.\nЕще одним преимуществом модулей является то, что вы можете взять эти модули и использовать их в других проектах или публично поделиться ими, чтобы помочь сообществу.\nМы разбиваем нашу инфраструктуру на компоненты, компоненты известны здесь как модули.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"60. Контейнеры, провайдеры и модули Docker","uri":"/ru/docs/90daysofdevops/day60/"},{"content":"Kubernetes и множественные среды До сих пор в этом разделе, посвященном инфраструктуре как коду, мы рассматривали развертывание виртуальных машин, хотя и с помощью virtualbox, но суть одна и та же: мы определяем в коде, как должна выглядеть наша виртуальная машина, а затем развертываем ее. То же самое касается контейнеров Docker, и на этом занятии мы рассмотрим, как Terraform можно использовать для взаимодействия с ресурсами, поддерживаемыми Kubernetes.\nЯ использовал Terraform для развертывания своих кластеров Kubernetes в демонстрационных целях на трех основных облачных провайдерах, и вы можете найти репозиторий tf_k8deploy.\nОднако вы также можете использовать Terraform для взаимодействия с объектами внутри кластера Kubernetes, это может быть использование Kubernetes provider или Helm provider для управления развертыванием диаграмм.\nТеперь мы можем использовать kubectl, как мы показывали в предыдущих разделах. Но есть некоторые преимущества использования Terraform в вашей среде Kubernetes.\nУнифицированный рабочий процесс - если вы использовали Terraform для развертывания кластеров, вы можете использовать тот же рабочий процесс и инструмент для развертывания в кластерах Kubernetes.\nУправление жизненным циклом - Terraform - это не просто инструмент инициализации, он позволяет вносить изменения, обновления и удаления.\nПростая демонстрация Kubernetes Подобно демо, которое мы создали на прошлом занятии, мы можем развернуть nginx в нашем кластере Kubernetes, я снова буду использовать minikube в демонстрационных целях. Мы создаем наш файл Kubernetes.tf, который вы можете найти в папке.\nВ этом файле мы определим нашего провайдера Kubernetes, укажем на наш файл kubeconfig, создадим пространство имен nginx, затем создадим развертывание, содержащее 2 реплики и, наконец, сервис.\nterraform {\rrequired_providers {\rkubernetes = {\rsource = \"hashicorp/kubernetes\"\rversion = \"\u003e= 2.0.0\"\r}\r}\r}\rprovider \"kubernetes\" {\rconfig_path = \"~/.kube/config\"\r}\rresource \"kubernetes_namespace\" \"test\" {\rmetadata {\rname = \"nginx\"\r}\r}\rresource \"kubernetes_deployment\" \"test\" {\rmetadata {\rname = \"nginx\"\rnamespace = kubernetes_namespace.test.metadata.0.name\r}\rspec {\rreplicas = 2\rselector {\rmatch_labels = {\rapp = \"MyTestApp\"\r}\r}\rtemplate {\rmetadata {\rlabels = {\rapp = \"MyTestApp\"\r}\r}\rspec {\rcontainer {\rimage = \"nginx\"\rname = \"nginx-container\"\rport {\rcontainer_port = 80\r}\r}\r}\r}\r}\r}\rresource \"kubernetes_service\" \"test\" {\rmetadata {\rname = \"nginx\"\rnamespace = kubernetes_namespace.test.metadata.0.name\r}\rspec {\rselector = {\rapp = kubernetes_deployment.test.spec.0.template.0.metadata.0.labels.app\r}\rtype = \"NodePort\"\rport {\rnode_port = 30201\rport = 80\rtarget_port = 80\r}\r}\r}\rПервое, что мы должны сделать в папке нашего нового проекта, это выполнить команду terraform init.\nА затем, прежде чем мы выполним команду terraform apply, позвольте мне показать вам, что у нас нет пространств имен.\nКогда мы запустим нашу команду apply, она создаст эти 3 новых ресурса, пространство имен, развертывание и сервис в нашем кластере Kubernetes.\nТеперь мы можем взглянуть на развернутые ресурсы в нашем кластере.\nТеперь, поскольку мы используем minikube, и вы видели в предыдущем разделе, это имеет свои собственные ограничения, когда мы пытаемся играть с сетью docker для ingress. Но если мы просто выполним команду kubectl port-forward -n nginx svc/nginx 30201:80 и откроем браузер на http://localhost:30201/, мы увидим нашу страницу NGINX.\nЕсли вы хотите попробовать более подробные демонстрации с Terraform и Kubernetes, то на сайте HashiCorp Learn site вы сможете ознакомиться с ними.\nМножественные окружения Если мы хотим взять любой из демонстрационных примеров, которые мы проверили, но теперь хотим, чтобы определенные среды производства, постановки и разработки выглядели одинаково и использовали этот код, есть два подхода для достижения этого с помощью Terraform\nтерраформенные рабочие пространства - несколько именованных разделов в рамках одного бэкенда\nфайловая структура - расположение каталогов обеспечивает разделение, модули обеспечивают повторное использование.\nКаждый из этих подходов имеет свои плюсы и минусы.\nterraform workspaces Плюсы\nЛегко начать работу Удобное выражение terraform.workspace Минимизирует дублирование кода Минусы\nСклонность к человеческим ошибкам (мы пытались устранить это, используя TF) Состояние хранится в одном бэкенде Кодовая база не показывает однозначно конфигурации развертывания. Файловая структура Плюсы\nИзоляция бэкендов повышенная безопасность снижен потенциал для человеческих ошибок Кодовая база полностью представляет развернутое состояние Минусы\nТребуется многократное применение terraform для обеспечения окружения больше дублирования кода, но его можно минимизировать с помощью модулей. Ресурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform ","description":"","title":"61. Kubernetes и множественные среды","uri":"/ru/docs/90daysofdevops/day61/"},{"content":"Тестирование, инструменты и альтернативы Завершая этот раздел об инфраструктуре как коде, мы должны упомянуть о тестировании нашего кода, различных доступных инструментах, а также о некоторых альтернативах Terraform для достижения этой цели. Как я уже говорил в начале раздела, я остановился на Terraform, поскольку он, во-первых, бесплатный и с открытым исходным кодом, во-вторых, он кроссплатформенный и не зависит от окружения. Но есть и альтернативы, которые следует рассмотреть, но общая цель состоит в том, чтобы донести до людей, что это способ развертывания инфраструктуры.\nCode Rot Первая область, которую я хочу затронуть в этой сессии, - это гниение кода. В отличие от кода приложений, инфраструктура как код может использоваться, а затем не использоваться в течение очень долгого времени. Возьмем пример: мы собираемся использовать Terraform для развертывания нашей среды VM в AWS, все идеально, все работает с первого раза, и у нас есть наша среда, но эта среда не меняется слишком часто, поэтому код остается в состоянии, возможно, или, надеюсь, хранится в центральном месте, но код не меняется.\nА что если что-то изменится в инфраструктуре? Но это делается вне диапазона, или другие вещи меняются в нашей среде.\nВнеполосные изменения (Out of band changes) Неприкрепленные версии (Unpinned versions) Утратившие актуальность зависимости (Deprecated dependancies) Неприменимые изменения (Unapplied changes) Тестирование Еще одна огромная область, которая следует за гниением кода и в целом, это возможность протестировать ваш IaC и убедиться, что все области работают так, как должны.\nПрежде всего, есть несколько встроенных команд тестирования, на которые мы можем взглянуть:\nCommand Description terraform fmt Rewrite Terraform configuration files to a canonical format and style. terraform validate Validates the configuration files in a directory, referring only to the configuration terraform plan Creates an execution plan, which lets you preview the changes that Terraform plans to make Custom validation Validation of your input variables to ensure they match what you would expect them to be У нас также есть некоторые инструменты тестирования, доступные вне Terraform:\ntflint\nНайти возможные ошибки (Find possible errors) Предупреждать об устаревшем синтаксисе, неиспользуемых объявлениях. (Warn about deprecated syntax, unused declarations.) Применять лучшие практики, соглашения об именовании. (Enforce best practices, naming conventions.) Инструменты сканирования\ncheckov - сканирование конфигураций облачной инфраструктуры для поиска неправильных конфигураций до их развертывания. tfsec - сканер безопасности статического анализа для кода Terraform. terrascan - статический анализатор кода для Infrastructure as Code. terraform-compliance - легковесный тестовый фреймворк, ориентированный на безопасность и соответствие требованиям, для terraform, позволяющий проводить негативное тестирование вашей инфраструктуры как кода. snyk - сканирует код Terraform на предмет неправильной конфигурации и проблем безопасности. Управляемое облачное предложение\nTerraform Sentinel - встроенный фреймворк политики как кода, интегрированный с продуктами HashiCorp Enterprise. Она позволяет принимать решения о политике на основе логики и может быть расширена для использования информации из внешних источников. Автоматизированное тестирование\nTerratest - Terratest - это библиотека Go, которая предоставляет шаблоны и вспомогательные функции для инфраструктуры тестирования. Стоит упомянуть\nTerraform Cloud - Terraform Cloud - это управляемый сервис компании HashiCorp. Оно устраняет необходимость в ненужных инструментах и документации для практиков, команд и организаций для использования Terraform в производстве.\nTerragrunt - Terragrunt - это тонкая обертка, которая предоставляет дополнительные инструменты для сохранения DRY конфигураций, работы с несколькими модулями Terraform и управления удаленным состоянием.\nAtlantis - Terraform Pull Request Automation.\nАльтернативы В день 57, когда мы начали этот раздел, мы упоминали, что есть некоторые альтернативы, и я очень планирую изучить их после завершения этой задачи.\nCloud Specific Cloud Agnostic AWS CloudFormation Terraform Azure Resource Manager Pulumi Google Cloud Deployment Manager Я использовал AWS CloudFormation, вероятно, больше всего из вышеперечисленного списка, он является родным для AWS, но я не использовал другие, кроме Terraform. Как вы можете себе представить, версии для конкретных облаков очень хороши для конкретного облака, но если у вас несколько облачных сред, то вам будет сложно перенести эти конфигурации или у вас будет несколько плоскостей управления для ваших усилий IaC.\nЯ думаю, что следующим интересным шагом для меня будет уделить некоторое время и узнать больше о Pulumi.\nИз сравнения Pulumi на их сайте\n“И Terraform, и Pulumi предлагают модель инфраструктуры желаемого состояния как кода, где код представляет желаемое состояние инфраструктуры, а механизм развертывания сравнивает это желаемое состояние с текущим состоянием стека и определяет, какие ресурсы должны быть созданы, обновлены или удалены”.\nСамое большое отличие, которое я вижу, заключается в том, что в отличие от HashiCorp Configuration Language (HCL) Pulumi позволяет использовать языки общего назначения, такие как Python, TypeScript, JavaScript, Go и .NET.\nКраткий обзор Introduction to Pulumi: Modern Infrastructure as Code Мне нравится простота и возможность выбора, которую вам предлагают, и я хочу разобраться в этом немного подробнее.\nНа этом мы завершаем раздел “Инфраструктура как код” и переходим к тому, что немного пересекается с управлением конфигурацией, и, в частности, по мере того, как мы переходим к общей картине управления конфигурацией, мы будем использовать Ansible для некоторых из этих задач и демонстраций.\nРесурсы What is Infrastructure as Code? Difference of Infrastructure as Code Tools Terraform Tutorial | Terraform Course Overview 2021 Terraform explained in 15 mins | Terraform Tutorial for Beginners Terraform Course - From BEGINNER to PRO! HashiCorp Terraform Associate Certification Course Terraform Full Course for Beginners KodeKloud - Terraform for DevOps Beginners + Labs: Complete Step by Step Guide! Terraform Simple Projects Terraform Tutorial - The Best Project Ideas Awesome Terraform Pulumi - IaC in your favorite programming language! ","description":"","title":"62. Terraform - Тестирование, инструменты и альтернативы","uri":"/ru/docs/90daysofdevops/day62/"},{"content":"Введение: Управление конфигурацией Сразу после раздела, посвященного инфраструктуре как коду, мы, вероятно, будем говорить об управлении конфигурацией или управлении конфигурацией приложений.\nУправление конфигурацией - это процесс поддержания приложений, систем и серверов в требуемом состоянии. Пересечение с Infrastructure as code заключается в том, что IaC гарантирует, что ваша инфраструктура находится в желаемом состоянии, но после этого, особенно terraform, не будет заботиться о желаемом состоянии настроек вашей ОС или приложений, и именно здесь на помощь приходят инструменты управления конфигурацией. Убедитесь, что система и приложения работают так, как ожидается, поскольку изменения происходят в Deane.\nУправление конфигурацией убережет вас от внесения мелких или крупных изменений, которые останутся недокументированными.\nПочему вы хотите использовать управление конфигурацией Сценарий или почему вы хотите использовать управление конфигурацией, познакомьтесь с Дином. Он наш системный администратор, и Дин - счастливый турист, который работает над всеми своими системами. работает над всеми системами в своем окружении.\nЧто произойдет, если их система выйдет из строя, если случится пожар, сервер выйдет из строя? Дин точно знает, что делать, он может легко устранить пожар, но если несколько серверов начнут выходить из строя, особенно если у вас большая и расширяющаяся среда, вот почему Дину действительно необходимо иметь инструмент управления конфигурацией. Инструменты управления конфигурацией могут помочь Дину выглядеть как рок-звезда, все, что ему нужно сделать, это настроить правильные коды, которые позволят ему быстро, эффективно и масштабно передать инструкции по настройке каждого из серверов.\nИнструменты управления конфигурацией Существует множество инструментов управления конфигурацией, и каждый из них имеет специфические особенности, которые делают его лучше для одних ситуаций, чем для других.\nНа этом этапе мы быстро рассмотрим варианты, показанные на рисунке выше, прежде чем сделать выбор, какой из них мы будем использовать и почему.\nChef\nChef обеспечивает последовательное применение конфигурации в любой среде, в любом масштабе с помощью автоматизации инфраструктуры. Chef - это инструмент с открытым исходным кодом, разработанный компанией OpsCode и написанный на Ruby и Erlang. Chef лучше всего подходит для организаций, которые имеют гетерогенную инфраструктуру и ищут зрелые решения. Рецепты и Cookbooks определяют код конфигурации для ваших систем. Pro - Доступна большая коллекция рецептов Pro - Хорошо интегрируется с Git, что обеспечивает надежный контроль версий. Против - Крутая кривая обучения, требуется значительное количество времени. Против - Главный сервер не имеет большого контроля. Архитектура - сервер / клиенты Простота настройки - Умеренная Язык - Процедурный - Указать, как выполнить задачу Puppet\nPuppet - это инструмент управления конфигурацией, который поддерживает автоматическое развертывание. Puppet построен на Ruby и использует DSL для написания манифестов. Puppet также хорошо работает с гетерогенной инфраструктурой, где основное внимание уделяется масштабируемости. За - Большое сообщество поддержки. За - Хорошо развитый механизм отчетности. Против - Продвинутые задачи требуют знания языка Ruby. Против - Главный сервер не имеет большого контроля. Архитектура - сервер / клиенты Простота установки - Умеренная Язык - Декларативный - указывать только то, что нужно делать Ansible\nAnsible - это инструмент автоматизации ИТ, который автоматизирует управление конфигурацией, предоставление облака, развертывание и оркестровку. Ядро плейбуков Ansible написано на языке YAML. (Следует сделать раздел о YAML, так как мы уже несколько раз сталкивались с этим). Ansible хорошо работает в средах, где основное внимание уделяется быстрой настройке и запуску. Работает на основе плейбуков, которые предоставляют инструкции вашим серверам. Pro - Не нужны агенты на удаленных узлах. Pro - YAML легко изучить. Против - Скорость работы часто ниже, чем у других инструментов (быстрее, чем Дин делает это сам вручную). Против - YAML не такой мощный, как Ruby, но его легче освоить. Архитектура - Только клиент Простота настройки - Очень просто Язык - Процедурный - Указать, как выполнить задачу SaltStack\nSaltStack - это инструмент на основе CLI, который автоматизирует управление конфигурацией и удаленное выполнение. SaltStack основан на Python, а инструкции написаны на YAML или собственном DSL. Идеально подходит для сред, где приоритетом является масштабируемость и отказоустойчивость. Плюсы - Простота использования при запуске Плюсы - Хороший механизм отчетности Против - Фаза установки сложная Против - Новый веб-уи, который гораздо менее проработан, чем другие. Архитектура - сервер / клиенты Простота установки - Умеренная Язык - Декларативный - указывайте только то, что нужно делать Ansible vs Terraform Инструментом, который мы будем использовать для этого раздела, будет Ansible. (Простой в использовании и требуются основы языка).\nЯ думаю, что важно коснуться некоторых различий между Ansible и Terraform, прежде чем мы рассмотрим инструментарий немного подробнее. | |Ansible |Terraform | | ————- | ————————————————————- | —————————————————————– | |Type |Ansible is a configuration management tool |Terraform is a an orchestration tool | |Infrastructure |Ansible provides support for mutable infrastructure |Terraform provides support for immutable infrastructure | |Language |Ansible follows procedural language |Terraform follows a declartive language | |Provisioning |Ansible provides partial provisioning (VM, Network, Storage) |Terraform provides extensive provisioning (VM, Network, Storage) | |Packaging |Ansible provides complete support for packaging \u0026 templating |Terraform provides partial support for packaging \u0026 templating | |Lifecycle Mgmt |Ansible does not have lifecycle management |Terraform is heavily dependant on lifecycle and state mgmt |\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! ","description":"","title":"63. Инструменты управления конфигурацией - Ansible/Terraform","uri":"/ru/docs/90daysofdevops/day63/"},{"content":"Основы Ansible\nAnsible: Начало работы Мы немного рассказали о том, что такое Ansible, на вчерашней большой сессии, но здесь мы собираемся начать с более подробной информации. Во-первых, Ansible поставляется компанией RedHat. Во-вторых, это агент, подключается через SSH и выполняет команды. В-третьих, он кроссплатформенный (Linux \u0026 macOS, WSL2) и с открытым исходным кодом (есть также платный корпоративный вариант) Ansible толкает конфигурацию по сравнению с другими моделями.\nУстановка Ansible Как вы можете себе представить, RedHat и команда Ansible проделали фантастическую работу по документированию Ansible. Обычно это начинается с шагов по установке, которые вы можете найти здесь. Помните, мы говорили, что Ansible - это инструмент автоматизации без агентов, инструмент развертывается на системе, называемой “узел управления”, с этого узла управления осуществляется управление машинами и другими устройствами (возможно, сетевыми) по SSH.\nВ документации по ссылке выше говорится, что ОС Windows не может использоваться в качестве узла управления.\nДля моего узла управления и, по крайней мере, для этой демонстрации я собираюсь использовать виртуальную машину Linux, которую мы создали еще в разделе Linux в качестве узла управления.\nЭта система работала под управлением Ubuntu, и для ее установки достаточно выполнить следующие команды.\nsudo apt update\rsudo apt install software-properties-common\rsudo add-apt-repository --yes --update ppa:ansible/ansible\rsudo apt install ansible\rТеперь у нас должна быть установлена ansible на нашем узле управления, вы можете проверить это, запустив ansible --version, и вы должны увидеть что-то похожее на это ниже.\nПрежде чем мы перейдем к управлению другими узлами в нашей среде, мы также можем проверить функциональность ansible, выполнив команду на нашей локальной машине ansible localhost -m ping будет использовать Ansible Module, и это быстрый способ выполнить одну задачу на многих различных системах. Я имею в виду, что это не очень весело только с локальным хостом, но представьте, что вы хотите получить что-то или убедиться, что все ваши системы работают, а у вас 1000+ серверов и устройств.\nИли реальное использование модуля в реальной жизни может быть чем-то вроде ansible webservers --m service -a \"name=httpd state=started\", это скажет нам, запущена ли служба httpd на всех наших веб-серверах. Я привел термин webservers, используемый в этой команде.\nhosts Как я использовал localhost выше для запуска простого модуля ping против системы, я не могу указать другую машину в моей сети, например, в среде, которую я использую, мой хост Windows, на котором работает VirtualBox, имеет сетевой адаптер с IP 10.0.0.1, но вы можете видеть ниже, что я могу связаться с ним с помощью ping, но я не могу использовать ansible для выполнения этой задачи.\nДля того чтобы указать наши узлы или узлы, которые мы хотим автоматизировать с помощью этих задач, нам необходимо их определить. Мы можем определить их, перейдя в каталог /etc/ansible в вашей системе.\nФайл, который мы хотим отредактировать - это файл hosts, используя текстовый редактор, мы можем зайти в него и определить наши хосты. Файл hosts содержит множество отличных инструкций по использованию и изменению файла. Мы хотим прокрутить вниз и создать новую группу под названием [windows] и добавить наш IP-адрес 10.0.0.1 для этого хоста. Сохраните файл.\nОднако помните, я говорил, что вам понадобится SSH, чтобы Ansible мог подключиться к вашей системе. Как вы можете видеть ниже, когда я запускаю ansible windows -m ping, мы получаем недостижимый результат, потому что не удалось подключиться через SSH.\nТеперь я также начал добавлять дополнительные хосты в наш инвентарь, другое название для этого файла, так как здесь вы собираетесь определить все ваши устройства, это могут быть сетевые устройства, например, коммутаторы и маршрутизаторы, которые также будут добавлены сюда и сгруппированы. В нашем файле hosts я также добавил свои учетные данные для доступа к группе систем linux.\nТеперь, если мы запустим ansible linux -m ping, мы получим успех, как показано ниже.\nДалее у нас есть требования к узлам, это целевые системы, на которых вы хотите автоматизировать конфигурацию. Мы не устанавливаем на них ничего для Ansible (то есть, мы можем установить программное обеспечение, но нам не нужен клиент Ansible). Ansible будет устанавливать соединение по SSH и отправлять все по SFTP (если вы хотите и у вас настроен SSH, вы можете использовать SCP против SFTP).\nКоманды Ansible Вы видели, что мы смогли запустить ansible linux -m ping на нашей Linux машине и получить ответ, в принципе, с Ansible у нас есть возможность запускать множество специальных команд. Но очевидно, что вы можете запустить это против группы систем и получить эту информацию обратно. ad hoc commands\nЕсли вы сталкиваетесь с повторением команд или, что еще хуже, вам приходится входить в отдельные системы для выполнения этих команд, то Ansible может помочь в этом случае. Например, простая команда ниже даст нам вывод всех сведений об операционной системе для всех систем, которые мы добавим в нашу группу linux. ansible linux -a \"cat /etc/os-release\".\nДругими вариантами использования могут быть перезагрузка систем, копирование файлов, управление упаковщиками и пользователями. Вы также можете объединить специальные команды с модулями Ansible.\nСпециальные команды используют декларативную модель, рассчитывая и выполняя действия, необходимые для достижения заданного конечного состояния. Они достигают идемпотентности, проверяя текущее состояние перед началом работы и ничего не делая, если текущее состояние не отличается от заданного конечного состояния.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! ","description":"","title":"64. Ansible Введение","uri":"/ru/docs/90daysofdevops/day64/"},{"content":"Ansible Playbooks В этом разделе мы рассмотрим основную причину, которую я вижу, по крайней мере, для Ansible. Я имею в виду, что это здорово - взять одну команду и обратиться ко многим различным серверам для выполнения простых команд, таких как перезагрузка длинного списка серверов и избавление от необходимости подключаться к каждому из них по отдельности.\nНо как насчет того, чтобы взять голую операционную систему, объявить программное обеспечение и службы, которые мы хотим запустить на этой системе, и убедиться, что все они работают в нужном состоянии.\nЗдесь на помощь приходят учебники Ansible. Плейбук позволяет нам взять группу серверов и выполнить задачи конфигурации и установки для этой группы.\nФормат плейбука Плейбук \u003e Игры \u003e Задачи\nЕсли вы занимаетесь спортом, вы, возможно, сталкивались с термином “плейбук”. Плейбук рассказывает команде о том, как вы будете играть, состоящий из различных пьес и задач. Если мы считаем пьесы декорациями в спорте или игре, а задачи связаны с каждой пьесой, у вас может быть несколько задач, составляющих пьесу, а в плейбуке может быть несколько различных пьес.\nЭти плейбуки написаны на YAML (YAML - это не язык разметки), вы найдете много разделов, которые мы уже рассмотрели, особенно контейнеры и Kubernetes, в которых используются файлы конфигурации в формате YAML.\nДавайте рассмотрим простой плейбук под названием playbook.yml.\n- name: Simple Play\rhosts: localhost\rconnection: local\rtasks:\r- name: Ping me\rping:\r- name: print os\rdebug:\rmsg: \"{{ ansible_os_family }}\"\rВы найдете вышеуказанный файл simple_play. Если мы затем используем команду ansible-playbook simple_play.yml, то пройдем следующие шаги.\nВы видите, что первая задача “сбор шагов” произошла, но мы не вызывали или не просили об этом? Этот модуль автоматически вызывается плейбуками для сбора полезных переменных об удаленных хостах. ansible.builtin.setup\nНашей второй задачей было установить ping, это не ICMP ping, а python скрипт, который сообщает pong об успешном соединении с удаленным или локальным хостом. ansible.builtin.ping\nЗатем наша третья или на самом деле вторая определенная задача, так как первая будет выполняться, если вы не отключите печать сообщения, сообщающего нам о нашей ОС. В этой задаче мы используем условия, мы можем запустить этот плейбук на всех различных типах операционных систем, и это вернет нам имя ОС. Мы просто передаем этот вывод для удобства, но мы могли бы добавить задачу, чтобы сказать что-то вроде:\ntasks: - name: \"shut down Debian flavoured systems\"\rcommand: /sbin/shutdown -t now when: ansible_os_family == \"Debian\"\rVagrant для настройки нашего окружения Мы будем использовать Vagrant для настройки нашего узлового окружения, я собираюсь оставить разумные 4 узла, но вы, надеюсь, увидите, что их может быть 300 или 3000. В этом и заключается сила Ansible и других инструментов управления конфигурацией, чтобы иметь возможность настраивать ваши серверы.\nВы можете найти этот файл здесь (Vagrantfile)\nVagrant.configure(\"2\") do |config|\rservers=[\r{\r:hostname =\u003e \"db01\",\r:box =\u003e \"bento/ubuntu-21.10\",\r:ip =\u003e \"192.168.169.130\",\r:ssh_port =\u003e '2210'\r},\r{\r:hostname =\u003e \"web01\",\r:box =\u003e \"bento/ubuntu-21.10\",\r:ip =\u003e \"192.168.169.131\",\r:ssh_port =\u003e '2211'\r},\r{\r:hostname =\u003e \"web02\",\r:box =\u003e \"bento/ubuntu-21.10\",\r:ip =\u003e \"192.168.169.132\",\r:ssh_port =\u003e '2212'\r},\r{\r:hostname =\u003e \"loadbalancer\",\r:box =\u003e \"bento/ubuntu-21.10\",\r:ip =\u003e \"192.168.169.134\",\r:ssh_port =\u003e '2213'\r}\r]\rconfig.vm.base_address = 600\rservers.each do |machine|\rconfig.vm.define machine[:hostname] do |node|\rnode.vm.box = machine[:box]\rnode.vm.hostname = machine[:hostname]\rnode.vm.network :public_network, bridge: \"Intel(R) Ethernet Connection (7) I219-V\", ip: machine[:ip]\rnode.vm.network \"forwarded_port\", guest: 22, host: machine[:ssh_port], id: \"ssh\"\rnode.vm.provider :virtualbox do |v|\rv.customize [\"modifyvm\", :id, \"--memory\", 2048]\rv.customize [\"modifyvm\", :id, \"--name\", machine[:hostname]]\rend\rend\rend\rend\rИспользуйте команду vagrant up, чтобы запустить эти машины в VirtualBox, Вы можете добавить больше памяти, а также определить разные частные_сетевые адреса для каждой машины, но это работает в моей среде. Помните, что наш блок управления - это рабочий стол Ubuntu, который мы установили в разделе Linux.\nЕсли вы ограничены в ресурсах, вы также можете запустить vagrant up web01 web02, чтобы поднять только веб-серверы, которые мы используем здесь.\nКонфигурация хоста Ansible Теперь, когда наша среда готова, мы можем проверить ansible, и для этого мы будем использовать наш рабочий стол Ubuntu (вы можете использовать его, но вы также можете использовать любую машину на базе Linux в вашей сети, доступную для сети ниже) в качестве нашего управления, давайте также добавим новые узлы в нашу группу в файле ansible hosts, Вы можете считать этот файл инвентаризацией, альтернативой этому может быть другой файл инвентаризации, который вызывается как часть вашей команды ansible с -i filename, это может быть полезно по сравнению с использованием файла host, так как вы можете иметь разные файлы для разных сред, например, production, test и staging. Поскольку мы используем стандартный файл hosts, нам не нужно его указывать, так как он будет использоваться по умолчанию.\nЯ добавил следующее в файл hosts по умолчанию.\n[control]\ransible-control\r[proxy] loadbalancer\r[webservers] web01\rweb02\r[database] db01\rПрежде чем двигаться дальше, мы хотим убедиться, что можем выполнить команду для наших узлов, давайте выполним ansible nodes -m command -a hostname, эта простая команда проверит, что у нас есть подключение и сообщит имена наших узлов.\nТакже обратите внимание, что я добавил эти узлы и IP на мой узел управления Ubuntu в файл /etc/hosts для обеспечения подключения. Нам также может понадобиться выполнить конфигурацию SSH для каждого узла с блока Ubuntu.\n192.168.169.140 ansible-control\r192.168.169.130 db01\r192.168.169.131 web01\r192.168.169.132 web02\r192.168.169.133 loadbalancer\rНа этом этапе мы хотим выполнить настройку SSH ключей между узлами управления и сервера. Это то, что мы будем делать дальше, другим способом здесь может быть добавление переменных в ваш файл hosts для указания имени пользователя и пароля. Я бы не советовал этого делать, так как это никогда не будет лучшей практикой.\nЧтобы настроить SSH и общий доступ между узлами, выполните следующие шаги, вам будет предложено ввести пароль (vagrant), и вам, вероятно, придется нажать y несколько раз, чтобы согласиться.\nssh-keygen\nssh-copy-id localhost\nТеперь, если все ваши ВМ включены, вы можете запустить команду ssh-copy-id web01 \u0026\u0026 ssh-copy-id web02 \u0026\u0026 ssh-copy-id loadbalancer \u0026\u0026 ssh-copy-id db01, которая запросит у вас пароль, в нашем случае пароль vagrant.\nЯ не запускаю все свои виртуальные машины, а запускаю только веб-серверы, поэтому я выдал команду sh-copy-id web01 \u0026\u0026 ssh-copy-id web02.\nПеред запуском любых плейбуков я хочу убедиться, что у меня есть простое соединение с моими группами, поэтому я запустил ansible webservers -m ping для проверки соединения.\nНаш первый “настоящий” плейбук Ansible Наш первый плейбук Ansible будет настраивать наши веб-серверы, мы сгруппировали их в нашем файле hosts под группировкой [webservers].\nПеред запуском нашего плейбука мы можем убедиться, что на web01 и web02 не установлен apache. В верхней части скриншота ниже показано расположение папок и файлов, которые я создал в моей системе управления ansible для запуска этого плейбука, у нас есть playbook1.yml, затем в папке templates у нас есть файлы index.html.j2 и ports.conf.j2. Вы можете найти эти файлы в папке, указанной выше в репозитории.\nЗатем мы подключаемся по SSH к web01, чтобы проверить, установлен ли у нас apache?\nИз вышеприведенного видно, что у нас не установлен apache на web01, поэтому мы можем исправить это, запустив следующий плейбук.\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps\"\rtasks:\r- name: ensure apache is at the latest version\rapt:\rname: apache2\rstate: latest\r- name: write the apache2 ports.conf config file\rtemplate:\rsrc: templates/ports.conf.j2\rdest: /etc/apache2/ports.conf\rnotify:\r- restart apache\r- name: write a basic index.html file\rtemplate:\rsrc: templates/index.html.j2\rdest: /var/www/html/index.html\rnotify:\r- restart apache\r- name: ensure apache is running\rservice:\rname: apache2\rstate: started\rhandlers:\r- name: restart apache\rservice:\rname: apache2\rstate: restarted\rРазбираем вышеприведенный плейбук:\n- hosts: webservers означает, что наша группа, на которой будет запущен этот плейбук, называется webservers. become: yes означает, что наш пользователь, запускающий плейбук, станет root на наших удаленных системах. Вам будет предложено ввести пароль root. Затем у нас есть vars, и это определяет некоторые переменные окружения, которые мы хотим использовать на наших веб-серверах. После этого мы приступаем к выполнению наших задач,\nЗадача 1 - убедиться, что apache работает на последней версии. Задача 2 - написать файл ports.conf из нашего исходного файла, который находится в папке templates. Задача 3 - создание базового файла index.html Задача 4 - убедиться, что apache запущен. Наконец, у нас есть раздел обработчиков, Handlers: Running operations on change\n“Иногда вы хотите, чтобы задача выполнялась только тогда, когда на машине происходят изменения. Например, вы можете захотеть перезапустить службу, если задача обновляет конфигурацию этой службы, но не перезапускать ее, если конфигурация не изменилась. Для решения этой задачи в Ansible используются обработчики. Обработчики - это задачи, которые выполняются только при получении уведомления. Каждый обработчик должен иметь глобально уникальное имя”.\nНа этом этапе вы можете подумать, но мы развернули 5 виртуальных машин (включая нашу машину Ubuntu Desktop, которая действует как наш Ansible Control) Остальные системы будут задействованы в оставшейся части раздела.\nЗапуск нашего плейбука Теперь мы готовы запустить наш учебник на наших узлах. Для запуска нашего плейбука мы можем использовать ansible-playbook playbook1.yml Мы определили наши узлы, на которых будет работать наш учебник, и это позволит выполнить наши задачи, которые мы определили.\nПосле завершения команды мы получим результат, показывающий наши пьесы и задачи, это может занять некоторое время, вы можете видеть на изображении ниже, что это заняло некоторое время, чтобы пойти и установить наше желаемое состояние.\nЗатем мы можем дважды проверить это, зайдя в узел и проверив, что на нашем узле установлено программное обеспечение.\nТеперь, когда мы развернули два автономных веб-сервера, мы можем перейти на соответствующие IP, которые мы определили, и получить наш новый веб-сайт.\nМы будем опираться на это руководство по ходу работы над остальной частью этого раздела. Мне также интересно взять наш рабочий стол Ubuntu и посмотреть, сможем ли мы загрузить наши приложения и конфигурацию с помощью Ansible, поэтому мы также можем коснуться этого. Вы видели, что мы можем использовать локальный хост в наших командах, мы также можем запускать плейбуки, например, на нашем локальном хосте.\nЕще одна вещь, которую следует добавить, заключается в том, что мы работаем только с виртуальными машинами Ubuntu, но Ansible не зависит от целевых систем. Альтернативы, которые мы уже упоминали ранее для управления системами, могут быть сервер за сервером (не масштабируемый, когда вы получаете большое количество серверов, плюс боль даже с 3 узлами), мы также можем использовать скрипты оболочки, которые мы рассматривали в разделе Linux, но эти узлы потенциально разные, так что да, это можно сделать, но тогда кто-то должен поддерживать и управлять этими скриптами. Ansible бесплатна и позволяет легко справиться с этой задачей по сравнению с необходимостью иметь специализированный скрипт.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"65. Ansible Playbooks - Часть 1","uri":"/ru/docs/90daysofdevops/day65/"},{"content":"Ansible Playbooks Продолжение… В нашем последнем разделе мы начали с создания небольшой лаборатории, используя файл Vagrant для развертывания 4 машин, и мы использовали нашу Linux-машину, которую мы создали в этом разделе, в качестве нашей системы управления Ansible.\nМы также проверили несколько скриптов плейбуков, и в конце у нас был плейбук, который сделал наши web01 и web02 отдельными веб-серверами.\nНаведение порядка Прежде чем перейти к дальнейшей автоматизации и развертыванию, мы должны рассказать о том, как сохранить наш плейбук аккуратным и опрятным и как мы можем разделить наши такты и обработчики по подпапкам.\nВ основном мы собираемся копировать наши задачи в их собственный файл в папке.\n- name: ensure apache is at the latest version\rapt: name=apache2 state=latest\r- name: write the apache2 ports.conf config file\rtemplate: src=templates/ports.conf.j2 dest=/etc/apache2/ports.conf\rnotify: restart apache\r- name: write a basic index.html file\rtemplate:\rsrc: templates/index.html.j2\rdest: /var/www/html/index.html\rnotify:\r- restart apache\r- name: ensure apache is running\rservice:\rname: apache2\rstate: started\rи то же для обработчиков.\n- name: restart apache\rservice:\rname: apache2\rstate: restarted\rЗатем в нашем плейбуке, который теперь называется playbook2.yml, мы указываем на эти файлы. Все эти файлы можно найти по адресу ansible-scenario2.\nВы можете проверить это на своей контрольной машине. Если вы скопировали файлы из репозитория, вы должны были заметить, что кое-что изменилось в пункте “написать основной файл index.html”\nДавайте выясним, какое простое изменение я сделал. Использование curl web01:8000\nМы только что привели в порядок наш плейбук и начали разделять области, которые могут сделать плейбук очень перегруженным в масштабе.\nРоли и Ansible Galaxy На данный момент мы развернули 4 виртуальные машины и настроили 2 из них как веб-серверы, но у нас есть еще несколько специфических функций, а именно: сервер базы данных и балансировщик нагрузки или прокси. Для того чтобы сделать это и привести в порядок наш репозиторий, мы можем использовать роли в Ansible.\nДля этого мы воспользуемся командой ansible-galaxy, которая предназначена для управления ролями Ansible в общих репозиториях.\nМы собираемся использовать ansible-galaxy для создания роли для apache2, где мы собираемся разместить специфику наших веб-серверов.\nПриведенная выше команда ansible-galaxy init roles/apache2 создаст структуру папок, которую мы показали выше. Следующим шагом нам нужно переместить существующие задачи и шаблоны в соответствующие папки в новой структуре.\nКопировать и вставить легко для перемещения этих файлов, но нам также нужно внести изменения в tasks/main.yml, чтобы указать его на apache2_install.yml.\nНам также нужно изменить наш playbook, чтобы он ссылался на нашу новую роль. В playbook1.yml и playbook2.yml мы определяем наши задачи и обработчики по-разному, так как мы изменили их между двумя версиями. Нам нужно изменить наш плейбук, чтобы использовать эту роль, как показано ниже:\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\"\rroles:\r- apache2\rТеперь мы можем запустить наш плейбук снова, на этот раз с новым именем плейбука ansible-playbook playbook3.yml Вы заметите обесценивание, мы можем исправить это дальше.\nХорошо, амортизация хотя наш плейбук запустился, теперь мы должны исправить наши пути, для этого я изменил опцию include в tasks/main.yml на import_tasks, как показано ниже.\nВы можете найти эти файлы в папке ansible-scenario3.\nМы также собираемся создать еще несколько ролей, используя ansible-galaxy, которые мы собираемся создать:\ncommon = for all of our servers (ansible-galaxy init roles/common) nginx = for our loadbalancer (ansible-galaxy init roles/nginx) Я собираюсь оставить этот вариант здесь, а в следующей сессии мы начнем работать над другими узлами, которые мы развернули, но еще ничего не сделали.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"66. Ansible Playbooks - Часть 2","uri":"/ru/docs/90daysofdevops/day66/"},{"content":"На последнем занятии мы рассмотрели роли и использовали команду ansible-galaxy, чтобы помочь создать структуру папок для некоторых ролей, которые мы будем использовать. В итоге мы получили гораздо более аккуратное рабочее хранилище для нашего кода конфигурации, поскольку все спрятано в папках ролей.\nОднако мы использовали только роль apache2 и получили рабочий playbook3.yaml для работы с нашими веб-серверами.\nНа данном этапе, если вы использовали только vagrant up web01 web02, пришло время запустить vagrant up loadbalancer, который откроет другую систему Ubuntu, которую мы будем использовать в качестве балансировщика нагрузки/прокси.\nМы уже определили эту новую машину в нашем файле hosts, но у нас нет настроенного ssh-ключа, пока он не доступен, поэтому нам нужно также запустить ssh-copy-id loadbalancer, когда система будет запущена и готова.\nОбщая роль В конце вчерашней сессии я создал роль common, роль common будет использоваться на всех наших серверах, в то время как другие роли специфичны для конкретных случаев использования, сейчас приложения, которые я собираюсь установить в качестве common, не так просты, и я не вижу много причин для этого, но это показывает цель. В структуре папок нашей общей роли перейдите в папку tasks, и у вас появится файл main.yml. В этом yaml нам нужно указать на наш файл install_tools.yml, и мы делаем это, добавляя строку - import_tasks: install_tools.yml. Раньше это был include, но он скоро будет устаревшим, поэтому мы используем import_tasks.\n- name: \"Install Common packages\"\rapt: name={{ item }} state=latest\rwith_items:\r- neofetch\r- tree\r- figlet\rЗатем в нашем плейбуке мы добавляем общую роль для каждого блока хоста.\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\"\rroles:\r- common\r- apache2\rnginx Следующим этапом будет установка и настройка nginx на нашем виртуальном компьютере loadbalancer. Как и в общей структуре папок, у нас есть nginx, основанный на последнем сеансе.\nПрежде всего, мы добавим блок host в наш playbook. Этот блок будет включать нашу общую роль, а затем нашу новую роль nginx.\nПлейбук можно найти здесь. playbook4.yml\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\"\rroles:\r- common\r- apache2\r- hosts: proxy become: yes\rroles: - common\r- nginx\rДля того чтобы это что-то значило, мы должны определить наши задачи, которые мы хотим запустить, таким же образом мы изменим main.yml в задачах, чтобы указать на два файла, один для установки и один для конфигурации.\nЕсть и другие файлы, которые я изменил в зависимости от желаемого результата, посмотрите в папке ansible-scenario4 все измененные файлы. Вам следует проверить папки tasks, handlers и templates в папке nginx, и вы найдете эти дополнительные изменения и файлы.\nЗапуск обновленного плейбука Со вчерашнего дня мы добавили роль common, которая теперь будет устанавливать некоторые пакеты в нашей системе, а затем мы также добавили роль nginx, которая включает установку и настройку.\nДавайте запустим наш playbook4.yml, используя ansible-playbook playbook4.yml.\nТеперь, когда мы настроили наши веб-серверы и loadbalancer, мы должны иметь возможность перейти по адресу http://192.168.169.134/, который является IP-адресом нашего loadbalancer.\nЕсли вы следите за развитием событий и у вас нет такого состояния, то это может быть связано с IP-адресами серверов в вашем окружении. Файл находится в templates\\mysite.j2 и выглядит примерно так, как показано ниже: Вам необходимо обновить IP-адреса ваших веб-серверов.\nupstream webservers {\rserver 192.168.169.131:8000;\rserver 192.168.169.132:8000;\r}\rserver {\rlisten 80;\rlocation / { proxy_pass http://webservers;\r}\r}\rЯ уверен, что все, что мы установили, в порядке, но давайте воспользуемся специальной командой с помощью ansible, чтобы проверить установку этих общих инструментов.\nansible loadbalancer -m command -a neofetch.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible TЭтот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"67. Роли и развертывание балансировщика нагрузки","uri":"/ru/docs/90daysofdevops/day67/"},{"content":"Теги Поскольку мы оставили наш плейбук во время вчерашней сессии, нам нужно будет запустить все задачи и пьесы в рамках этого плейбука. Это означает, что нам придется запустить веб-серверы и балансировщик нагрузки до конца.\nОднако теги могут позволить нам отделить их друг от друга, если мы захотим. Это может быть эффективным шагом, если в нашей среде есть очень большие и длинные плейбуки.\nВ нашем файле плейбука, в данном случае мы используем ansible-scenario5\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 66!\"\rroles:\r- common\r- apache2\rtags: web\r- hosts: proxy become: yes\rroles: - common\r- nginx\rtags: proxy\rЗатем мы можем подтвердить это с помощью команды ansible-playbook playbook5.yml --list-tags, а список тегов будет содержать теги, которые мы определили в нашем плейбуке.\nТеперь, если мы хотим нацелиться только на прокси, мы можем сделать это, выполнив ansible-playbook playbook5.yml --tags proxy, и это, как вы можете видеть ниже, запустит плейбук только против прокси.\nТеги могут быть добавлены и на уровне задач, так что мы можем получить действительно подробную информацию о том, где и что вы хотите, чтобы произошло. Это могут быть теги, ориентированные на приложения, например, мы можем пройтись по задачам и пометить наши задачи на основе установки, настройки или удаления. Еще один очень полезный тег, который вы можете использовать, это\ntag: always, который гарантирует, что независимо от того, какие -теги вы используете в вашей команде, если что-то помечено значением always, то оно всегда будет запущено при выполнении команды ansible-playbook.\nС помощью тегов мы также можем объединить несколько тегов вместе, и если мы выполним команду ansible-playbook playbook5.yml --tags proxy,web, то будут запущены все элементы с этими тегами. Очевидно, что в нашем случае это будет означать то же самое, что и запуск самого плейбука, но если бы у нас было несколько других плейбуков, то это имело бы смысл.\nВы также можете определить более одного тега.\nПеременные В Ansible существует два основных типа переменных.\nСозданная пользователем (User created) Факты Ansible (Ansible Facts) Факты Ansible Каждый раз, когда мы запускали наши плейбуки, у нас была задача, которую мы не определяли, называемая “Сбор фактов”, мы можем использовать эти переменные или факты, чтобы заставить вещи происходить с нашими задачами автоматизации.\nЕсли мы выполним следующую команду ansible proxy -m setup, то увидим много выходных данных в формате JSON. Однако на вашем терминале будет много информации, чтобы действительно использовать ее, поэтому мы хотим вывести ее в файл, используя команду ansible proxy -m setup \u003e\u003e facts.json, вы можете увидеть этот файл в этом репозитории, ansible-scenario5\nЕсли открыть этот файл, то можно увидеть всевозможную информацию для нашей команды. Мы можем получить наши IP-адреса, архитектуру, версию биоса. Много полезной информации, если мы захотим использовать ее в наших плейбуках.\nИдея заключается в том, чтобы потенциально использовать одну из этих переменных в шаблоне nginx mysite.j2, где мы жестко закодировали IP-адреса наших веб-серверов. Вы можете сделать это, создав цикл for в вашем mysite.j2, который будет проходить через группу [webservers], что позволит нам иметь более двух веб-серверов, автоматически и динамически созданных или добавленных в эту конфигурацию балансировщика нагрузки.\n#Dynamic Config for server {{ ansible_facts['nodename'] }}\rupstream webservers {\r{% for host in groups['webservers'] %}\rserver {{ hostvars[host]['ansible_facts']['nodename'] }}:8000;\r{% endfor %}\r}\rserver {\rlisten 80;\rlocation / { proxy_pass http://webservers;\r}\r}\rРезультат вышеописанных действий будет выглядеть так же, как и сейчас, но если мы добавим больше веб-серверов или удалим один, это динамически изменит конфигурацию прокси. Чтобы это работало, необходимо настроить разрешение имен.\nСозданные пользователем Переменные, созданные пользователем, - это то, что мы создали сами. Если вы посмотрите в наш playbook, то увидите, что у нас есть vars:, а затем список из трех переменных, которые мы используем.\n- hosts: webservers\rbecome: yes\rvars:\rhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\"\rroles:\r- common\r- apache2\rtags: web\r- hosts: proxy become: yes\rroles: - common\r- nginx\rtags: proxy\rОднако мы можем очистить наш плейбук от переменных, переместив их в собственный файл. Мы так и сделаем, но перенесем их в папку ansible-scenario6. В корне этой папки мы создадим папку group_vars. Затем мы создадим еще одну папку под названием all (все группы получат эти переменные). В ней мы создадим файл под названием common_variables.yml и скопируем в него наши переменные из нашего плейбука. Удалим их из плейбука вместе с vars:.\nhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\"\rПоскольку мы связываем это с глобальной переменной, мы также можем добавить сюда наши серверы NTP и DNS. Переменные устанавливаются из созданной нами структуры папок. Ниже вы можете видеть, как чисто выглядит наш Playbook.\n- hosts: webservers\rbecome: yes\rroles:\r- common\r- apache2\rtags: web\r- hosts: proxy become: yes\rroles: - common\r- nginx\rtags: proxy\rОдной из этих переменных был http_port, мы можем использовать его снова в нашем цикле for в файле mysite.j2, как показано ниже:\n#Dynamic Config for server {{ ansible_facts['nodename'] }}\rupstream webservers {\r{% for host in groups['webservers'] %}\rserver {{ hostvars[host]['ansible_facts']['nodename'] }}:{{ http_port }};\r{% endfor %}\r}\rserver {\rlisten 80;\rlocation / { proxy_pass http://webservers;\r}\r}\rМы также можем определить ansible fact в нашем файле roles/apache2/templates/index.html.j2, чтобы мы могли понять, на каком веб-сервере мы находимся.\n\u003chtml\u003e\r\u003ch1\u003e{{ html_welcome_msg }}! I'm webserver {{ ansible_facts['nodename'] }} \u003c/h1\u003e\r\u003c/html\u003e\rРезультаты выполнения команды ansible-playbook playbook6.yml с нашими изменениями переменных означают, что когда мы нажимаем на наш loadbalancer, вы можете увидеть, что мы нажимаем на любой из веб-серверов, которые есть в нашей группе. Мы также можем добавить папку host_vars и создать web01.yml и иметь определенное сообщение или изменить то, как это выглядит для каждого хоста, если захотим.\nФайлы инвентаризации До сих пор мы использовали файл hosts по умолчанию в папке /etc/ansible для определения наших хостов. Однако мы можем иметь разные файлы для разных окружений, например, production и staging. Я не собираюсь создавать больше окружений. Но мы можем создавать свои собственные файлы хостов.\nМы можем создать несколько файлов для нашего различного количества серверов и узлов. Мы будем вызывать их с помощью ansible-playbook -i dev playbook.yml Вы также можете определить переменные в файле hosts и затем распечатать их или использовать эти переменные где-нибудь еще в своих плейбуках. Например, в примере и учебном курсе, за которым я слежу ниже, они добавили переменную окружения, созданную в файле host, в шаблон веб-страницы loadbalancer, чтобы показать окружение как часть сообщения веб-страницы.\nРазвертывание нашего сервера базы данных У нас осталась еще одна машина, которую мы еще не включили и не настроили. Мы можем сделать это с помощью команды vagrant up db01 из места, где находится наш Vagrantfile. Когда машина будет запущена и доступна, нам нужно убедиться, что SSH-ключ скопирован с помощью ssh-copy-id db01, чтобы мы могли получить доступ.\nМы будем работать из папки ansible-scenario7.\nЗатем воспользуемся командой ansible-galaxy init roles/mysql, чтобы создать новую структуру папок для новой роли под названием “mysql”.\nВ нашем плейбуке мы собираемся добавить новый блок для конфигурации базы данных. В файле /etc/ansible/hosts мы определили нашу группу базы данных. Затем мы указываем нашей группе базы данных роль common и новую роль mysql, которую мы создали в предыдущем шаге. Мы также помечаем нашу группу базы данных тегами database, что означает, как мы обсуждали ранее, что мы можем выбрать запуск только с этими тегами, если захотим.\n- hosts: webservers\rbecome: yes\rroles:\r- common\r- apache2\rtags:\rweb\r- hosts: proxy\rbecome: yes\rroles:\r- common\r- nginx\rtags: proxy\r- hosts: database\rbecome: yes\rroles:\r- common\r- mysql\rtags: database\rТеперь в структуре папок с нашими ролями автоматически создается дерево, в котором нам нужно заполнить следующее:\nHandlers - main.yml\n# handlers file for roles/mysql\r- name: restart mysql\rservice:\rname: mysql\rstate: restarted\rTasks - install_mysql.yml, main.yml \u0026 setup_mysql.yml\ninstall_mysql.yml - this task is going to be there to install mysql and ensure that the service is running.\n- name: \"Install Common packages\"\rapt: name={{ item }} state=latest\rwith_items:\r- python3-pip\r- mysql-client\r- python3-mysqldb\r- libmysqlclient-dev\r- name: Ensure mysql-server is installed latest version\rapt: name=mysql-server state=latest\r- name: Installing python module MySQL-python\rpip:\rname: PyMySQL\r- name: Ensure mysql-server is running\rservice:\rname: mysql\rstate: started\rmain.yml is a pointer file that will suggest that we import_tasks from these files.\n# tasks file for roles/mysql\r- import_tasks: install_mysql.yml\r- import_tasks: setup_mysql.yml\rsetup_mysql.yml - This task will create our database and database user.\n- name: Create my.cnf configuration file\rtemplate: src=templates/my.cnf.j2 dest=/etc/mysql/conf.d/mysql.cnf\rnotify: restart mysql\r- name: Create database user with name 'devops' and password 'DevOps90' with all database privileges\rcommunity.mysql.mysql_user:\rlogin_unix_socket: /var/run/mysqld/mysqld.sock\rlogin_user: \"{{ mysql_user_name }}\" login_password: \"{{ mysql_user_password }}\" name: \"{{db_user}}\"\rpassword: \"{{db_pass}}\"\rpriv: '*.*:ALL'\rhost: '%'\rstate: present\r- name: Create a new database with name '90daysofdevops'\rmysql_db:\rlogin_user: \"{{ mysql_user_name }}\" login_password: \"{{ mysql_user_password }}\" name: \"{{ db_name }}\"\rstate: present\rВы можете видеть, что мы используем некоторые переменные для определения некоторых конфигураций, таких как пароли, имена пользователей и базы данных, все это хранится в файле group_vars/all/common_variables.yml.\nhttp_port: 8000\rhttps_port: 4443\rhtml_welcome_msg: \"Hello 90DaysOfDevOps - Welcome to Day 68!\"\rmysql_user_name: root\rmysql_user_password: \"vagrant\"\rdb_user: devops\rdb_pass: DevOps90\rdb_name: 90DaysOfDevOps\rУ нас также есть файл my.cnf.j2 в папке templates, который выглядит следующим образом:\n[mysql] bind-address = 0.0.0.0\rЗапуск плейбука Теперь наша виртуальная машина запущена и работает, и у нас есть наши конфигурационные файлы на месте, теперь мы готовы запустить наш плейбук, который будет включать все, что мы сделали раньше, если мы запустим следующий ansible-playbook playbook7.yml или мы можем выбрать просто развертывание на нашу группу баз данных с помощью команды ansible-playbook playbook7.yml --tags database, которая просто запустит наши новые конфигурационные файлы.\nЯ запустил только тег database, но наткнулся на ошибку. Эта ошибка говорит мне, что у нас не установлен pip3 (Python). Мы можем исправить это, добавив это в наши общие задачи и установив\nМы исправили вышеуказанное и запустили плейбук снова, и у нас получилось успешное изменение.\nМы должны убедиться, что на нашем новом настроенном сервере db01 все так, как мы хотим. Мы можем сделать это с нашего узла управления с помощью команды ssh db01.\nДля подключения к MySQL я использовал команду sudo /usr/bin/mysql -u root -p и указал пароль vagrant для root.\nКогда мы подключились, давайте сначала убедимся, что у нас создан пользователь devops. select user, host from mysql.user;\nТеперь мы можем выполнить команду SHOW DATABASES;, чтобы увидеть нашу новую базу данных, которая также была создана.\nНа самом деле я использовал root для подключения, но теперь мы можем войти в систему под учетной записью devops, используя команду sudo /usr/bin/mysql -u devops -p, но пароль здесь будет DevOps90.\nЯ обнаружил, что в нашем setup_mysql.yml мне пришлось добавить строку login_unix_socket: /var/run/mysqld/mysqld.sock для успешного подключения к моему экземпляру db01 mysql, и теперь каждый раз, когда я запускаю это, он сообщает об изменении при создании пользователя, любые предложения будут очень признательны.\nРесурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате.\n","description":"","title":"68. Теги, переменные, инвентаризация и конфигурация сервера базы данных","uri":"/ru/docs/90daysofdevops/day68/"},{"content":"Завершая раздел об управлении конфигурацией, я хотел бы рассмотреть другие области, с которыми вы можете столкнуться при работе с Ansible.\nСуществует множество продуктов, составляющих платформу Ansible Automation.\nRed Hat Ansible Automation Platform - это основа для создания и эксплуатации автоматизации в организации. Платформа включает в себя все инструменты, необходимые для внедрения автоматизации в масштабах предприятия.\nЯ постараюсь осветить некоторые из них в этом посте. Но для получения более подробной информации на официальном сайте Red Hat Ansible есть много другой информации. Ansible.com\nAnsible Automation Controller | AWX Я объединил эти два продукта вместе, потому что Automation Controller и AWX очень похожи в том, что они предлагают.\nПроект AWX или сокращенно AWX - это проект сообщества с открытым исходным кодом, спонсируемый Red Hat, который позволяет вам лучше контролировать ваши проекты Ansible в ваших средах. AWX - это основной проект, из которого взят компонент контроллера автоматизации.\nЕсли вы ищете корпоративное решение, то вам нужен контроллер автоматизации, или вы могли слышать его как Ansible Tower. Контроллер автоматизации Ansible - это плоскость управления для платформы автоматизации Ansible.\nИ AWX, и контроллер автоматизации обладают следующими характеристиками, превосходящими все, что мы рассмотрели в этом разделе до сих пор.\nПользовательский интерфейс Управление доступом на основе ролей Рабочие процессы Интеграция CI/CD Automation Controller - это корпоративное предложение, в котором вы платите за поддержку.\nМы рассмотрим развертывание AWX в нашей среде minikube Kubernetes.\nРазвертывание Ansible AWX AWX не нужно развертывать в кластере Kubernetes, github для AWX от ansible даст вам эту подробную информацию. Однако, начиная с версии 18.0, AWX Operator является предпочтительным способом установки AWX.\nПрежде всего, нам нужен кластер minikube. Мы можем сделать это, если вы следили за разделом Kubernetes, создав новый кластер minikube с помощью команды minikube start --cpus=4 --memory=6g --addons=ingress.\nОфициальный Ansible AWX Operator можно найти здесь. Как указано в инструкции по установке, вы должны клонировать этот репозиторий, а затем выполнить развертывание.\nЯ сделал форк вышеуказанного репозитория, а затем выполнил команду git clone https://github.com/MichaelCade/awx-operator.git. Я советую вам сделать то же самое и не использовать мой репозиторий, так как я могу что-то изменить или его там может не быть.\nВ клонированном репозитории вы найдете файл awx-demo.yml, в котором нам нужно изменить NodePort на ClusterIP, как показано ниже:\n---\rapiVersion: awx.ansible.com/v1beta1\rkind: AWX\rmetadata:\rname: awx-demo\rspec:\rservice_type: ClusterIP\rСледующим шагом будет определение нашего пространства имен, в котором мы будем развертывать оператор awx, используя команду export NAMESPACE=awx, а затем команду make deploy, мы начнем развертывание.\nПри проверке у нас есть наше новое пространство имен, и у нас есть наш awx-operator-controller pod, запущенный в нашем пространстве имен. kubectl get pods -n awx.\nВ клонированном репозитории вы найдете файл awx-demo.yml. Теперь мы хотим развернуть его в нашем кластере Kubernetes и нашем пространстве имен awx. kubectl create -f awx-demo.yml -n awx.\nВы можете следить за прогрессом с помощью kubectl get pods -n awx -w, который будет визуально следить за происходящим.\nУ вас должно получиться что-то похожее на изображение, которое вы видите ниже, когда все работает.\nТеперь мы должны иметь доступ к нашей awx установке после запуска в новом терминале minikube service awx-demo-service --url -n $NAMESPACE, чтобы открыть ее через minikube ingress.\nЕсли мы откроем браузер по этому адресу [], вы увидите, что нам будет предложено ввести имя пользователя и пароль.\nПо умолчанию имя пользователя - admin, чтобы получить пароль, мы можем выполнить следующую команду kubectl get secret awx-demo-admin-password -o jsonpath=\"{.data.password}\" -n awx| base64 --decode.\nОчевидно, что это дает вам пользовательский интерфейс для централизованного управления плейбуком и задачами управления конфигурацией, а также позволяет вам работать вместе, в отличие от того, что мы делали до сих пор, когда мы работали с одной станции управления ansible.\nЭто еще одна из тех областей, где вы, вероятно, могли бы провести еще много времени, изучая возможности этого инструмента.\nЯ приведу отличный ресурс от Джеффа Гирлинга, который более подробно рассказывает об использовании Ansible AWX. Ansible 101 - Episode 10 - Ansible Tower and AWX\nВ этом видео он также подробно рассказывает о различиях между Automation Controller (ранее Ansible Tower) и Ansible AWX (Free and Open Source).\nAnsible Vault ansible-vault позволяет нам шифровать и расшифровывать файлы данных Ansible. На протяжении всего этого раздела мы пропустили и поместили часть нашей конфиденциальной информации в открытый текст.\nВстроенный в двоичный файл Ansible ansible-vault позволяет нам скрыть эту конфиденциальную информацию.\nУправление секретами постепенно становится еще одной областью, которой следовало бы уделить больше времени наряду с такими инструментами, как HashiCorp Vault или AWS Key Management Service. Я отмечу эту область как ту, в которую следует погрузиться глубже.\nЯ собираюсь дать ссылку на отличный ресурс и демонстрационный пример от Jeff Geerling Ansible 101 - Episode 6 - Ansible Vault and Roles\nAnsible Galaxy (Docs) Итак, мы уже использовали ansible-galaxy для создания некоторых ролей и файловой структуры для нашего демо-проекта. Но у нас также есть документация по Ansible Galaxy\n“Galaxy - это центр для поиска и обмена содержимым Ansible”.\nТестирование Ansible Ansible Molecule - проект Molecule предназначен для помощи в разработке и тестировании ролей Ansible.\nAnsible Lint - CLI-инструмент для линтинга плейбуков, ролей и коллекций.\nДругой ресурс Документация Ansible Ресурсы What is Ansible Ansible 101 - Episode 1 - Introduction to Ansible NetworkChuck - You need to learn Ansible right now! Your complete guide to Ansible Этот последний плейлист, приведенный выше, является тем местом, откуда было взято много кода и идей для этого раздела, отличным ресурсом и руководством в видеоформате. В этом посте мы завершаем рассмотрение управления конфигурацией, далее мы перейдем к CI/CD Pipelines и некоторым инструментам и процессам, которые мы можем увидеть и использовать для достижения этого рабочего процесса при разработке и выпуске приложений.\n","description":"","title":"69. Ansible - контроллер автоматизации (Tower), AWX, Vault","uri":"/ru/docs/90daysofdevops/day69/"},{"content":"Общая картина: DevOps и изучение языка программирования Я думаю, будет справедливо сказать, что для достижения успеха в качестве инженера DevOps в долгосрочной перспективе необходимо знать хотя бы один язык программирования на базовом уровне. Я хочу провести это первое занятие в этой статье, чтобы выяснить, почему это такой важный навык, и, надеюсь, к концу этой недели или раздела вы будете лучше понимать, почему, как и что делать. делайте, чтобы продвигаться в своем учебном путешествии.\nЯ думаю, что если бы я спросил в социальных сетях, нужны ли вам навыки программирования для ролей, связанных с DevOps, ответ, скорее всего, будет утвердительным? Дайте мне знать, если вы думаете иначе? Хорошо, но тогда более важный вопрос, и здесь вы не получите такого четкого ответа, какой язык программирования? Наиболее распространенным ответом, который я видел здесь, был Python, или все чаще мы видим, что Golang или Go должны быть языком, который вы изучаете.\nЧтобы быть успешным в DevOps, вы должны хорошо знать навыки программирования, по крайней мере, мой вывод из этого. Но мы должны понять, зачем нам это нужно, чтобы выбрать правильный путь.\nПонимание зачем вам нужно изучать язык программирования Причина, по которой Python и Go так часто рекомендуются инженерам DevOps, заключается в том, что многие инструменты DevOps написаны либо на Python, либо на Go, что имеет смысл, если вы собираетесь создавать инструменты DevOps. Теперь это важно, так как это действительно определит, что вы должны изучить, и это, вероятно, будет наиболее полезным. Если вы собираетесь создавать инструменты DevOps или присоединяетесь к команде, которая занимается этим, имеет смысл выучить тот же язык. Если вы собираетесь активно участвовать в Kubernetes или контейнерах, то, скорее всего, вы захотите выберите Go в качестве языка программирования. Для меня компания, в которой я работаю (Kasten by Veeam), находится в экосистеме Cloud-Native, ориентированной на управление данными для Kubernetes, и все написано на Go.\nНо тогда у вас может не быть четких рассуждений, подобных этим, чтобы выбрать, быть ли вам студентом или менять карьеру без реального решения за вас. Я думаю, что в этой ситуации вы должны выбрать тот, который, кажется, резонирует и подходит для приложений, с которыми вы хотите работать.\nПомните, что я не собираюсь становиться здесь разработчиком программного обеспечения, я просто хочу немного больше узнать о языке программирования, чтобы я мог читать и понимать, что делают эти инструменты, а затем это, возможно, приведет к тому, как мы можем помочь улучшить ситуацию.\nЯ также хотел бы знать, как вы взаимодействуете с этими инструментами DevOps, такими как Kasten K10 или Terraform и HCL. Это то, что мы будем называть конфигурационными файлами, и именно так вы взаимодействуете с этими инструментами DevOps, чтобы что-то происходило, обычно это будет YAML. (Мы можем использовать последний день этого раздела, чтобы немного погрузиться в YAML)\nЯ только что отговорил себя от изучения языка программирования? Большую часть времени или в зависимости от роли вы будете помогать инженерным командам внедрять DevOps в свой рабочий процесс, много тестировать приложение и следить за тем, чтобы созданный рабочий процесс соответствовал тем принципам DevOps, которые мы упоминали в первые несколько дней. . Но на самом деле много времени уходит на устранение проблем с производительностью приложений или что-то в этом роде. Это возвращает меня к моей первоначальной точке зрения и рассуждениям: язык программирования, который мне нужно знать, — это тот, на котором написан код? Если их приложение написано на NodeJS, это не сильно поможет, если у вас есть значок Go или Python.\nПочему Go Почему Golang — следующий язык программирования для DevOps? В последние годы Go стал очень популярным языком программирования. Согласно опросу StackOverflow за 2021 год, Go занял четвертое место среди самых востребованных языков программирования, сценариев и разметки, а Python был на первом месте, но выслушайте меня. StackOverflow 2021 Developer Survey – Most Wanted Link\nКак я уже упоминал, некоторые из самых известных инструментов и платформ DevOps написаны на Go, такие как Kubernetes, Docker, Grafana и Prometheus.\nКакие характеристики Go делают его идеальным для DevOps?\nСборка и развертывание программ Go Преимущество использования такого языка, как Python, который интерпретируется в роли DevOps, заключается в том, что вам не нужно компилировать программу Python перед ее запуском. Особенно для небольших задач автоматизации вы не хотите, чтобы процесс сборки, требующий компиляции, замедлялся, несмотря на то, что Go — компилируемый язык программирования, Go компилируется непосредственно в машинный код. Go также известен быстрым временем компиляции.\nGo или Python для DevOps Программы Go статически связаны, это означает, что когда вы компилируете программу Go, все включается в один исполняемый двоичный файл, не требуется никаких внешних зависимостей, которые необходимо установить на удаленной машине, это упрощает развертывание программ Go, по сравнению с программой Python, которая использует внешние библиотеки, где вы должны убедиться, что все эти библиотеки установлены на удаленной машине, на которой вы хотите работать.\nGo — это независимый от платформы язык, что означает, что вы можете создавать двоичные исполняемые файлы для * всех операционных систем, Linux, Windows, macOS и т. д., и это очень легко сделать. С Python не так просто создавать эти двоичные исполняемые файлы для конкретных операционных систем.\nGo — очень производительный язык, он имеет быструю компиляцию и быстрое время выполнения с меньшим использованием ресурсов, таких как процессор и память, особенно по сравнению с python, в языке Go были реализованы многочисленные оптимизации, которые делают его таким производительным. (Ресурсы ниже)\nВ отличие от Python, который часто требует использования сторонних библиотек для реализации конкретной программы Python, go включает в себя стандартную библиотеку, которая имеет большую часть функций, которые вам понадобятся для DevOps, встроенных непосредственно в нее. Это включает в себя функциональную обработку файлов, веб-службы HTTP, обработку JSON, встроенную поддержку параллелизма и параллелизма, а также встроенное тестирование.\nЭто ни в коем случае не бросает Python под автобус, я просто излагаю свои причины выбора Go, но они не являются вышеупомянутым Go против Python, это обычно потому, что это имеет смысл, поскольку компания, в которой я работаю, разрабатывает программное обеспечение на Go, вот почему.\nЯ скажу, что как только как только вы выучите свой первый язык программирования, вам станет легче осваивать другие языки. Вероятно, у вас никогда не будет ни одной работы в какой-либо компании, где бы вам не приходилось иметь дело с управлением, архитектурой, оркестровкой, отладкой приложений JavaScript и Node JS.\nИсточники StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Теперь в течение следующих 6 дней этой темы я намерен работать с некоторыми из ресурсов, перечисленных выше, и документировать свои заметки на каждый день. Вы заметите, что они, как правило, составляют около 3 часов в качестве полного курса, я хотел поделиться своим полным списком, чтобы, если у вас есть время, вы могли двигаться вперед и работать над каждым, если позволяет время, я буду придерживаться моего часа обучения каждый день.\nДо встречи в День 8\n","description":"DevOps - изучение языка программирования","title":"7. DevOps - изучение языка программирования","uri":"/ru/docs/90daysofdevops/day07/"},{"content":"Что вы делаете, когда в вашей программе происходит что-то плохое? Допустим, вы пытаетесь открыть файл, но вводите неправильный путь или запрашиваете у пользователя информацию, а он вводит какой-то мусор. Вы не хотите, чтобы ваша программа аварийно завершилась, поэтому вы реализуете обработку исключений. В Python эта конструкция обычно обернута в так называемый try/except. В этой главе мы рассмотрим следующие темы:\nОбщие типы исключений Обработка исключений с помощью try/except Изучим, как работает try/except/finally Исследуем, как оператор else работает в сочетании с try/except. Давайте начнем с изучения некоторых наиболее распространенных исключений, которые встречаются в Python. Примечание: ошибка и исключение - это просто разные слова, которые описывают одно и то же, когда мы говорим об обработке исключений.\nРаспространенные исключения Вы уже видели несколько исключений. Вот список наиболее распространенных встроенных исключений (определения взяты из документации Python):\n- **Exception** (это то, на чем построены почти все остальные) - **AttributeError** - Возникает, когда ссылка на атрибут или присвоение не удается. - **IOError** - Возникает, когда операция ввода/вывода (например, оператор печати, встроенная функция open() или метод объекта файла) не выполняется по причине, связанной с вводом/выводом, например, \"файл не найден\" или \"диск заполнен\". - **ImportError** - Возникает, когда оператор import не может найти определение модуля или когда при **импорте from ...** не удается найти имя, которое должно быть импортировано. - *IndexError** - Возникает, когда подскрипт последовательности выходит за пределы диапазона. - **KeyError** - Возникает, когда ключ отображения (словаря) не найден в наборе существующих ключей. - **KeyboardInterrupt** - Возникает, когда пользователь нажимает клавишу прерывания (обычно Control-C или Delete). - **NameError** - Возникает, когда не найдено локальное или глобальное имя. - **OSError** - Возникает, когда функция возвращает системную ошибку. - **SyntaxError** - Возникает, когда синтаксический анализатор встречает синтаксическую ошибку. - **TypeError** - Возникает, когда операция или функция применяется к объекту неподходящего типа. Связанное значение представляет собой строку, содержащую подробную информацию о несоответствии типа. - **ValueError** - Возникает, когда встроенная операция или функция получает аргумент, имеющий правильный тип, но несоответствующее значение, и ситуация не описывается более точным исключением, таким как IndexError. - **ZeroDivisionError** - Возникает, когда второй аргумент операции деления или модуляции равен нулю. Существует также множество других исключений, но, скорее всего, вы не будете сталкиваться с ними так часто. Однако, если вам интересно, вы можете прочитать о них в документации Python.\nКак работать с исключениями Обработка исключений в Python очень проста. Давайте потратим немного времени на написание нескольких примеров, которые будут вызывать исключения. Мы начнем с одной из самых распространенных проблем в информатике: деление на ноль.\n\u003e\u003e\u003e 1 / 0 Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e ZeroDivisionError: integer division or modulo by zero \u003e\u003e\u003e try: 1 / 0 except ZeroDivisionError: print(\"You cannot divide by zero!\") You cannot divide by zero! Если вы вспомните уроки начальной математики, то вспомните, что нельзя делить на ноль. В Python эта операция приводит к ошибке, как видно из первой половины примера. Чтобы поймать ошибку, мы обернем операцию оператором try/except.\nГолые исключения\nВот еще один способ поймать ошибку:\n\u003e\u003e\u003e try: 1 / 0 except: print(\"You cannot divide by zero!\") Это не рекомендуется! В Python это известно как “голое исключение”, , что означает, что будут найдены вообще все исключения. Причина, по которой не рекомендуется так делать, заключается в том, что вы не знаете, какое именно исключение вы отлавливаете. Когда у вас есть что-то вроде except ZeroDivisionError, вы, очевидно, пытаетесь поймать ошибку деления на ноль. В коде, написанном выше, вы не можете указать, что именно вам нужно выявить.\nДавайте рассмотрим еще несколько примеров.\n\u003e\u003e\u003e my_dict = {\"a\":1, \"b\":2, \"c\":3} \u003e\u003e\u003e try: value = my_dict[\"d\"] except KeyError: print(\"That key does not exist!\") That key does not exist! \u003e\u003e\u003e my_list = [1, 2, 3, 4, 5] \u003e\u003e\u003e try: my_list[6] except IndexError: print(\"That index is not in the list!\") That index is not in the list! В первом примере мы создаем словарь из 3 элементов. Затем мы пытаемся получить доступ к ключу, которого нет в словаре. Поскольку ключа нет в словаре, возникает ошибка KeyError, которую мы выявляем. Во втором примере показан список длиной 5 элементов. Мы пытаемся взять 7-й объект из индекса. Помните, что списки Python начинаются с нуля поэтому когда вы говорите [6], вы запрашиваете 7-й элемент. В любом случае поскольку элементов всего 5, возникает ошибка IndexError, которую мы также выявляем.\nВы также можете поймать несколько исключений с помощью одного оператора. Есть несколько различных способов сделать это. Давайте посмотрим:\nmy_dict = {\"a\":1, \"b\":2, \"c\":3} try: value = my_dict[\"d\"] except IndexError: print(\"This index does not exist!\") except KeyError: print(\"This key is not in the dictionary!\") except: print(\"Some other error occurred!\") Это самый стандартный способ выявить несколько исключений. Сначала мы попробовали открыть доступ к несуществующему ключу, которого нет в нашем словаре. При помощи try/except мы проверили код на наличие ошибки KeyError, которая находится во втором операторе except. Обратите внимание на то, что в конце кода у нас появилась «голое» исключение. Обычно это не рекомендуется, но вы, вероятно, будете сталкиваться с этим время от времени, поэтому полезно знать об этом. Также обратите внимание, что в большинстве случаев вам не нужно использовать целый блок кода для обработки нескольких исключений. Обычно, целый блок используется для выявления одного единственного исключения.\nВот еще один способ перехвата нескольких исключений:\ntry: value = my_dict[\"d\"] except (IndexError, KeyError): print(\"An IndexError or KeyError occurred!\") Обратите внимание, что в этом примере мы помещаем ошибки, которые хотим перехватить, внутрь круглых скобок. Проблема этого метода в том, что трудно определить, трудно сказать какая именно ошибка произошла, поэтому рекомендуется использовать предыдущий пример.\nВ большинстве случаев, когда возникает исключение, необходимо уведомить пользователя, выведя сообщение на экран или записав его в журнал. В зависимости от серьезности ошибки, вам может понадобиться завершить работу программы. Иногда перед выходом из программы необходимо выполнить очистку. Например, если вы открыли соединение с базой данных, вам нужно будет закрыть его, перед выходом из программы, или вы можете закончить с открытым соединением. Другой пример - закрытие дескриптора файла, в который вы записывали данные. Подробнее о работе с файлами вы узнаете в следующей главе. Но сначала нам нужно научиться убирать за собой. Это легко сделать с оператором finally.\nОператор finally Оператор finally очень прост в использовании. Давайте рассмотрим глупый пример:\nmy_dict = {\"a\":1, \"b\":2, \"c\":3} try: value = my_dict[\"d\"] except KeyError: print(\"A KeyError occurred!\") finally: print(\"The finally statement has executed!\") Если вы запустите это код, оно отобразиться и в операторе except и в finally. Это довольно просто, верно? Теперь вы можете использовать оператор finally, чтобы убрать за собой. В конце оператора finally вы также можете поместить код завершения.\ntry, except, или else! Оператор try/except также имеет пункт else. ОН будет выполняться только в том случае, если не возникнет ошибок. Давайте потратим несколько минут на рассмотрение нескольких примеров:\nкmy_dict = {\"a\":1, \"b\":2, \"c\":3} try: value = my_dict[\"a\"] except KeyError: print(\"A KeyError occurred!\") else: print(\"No error occurred!\")од Мы видим словарь с 3 элементами, и в try/except мы обращаемся к существующему ключу. Это работает, поэтому ошибка KeyError не возникает. Поскольку ошибки нет, else выполняется, и на экран выводится сообщение “No error occurred!”. Теперь добавим оператор finally:\nmy_dict = {\"a\":1, \"b\":2, \"c\":3} try: value = my_dict[\"a\"] except KeyError: print(\"A KeyError occurred!\") else: print(\"No error occurred!\") finally: print(\"The finally statement ran!\") Если вы запустите этот пример, он выполнит утверждения else и finally. В большинстве случаев оператор else не используется, поскольку любой код, следующий за try/except, будет выполнен, если не возникло ошибок. Единственное хорошее использование оператора else, которое я видел, это когда вы хотите выполнить вторую часть кода, которая также может вызвать ошибку. Конечно, если ошибка возникнет в else, то она не будет поймана.\nПодведение итогов Теперь вы должны уметь обрабатывать исключения в своем коде. Если вы обнаружите, что ваш код вызывает исключение, вы будете знать, как выявить его таким образом, чтобы поймать ошибку и спокойно выйти или продолжить работу без прерывания.\nТеперь мы готовы двигаться дальше и узнать о том, как работать с файлами в Python.\n","description":"Python 101","title":"7. Обработка исключений","uri":"/ru/docs/python101/chapter7_exception_handling/"},{"content":"Реализация конвейера CI/CD (Continous Integration/Continous Deployment) является основой современной среды DevOps.\nОн устраняет разрыв между разработкой и операциями, автоматизируя сборку, тестирование и развертывание приложений.\nМы много говорили об этой мантре Continous во вступительном разделе задачи. Но повторим еще раз:\nContinous Integration (CI) - это более современная практика разработки программного обеспечения, при которой инкрементные изменения кода вносятся чаще и надежнее. Автоматизированные шаги рабочего процесса сборки и тестирования, запускаемые Contininous Integration, обеспечивают надежность изменений кода, сливаемых в репозиторий.\nЗатем этот код / приложение быстро и беспрепятственно доставляется в рамках процесса непрерывного развертывания.\nВажность CI/CD? Доставка программного обеспечения быстро и эффективно Облегчает эффективный процесс вывода приложений на рынок как можно быстрее. Непрерывный поток исправлений ошибок и новых функций без ожидания месяцев или лет выпуска версии. Возможность для разработчиков регулярно вносить небольшие важные изменения означает, что мы быстрее получаем исправления и новые функции.\nХорошо, так что же это значит? В День 5 мы рассмотрели много теории, лежащей в основе DevOps, и, как уже упоминалось здесь, CI/CD Pipeline является основой современной среды DevOps.\nЯ хочу повторить некоторые ключевые моменты на этом изображении выше, теперь, когда мы немного продвинулись в изучении основ DevOps.\nМы имеем в виду жизненный цикл разработки программного обеспечения (SDLC).\nЭтапы обычно записываются в бесконечном цикле, поскольку этот цикл повторяется вечно.\nThe steps in the cycle are, developers write the code then it gets built or all compiled together then it’s tested for bugs then it’s deployed into production where it’s used (Operated) by end users or customers then we monitor and collect feedback and finally we plan improvements around that feedback rinse and repeat.\nДавайте немного углубимся в CI/CD CI CI - это практика разработки, которая требует от разработчиков интегрировать код в общий репозиторий несколько раз в день.\nКогда код написан и помещен в репозиторий, такой как github или gitlab, вот тут-то и начинается волшебство.\nКод проверяется автоматизированной сборкой, что позволяет командам или владельцу проекта обнаружить любые проблемы на ранней стадии.\nПосле этого код анализируется и подвергается серии автоматизированных тестов.\nЮнит-тестирование - тестирование отдельных частей исходного кода. тестирование на валидность - проверяется, что программное обеспечение удовлетворяет или соответствует предполагаемому использованию. Тестирование формата проверяет синтаксис и другие ошибки форматирования. Эти тесты создаются как рабочий процесс и затем запускаются каждый раз, когда вы продвигаете мастер-ветку, поэтому практически каждая крупная команда разработчиков имеет какой-то рабочий процесс CI/CD, и помните, что в команде разработчиков новый код может поступать из команд по всему миру в разное время суток от разработчиков, работающих над самыми разными проектами, поэтому эффективнее построить автоматизированный рабочий процесс тестов, которые убеждаются, что все находятся на одной странице, прежде чем код будет принят. Человеку потребуется гораздо больше времени, чтобы сделать это каждый раз.\nКак только мы завершили наши тесты и они прошли успешно, мы можем скомпилировать их и отправить в наш репозиторий. Для примера я использую Docker Hub, но это может быть любое другое хранилище, которое затем будет использовано для CD-аспекта конвейера.\nИтак, этот процесс, очевидно, очень похож на процесс разработки программного обеспечения: мы создаем наше приложение, добавляем, исправляем ошибки и т.д., затем обновляем контроль исходных текстов и версионируем их, одновременно тестируя.\nПереходим к следующему этапу - элементу CD, который на самом деле все больше и больше является тем, что мы обычно видим от любого готового программного обеспечения, я бы утверждал, что мы увидим тенденцию, что если мы получим наше программное обеспечение от такого поставщика, как Oracle или Microsoft, мы будем потреблять его из репозитория типа Docker Hub, а затем мы будем использовать наши конвейеры CD для развертывания этого в наших средах.\nCD Теперь у нас есть протестированная версия нашего кода, и мы готовы к развертыванию на природе. Как я уже сказал, поставщик программного обеспечения пройдет через этот этап, но я твердо уверен, что именно так мы все будем развертывать готовое программное обеспечение, которое нам понадобится в будущем.\nТеперь пришло время выпустить наш код в среду. Это будет включать в себя производственную среду, но также, вероятно, и другие среды, такие как staging.\nСледующим шагом, по крайней мере, в день 1 v1 развертывания программного обеспечения, является то, что нам нужно убедиться, что мы переносим правильную кодовую базу в правильную среду. Это может быть извлечение элементов из репозитория программного обеспечения (DockerHub), но более чем вероятно, что мы также извлечем дополнительную конфигурацию из другого репозитория кода, например, конфигурацию для приложения. На диаграмме ниже мы извлекаем последний релиз программного обеспечения из DockerHub, а затем выпускаем его в нашу среду, при этом, возможно, получая конфигурацию из репозитория Git. Наш CD-инструмент выполняет это и передает все в нашу среду.\nСкорее всего, это делается не одновременно, т.е. мы переходим в промежуточную среду и запускаем ее с нашей собственной конфигурацией, чтобы убедиться, что все правильно, и это может быть ручным шагом для тестирования или автоматизированным (давайте остановимся на автоматизированном), прежде чем позволить этому коду быть развернутым в продакшн.\nПосле этого, когда выйдет v2 приложения, мы прополощем и повторим шаги, на этот раз мы убедимся, что наше приложение + конфигурация развернуты в staging, убедимся, что все хорошо, и затем развернем в production.\nЗачем использовать CI/CD? Я думаю, мы уже неоднократно рассказывали о преимуществах, но они заключаются в том, что CI/CD автоматизирует то, что в противном случае пришлось бы делать вручную. Он находит небольшие проблемы до того, как они проникнут в основную кодовую базу. Вы, вероятно, можете себе представить, что если вы выкладываете плохой код своим клиентам, то у вас будут плохие времена!\nЭто также помогает предотвратить то, что мы называем техническим долгом - идею о том, что поскольку основные репозитории кода постоянно дорабатываются с течением времени, то быстрое исправление, сделанное в первый день, становится экспоненциально более дорогим исправлением годы спустя, потому что теперь этот пластырь исправления будет так глубоко переплетен и вплетен во все кодовые базы и логику.\nИнструментарий Как и в других разделах, мы будем работать с некоторыми инструментами, которые обеспечивают процесс конвейера CI/CD.\nЯ считаю важным отметить, что не все инструменты должны делать и CI, и CD. Мы рассмотрим ArgoCD, который, как вы догадались, отлично справляется с CD-элементом развертывания нашего программного обеспечения в кластере Kubernetes. Но что-то вроде Jenkins может работать на разных платформах.\nЯ планирую рассмотреть следующее:\nJenkins ArgoCD GitHub Actions Ресурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"70. Конвейеры CI/CD","uri":"/ru/docs/90daysofdevops/day70/"},{"content":" Jenkins - это инструмент непрерывной интеграции, который позволяет непрерывно разрабатывать, тестировать и развертывать вновь созданный код.\nЭтого можно достичь двумя способами: ночные сборки или непрерывная разработка. Первый вариант заключается в том, что наши разработчики в течение дня занимаются своими задачами и в конце рабочего дня вносят свои изменения в репозиторий исходного кода. Затем в течение ночи мы проводим модульные тесты и собираем программное обеспечение. Это можно считать старым способом интеграции всего кода.\nДругой вариант и более предпочтительный способ заключается в том, что наши разработчики по-прежнему фиксируют свои изменения в исходном коде, а затем, после фиксации кода, непрерывно запускается процесс сборки.\nПриведенные выше методы означают, что при распределении разработчиков по всему миру у нас нет определенного времени каждый день, когда мы должны прекратить фиксацию изменений в коде. Именно здесь на помощь приходит Jenkins, который выступает в роли CI-сервера, контролирующего тесты и процессы сборки.\nЯ знаю, что мы говорим о Jenkins, но я также хочу добавить еще несколько, которые можно будет рассмотреть позже, чтобы понять, почему я вижу Jenkins как наиболее популярный, почему это так и что другие могут сделать по сравнению с Jenkins.\nTravisCI - Размещенный, распределенный сервис непрерывной интеграции, используемый для сборки и тестирования программных проектов, размещенных на GitHub.\nBamboo - может запускать несколько сборок параллельно для более быстрой компиляции, имеет встроенную функциональность для связи с репозиториями и задачи сборки для Ant, Maven.\nBuildbot - это фреймворк с открытым исходным кодом для автоматизации процессов сборки, тестирования и выпуска программного обеспечения. Он написан на языке Python и поддерживает распределенное, параллельное выполнение заданий на нескольких платформах.\nApache Gump - специфичен для Java-проектов, разработан с целью сборки и тестирования этих Java-проектов каждую ночь. обеспечивает совместимость всех проектов как на уровне API, так и на уровне функциональности.\nПоскольку мы сейчас сосредоточимся на Jenkins - Jenkins, как и все вышеперечисленные инструменты, имеет открытый исходный код и представляет собой сервер автоматизации, написанный на Java. Он используется для автоматизации процесса разработки программного обеспечения посредством непрерывной интеграции и облегчает непрерывную доставку.\nОсобенности Jenkins Как и следовало ожидать, Jenkins имеет множество функций, охватывающих множество областей.\nПростая установка - Jenkins - это самостоятельная программа на базе java, готовая к работе с пакетами для операционных систем Windows, macOS и Linux.\nПростая конфигурация - Простая установка и настройка через веб-интерфейс, включающий проверку ошибок и встроенную помощь.\nПлагины - Множество плагинов доступно в Центре обновления и интегрируется со многими инструментами в инструментальной цепочке CI / CD.\nРасширяемость - В дополнение к доступным плагинам, Jenkins может быть расширен за счет архитектуры плагинов, что обеспечивает практически бесконечное количество вариантов того, для чего он может быть использован.\nРаспределенность - Jenkins легко распределяет работу по нескольким машинам, помогая ускорить сборку, тестирование и развертывание на различных платформах.\nJenkins Pipeline Вы уже видели этот конвейер, но он используется гораздо шире, и мы не говорили о конкретных инструментах.\nВы собираетесь фиксировать код в Jenkins, который затем будет собирать ваше приложение со всеми автоматизированными тестами, а затем выпускать и развертывать этот код после завершения каждого этапа. Jenkins позволяет автоматизировать этот процесс.\nАрхитектура Jenkins Во-первых, чтобы не изобретать велосипед, всегда стоит начать с Документации Jenkins, но я собираюсь изложить свои заметки и выводы и здесь.\nJenkins может быть установлен на многих различных операционных системах, Windows, Linux и macOS, а также имеет возможность развертывания в виде контейнера Docker и в Kubernetes. Установка Jenkins\nПо мере изучения этого вопроса мы, вероятно, рассмотрим установку Jenkins в кластере minikube, имитируя развертывание в Kubernetes. Но это будет зависеть от скриптов, которые мы составим в оставшейся части раздела.\nТеперь давайте разберем изображение ниже.\nШаг 1 - Разработчики фиксируют изменения в репозитории исходного кода.\nШаг 2 - Jenkins проверяет репозиторий через регулярные промежутки времени и извлекает любой новый код.\nШаг 3 - Сервер сборки затем собирает код в исполняемый файл, в данном примере мы используем maven как хорошо известный сервер сборки. Еще одна область, которую необходимо охватить.\nШаг 4 - Если сборка не удалась, то разработчикам отправляется обратная связь.\nШаг 5 - Jenkins развертывает собранное приложение на тестовом сервере, в данном примере мы используем selenium как хорошо известный тестовый сервер. Еще одна область, которую необходимо охватить.\nШаг 6 - Если тест не прошел, то обратная связь передается разработчикам.\nШаг 7 - Если тесты прошли успешно, мы можем выпустить продукт в производство.\nЭтот цикл непрерывен, именно это позволяет обновлять приложения за минуты, а не за часы, дни, месяцы, годы!\nАрхитектура Jenkins может быть описана гораздо подробнее, если вам это нужно, у них есть возможность работы в режиме master-slave, что позволяет ведущему распределять задачи между подчиненными jenkins.\nДля справки, поскольку Jenkins является открытым исходным кодом, будет много предприятий, которым требуется поддержка, CloudBees - это корпоративная версия Jenkins, которая предоставляет поддержку и, возможно, другие функциональные возможности для платного корпоративного клиента.\nПримером такого клиента является компания Bosch, вы можете ознакомиться с примером Bosch здесь.\nЯ собираюсь найти пошаговый пример приложения, которое мы могли бы использовать, чтобы пройтись по Jenkins, а затем использовать его с другими инструментами.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"71. Введение в Jenkins","uri":"/ru/docs/90daysofdevops/day71/"},{"content":"Сегодня мы планируем немного поработать с Jenkins и сделать что-то в рамках нашего конвейера CI, рассматривая некоторые примеры кодовых баз, которые мы можем использовать.\nЧто такое конвейер? Прежде чем мы начнем, нам нужно знать, что такое конвейер, когда речь идет о CI, и мы уже рассмотрели это на вчерашнем занятии с помощью следующего изображения.\nМы хотим взять процессы или шаги, описанные выше, и автоматизировать их, чтобы в итоге получить результат, то есть развернутое приложение, которое мы можем отправить нашим клиентам, конечным пользователям и т.д.\nЭтот автоматизированный процесс позволяет нам иметь контроль версий для наших пользователей и клиентов. Каждое изменение, улучшение функций, исправление ошибок и т.д. проходит через этот автоматизированный процесс, подтверждая, что все в порядке, без излишнего ручного вмешательства, чтобы убедиться, что наш код хорош.\nЭтот процесс включает в себя создание программного обеспечения надежным и повторяемым способом, а также продвижение созданного программного обеспечения (называемого “сборкой”) через несколько этапов тестирования и развертывания.\nКонвейер jenkins записывается в текстовый файл Jenkinsfile. Который сам должен быть зафиксирован в репозитории контроля исходного кода. Это также известно как Pipeline as code, мы также можем сравнить это с Infrastructure as code, о которой мы рассказывали несколько недель назад.\nJenkins Pipeline Definition\nРазвертывание Jenkins Я получил некоторое удовольствие от развертывания Jenkins, Вы заметите из документации, что есть много вариантов того, где вы можете установить Jenkins.\nУчитывая, что у меня под рукой есть minikube, и мы уже использовали его несколько раз, я хотел использовать его и для этой задачи. (Хотя шаги, описанные в Kubernetes Installation, привели к тому, что я уперся в стену и не смог запустить систему, вы можете сравнить эти два варианта, когда я задокументирую свои шаги здесь.\nПервым шагом будет запуск нашего кластера minikube, мы можем сделать это с помощью команды minikube start.\nЯ добавил папку со всеми конфигурациями и значениями YAML, которые можно найти здесь Теперь, когда у нас есть наш кластер, мы можем выполнить следующие действия для создания пространства имен jenkins. kubectl create -f jenkins-namespace.yml\nМы будем использовать Helm для развертывания jenkins в нашем кластере, о Helm мы рассказывали в разделе Kubernetes. Сначала нам нужно добавить репозиторий jenkinsci в helm helm repo add jenkinsci https://charts.jenkins.io, затем обновить наши таблицы helm repo update.\nИдея Jenkins заключается в том, что он будет сохранять состояние для своих пайплайнов, вы можете запустить вышеупомянутую установку helm без персистентности, но если эти pods будут перезагружены, изменены или модифицированы, то все пайплайны или конфигурации, которые вы создали, будут потеряны. Мы создадим том для персистентности, используя файл jenkins-volume.yml с помощью команды kubectl apply -f jenkins-volume.yml.\nНам также нужна учетная запись службы, которую мы можем создать с помощью этого yaml-файла и команды. kubectl apply -f jenkins-sa.yml\nНа этом этапе мы готовы к развертыванию с помощью схемы helm, сначала мы определим нашу схему с помощью chart=jenkinsci/jenkins, а затем развернем с помощью этой команды, где jenkins-values.yml содержит учетные записи персистентности и сервисов, которые мы ранее развернули на нашем кластере. helm install jenkins -n jenkins -f jenkins-values.yml $chart.\nНа этом этапе наши капсулы будут извлекать образ, но у капсулы не будет доступа к хранилищу, поэтому никакая конфигурация не может быть начата с точки зрения запуска Jenkins.\nИменно здесь документация не помогла мне понять, что должно произойти. Но мы видим, что у нас нет разрешения на запуск установки jenkins.\nДля того чтобы исправить вышеописанное или решить проблему, нам нужно убедиться, что мы предоставили доступ или правильное разрешение для того, чтобы наши jenkins pods могли писать в это место, которое мы предложили. Мы можем сделать это, используя minikube ssh, который введет нас в докер-контейнер minikube, на котором мы работаем, а затем, используя sudo chown -R 1000:1000 /data/jenkins-volume, мы можем убедиться, что у нас установлены разрешения на наш том данных.\nВышеописанный процесс должен исправить капсулы, однако если это не так, вы можете заставить капсулы обновиться с помощью команды kubectl delete pod jenkins-0 -n jenkins. На этом этапе у вас должно быть 2/2 запущенных стручка под названием jenkins-0.\nТеперь нам нужен наш пароль администратора, и мы можем сделать это с помощью следующей команды. kubectl exec --namespace jenkins -it svc/jenkins -c jenkins -- /bin/cat /run/secrets/chart-admin-password \u0026\u0026 echo\nТеперь откройте новый терминал, так как мы собираемся использовать команду port-forward, чтобы получить доступ с нашей рабочей станции. kubectl --namespace jenkins port-forward svc/jenkins 8080:8080.\nТеперь мы должны быть в состоянии открыть браузер и войти на http://localhost:8080 и аутентифицироваться с именем пользователя: admin и паролем, которые мы собрали в предыдущем шаге.\nПосле аутентификации наша страница приветствия Jenkins должна выглядеть примерно так:\nОтсюда я бы предложил перейти к “Manage Jenkins”, и вы увидите “Manage Plugins”, где будут доступны некоторые обновления. Выберите все эти плагины и выберите “Загрузить сейчас и установить после перезапуска”.\nЕсли вы хотите пойти еще дальше и автоматизировать развертывание Jenkins с помощью shell-скрипта, этот замечательный репозиторий был предоставлен мне в twitter mehyedes/nodejs-k8s\nJenkinsfile Теперь у нас есть Jenkins, развернутый в нашем кластере Kubernetes, мы можем вернуться назад и подумать об этом Jenkinsfile.\nКаждый Jenkinsfile, скорее всего, будет начинаться примерно так: сначала вы определяете шаги вашего конвейера, в данном случае это Build \u003e Test \u003e Deploy. Но на самом деле мы не делаем ничего, кроме использования команды echo для вызова определенных этапов.\nJenkinsfile (декларативный конвейер)\rpipeline {\ragent any\rstages {\rstage('Build') {\rsteps {\recho 'Building..'\r}\r}\rstage('Test') {\rsteps {\recho 'Testing..'\r}\r}\rstage('Deploy') {\rsteps {\recho 'Deploying....'\r}\r}\r}\r}\rВ нашей приборной панели Jenkins выберите “New Item” дайте элементу имя, я собираюсь “echo1” Я собираюсь предложить, что это Pipeline.\nНажмите Ok, и у вас появятся вкладки (General, Build Triggers, Advanced Project Options и Pipeline) для простого теста нас интересует только Pipeline. В разделе Pipeline у вас есть возможность добавить скрипт, мы можем скопировать и вставить приведенный выше скрипт в поле.\nКак мы уже говорили выше, это не даст многого, но покажет нам этапы нашей сборки \u003e тестирования \u003e развертывания\nНажмите Save, теперь мы можем запустить нашу сборку, используя сборку, показанную ниже.\nМы также должны открыть терминал и выполнить команду kubectl get pods -n jenkins, чтобы посмотреть, что произойдет.\nХорошо, очень просто, но теперь мы можем видеть, что наше развертывание и установка Jenkins работает правильно, и мы можем начать видеть здесь строительные блоки конвейера CI.\nВ следующем разделе мы будем строить конвейер Jenkins.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"72. Работа с Jenkins","uri":"/ru/docs/90daysofdevops/day72/"},{"content":"В предыдущем разделе мы развернули Jenkins на нашем кластере Minikube и создали очень простой Jenkins Pipeline, который не делал ничего особенного, кроме как повторял этапы Pipeline.\nВы также могли заметить, что в процессе создания Jenkins Pipeline нам доступны некоторые примеры скриптов для запуска.\nПервый демонстрационный скрипт - “Declartive (Kubernetes)”, и вы можете увидеть его этапы ниже.\n// Uses Declarative syntax to run commands inside a container.\rpipeline {\ragent {\rkubernetes {\r// Rather than inline YAML, in a multibranch Pipeline you could use: yamlFile 'jenkins-pod.yaml'\r// Or, to avoid YAML:\r// containerTemplate {\r// name 'shell'\r// image 'ubuntu'\r// command 'sleep'\r// args 'infinity'\r// }\ryaml '''\rapiVersion: v1\rkind: Pod\rspec:\rcontainers:\r- name: shell\rimage: ubuntu\rcommand:\r- sleep\rargs:\r- infinity\r'''\r// Can also wrap individual steps:\r// container('shell') {\r// sh 'hostname'\r// }\rdefaultContainer 'shell'\r}\r}\rstages {\rstage('Main') {\rsteps {\rsh 'hostname'\r}\r}\r}\r}\rНиже показан результат того, что происходит при выполнении этого конвейера.\nСоздание задания Цели\nСоздать простое приложение и сохранить его в публичном репозитории GitHub (https://github.com/scriptcamp/kubernetes-kaniko.git).\nС помощью Jenkins собрать образ нашего docker-контейнера и выложить в docker hub. (Для этого мы будем использовать частный репозиторий).\nЧтобы добиться этого в нашем кластере Kubernetes, работающем в Minikube или с его помощью, нам нужно использовать нечто под названием Kaniko В общем, если вы используете Jenkins в реальном кластере Kubernetes или запускаете его на сервере, вы можете указать агента, который даст вам возможность выполнять команды сборки docker и загружать их в DockerHub.\nУчитывая вышесказанное, мы также собираемся развернуть секрет в Kubernetes с нашими учетными данными GitHub.\nkubectl create secret docker-registry dockercred \\\r--docker-server=https://index.docker.io/v1/ \\\r--docker-username=\u003cdockerhub-username\u003e \\\r--docker-password=\u003cdockerhub-password\u003e\\\r--docker-email=\u003cdockerhub-email\u003e\rНа самом деле я хочу поделиться еще одним замечательным ресурсом от DevOpsCube.com, где рассматривается многое из того, о чем мы будем говорить здесь.\nДобавление учетных данных в Jenkins Однако если вы используете систему Jenkins, в отличие от нашей, то вы, скорее всего, захотите определить свои учетные данные в Jenkins, а затем использовать их несколько раз в своих конвейерах и конфигурациях. Мы можем ссылаться на эти учетные данные в конвейерах, используя ID, который мы определили при создании. Я пошел дальше и создал учетные данные для DockerHub и GitHub.\nСначала выберите “Manage Jenkins”, а затем “Manage Credentials”.\nВ центре страницы вы увидите магазины, предназначенные для Jenkins, нажмите на Jenkins здесь.\nТеперь выберите Global Credentials (Unrestricted).\nЗатем в левом верхнем углу у вас есть Добавить учетные данные\nЗаполните данные вашей учетной записи и затем выберите OK, помните, что ID - это то, на что вы будете ссылаться, когда захотите вызвать эту учетную запись. Мой совет здесь также заключается в том, что вы должны использовать специальные маркеры доступа, а не пароли.\nДля GitHub вы должны использовать Personal Access Token.\nЛично мне процесс создания этих учетных записей показался не очень интуитивным, поэтому, хотя мы не используем их, я хотел поделиться процессом, так как он не совсем понятен из пользовательского интерфейса.\nПостроение конвейера У нас есть учетные данные DockerHub, развернутые как секрет в нашем кластере Kubernetes, к которым мы будем обращаться на этапе docker deploy to DockerHub в нашем конвейере.\nСценарий конвейера - это то, что вы видите ниже, это, в свою очередь, может стать нашим Jenkinsfile, расположенным в нашем репозитории GitHub, который, как вы можете видеть, также указан на этапе Get the project в конвейере.\npodTemplate(yaml: '''\rapiVersion: v1\rkind: Pod\rspec:\rcontainers:\r- name: maven\rimage: maven:3.8.1-jdk-8\rcommand:\r- sleep\rargs:\r- 99d\r- name: kaniko\rimage: gcr.io/kaniko-project/executor:debug\rcommand:\r- sleep\rargs:\r- 9999999\rvolumeMounts:\r- name: kaniko-secret\rmountPath: /kaniko/.docker\rrestartPolicy: Never\rvolumes:\r- name: kaniko-secret\rsecret:\rsecretName: dockercred\ritems:\r- key: .dockerconfigjson\rpath: config.json\r''') {\rnode(POD_LABEL) {\rstage('Get the project') {\rgit url: 'https://github.com/scriptcamp/kubernetes-kaniko.git', branch: 'main'\rcontainer('maven') {\rstage('Test the project') {\rsh '''\recho pwd\r'''\r}\r}\r}\rstage('Build \u0026 Test the Docker Image') {\rcontainer('kaniko') {\rstage('Deploy to DockerHub') {\rsh '''\r/kaniko/executor --context `pwd` --destination michaelcade1/helloworld:latest\r'''\r}\r}\r}\r}\r}\rЧтобы начать работу на приборной панели Jenkins, нам нужно выбрать “Новый элемент”\nЗатем мы дадим нашему элементу имя, выберем Pipeline и нажмем OK.\nМы не будем выбирать общие триггеры или триггеры сборки, но поиграйте с ними, так как здесь есть несколько интересных расписаний и других конфигураций, которые могут быть полезны.\nНас интересует только вкладка Pipeline в конце.\nВ определении пайплайн мы скопируем и вставим скрипт пайплайна, который мы описали выше, в раздел Script и нажмем кнопку save.\nДалее мы выберем опцию “Build Now” в левой части страницы.\nТеперь вам нужно подождать некоторое время, меньше минуты, и вы должны увидеть в статусе этапы, которые мы определили выше в нашем скрипте.\nЧто еще более важно, если мы теперь перейдем на наш DockerHub и проверим, что у нас есть новая сборка.\nВ целом это заняло некоторое время, но я хотел придерживаться этого, чтобы получить практический опыт и проработать скрипт, который может выполнить каждый, используя minikube и доступ к github и dockerhub.\nРепозиторий DockerHub, который я использовал для этого демо, был частным. Но в следующем разделе я хочу продвинуть некоторые из этих этапов и заставить их действительно что-то делать, а не просто выводить pwd, и действительно запустить некоторые тесты и этапы сборки.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"73. Построение конвейера Jenkins","uri":"/ru/docs/90daysofdevops/day73/"},{"content":"Здравствуй мир - Jenkinsfile App Pipeline В предыдущем разделе мы построили простой конвейер в Jenkins, который будет перемещать наш образ докера из нашего dockerfile в публичном репозитории GitHub в наш частный репозиторий Dockerhub.\nВ этом разделе мы хотим сделать еще один шаг вперед и добиться следующего с помощью нашего простого приложения.\nЦель Dockerfile (Hello World) Jenkinsfile Jenkins Pipeline для запуска при обновлении репозитория GitHub Используйте репозиторий GitHub в качестве источника. Запуск - Clone/Get Repository, Build, Test, Deploy Stages Развертывание на DockerHub с инкрементными номерами версий Stretch Goal для развертывания на нашем кластере Kubernetes (для этого потребуется еще одно задание и репозиторий манифеста с использованием учетных данных GitHub). Шаг первый У нас есть наш GitHub репозиторий В настоящее время он содержит наш Dockerfile и наш index.html\nЭто то, что мы использовали в качестве источника в нашем конвейере, теперь мы хотим добавить этот скрипт Jenkins Pipeline в наш репозиторий GitHub.\nТеперь вернемся к нашей приборной панели Jenkins и создадим новый пайплайн, но теперь вместо вставки нашего скрипта мы будем использовать “Pipeline script from SCM” Мы будем использовать приведенные ниже параметры конфигурации.\nДля справки мы будем использовать https://github.com/MichaelCade/Jenkins-HelloWorld.git в качестве URL репозитория.\nНа этом этапе мы можем нажать кнопку сохранить и применить, после чего мы сможем вручную запустить наш Pipeline для сборки нового образа Docker, загруженного в наш репозиторий DockerHub.\nОднако я также хочу убедиться, что мы установили расписание, по которому при каждом изменении нашего репозитория или исходного кода будет запускаться сборка. Мы можем использовать веб-крючки или запланированное извлечение.\nЭто важный момент, потому что если вы используете дорогостоящие облачные ресурсы для хранения конвейера и у вас много изменений в репозитории кода, то вы понесете большие расходы. Мы знаем, что это демонстрационная среда, поэтому я использую опцию “poll scm”. (Также я считаю, что при использовании minikube мне не хватает возможности использовать webhooks)\nОдна вещь, которую я изменил со вчерашней сессии, это то, что теперь я хочу загружать изображение в публичный репозиторий, который в данном случае будет michaelcade1\\90DaysOfDevOps, мой Jenkinsfile уже содержит это изменение. И из предыдущих разделов я удалил все существующие образы демо-контейнеров.\nДвигаясь назад, мы создали наш Pipeline, а затем, как было показано ранее, добавили нашу конфигурацию.\nНа данном этапе наш конвейер еще не запущен, и вид сцены будет выглядеть примерно так.\nТеперь нажмем кнопку “Build Now”. и в представлении этапа будут отображены наши этапы.\nЕсли мы перейдем к нашему репозиторию DockerHub, у нас должно быть 2 новых образа Docker. У нас должен быть идентификатор сборки 1 и последняя версия, потому что каждая сборка, которую мы создаем на основе команды “Upload to DockerHub”, отправляет версию, используя переменную окружения Jenkins Build_ID, а также выпускает последнюю версию.\nДавайте создадим обновление файла index.html в нашем репозитории GitHub, как показано ниже, я позволю вам пойти и узнать, что говорила версия 1 файла index.html.\nЕсли мы вернемся в Jenkins и снова выберем “Build Now”. Мы увидим, что наша сборка #2 прошла успешно.\nЗатем быстро взглянув на DockerHub, мы увидим, что у нас есть наш тег версии 2 и наш последний тег.\nЗдесь стоит отметить, что я добавил в свой кластер Kubernetes секрет, который позволяет мне получить доступ и аутентификацию для отправки моих сборок docker в DockerHub. Если вы следуете этому примеру, вам следует повторить этот процесс для своей учетной записи, а также внести изменения в Jenkinsfile, связанный с моим репозиторием и учетной записью.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"74. Hello World - Jenkinsfile App Pipeline","uri":"/ru/docs/90daysofdevops/day74/"},{"content":"Обзор действий GitHub В этом разделе я хотел бы перейти к рассмотрению, возможно, другого подхода, чем тот, на который мы только что потратили время. На этом занятии мы сосредоточимся на GitHub Actions.\nGitHub Actions - это платформа CI/CD, которая позволяет нам строить, тестировать и развертывать, помимо прочих задач, наш конвейер. В ней есть концепция рабочих процессов, которые собираются и тестируются на основе репозитория GitHub. Вы также можете использовать GitHub Actions для управления другими рабочими процессами на основе событий, происходящих в вашем репозитории.\nРабочие процессы В целом, в GitHub Actions наша задача называется рабочий процесс.\nРабочий процесс** - это настраиваемый автоматизированный процесс. Определяется как файлы YAML. Содержит и запускает одно или несколько заданий. Запускается при срабатывании события в вашем хранилище или может быть запущен вручную. Вы можете использовать несколько рабочих процессов для каждого хранилища. рабочий процесс содержит задание, а затем шаги для достижения этого задания. В рамках рабочего процесса у нас также будет запускающий механизм, на котором будет выполняться наш рабочий процесс. Например, у вас может быть один рабочий процесс для создания и тестирования запросов, другой рабочий процесс для развертывания вашего приложения каждый раз, когда создается релиз, и еще один рабочий процесс, который добавляет метку каждый раз, когда кто-то открывает новую проблему.\nСобытия События - это определенные события в хранилище, которые запускают рабочий процесс на выполнение.\nЗадания Задание - это набор шагов рабочего процесса, которые выполняются на бегунке.\nШаги Каждый шаг в задании может быть скриптом оболочки, который выполняется, или действием. Шаги выполняются по порядку и зависят друг от друга.\nДействия Повторяющееся пользовательское приложение, используемое для часто повторяющихся задач.\nБегуны Бегунок - это сервер, который запускает рабочий процесс, каждый бегунок выполняет одно задание за раз. GitHub Actions предоставляет возможность запуска бегунов для Ubuntu Linux, Microsoft Windows и macOS. Вы также можете разместить свой собственный на определенной ОС или оборудовании.\nНиже вы можете увидеть, как это выглядит: у нас есть событие, запускающее наш рабочий процесс \u003e наш рабочий процесс состоит из двух заданий \u003e внутри наших заданий есть шаги, а затем действия.\nYAML Прежде чем мы приступим к рассмотрению реального случая использования, давайте взглянем на приведенное выше изображение в виде примера YAML-файла.\nЯ добавил #, чтобы прокомментировать, где мы можем найти компоненты рабочего процесса YAML.\n#Workflow\rname: 90DaysOfDevOps\r#Event\ron: [push]\r#Jobs\rjobs:\rcheck-bats-version:\r#Runners\rruns-on: ubuntu-latest\r#Steps\rsteps:\r#Actions\r- uses: actions/checkout@v2\r- uses: actions/setup-node@v2\rwith:\rnode-version: '14'\r- run: npm install -g bats\r- run: bats -v\rПриступаем к работе с GitHub Actions Я думаю, что у GitHub Actions есть много возможностей, да, они удовлетворят ваши потребности в CI/CD, когда речь идет о сборке, тестировании, развертывании вашего кода и последующих шагах.\nЯ вижу множество вариантов и других автоматизированных задач, для которых мы могли бы использовать GitHub Actions.\nИспользование GitHub Actions для линтинга вашего кода Один из вариантов - убедиться, что ваш код чист и аккуратен в вашем репозитории. Это будет наш первый демонстрационный пример.\nЯ собираюсь использовать некоторый пример кода, связанный в одном из ресурсов для этого раздела, мы будем использовать github/super-linter для проверки нашего кода.\nname: Super-Linter\ron: push\rjobs:\rsuper-lint:\rname: Lint code base\rruns-on: ubuntu-latest\rsteps:\r- name: Checkout code\ruses: actions/checkout@v2\r- name: Run Super-Linter\ruses: github/super-linter@v3\renv:\rDEFAULT_BRANCH: main\rGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\rgithub/super-linter Вы можете видеть, что для одного из наших шагов у нас есть действие под названием github/super-linter, которое ссылается на шаг, уже написанный сообществом. Вы можете узнать больше об этом здесь Super-Linter\n“Этот репозиторий предназначен для GitHub Action для запуска Super-Linter. Это простая комбинация различных линтеров, написанных на bash, чтобы помочь проверить ваш исходный код.”\nТакже в приведенном фрагменте кода упоминается GITHUB_TOKEN, поэтому мне было интересно узнать, зачем и для чего это нужно.\n“ПРИМЕЧАНИЕ: Если вы передадите переменную окружения GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} в вашем рабочем процессе, то GitHub Super-Linter будет отмечать статус каждого отдельного запуска линтера в разделе “Проверки” запроса на выгрузку. Без этого вы будете видеть только общий статус всего прогона. Не нужно устанавливать GitHub Secret, так как он автоматически устанавливается GitHub, его нужно только передать в действие.”.\nВыделенный жирным текст важно отметить на данном этапе. Мы используем его, но нам не нужно устанавливать какую-либо переменную окружения в нашем репозитории.\nДля тестирования мы будем использовать наш репозиторий, который мы использовали в нашей демонстрации Jenkins.Jenkins-HelloWorld.\nВот наш репозиторий в том виде, в котором мы оставили его в сессии Jenkins.\nДля того, чтобы воспользоваться преимуществами, мы должны использовать вкладку Actions выше, чтобы выбрать из рынка, о котором я расскажу в ближайшее время, или мы можем создать наши собственные файлы, используя наш код супер-лайнера выше, чтобы создать свой собственный, вы должны создать новый файл в вашем репозитории именно в этом месте. .github/workflows/workflow_name, очевидно, убедившись, что имя workflow_name - это что-то полезное для вас, узнаваемое. Здесь мы можем иметь множество различных рабочих процессов, выполняющих различные задания и задачи в нашем репозитории.\nМы создадим .github/workflows/super-linter.yml.\nЗатем мы можем вставить наш код и зафиксировать его в нашем репозитории, если мы перейдем на вкладку Actions, то увидим наш рабочий процесс Super-Linter в списке, как показано ниже,\nМы определили в нашем коде, что этот рабочий процесс будет запускаться, когда мы будем перемещать что-либо в наш репозиторий, поэтому при перемещении файла super-linter.yml в наш репозиторий мы запустили рабочий процесс.\nКак вы можете видеть из вышеприведенного, у нас есть некоторые ошибки, скорее всего, из-за моих способностей к взлому и кодированию.\nХотя на самом деле это был не мой код, по крайней мере пока, запустив его и получив ошибку, я обнаружил вот это issue\nДубль #2 Я изменил версию Super-Linter с версии 3 на 4 и запустил задачу снова.\nКак и ожидалось, мой хакерский кодинг вызвал некоторые проблемы, и вы можете увидеть их здесь, в рабочем процессе.\nЯ хотел показать, как теперь выглядит наш репозиторий, когда что-то в рабочем процессе не сработало или сообщило об ошибке.\nТеперь, если мы решим проблему с моим кодом и внесем изменения, наш рабочий процесс снова запустится (как видно из изображения, потребовалось некоторое время, чтобы устранить наши “ошибки”). Удаление файла, вероятно, не рекомендуется, но это очень быстрый способ показать, что проблема решена.\nЕсли вы нажмете кнопку “Новый рабочий процесс”, выделенную выше, это откроет вам дверь к огромному количеству действий. Вы, наверное, заметили, что мы не хотим изобретать колесо, мы хотим стоять на плечах гигантов и делиться нашим кодом, автоматизацией и навыками, чтобы сделать нашу жизнь проще.\nО, я не показал вам зеленую галочку на репозитории, когда наш рабочий процесс был успешным.\nЯ думаю, что на этом основы GitHub Actions исчерпаны, но если вы похожи на меня, то вы наверняка видите, как еще можно использовать GitHub Actions для автоматизации множества задач.\nДалее мы рассмотрим другую область CD, мы рассмотрим ArgoCD для развертывания наших приложений в наших средах.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"75. Обзор GitHub Actions","uri":"/ru/docs/90daysofdevops/day75/"},{"content":"Обзор ArgoCD “Argo CD - это декларативный инструмент непрерывной доставки GitOps для Kubernetes”.\nКонтроль версий - ключевой момент здесь. Вы когда-нибудь вносили изменения в вашу среду на лету и не помните об этих изменениях, а поскольку свет горит и все вокруг зеленое, вы продолжаете упорно двигаться вперед? Вы когда-нибудь вносили изменения и ломали все или часть всего? Вы могли бы знать, что внесли изменение, и вы можете быстро откатить свое изменение, тот плохой скрипт или опечатку. А теперь сделайте это в массовом масштабе, и, возможно, это были не вы, или, возможно, ошибка была обнаружена не сразу, и теперь бизнес страдает. Поэтому контроль версий очень важен. Не только это, но и “определения приложений, конфигурации и окружения должны быть декларативными и контролируемыми по версиям”. В дополнение к этому (что взято из ArgoCD), они также упоминают, что “развертывание приложений и управление жизненным циклом должно быть автоматизировано, проверяемо и просто для понимания”.\nС точки зрения операционной деятельности, но много играя с Infrastructure as Code, это следующий шаг к обеспечению того, чтобы все эти хорошие вещи были улажены по пути с помощью рабочих процессов непрерывного развертывания/доставки.\nЧто такое ArgoCD\nРазвертывание ArgoCD Для этого развертывания мы снова будем использовать наш надежный кластер minikube Kubernetes локально.\nkubectl create namespace argocd\rkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\rУбедитесь, что все подсистемы ArgoCD запущены и работают с помощью команды kubectl get pods -n argocd.\nТакже проверим все, что мы развернули в пространстве имен с помощью kubectl get all -n argocd\nКогда все выглядит хорошо, мы должны рассмотреть возможность доступа к этому через порт. Используя команду kubectl port-forward svc/argocd-server -n argocd 8080:443. Сделайте это в новом терминале.\nЗатем откройте новый веб-браузер и перейдите по адресу https://localhost:8080.\nДля входа в систему вам понадобится имя пользователя admin, а для получения созданного вами секрета в качестве пароля используйте команду kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d \u0026\u0026 echo\nПосле входа в систему у вас будет чистый холст CD.\nРазвертывание нашего приложения Теперь у нас есть ArgoCD, и мы можем начать использовать его для развертывания наших приложений из наших Git-репозиториев, а также Helm.\nПриложение, которое я хочу развернуть, это Pac-Man, да, именно так, знаменитая игра и то, что я использую во многих демонстрациях, когда речь идет об управлении данными, это не последний раз, когда мы видим Pac-Man.\nВы можете найти репозиторий для Pac-Man здесь.\nВместо того чтобы описывать каждый шаг с помощью снимков экрана, я решил, что будет проще создать видеоролик с описанием шагов, предпринятых для развертывания этого конкретного приложения.\nArgoCD Demo - 90DaysOfDevOps\nПримечание - Во время видео есть служба, которая никогда не удовлетворяется как здоровое приложение, это потому, что тип LoadBalancer, установленный для службы pacman, находится в состоянии ожидания, в Minikube у нас нет настроенного loadbalancer. Если вы хотите проверить это, вы можете изменить YAML для службы на ClusterIP и использовать проброс портов для игры.\nНа этом мы завершаем раздел CICD Pipelines, я считаю, что в настоящее время в индустрии уделяется большое внимание этой области, и вы также услышите термины GitOps, связанные с методологиями, используемыми в CICD в целом.\nСледующий раздел, в который мы переходим, посвящен Observability, еще одной концепции или области, которая не является новой, но становится все более важной, поскольку мы смотрим на наши среды по-другому.\nРесурсы Jenkins is the way to build, test, deploy Jenkins.io ArgoCD ArgoCD Tutorial for Beginners What is Jenkins? Complete Jenkins Tutorial GitHub Actions GitHub Actions CI/CD ","description":"","title":"76. Обзор ArgoCD","uri":"/ru/docs/90daysofdevops/day76/"},{"content":"Введение: Мониторинг В этом разделе мы поговорим о мониторинге, что это такое, зачем он нам нужен?\nЧто такое мониторинг? Мониторинг - это процесс пристального наблюдения за всей инфраструктурой.\nи зачем он нам нужен? Предположим, что мы управляем тысячей серверов, которые включают в себя множество специализированных серверов, таких как серверы приложений, серверы баз данных и веб-серверы. Мы также можем усложнить эту задачу за счет дополнительных сервисов и различных платформ, включая публичные облачные предложения и Kubernetes.\nМы отвечаем за то, чтобы все сервисы, приложения и ресурсы на серверах работали так, как должны.\nКак мы это делаем? Есть три способа:\nВойти вручную на все наши серверы и проверить все данные, относящиеся к процессам и ресурсам служб. Написать скрипт, который заходит на серверы за нас и проверяет данные. Оба варианта потребуют от нас значительного объема работы,\nТретий вариант проще, мы можем использовать решение для мониторинга, которое доступно на рынке.\nNagios и Zabbix - это возможные решения, которые легко доступны и позволяют нам расширить нашу инфраструктуру мониторинга, чтобы включить столько серверов, сколько мы захотим.\nNagios Nagios - это инструмент мониторинга инфраструктуры, созданный одноименной компанией. Версия этого инструмента с открытым исходным кодом называется Nagios core, а коммерческая версия называется Nagios XI. Сайт Nagios\nЭтот инструмент позволяет нам следить за нашими серверами и видеть, достаточно ли они используются или есть какие-либо задачи, требующие решения.\nПо сути, мониторинг позволяет нам достичь этих двух целей, проверить состояние наших серверов и сервисов и определить здоровье нашей инфраструктуры. Он также дает нам возможность увидеть всю инфраструктуру с высоты 40 000 метров, чтобы увидеть, работают ли наши серверы, правильно ли работают приложения, доступны или нет веб-серверы.\nОн сообщит нам, что объем нашего диска увеличивался на 10 процентов в течение последних 10 недель на определенном сервере, что он будет полностью исчерпан в течение следующих четырех или пяти дней, и мы не сможем ответить в ближайшее время. Он предупредит нас, когда ваш диск или сервер находится в критическом состоянии, чтобы мы могли принять соответствующие меры, чтобы избежать возможных сбоев.\nВ этом случае мы можем освободить некоторое дисковое пространство и гарантировать, что наши серверы не выйдут из строя и наши пользователи не пострадают.\nСложный вопрос для большинства инженеров по мониторингу - что мы отслеживаем, а что нет?\nКаждая система имеет ряд ресурсов, за какими из них мы должны внимательно следить, а на какие можем закрыть глаза, например, нужно ли следить за использованием процессора, ответ “да” очевиден, тем не менее, это все равно решение, которое нужно принять, нужно ли следить за количеством открытых портов в системе, мы можем следить или не следить в зависимости от ситуации, если это сервер общего назначения, то, вероятно, не нужно, но если это веб-сервер, то, вероятно, нужно.\nПостоянный мониторинг Мониторинг не является чем-то новым, и даже непрерывный мониторинг был идеалом, который многие предприятия приняли в течение многих лет.\nЕсть три ключевых области, на которых необходимо сосредоточиться, когда речь заходит о мониторинге.\nМониторинг инфраструктуры Мониторинг приложений Мониторинг сети Важно отметить, что существует множество доступных инструментов, мы упомянули две общие системы и инструменты в этой сессии, но их очень много. Реальная польза от решения для мониторинга появляется тогда, когда вы действительно потратили время на то, чтобы убедиться, что вы ответили на вопрос, что мы должны отслеживать, а что нет?\nМы можем включить решение мониторинга в любой из наших платформ, и оно начнет собирать информацию, но если этой информации просто слишком много, вам будет трудно извлечь пользу из этого решения, вам придется потратить время на настройку.\nНа следующем занятии мы попробуем использовать инструмент мониторинга и посмотрим, что мы можем начать отслеживать.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring ","description":"","title":"77. Мониторинг","uri":"/ru/docs/90daysofdevops/day77/"},{"content":"Инструменты мониторинга своими руками На последнем занятии я говорил об общей картине мониторинга и рассмотрел Nagios, для этого было две причины. Во-первых, это программное обеспечение, о котором я много слышал на протяжении многих лет, поэтому хотел узнать немного больше о его возможностях.\nСегодня я буду изучать Prometheus, я все больше и больше вижу Prometheus в ландшафте Cloud-Native, но его также можно использовать для присмотра за физическими ресурсами вне Kubernetes и тому подобного.\nPrometheus - мониторинг практически всего Прежде всего, Prometheus - это Open-Source, который может помочь вам контролировать контейнеры и системы на базе микросервисов, а также физические, виртуальные и другие сервисы. За Prometheus стоит большое сообщество.\nPrometheus имеет большой набор интеграций и экспортеров Ключевым моментом является экспорт существующих метрик в метрики Prometheus. Кроме того, он также поддерживает несколько языков программирования.\nПодход Pull - Если вы работаете с тысячами микросервисов или систем и сервисов, то метод push - это метод, при котором сервис, как правило, обращается к системе мониторинга. При этом возникают некоторые проблемы, связанные с переполнением сети, высокой производительностью процессора и единой точкой отказа. Метод Pull дает нам гораздо лучший опыт, когда Prometheus будет получать данные из конечной точки метрики на каждом сервисе.\nИ снова мы видим YAML для конфигурации Prometheus.\nПозже вы увидите, как это выглядит при развертывании в Kubernetes, в частности, у нас есть PushGateway, который получает наши метрики от наших заданий/экспортеров.\nУ нас есть AlertManager, который рассылает оповещения, и именно здесь мы можем интегрироваться во внешние сервисы, такие как электронная почта, slack и другие инструменты.\nЗатем у нас есть сервер Prometheus, который управляет получением этих метрик из PushGateway, а затем отправляет эти оповещения в AlertManager. Сервер Prometheus также хранит данные на локальном диске. Хотя можно использовать решения для удаленного хранения данных.\nУ нас также есть PromQL - язык, используемый для взаимодействия с метриками, который можно увидеть позже в веб-интерфейсе Prometheus, но позже в этом разделе вы также увидите, как он используется в инструментах визуализации данных, таких как Grafana.\nСпособы развертывания Prometheus Существуют различные способы установки Prometheus, Download Section Также доступны образы Docker.\ndocker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus.\nНо мы сосредоточим наши усилия на развертывании в Kubernetes. У которого также есть несколько вариантов.\nСоздание конфигурационных YAML-файлов Использование оператора (менеджер всех компонентов prometheus) Использование диаграммы helm для развертывания оператора Развертывание в Kubernetes Для этой быстрой и простой установки мы снова будем использовать наш локальный кластер minikube. Как и в предыдущих случаях с minikube, мы будем использовать helm для развертывания диаграммы Prometheus helm.\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts.\nКак видно из вышеприведенного, мы также выполнили обновление репо helm, теперь мы готовы развернуть Prometheus в нашей среде minikube с помощью команды helm install stable prometheus-community/prometheus.\nЧерез пару минут вы увидите, что появилось несколько новых подкастов, для этого демо я развернул их в пространство имен по умолчанию, обычно я бы развернул их в собственное пространство имен.\nПосле запуска всех подсистем мы также можем посмотреть на все развернутые аспекты Prometheus.\nТеперь, чтобы получить доступ к пользовательскому интерфейсу сервера Prometheus, мы можем использовать следующую команду для проброса портов.\nexport POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\")\rkubectl --namespace default port-forward $POD_NAME 9090\rКогда мы впервые открываем наш браузер на http://localhost:9090, мы видим следующий очень пустой экран.\nПоскольку мы развернули наш кластер Kubernetes, мы будем автоматически получать метрики из нашего Kubernetes API, поэтому мы можем использовать некоторые PromQL, чтобы убедиться, что мы получаем метрики container_cpu_usage_seconds_total.\nКоротко об изучении PromQL и применении его на практике. Это очень похоже на то, о чем я говорил ранее: получение метрик - это здорово, как и мониторинг, но вы должны знать, что вы отслеживаете и почему, и что вы не отслеживаете и почему!\nЯ хочу вернуться к Prometheus, но пока я думаю, что нам нужно подумать об управлении журналами и визуализации данных, чтобы позже вернуться к Prometheus.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples ","description":"","title":"78. Hands-On Monitoring Tools","uri":"/ru/docs/90daysofdevops/day78/"},{"content":"Введение: Управление журналами В продолжение проблем и решений в области мониторинга инфраструктуры, управление журналами - это еще один пазл в общей картине наблюдаемости.\nУправление и агрегация журналов Давайте поговорим о двух основных концепциях, первая из которых - агрегация журналов, это способ сбора и маркировки журналов приложений от множества различных служб в единую приборную панель, по которой можно легко осуществлять поиск.\nОдной из первых систем, которые должны быть построены в системе управления производительностью приложений, является агрегация журналов. Управление производительностью приложений - это та часть жизненного цикла devops, когда все было создано и развернуто, и вам нужно убедиться, что они постоянно работают, что им выделено достаточно ресурсов и что ошибки не показываются пользователям. В большинстве производственных развертываний существует множество связанных событий, которые передают журналы по сервисам, в google один поиск может попасть в десять различных сервисов, прежде чем будет возвращен пользователю, если вы получили неожиданные результаты поиска, это может означать логическую проблему в любом из десяти сервисов, и агрегация журналов помогает таким компаниям, как google, диагностировать проблемы в производстве.\nВ этом суть хорошей платформы для агрегации журналов, которая эффективно собирает журналы отовсюду, откуда они исходят, и делает их легко доступными для поиска в случае повторного возникновения неисправности.\nПример приложения Наш пример приложения - это веб-приложение, у нас есть типичный фронт-энд и бэк-энд, хранящий наши важные данные в базе данных MongoDB.\nЕсли бы пользователь сказал нам, что страница стала белой и вывела сообщение об ошибке, мы бы с трудом диагностировали проблему с помощью нашего текущего стека. Пользователь должен вручную отправить нам ошибку, а мы должны сопоставить ее с соответствующими журналами в трех других сервисах.\nELK Давайте посмотрим на ELK, популярный стек агрегации логов с открытым исходным кодом, названный в честь его трех компонентов elasticsearch, logstash и kibana, если мы установим его в той же среде, что и наше приложение.\nВеб-приложение подключается к фронтенду, который затем подключается к бэкенду, бэкенд отправляет журналы в logstash, а затем то, как работают эти три компонента.\nКомпоненты elk Elasticsearch, logstash и Kibana заключается в том, что все сервисы отправляют журналы в logstash, logstash принимает эти журналы, которые являются текстом, испускаемым приложением. Например, веб-приложение, когда вы посещаете веб-страницу, может зарегистрировать доступ посетителя к этой странице в это время, и это пример сообщения журнала, которое будет отправлено в logstash.\nЗатем Logstash извлекает из них информацию, так что для этого сообщения пользователь сделал что-то, в время. Он извлечет время, извлечет сообщение, извлечет пользователя и включит все это в качестве тегов, так что сообщение будет объектом тегов и сообщений, так что вы можете легко искать по ним, вы можете найти все запросы, сделанные определенным пользователем, но logstash не хранит вещи самостоятельно, он хранит вещи в elasticsearch, который является эффективной базой данных для запроса текста, и elasticsearch раскрывает результаты как Kibana, а Kibana - это веб-сервер, который подключается к elasticsearch и позволяет администраторам, таким как devops или другим людям в вашей команде, дежурному инженеру просматривать журналы в производстве при возникновении серьезных неполадок. Вы, как администратор, подключаетесь к Kibana, Kibana запрашивает elasticsearch на предмет журналов, соответствующих тому, что вы хотите.\nВы можете сказать: “Эй, Kibana, в строке поиска я хочу найти ошибки”, и Kibana скажет elasticsearch найти сообщения, которые содержат строку error, а затем elasticsearch вернет результаты, которые были заполнены logstash. Logstash получил бы эти результаты от всех других служб.\nкак бы мы использовали elk для диагностики производственной проблемы Пользователь говорит, что я увидел код ошибки один два три четыре пять шесть семь, когда я попытался сделать это с помощью настройки elk, мы должны зайти в kibana, ввести один два три четыре пять шесть семь в строке поиска, нажать enter, а затем это покажет нам журналы, которые соответствуют этому, и один из журналов может сказать внутреннюю ошибку сервера, возвращающую один два три четыре пять шесть семь, и мы увидим, что служба, которая выдала этот журнал. и мы увидим, что служба, которая выдала этот журнал, была backend, и мы увидим, в какое время был выдан этот журнал, поэтому мы можем перейти ко времени в этом журнале и посмотреть на сообщения выше и ниже него в backend, и тогда мы сможем увидеть лучшую картину того, что произошло для запроса пользователя, и мы сможем повторить этот процесс, переходя к другим службам, пока не найдем, что на самом деле вызвало проблему у пользователя.\nБезопасность и доступ к журналам Важной частью головоломки является обеспечение того, чтобы журналы были видны только администраторам (или пользователям и группам, которым абсолютно необходим доступ). Журналы могут содержать конфиденциальную информацию, такую как токены, поэтому важно, чтобы только аутентифицированные пользователи могли получить к ним доступ. Вы не захотите выставлять Kibana в интернет без какого-либо способа аутентификации.\nПримеры инструментов управления журналами Примерами платформ для управления журналами являются\nElasticsearch Logstash Kibana Fluentd - популярный вариант с открытым исходным кодом Datadog - хостинговое предложение, обычно используется на крупных предприятиях, LogDNA - хостируемое предложение Splunk Облачные провайдеры также предоставляют протоколирование, например, AWS CloudWatch Logs, Microsoft Azure Monitor и Google Cloud Logging.\nУправление журналами является ключевым аспектом общей наблюдаемости ваших приложений и среды инфраструктур для диагностики проблем в производстве. Относительно просто установить готовое решение, такое как ELK или CloudWatch, и это значительно упрощает диагностику и устранение проблем в производстве.\nРесурсы The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained ","description":"","title":"79. Log Management","uri":"/ru/docs/90daysofdevops/day79/"},{"content":"Настройка DevOps окружения для запуска Hello World на Go Прежде чем мы приступим к некоторым основам Go, мы должны установить Go на нашу рабочую станцию и сделать то, чему нас учит каждый модуль «Изучение программирования 101», а именно создать приложение Hello World. Так как здесь будут описаны шаги по установке Go на ваш ПК, мы попытаемся задокументировать процесс в картинках, чтобы людям было легко следовать за ним.\nВозможные варианты установки Golang\nИсполняемый файл Пакет из исходного кода Mac Os Homebrew #Homebrew install command brew install go Быстрый тьюториал для ознакомления с языком Go\nРассмотрим вараинт установки с помощью инсталляционного файла\nЕсли мы зашли так далеко, вы, вероятно, знаете, какая операционная система рабочей станции у вас установлена, поэтому выберите соответствующую загрузку, и тогда мы сможем приступить к установке. Я использую Windows для этого пошагового руководства. На следующем шаге мы можем оставить все значения по умолчанию. (Отмечу, что на момент написания это была последняя версия, поэтому скриншоты могут быть устаревшими)\nТакже обратите внимание, что если у вас установлена более старая версия Go, вам придется удалить ее перед установкой, поскольку в Windows она встроена в установщик, и она будет удалена и установлена как единое целое.\nПосле завершения вы должны открыть командную строку / терминал, и мы хотим проверить, установлен ли Go. Если вы не получите вывод, который мы видим ниже, значит, Go не установлен, и вам нужно будет повторить свои шаги.\ngo version Далее мы хотим проверить нашу среду на наличие Go. Это всегда полезно проверить, чтобы убедиться, что ваши рабочие каталоги настроены правильно, как вы можете видеть ниже, нам нужно убедиться, что в вашей системе есть следующий каталог.\nХорошо, давайте создадим этот каталог для простоты. Я собираюсь использовать команду mkdir в своем терминале PowerShell. Нам также нужно создать 3 папки в папке Go, как вы увидите ниже.\nТеперь у нас установлен Go, и у нас есть рабочий каталог Go, готовый к действию. Теперь нам нужна интегрированная среда разработки (IDE). Сейчас есть много доступных, которые вы можете использовать, но наиболее распространенным и тем, который я использую, является Visual Studio Code или Code. Вы можете узнать больше об IDE здесь.\nЕсли вы еще не загрузили и не установили VSCode на свою рабочую станцию, вы можете сделать это, перейдя по ссылке. Как вы можете видеть ниже, у вас есть разные варианты ОС.\nПочти так же, как и при установке Go, мы собираемся загрузить и установить и сохранить значения по умолчанию. После завершения вы можете открыть VSCode, выбрать «Открыть файл» и перейти в наш каталог Go, который мы создали выше.\nВы можете получить всплывающее окно о доверии, прочитать его, если хотите, а затем нажать «Да, доверять авторам». (Позже я не несу ответственности, если вы начнете открывать вещи, которым не доверяете!)\nТеперь вы должны увидеть три папки, которые мы также создали ранее, и теперь мы хотим щелкнуть правой кнопкой мыши папку src и создать новую папку с именем «Hello».\nДовольно простые вещи, я бы сказал до этого момента? Теперь мы собираемся создать нашу первую программу Go, не понимая, что мы вкладываем в этот следующий этап.\nЗатем создайте файл с именем main.go в папке Hello. Как только вы нажмете Enter на main.go, вас спросят, хотите ли вы установить расширение Go, а также пакеты, вы также можете проверить этот пустой файл pkg, который мы сделали несколько шагов назад, и обратите внимание, что у нас должны быть новые пакеты. там сейчас?\nТеперь давайте запустим это приложение Hello World, скопируйте следующий код в новый файл main.go и сохраните его.\npackage main import \"fmt\" func main() { fmt.Println(\"Hello #90DaysOfDevOps\") } Я понимаю, что вышеизложенное может не иметь никакого смысла, но мы подробнее расскажем о функциях, пакетах и многом другом позже. А пока давайте запустим наше приложение. Вернувшись в терминал и в нашу папку Hello, мы можем проверить, все ли работает. Используя приведенную ниже команду, мы можем проверить, работает ли наша общая программа обучения.\ngo run main.go Однако на этом это не заканчивается, что, если теперь мы захотим взять нашу программу и запустить ее на других машинах с Windows? Мы можем сделать это, создав наш двоичный файл, используя следующую команду\ngo build main.go Попробуем запустить\n#Windows ./main.exe #Linux/Mac Os ./main Источники Быстрое погружение в Golang StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 9-й день\n","description":"Настройка DevOps окружения для запуска Hello World на Go","title":"8. Настройка DevOps окружения для запуска Hello World на Go","uri":"/ru/docs/90daysofdevops/day08/"},{"content":"Эта глава знакомит с темой чтения и записи данных в файлы на жестком диске. Вы увидите, что читать и записывать файлы в Python очень просто. Давайте приступим!\nКак читать файл В Python есть встроенная функция open, которую мы можем использовать для открытия файла для чтения. Создайте текстовый файл с именем “test.txt” со следующим содержимым:\nThis is a test file line 2 line 3 this line intentionally left blank Вот несколько примеров, которые показывают, как использовать open для чтения:\nhandle = open(\"test.txt\") handle = open(r\"C:\\Users\\mike\\py101book\\data\\test.txt\", \"r\") Первый пример откроет файл с именем test.txt в режиме “только для чтения”. Это стандартный режим функции открытия файлов. Обратите внимание, что в первом примере мы не указали полный путь к файлу, который хотим открыть. Python автоматически ищет test.txt в папке, в которой запущен сценарий. Если он не найдет его, то вы получите ошибку IOError.\nВо втором примере показан полный путь к файлу, но обратите внимание на то, что он начинается с “r”. Это значит, что мы указываем Python, чтобы строка обрабатывалась как исходная. Давайте посмотрим на разницу между исходной строкой и обычной:\n\u003e\u003e\u003e print(\"C:\\Users\\mike\\py101book\\data\\test.txt\") C:\\Users\\mike\\py101book\\data est.txt \u003e\u003e\u003e print(r\"C:\\Users\\mike\\py101book\\data\\test.txt\") C:\\Users\\mike\\py101book\\data\\test.txt Как видно из примера, когда мы не определяем строку как исходную, мы получаем неправильный путь.. Почему это происходит? Как вы помните из главы о строках, есть некоторые специальные символы, которые должны быть экранированы, например, “n” или “t”. В данном случае мы видим “t” (т.е. табуляцию), поэтому строка послушно добавляет табуляцию к нашему пути и портит его.\nВторым аргументом во втором примере также является “r”. Это говорит open, что мы хотим открыть файл в режиме только для чтения. Другими словами, это делает то же самое, что и первый пример, но более явно. Теперь давайте действительно прочитаем файл!\nЗапишите следующие строки в сценарий Python и сохраните его в том же месте, где находится файл test.txt:\nhandle = open(\"test.txt\", \"r\") data = handle.read() print(data) handle.close() Если вы запустите эту программу, она откроет файл и прочитает весь файл как строку в переменную data. Затем мы печатаем эти данные и закрываем дескриптор файла. Следует всегда закрывать дескриптор файла, так как неизвестно когда и какая именно программа захочет получить к нему доступ. Закрытие файла также поможет сохранить память и избежать появления странных багов в программе. Вы можете указать Python читать по строке за раз, читать все строки в список Python или читать файл по частям. Последний вариант очень удобен, когда вы имеете дело с очень большими файлами и не хотите читать их целиком, что может заполнить память компьютера.\nДавайте потратим немного времени на рассмотрение различных способов чтения файлов.\nhandle = open(\"test.txt\", \"r\") data = handle.readline() # read just one line print(data) handle.close() Если вы запустите этот пример, он прочитает только первую строку вашего текстового файла и распечатает ее. Это не слишком полезно, поэтому давайте попробуем метод readlines() дескриптора файла:\nhandle = open(\"test.txt\", \"r\") data = handle.readlines() # read ALL the lines! print(data) handle.close() После выполнения этого кода вы увидите список Python, выведенный на экран, потому что это то, что возвращает метод readlines: список! Давайте уделим немного времени тому, как читать файл по частям.\nКак читать файлы по частям Самый простой способ читать файл по частям - использовать цикл. Сначала мы научимся читать файл строка за строкой, а затем - по килобайту за раз. Для первого примера мы будем использовать цикл for:\nhandle = open(\"test.txt\", \"r\") for line in handle: print(line) handle.close() Здесь мы открываем файл в дескрипторе в режиме “только чтение”, а затем используем цикл for для итерации по нему. Вы увидите, что в Python можно выполнять итерации над всеми видами объектов (строки, списки, кортежи, ключи в словаре и т.д.). Это было довольно просто, верно? Теперь давайте сделаем это по частям!\nhandle = open(\"test.txt\", \"r\") while True: data = handle.read(1024) print(data) if not data: break В этом примере мы используем цикл while в Python для чтения по одному килобайту файла за раз. Как вы, вероятно, знаете, килобайт - это 1024 байта или символа. Теперь давайте представим, что мы хотим прочитать двоичный файл, например PDF.\nКак прочитать двоичный файл Прочитать двоичный файл очень просто. Все что вам нужно, это изменить способ доступа к файлу:\nhandle = open(\"test.pdf\", \"rb\") Мы изменили способ доступа к файлу на rb, что означает read-binary. Вам может понадобиться читать двоичные файлы, когда вы скачиваете PDF-файлы из Интернета или передаете файлы с компьютера на компьютер.\nЗапись файлов в Python Если вы следили за развитием событий, то, вероятно, догадываетесь, режимы написания файлов в Python это “w” и “wb” для write-mode и write-binary-mode соответственно. Теперь давайте взглянем на простой пример того, как они применяются.\nВНИМАНИЕ: При использовании режимов “w” или “wb”, если файл уже существует, он будет перезаписан без предупреждения! Вы можете проверить, существует ли файл до того, как вы его откроете, с помощью модуля os в Python. См. раздел os.path.exists в Главе 16.\nhandle = open(\"test.txt\", \"w\") handle.write(\"This is a test!\") handle.close() Это было просто! Все, что мы сделали, это изменили режим файла на “w” и вызвали метод write дескриптора файла, чтобы записать текст в файл. У дескриптора файла также есть метод writelines, который принимает список строк, которые дескриптор записывает на диск по порядку.\nИспользование оператора with В Python есть небольшой встроенный оператор with, который можно использовать для упрощения чтения и записи файлов. Оператор with создает то, что в Python известно как менеджер контекста, который автоматически закроет файл, когда вы закончите его обработку. Давайте посмотрим, как это работает:\nwith open(\"test.txt\") as file_handler: for line in file_handler: print(line) Синтаксис оператора with немного странный, но вы быстро разберетесь в нем. По сути, мы делаем замену:\nhandle = open(\"test.txt\") на это:\nwith open(\"test.txt\") as file_handler: Вы можете выполнять все обычные операции ввода-вывода файлов, которые вы обычно делаете, пока вы находитесь внутри блока кода with. Как только вы покинете этот блок кода, дескриптор файла закроется, и вы больше не сможете его использовать. Да, вы правильно прочитали. Вам больше не нужно явно закрывать дескриптор файла, поскольку оператор with делает это автоматически! Попробуйте изменить некоторые предыдущие примеры из этой главы так, чтобы в них тоже использовался метод with.\nВыявление ошибок Иногда при работе с файлами случаются неприятные вещи. Файл заблокирован, потому что его использует другой процесс, или у вас возникла какая-то ошибка разрешения. Когда это происходит, вероятно, возникнет ошибка IOError. В этом разделе мы рассмотрим, как ловить ошибки обычным способом и как ловить их с помощью оператора with. Подсказка: идея в обоих случаях практически одинакова!\ntry: file_handler = open(\"test.txt\") for line in file_handler: print(line) except IOError: print(\"An IOError has occurred!\") finally: file_handler.close() В приведенном выше примере мы помещаем обычный код в конструкции try/except. Если возникает ошибка, мы выводим сообщение на экран. Обратите внимание, что мы также закрываем файл с помощью оператора finally. Теперь мы готовы рассмотреть, как сделать то же самое, используя оператор with:\ntry: with open(\"test.txt\") as file_handler: for line in file_handler: print(line) except IOError: print(\"An IOError has occurred!\") Как вы уже догадались, мы просто обернули блок with таким же образом, как и в предыдущем примере. Разница в том, что нам не нужен оператор finally, так как менеджер контекста сделает это за нас.\nПодведение итогов К этому моменту вы должны быть достаточно хорошо знакомы с работой с файлами в Python. Теперь вы знаете, как читать и записывать файлы, используя старый стиль и новый стиль with. Скорее всего, вы встретите оба стиля в реальной жизни. В следующей главе мы узнаем, как импортировать другие модули, поставляемые с Python. Это позволит нам создавать программы, используя готовые модули. Давайте начнем!\n","description":"Python 101","title":"8. Работа с файлами","uri":"/ru/docs/python101/chapter8_file_io/"},{"content":"ELK Stack На этом занятии мы немного подробнее рассмотрим некоторые из упомянутых нами опций.\nELK Stack ELK Stack - это комбинация трех отдельных инструментов:\nElasticsearch - это распределенный, бесплатный и открытый поисковый и аналитический механизм для всех типов данных, включая текстовые, числовые, геопространственные, структурированные и неструктурированные.\nLogstash - свободный и открытый конвейер обработки данных на стороне сервера, который получает данные из множества источников, преобразует их, а затем отправляет в ваш любимый “тайник”.\nKibana - это бесплатный и открытый пользовательский интерфейс, позволяющий визуализировать данные Elasticsearch и перемещаться по стеку Elastic Stack. Делайте все, что угодно: от отслеживания загрузки запросов до понимания того, как запросы проходят через ваши приложения.\nСтек ELK позволяет нам надежно и безопасно получать данные из любого источника, в любом формате, затем искать, анализировать и визуализировать их в режиме реального времени.\nВ дополнение к вышеперечисленным компонентам вы также можете увидеть Beats - легковесные агенты, которые устанавливаются на пограничных узлах для сбора различных типов данных для передачи в стек.\nЖурналы: Определяются журналы сервера, которые необходимо проанализировать.\nLogstash: Собирает журналы и данные о событиях. Он даже анализирует и преобразует данные.\nElasticSearch: Преобразованные данные из Logstash хранятся, ищутся и индексируются.\nKibana использует БД Elasticsearch для изучения, визуализации и обмена данными\nИзображение взято с сайта Guru99\nХороший ресурс, объясняющий это The Complete Guide to the ELK Stack\nС добавлением битов стек ELK теперь также известен как Elastic Stack.\nДля практического скрипта существует множество мест, где можно развернуть Elastic Stack, но мы будем использовать docker compose для локального развертывания в нашей системе.\nStart the Elastic Stack with Docker Compose\nОригинальные файлы и руководство, которые я использовал, вы найдете здесь deviantony/docker-elk\nТеперь мы можем запустить docker-compose up -d, при первом запуске потребуется вытащить изображения.\nЕсли вы следите за этим репозиторием или за тем, который использовал я, у вас будет пароль “changeme” или в моем репозитории пароль “90DaysOfDevOps”. Имя пользователя - “elastic”.\nЧерез несколько минут мы можем перейти на сайт http://localhost:5601/, который является нашим сервером Kibana / Docker-контейнером.\nВаш начальный главный экран будет выглядеть примерно так.\nВ разделе “Get started by adding integrations” есть пункт “try sample data”, нажмите на него, и мы сможем добавить одну из показанных ниже интеграций.\nЯ собираюсь выбрать “Sample web logs”, но это действительно для того, чтобы получить представление о том, какие наборы данных можно получить в стеке ELK.\nКогда вы выбрали “Добавить данные”, требуется некоторое время, чтобы заполнить некоторые из этих данных, а затем у вас появляется опция “Просмотр данных” и список доступных способов просмотра этих данных в выпадающем списке.\nКак указано в представлении приборной панели:\nОбразцы данных журналов\nЭта приборная панель содержит образцы данных, с которыми вы можете поиграть. Вы можете просматривать их, искать и взаимодействовать с визуализациями. Для получения дополнительной информации о Kibana ознакомьтесь с нашей документацией.\nЗдесь используется Kibana для визуализации данных, которые были добавлены в ElasticSearch через Logstash. Это не единственный вариант, но я лично хотел развернуть и посмотреть на это.\nВ какой-то момент мы рассмотрим Grafana, и вы увидите некоторые сходства в визуализации данных между ними, вы также видели Prometheus.\nКлючевой момент, который я уловил между Elastic Stack и Prometheus + Grafana, заключается в том, что Elastic Stack или ELK Stack сосредоточен на журналах, а Prometheus - на метриках.\nЯ читал эту статью от MetricFire Prometheus vs. ELK, чтобы лучше понять различные предложения.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? [Fluentd simply explained](https://www.youtube.com/watch?v=5ofsNyHZwWE\u0026t=14s ","description":"","title":"80. ELK Stack","uri":"/ru/docs/90daysofdevops/day80/"},{"content":"Fluentd и FluentBit Еще одним коллектором данных, который я хотел изучить в рамках раздела о наблюдаемости, был Fluentd. Это унифицированный уровень протоколирования с открытым исходным кодом.\nFluentd имеет четыре ключевые особенности, которые делают его подходящим для создания чистых, надежных конвейеров протоколирования:\nУнифицированное протоколирование с JSON: Fluentd старается структурировать данные в виде JSON, насколько это возможно. Это позволяет Fluentd унифицировать все аспекты обработки данных журналов: сбор, фильтрацию, буферизацию и вывод журналов из нескольких источников и мест назначения. Последующая обработка данных намного проще с JSON, так как он имеет достаточную структуру, чтобы быть доступным без принуждения к жестким схемам.\nПодключаемая архитектура: Fluentd имеет гибкую систему плагинов, которая позволяет сообществу расширять его функциональность. Более 300 плагинов, созданных сообществом, соединяют десятки источников данных с десятками выходных данных, манипулируя данными по мере необходимости. Используя плагины, вы можете сразу же повысить эффективность использования ваших журналов.\nТребуется минимум ресурсов: Коллектор данных должен быть легким, чтобы его можно было легко запустить на загруженной машине. Fluentd написан на комбинации C и Ruby и требует минимальных системных ресурсов. Ванильный экземпляр работает на 30-40 МБ памяти и может обрабатывать 13 000 событий/секунду/ядро.\nВстроенная надежность: Потеря данных никогда не должна произойти. Fluentd поддерживает буферизацию на основе памяти и файлов для предотвращения потери данных между узлами. Fluentd также поддерживает надежное восстановление после отказа и может быть настроен на высокую доступность.\nУстановка Fluentd\nКак приложения записывают данные в журнал? Запись в файлы. Файлы .log (трудно анализировать без инструмента и в масштабе) Вести журнал непосредственно в базу данных (каждое приложение должно быть настроено на правильный формат) Сторонние приложения (NodeJS, NGINX, PostgreSQL). Вот почему нам нужен единый уровень логирования.\nFluentD позволяет использовать 3 типа данных, показанных выше, и дает нам возможность собирать, обрабатывать и отправлять их по назначению, это может быть отправка логов в базы данных Elastic, MongoDB, Kafka, например.\nЛюбые данные, любой источник данных может быть отправлен в FluentD, и эти данные могут быть отправлены в любое место назначения. FluentD не привязан к какому-либо конкретному источнику или месту назначения.\nИзучая Fluentd, я постоянно натыкался на Fluent bit как еще один вариант, и похоже, что если вы хотите развернуть инструмент протоколирования в среде Kubernetes, то Fluent bit даст вам такую возможность, хотя Fluentd также может быть развернут как на контейнерах, так и на серверах.\nFluentd \u0026 Fluent Bit\nFluentd и Fluentbit будут использовать входные плагины для преобразования данных в формат Fluent Bit, затем у нас есть выходные плагины для любой цели вывода, например, elasticsearch.\nМы также можем использовать теги и соответствия между конфигурациями.\nЯ не вижу веских причин для использования Fluentd, и кажется, что Fluent Bit - лучший способ начать работу. Хотя в некоторых архитектурах они могут использоваться вместе.\nFluent Bit в Kubernetes Fluent Bit в Kubernetes развертывается как DaemonSet, что означает, что он будет запущен на каждом узле кластера. Каждая капсула Fluent Bit на каждом узле будет читать каждый контейнер на этом узле и собирать все доступные журналы. Он также будет собирать метаданные с сервера Kubernetes API Server.\nАннотации Kubernetes можно использовать в конфигурационном YAML наших приложений.\nПрежде всего, мы можем развернуть приложение из репозитория fluent helm. helm repo add fluent https://fluent.github.io/helm-charts, а затем установить с помощью команды helm install fluent-bit fluent/fluent-bit.\nВ моем кластере я также запускаю prometheus в моем пространстве имен по умолчанию (в тестовых целях), нам нужно убедиться, что наш fluent-bit pod запущен и работает. Мы можем сделать это с помощью команды kubectl get all | grep fluent, которая покажет нам наш запущенный pod, сервис и набор демонов, о которых мы говорили ранее.\nЧтобы Fluentbit знал, откуда получать журналы, у нас есть конфигурационный файл, в этом развертывании Fluentbit на Kubernetes у нас есть configmap, который напоминает конфигурационный файл.\nЭта ConfigMap будет выглядеть примерно так:\nName: fluent-bit\rNamespace: default\rLabels: app.kubernetes.io/instance=fluent-bit\rapp.kubernetes.io/managed-by=Helm\rapp.kubernetes.io/name=fluent-bit\rapp.kubernetes.io/version=1.8.14\rhelm.sh/chart=fluent-bit-0.19.21\rAnnotations: meta.helm.sh/release-name: fluent-bit\rmeta.helm.sh/release-namespace: default\rData\r====\rcustom_parsers.conf:\r----\r[PARSER]\rName docker_no_time\rFormat json\rTime_Keep Off\rTime_Key time\rTime_Format %Y-%m-%dT%H:%M:%S.%L\rfluent-bit.conf:\r----\r[SERVICE]\rDaemon Off\rFlush 1\rLog_Level info\rParsers_File parsers.conf\rParsers_File custom_parsers.conf\rHTTP_Server On\rHTTP_Listen 0.0.0.0\rHTTP_Port 2020\rHealth_Check On\r[INPUT]\rName tail\rPath /var/log/containers/*.log\rmultiline.parser docker, cri\rTag kube.*\rMem_Buf_Limit 5MB\rSkip_Long_Lines On\r[INPUT]\rName systemd\rTag host.*\rSystemd_Filter _SYSTEMD_UNIT=kubelet.service\rRead_From_Tail On\r[FILTER]\rName kubernetes\rMatch kube.*\rMerge_Log On\rKeep_Log Off\rK8S-Logging.Parser On\rK8S-Logging.Exclude On\r[OUTPUT]\rName es\rMatch kube.*\rHost elasticsearch-master\rLogstash_Format On\rRetry_Limit False\r[OUTPUT]\rName es\rMatch host.*\rHost elasticsearch-master\rLogstash_Format On\rLogstash_Prefix node\rRetry_Limit False\rEvents: \u003cnone\u003e\rТеперь мы можем перенаправить наш pod на наш localhost, чтобы убедиться, что у нас есть соединение. Сначала узнайте имя вашего pod с помощью kubectl get pods | grep fluent и затем используйте kubectl port-forward fluent-bit-8kvl4 2020:2020 откройте веб-браузер на http://localhost:2020/.\nЯ также нашел эту замечательную статью на Medium, в которой рассказывается о Fluent Bit.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained Fluent Bit explained | Fluent Bit vs Fluentd ) ","description":"","title":"81. Fluentd и FluentBit","uri":"/ru/docs/90daysofdevops/day81/"},{"content":"EFK Stack В предыдущем разделе мы говорили о ELK Stack, который использует Logstash в качестве сборщика логов в стеке, в EFK Stack мы меняем его на FluentD или FluentBit.\nНаша задача в этом разделе - отслеживать журналы Kubernetes с помощью EFK.\nОбзор EFK Мы развернем следующее в нашем кластере Kubernetes.\nСтек EFK представляет собой набор из 3 программ, объединенных вместе, включая:\nElasticsearch : NoSQL база данных используется для хранения данных и предоставляет интерфейс для поиска и журнал запросов.\nFluentd : Fluentd - это сборщик данных с открытым исходным кодом для унифицированного уровня логирования. Fluentd позволяет унифицировать сбор и потребление данных для лучшего использования и понимания данных.\nKibana : Интерфейс для управления и статистики журналов. Отвечает за чтение информации из elasticsearch .\nРазвертывание EFK на Minikube Мы будем использовать наш надежный кластер minikube для развертывания нашего стека EFK. Давайте запустим кластер с помощью minikube start на нашей системе. Я использую ОС Windows с включенным WSL2.\nЯ создал efk-stack.yaml, который содержит все необходимое для развертывания стека EFK в нашем кластере, используя команду kubectl create -f efk-stack.yaml мы видим, что все развернуто.\nВ зависимости от вашей системы и если вы уже выполняли эту процедуру и получили изображения, теперь вам нужно посмотреть, как стручки переходят в состояние готовности, прежде чем мы сможем двигаться дальше, вы можете проверить прогресс с помощью следующей команды. kubectl get pods -n kube-logging -w Это может занять несколько минут.\nПриведенная выше команда позволяет нам следить за ситуацией, но я люблю уточнять, все ли в порядке, выполняя следующую команду kubectl get pods -n kube-logging, чтобы убедиться, что все pods теперь работают.\nПосле того, как мы запустили все наши pods, и на этом этапе мы должны увидеть\n3 стручка, связанные с ElasticSearch 1 стручок, связанный с Fluentd 1 стручок, связанный с Kibana Мы также можем использовать kubectl get all -n kube-logging, чтобы показать все в нашем пространстве имен, fluentd, как объяснялось ранее, развернут как набор демонов, kibana как развертывание и ElasticSearch как набор состояний.\nТеперь все наши pods работают, и мы можем ввести в новом терминале команду port-forward, чтобы мы могли получить доступ к нашей приборной панели kibana. Обратите внимание, что имя вашего pod будет отличаться от команды, которую мы видим здесь. kubectl port-forward kibana-84cf7f59c-v2l8v 5601:5601 -n kube-logging.\nТеперь мы можем открыть браузер и перейти по этому адресу, http://localhost:5601 вас встретит либо экран, который вы видите ниже, либо вы можете увидеть экран с примерами данных, либо продолжить и настроить самостоятельно. В любом случае и непременно посмотрите на эти тестовые данные, это то, что мы рассмотрели при изучении стека ELK в предыдущей сессии.\nДалее нам нужно перейти на вкладку “discover” в левом меню и добавить “*” к нашему шаблону индекса. Перейдите к следующему шагу, нажав кнопку “Следующий шаг”.\nНа шаге 2 из 2 мы будем использовать опцию @timestamp из выпадающего списка, так как это позволит отфильтровать наши данные по времени. Когда вы нажмете кнопку создать шаблон, это может занять несколько секунд.\nЕсли через несколько секунд мы вернемся на вкладку “discover”, вы должны увидеть данные, поступающие с вашего кластера Kubernetes.\nТеперь, когда у нас установлен и работает стек EFK и мы собираем журналы с нашего кластера Kubernetes через Fluentd, мы можем взглянуть на другие источники, которые мы можем выбрать. Если вы перейдете на главный экран, нажав на логотип Kibana в левом верхнем углу, вас встретит та же страница, которую мы видели при первом входе в систему.\nУ нас есть возможность добавить APM, данные журнала, метрические данные и события безопасности из других плагинов или источников.\nЕсли мы выберем “Добавить данные журнала”, то увидим ниже, что у нас есть большой выбор, откуда мы хотим получать наши журналы, вы можете увидеть, что там упоминается Logstash, который является частью стека ELK.\nПод данными метрик вы увидите, что можно добавить источники для Prometheus и многих других сервисов. Переведено с помощью www.DeepL.com/Translator (бесплатная версия)\nAPM (Мониторинг производительности приложений) Также есть возможность собрать APM (мониторинг производительности приложений), который собирает подробные показатели производительности и ошибки изнутри вашего приложения. Он позволяет отслеживать производительность тысяч приложений в режиме реального времени.\nЯ не буду здесь углубляться в APM, но вы можете узнать больше на сайте Elastic.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained See you on Day 83\n","description":"","title":"82. EFK Stack","uri":"/ru/docs/90daysofdevops/day82/"},{"content":"Визуализация данных - Grafana Мы много говорили о Kibana в этом разделе, посвященном Observability. Но мы также должны уделить некоторое время Grafana. Но это не одно и то же, и они не полностью конкурируют друг с другом.\nОсновной функцией Kibana является запрос и анализ данных. Используя различные методы, пользователи могут искать в данных, проиндексированных в Elasticsearch, определенные события или строки в данных для анализа и диагностики первопричин. На основе этих запросов пользователи могут использовать функции визуализации Kibana, которые позволяют визуализировать данные различными способами, используя графики, таблицы, географические карты и другие виды визуализации.\nGrafana фактически началась как форк Kibana, целью Grafana была поддержка метрик и мониторинга, которые в то время Kibana не предоставляла.\nGrafana - это бесплатный инструмент визуализации данных с открытым исходным кодом. Обычно мы видим Prometheus и Grafana вместе в полевых условиях, но мы также можем увидеть Grafana вместе с Elasticsearch и Graphite.\nКлючевое различие между этими двумя инструментами - это логирование и мониторинг. В начале раздела мы рассмотрели мониторинг с помощью Nagios, затем Prometheus и перешли к логированию, где мы рассмотрели стеки ELK и EFK.\nGrafana предназначена для анализа и визуализации таких показателей, как использование системного процессора, памяти, дисков и ввода-вывода. Платформа не позволяет выполнять полнотекстовые запросы данных. Kibana работает поверх Elasticsearch и используется в основном для анализа сообщений журнала.\nКак мы уже выяснили, Kibana довольно проста в развертывании, а также в выборе места установки, то же самое можно сказать и о Grafana.\nОба поддерживают установку на Linux, Mac, Windows, Docker или сборку из исходников.\nНесомненно, есть и другие, но Grafana - это инструмент, который, по моим наблюдениям, охватывает виртуальные, облачные и облачно-нативные платформы, поэтому я хотел рассказать о нем в этом разделе.\nОператор Prometheus + развертывание Grafana Мы уже рассказывали о Prometheus в этом разделе, но поскольку мы так часто видим эти пары, я хотел создать среду, которая позволила бы нам хотя бы увидеть, какие метрики мы могли бы отображать в визуализации. Мы знаем, что мониторинг наших сред очень важен, но просмотр этих метрик в Prometheus или любом другом метрическом инструменте будет громоздким и не будет масштабироваться. Именно здесь на помощь приходит Grafana, которая предоставляет нам интерактивную визуализацию этих метрик, собранных и сохраненных в базе данных Prometheus.\nС помощью этой визуализации мы можем создавать пользовательские графики, диаграммы и оповещения для нашей среды. В этом руководстве мы будем использовать наш кластер minikube.\nДля начала мы клонируем его в нашу локальную систему. Используя git clone https://github.com/prometheus-operator/kube-prometheus.git и cd kube-prometheus.\nПервая задача - создать наше пространство имен в кластере minikube kubectl create -f manifests/setup, если вы не следили за предыдущими разделами, мы можем использовать minikube start для создания нового кластера.\nДалее мы собираемся развернуть все необходимое для нашего демо с помощью команды kubectl create -f manifests/, как вы можете видеть, это развернет множество различных ресурсов в нашем кластере.\nЗатем нам нужно подождать, пока наши стручки поднимутся, и, находясь в запущенном состоянии, мы можем использовать команду kubectl get pods -n monitoring -w, чтобы следить за стручками.\nКогда все запущено, мы можем проверить, что все pods находятся в рабочем и здоровом состоянии, используя команду kubectl get pods -n monitoring.\nПри развертывании мы развернули ряд сервисов, которые мы будем использовать позже в демо, вы можете проверить их с помощью команды kubectl get svc -n monitoring.\nИ, наконец, давайте проверим все ресурсы, развернутые в нашем новом пространстве имен мониторинга, используя команду kubectl get all -n monitoring.\nОткрыв новый терминал, мы готовы получить доступ к нашему инструменту Grafana и начать собирать и визуализировать некоторые из наших метрик, команда для использования - kubectl --namespace monitoring port-forward svc/grafana 3000.\nОткройте браузер и перейдите по адресу http://localhost:3000, вам будет предложено ввести имя пользователя и пароль.\nПо умолчанию имя пользователя и пароль для доступа следующие\nИмя пользователя: admin Пароль: admin\rОднако при первом входе в систему вам будет предложено ввести новый пароль. На начальном экране или домашней странице вы увидите несколько областей для изучения, а также некоторые полезные ресурсы для ознакомления с Grafana и ее возможностями. Обратите внимание на виджеты “Добавить свой первый источник данных” и “Создать свою первую приборную панель”, мы будем использовать их позже.\nВы увидите, что источник данных prometheus уже добавлен в источники данных Grafana, однако, поскольку мы используем minikube, нам нужно также перенаправить prometheus, чтобы он был доступен на нашем localhost, открыв новый терминал, мы можем выполнить следующую команду. kubectl --namespace monitoring port-forward svc/prometheus-k8s 9090 если на главной странице Grafana мы теперь заходим в виджет “Add your first data source” и отсюда выбираем Prometheus.\nДля нашего нового источника данных мы можем использовать адрес http://localhost:9090, и нам также нужно будет изменить выпадающий список на браузер, как показано ниже.\nВнизу страницы мы можем нажать кнопку сохранить и протестировать. Это должно дать нам результат, который вы видите ниже, если проброс порта для prometheus работает.\nВернитесь на главную страницу и найдите опцию “Create your first dashboard”, выберите “Add a new panel”.\nНиже вы увидите, что мы уже собираем данные из нашего источника данных Grafana, но мы хотели бы собирать метрики из нашего источника данных Prometheus, выберите выпадающий список источников данных и выберите наш недавно созданный “Prometheus-1”\nЕсли затем выбрать браузер Metrics, то появится длинный список метрик, собираемых из Prometheus, связанных с нашим кластером minikube.\nДля целей демонстрации я собираюсь найти метрику, которая дает нам некоторые данные о наших системных ресурсах, cluster:node_cpu:ratio{} дает нам некоторые подробности об узлах в нашем кластере и доказывает, что эта интеграция работает.\nЕсли вас устраивает такая визуализация, нажмите кнопку “Применить” в правом верхнем углу, и вы добавите этот график на свою приборную панель. Разумеется, вы можете добавлять дополнительные графики и другие диаграммы, чтобы обеспечить нужную вам визуализацию.\nОднако мы можем воспользоваться тысячами ранее созданных приборных панелей, которые мы можем использовать, чтобы не изобретать велосипед.\nЕсли мы выполним поиск по Kubernetes, то увидим длинный список готовых приборных панелей, из которых мы можем выбирать.\nМы выбрали приборную панель Kubernetes API Server и изменили источник данных, чтобы соответствовать нашему недавно добавленному источнику данных Prometheus-1, и мы видим некоторые метрики, отображаемые как показано ниже.\nОповещение Вы также можете использовать развернутый нами alertmanager для отправки оповещений в slack или другие интеграции, для этого вам нужно перенести сервис alertmanager, используя следующие данные.\nkubectl --namespace monitoring port-forward svc/alertmanager-main 9093 http://localhost:9093\nНа этом мы завершаем наш раздел о наблюдаемости. Лично я считаю, что этот раздел подчеркнул, насколько широка эта тема, но в равной степени, насколько она важна для наших ролей, и что будь то метрика, логирование или трассировка, вам необходимо иметь хорошее представление о том, что происходит в наших широких средах в будущем, особенно когда они могут так сильно измениться благодаря автоматизации, которую мы уже рассмотрели в других разделах.\nДалее мы рассмотрим управление данными и то, как принципы DevOps также необходимо учитывать, когда речь идет об управлении данными.\nРесурсы Understanding Logging: Containers \u0026 Microservices The Importance of Monitoring in DevOps Understanding Continuous Monitoring in DevOps? DevOps Monitoring Tools Top 5 - DevOps Monitoring Tools How Prometheus Monitoring works Introduction to Prometheus monitoring Promql cheat sheet with examples Log Management for DevOps | Manage application, server, and cloud logs with Site24x7 Log Management what DevOps need to know What is ELK Stack? Fluentd simply explained ","description":"","title":"83. Визуализация данных - Grafana","uri":"/ru/docs/90daysofdevops/day83/"},{"content":"Введение: Управление данными Управление данными - это далеко не новая стена, на которую нужно карабкаться, хотя мы знаем, что данные стали более важными, чем несколько лет назад. Ценные и постоянно меняющиеся, они также могут стать огромным кошмаром, когда мы говорим об автоматизации и непрерывной интеграции, тестировании и развертывании частых выпусков программного обеспечения. Вводим постоянные данные и базовые службы данных, которые часто являются главным виновником, когда что-то идет не так.\nНо прежде чем я перейду к управлению данными в облаке, нам нужно подняться на уровень выше. В ходе этой задачи мы затронули множество различных платформ. Будь то физические, виртуальные, облачные и Cloud-Native, включая Kubernetes, ни одна из этих платформ не обеспечивает отсутствие требований к управлению данными.\nКаким бы ни был наш бизнес, более чем вероятно, что вы найдете базу данных, скрывающуюся где-то в среде, будь то для самой критически важной системы в бизнесе или, по крайней мере, какой-то винтик в цепи хранит эти постоянные данные на каком-то уровне системы.\nDevOps и данные Как и в самом начале этой серии статей, где мы говорили о принципах DevOps, для улучшения процесса работы с данными вам необходимо привлечь нужных людей. Это могут быть DBA, но в равной степени это должны быть и люди, которые заботятся о резервном копировании этих сервисов данных.\nВо-вторых, нам также необходимо определить различные типы данных, домены, границы, которые мы связываем с нашими данными. Таким образом, данные не будут рассматриваться изолированно среди администраторов баз данных, инженеров по хранению данных или инженеров, специализирующихся на резервном копировании. Таким образом, вся команда может определить наилучший маршрут действий при разработке и размещении приложений для более широкого бизнеса и сосредоточиться на архитектуре данных, а не на том, о чем подумали позже.\nЭто может охватывать множество различных областей жизненного цикла данных, мы можем говорить о вводе данных, где и как данные будут вводиться в наш сервис или приложение? Как сервис, приложение или пользователи будут получать доступ к этим данным. Но затем нам также необходимо понять, как мы будем защищать данные, и как мы будем защищать эти данные.\nУправление данными 101 Управление данными, согласно Data Management Body of Knowledge, - это “разработка, выполнение и контроль планов, политик, программ и практик, которые контролируют, защищают, предоставляют и повышают ценность данных и информационных активов”.\nДанные - самый важный аспект вашего бизнеса - Данные - это только одна часть вашего бизнеса в целом. Я встречал выражение “Данные - это жизненная сила нашего бизнеса”, и, скорее всего, это абсолютно верно. Это заставило меня задуматься о том, что кровь очень важна для организма, но сама по себе она ничего не значит, нам все еще нужны аспекты организма, чтобы сделать кровь чем-то другим, кроме жидкости.\nКачество данных важно как никогда - Мы должны относиться к данным как к бизнес-активу, что означает, что мы должны уделять им должное внимание, чтобы они работали с нашими принципами автоматизации и DevOps.\nСвоевременный доступ к данным - Ни у кого не хватит терпения не иметь доступа к нужным данным в нужное время для принятия эффективных решений. Данные должны быть доступны в упорядоченном и своевременном виде независимо от формы представления.\nУправление данными должно стать помощником DevOps - я уже упоминал о рационализации, мы должны включить требования к управлению данными в наш цикл и обеспечить не только доступность этих данных, но и другие важные политические меры защиты этих точек данных, а также полностью протестированные модели восстановления.\nDataOps DataOps и DevOps применяют лучшие практики разработки и эксплуатации технологий для повышения качества, увеличения скорости, снижения угроз безопасности, восхищения клиентов и обеспечения значимой и сложной работы для квалифицированных специалистов. DevOps и DataOps имеют общие цели - ускорить доставку продукта путем автоматизации как можно большего количества этапов процесса. Для DataOps целью является устойчивый конвейер данных и надежные выводы из аналитики данных.\nНекоторые из наиболее распространенных областей более высокого уровня, которые фокусируются на DataOps, - это машинное обучение, большие данные и аналитика данных, включая искусственный интеллект.\nУправление данными - это управление информацией В этом разделе я не буду углубляться в машинное обучение или искусственный интеллект, а сосредоточусь на защите данных с точки зрения защиты информации. Этот подраздел называется “Управление данными - это управление информацией”, и мы можем считать, что информация = данные.\nТри ключевые области, которые мы должны рассмотреть на этом пути с данными, следующие:\nТочность - Убедитесь в том, что производственные данные точны, также нам необходимо убедиться в том, что наши данные в виде резервных копий также работают и протестированы на восстановление, чтобы быть уверенными в том, что в случае сбоя или возникновения причины нам необходимо иметь возможность восстановить работоспособность как можно быстрее.\nПоследовательность - Если наши службы данных расположены в нескольких местах, то для производства нам необходимо обеспечить последовательность во всех местах расположения данных, чтобы мы получали точные данные. Это также относится к защите данных, когда речь идет о защите этих служб данных, особенно служб данных, нам необходимо обеспечить последовательность на разных уровнях, чтобы убедиться, что мы делаем хорошую чистую копию этих данных для наших резервных копий, реплик и т. д.\nБезопасность - контроль доступа, а также просто хранение данных в целом - актуальная тема в настоящее время во всем мире. Убедиться в том, что нужные люди имеют доступ к вашим данным, - первостепенная задача, и это опять же относится к защите данных, где мы должны убедиться, что только необходимый персонал имеет доступ к резервным копиям и возможность восстановления из них, а также клонирования и предоставления других версий бизнес-данных.\nЛучшие данные = лучшие решения\nДни управления данными В течение следующих 6 занятий мы рассмотрим базы данных, резервное копирование и восстановление, аварийное восстановление, мобильность приложений с элементами демонстрации и практической работы.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"84. Управление данными","uri":"/ru/docs/90daysofdevops/day84/"},{"content":"Службы данных Базы данных являются наиболее распространенными службами данных, с которыми мы сталкиваемся в наших средах. На этом занятии я хотел бы рассмотреть некоторые из этих различных типов баз данных и некоторые случаи их использования. Некоторые из них мы уже использовали и видели в ходе решения задачи.\nС точки зрения разработки приложений выбор правильной службы данных или базы данных будет иметь огромное значение для производительности и масштабируемости вашего приложения.\nhttps://www.youtube.com/watch?v=W2Z7fbCLSTw\nКлюч-значение База данных “ключ-значение” - это тип нереляционной базы данных, которая использует простой метод “ключ-значение” для хранения данных. База данных “ключ-значение” хранит данные в виде набора пар “ключ-значение”, в которых ключ служит уникальным идентификатором. И ключи, и значения могут быть любыми, от простых объектов до сложных составных объектов. Базы данных “ключ-значение” хорошо поддаются разделению и позволяют горизонтальное масштабирование в таких масштабах, которые недостижимы для других типов баз данных.\nПримером базы данных типа “ключ-значение” является Redis.\n*Redis - это хранилище структур данных в памяти, используемое как распределенная база данных ключей-значений в памяти, кэш и брокер сообщений с возможностью долговечности. Redis поддерживает различные виды абстрактных структур данных, таких как строки, списки, карты, множества, сортированные множества, HyperLogLogs, растровые изображения, потоки и пространственные индексы.\nКак вы можете видеть из описания Redis, это означает, что наша база данных работает быстро, но мы ограничены в пространстве в качестве компромисса. Также нет запросов или объединений, что означает, что возможности моделирования данных очень ограничены.\nЛучше всего подходит для:\nКэширование Pub/Sub Лидерборды корзины покупок Обычно используется в качестве кэша над другим постоянным слоем данных.\nШирокий столбец База данных с широкими колонками - это база данных NoSQL, которая организует хранение данных в гибких колонках, которые могут быть распределены по нескольким серверам или узлам базы данных, используя многомерное отображение для ссылки на данные по столбцам, строкам и временным меткам.\nCassandra - это бесплатная система управления базами данных NoSQL с открытым исходным кодом, распределенная, с широким хранилищем колонок, разработанная для обработки больших объемов данных на множестве серверов, обеспечивающая высокую доступность без единой точки отказа.\nНет схемы, что означает возможность работы с неструктурированными данными, однако это может рассматриваться как преимущество для некоторых рабочих нагрузок.\nЛучше всего подходит для:\nВременные ряды Исторические записи Высокая запись, низкий уровень чтения Документ База данных документов (также известная как документо-ориентированная база данных или хранилище документов) - это база данных, которая хранит информацию в документах.\nMongoDB - это кросс-платформенная кросс-платформенная программа базы данных, ориентированная на документы. Классифицируемая как NoSQL база данных, MongoDB использует JSON-подобные документы с необязательными схемами. MongoDB разработана компанией MongoDB Inc. и лицензирована по лицензии Server Side Public License..\nДокументальные базы данных NoSQL позволяют предприятиям хранить простые данные без использования сложных кодов SQL. Быстрое хранение без ущерба для надежности.\nЛучше всего подходит для:\nБольшинство приложений Игры Интернет вещей Реляционная Если вы новичок в области баз данных, но знаете о них, то, скорее всего, вы сталкивались с реляционной базой данных.\nРеляционная база данных - это цифровая база данных, основанная на реляционной модели данных, предложенной Э. Ф. Коддом в 1970 году. Система, используемая для ведения реляционных баз данных, - это система управления реляционными базами данных. Многие системы реляционных баз данных имеют возможность использования SQL для запросов и ведения базы данных.\nMySQL - это система управления реляционными базами данных с открытым исходным кодом. Ее название представляет собой комбинацию слов “My”, имя дочери соучредителя Майкла Видениуса, и “SQL”, аббревиатура для языка структурированных запросов.\nMySQL является одним из примеров реляционной базы данных, существует множество других вариантов.\nПри изучении реляционных баз данных часто упоминается термин или аббревиатура ACID (atomicity, consistency, isolation, durability) - это набор свойств транзакций базы данных, призванных гарантировать достоверность данных, несмотря на ошибки, сбои питания и другие казусы. В контексте баз данных последовательность операций с базой данных, удовлетворяющая свойствам ACID (которую можно воспринимать как одну логическую операцию над данными), называется транзакцией. Например, перевод средств с одного банковского счета на другой, даже включающий несколько изменений, таких как дебетование одного счета и кредитование другого, является одной транзакцией.\nЛучше всего подходит для:\nБольшинство приложений (существует уже много лет, но это не значит, что он лучший). Она не идеальна для неструктурированных данных или способности к масштабированию - некоторые из других NoSQL обеспечивают лучшую способность к масштабированию для определенных рабочих нагрузок.\nGraph Графовая база данных хранит узлы и отношения вместо таблиц или документов. Данные хранятся так же, как вы можете набросать идеи на доске. Ваши данные хранятся без ограничения их заранее определенной моделью, что позволяет очень гибко подходить к их осмыслению и использованию.\nNeo4j - это система управления графовыми базами данных, разработанная компанией Neo4j, Inc. Разработчики описывают ее как ACID-совместимую транзакционную базу данных со встроенными средствами хранения и обработки графов.\nЛучшая для:\nГрафы Графы знаний Рекомендательные движки Поисковая система В предыдущем разделе мы фактически использовали базу данных поисковой системы на пути к Elasticsearch.\nБаза данных поисковой системы - это тип нереляционной базы данных, предназначенной для поиска данных. Базы данных поисковых систем используют индексы для категоризации схожих характеристик данных и облегчения поиска.\nElasticsearch - это поисковая система, основанная на библиотеке Lucene. Она представляет собой распределенную полнотекстовую поисковую систему с поддержкой многопользовательского доступа, веб-интерфейсом HTTP и документами JSON без схем.\nЛучшее для:\nПоисковые системы Typeahead Поиск по журналу Мультимодель Многомодельная база данных - это система управления базой данных, разработанная для поддержки нескольких моделей данных на основе единого интегрированного бэкенда. В отличие от этого, большинство систем управления базами данных организованы вокруг одной модели данных, которая определяет, как данные могут быть организованы, храниться и манипулироваться. Документ, граф, реляционная модель и модель ключ-значение - это примеры моделей данных, которые могут поддерживаться многомодельной базой данных.\nFauna - это гибкая, удобная для разработчиков, транзакционная база данных, предоставляемая в виде безопасного и масштабируемого облачного API со встроенным GraphQL..\nЛучшее решение для:\nВы не привязаны к выбору модели данных. Соответствует стандарту ACID Быстрая Отсутствие накладных расходов на инициализацию Как вы хотите использовать свои данные и предоставить облаку выполнять всю работу. На этом мы закончим обзор баз данных, независимо от того, в какой отрасли вы работаете, вы обязательно столкнетесь с одной из областей баз данных. Далее в этом разделе мы рассмотрим некоторые из этих примеров и управление данными и, в частности, защиту и хранение этих сервисов данных.\nСуществует масса ресурсов, ссылки на которые я привел ниже, и вы можете потратить 90 лет на глубокое погружение во все типы баз данных и все, что с этим связано.\nРесурсы Redis Crash Course - the What, Why and How to use Redis as your primary database Redis: How to setup a cluster - for beginners Redis on Kubernetes for beginners Intro to Cassandra - Cassandra Fundamentals MongoDB Crash Course MongoDB in 100 Seconds What is a Relational Database? Learn PostgreSQL Tutorial - Full Course for Beginners MySQL Tutorial for Beginners [Full Course] What is a graph database? (in 10 minutes) What is Elasticsearch? FaunaDB Basics - The Database of your Dreams Fauna Crash Course - Covering the Basics ","description":"","title":"85. Службы данных","uri":"/ru/docs/90daysofdevops/day85/"},{"content":"Резервное копирование всех платформ В ходе всего этого задания мы обсудили множество различных платформ и сред. Всех их объединяет то, что все они нуждаются в определенном уровне защиты данных!\nЗащита данных существует уже много лет, но богатство данных, которые мы имеем сегодня, и ценность, которую эти данные приносят, означает, что мы должны быть уверены не только в устойчивости к сбоям инфраструктуры за счет наличия нескольких узлов и высокой доступности приложений, но мы также должны учитывать, что нам нужна копия этих данных, этих важных данных в безопасном и надежном месте, если произойдет сбой.\nВ наши дни мы часто слышим о киберпреступности и программах-выкупах, и не поймите меня неправильно - это серьезная угроза, и я уверен, что вы подвергнетесь атаке программ-выкупов. Это не вопрос “если”, это вопрос “когда”. Поэтому еще больше причин убедиться в том, что ваши данные надежно защищены на тот случай, если такое время настанет. Однако самой распространенной причиной потери данных является не выкупное ПО или киберпреступность, а просто случайное удаление!\nМы все это делали, удаляли то, что не должны были удалять, и тут же сожалели об этом.\nНесмотря на все технологии и автоматизацию, о которых мы говорили в этой статье, требование защищать любые данные с состоянием или даже сложные конфигурации без состояния все еще существует, независимо от платформы.\nНо мы должны быть в состоянии выполнить эту защиту данных с учетом автоматизации и возможности интеграции в наши рабочие процессы.\nЕсли мы посмотрим, что такое резервное копирование:\nВ информационных технологиях резервная копия или резервное копирование данных - это копия компьютерных данных, снятая и сохраненная в другом месте, чтобы ее можно было использовать для восстановления оригинала после потери данных. Глагольная форма, обозначающая процесс создания такой копии, - “резервное копирование”, а существительное и прилагательное - “резервное копирование”.\nЕсли мы разберем это в самой простой форме, то резервное копирование - это копирование и вставка данных в новое место. Проще говоря, я могу сделать резервную копию прямо сейчас, скопировав файл с диска C: на диск D:, и у меня будет копия на случай, если что-то случится с диском C: или что-то будет неправильно отредактировано в файлах. Я могу вернуться к копии, которая находится на диске D:. Теперь, если мой компьютер умрет, где находятся оба диска C и D, я не буду защищен, поэтому мне придется искать решение или копировать данные вне моей системы, может быть, на NAS-накопитель у себя дома? Но тогда что произойдет, если что-то случится с моим домом, может быть, мне нужно подумать о хранении данных на другой системе в другом месте, может быть, облако - это вариант. Может быть, я могу хранить копии важных файлов в нескольких местах, чтобы снизить риск сбоя?\n3-2-1 Методика резервного копирования Сейчас самое время поговорить о правиле 3-2-1 или методологии резервного копирования. На самом деле я провел lightening talk, посвященный этой теме.\nМы уже упоминали о некоторых крайностях того, почему нам нужно защищать наши данные, но ниже перечислены еще несколько:\nЭто позволяет мне рассказать о методологии 3-2-1. Моя первая копия или резервная копия данных должна быть как можно ближе к моей производственной системе, причина этого заключается в скорости восстановления и, опять же, возвращаясь к исходному пункту о случайном удалении, это будет наиболее распространенной причиной для восстановления. Но я хочу хранить эти данные на подходящем втором носителе за пределами исходной или рабочей системы.\nЗатем мы хотим убедиться, что мы также отправляем копию наших данных на внешний носитель или за пределы системы, и здесь нам на помощь приходит второе место, будь то другой дом, здание, центр обработки данных или публичное облако.\nОтветственность за резервное копирование\nМы, скорее всего, слышали все мифы о том, что резервное копирование не нужно, например, такие как “Все не имеет состояния”. Если все не имеет состояния, то что тогда бизнес? Нет баз данных? документов? Очевидно, что каждый человек в компании несет определенную ответственность за обеспечение своей защиты, но, скорее всего, именно операционные команды должны обеспечить процесс резервного копирования критически важных приложений и данных.\nЕще одна хорошая фраза: “Высокая доступность - это моя резервная копия, мы встроили несколько узлов в наш кластер, поэтому он ни за что не выйдет из строя!”, кроме тех случаев, когда вы допускаете ошибку в базе данных, и она реплицируется на все узлы кластера, или когда происходит пожар, наводнение, что означает, что кластер больше недоступен, а вместе с ним и важные данные. Речь идет не об упрямстве, а о том, чтобы быть в курсе данных и сервисов, абсолютно все должны учитывать высокую доступность и отказоустойчивость в своей архитектуре, но это не заменяет необходимости резервного копирования!\nРепликация также может дать нам копию данных вне офиса, и, возможно, упомянутый выше кластер действительно живет в нескольких местах, однако первая случайная ошибка все равно будет реплицирована туда. Но, опять же, требование резервного копирования должно стоять в одном ряду с репликацией приложений или системной репликацией в среде.\nТеперь, учитывая все вышесказанное, можно впасть в крайность и отправить копии данных в слишком большое количество мест, что приведет не только к большим затратам, но и к увеличению риска подвергнуться атаке, поскольку площадь вашей поверхности теперь значительно увеличилась.\nВ любом случае, кто заботится о резервном копировании? В каждом предприятии это будет по-разному, но кто-то должен понимать требования к резервному копированию. Но также необходимо понимать план восстановления!\nНикому нет дела, пока всем нет дела Резервное копирование является ярким примером: никто не заботится о резервном копировании, пока вам не понадобится что-то восстановить. Наряду с требованием резервного копирования данных нам также необходимо подумать о том, как мы будем восстанавливать данные!\nВ нашем примере с текстовыми документами речь идет об очень маленьких файлах, поэтому возможность копирования туда и обратно является простой и быстрой. Но если речь идет о файлах размером более 100 ГБ, то на это потребуется время. Также необходимо учитывать уровень, на котором требуется восстановление, например, если мы возьмем виртуальную машину.\nУ нас есть вся виртуальная машина, у нас есть операционная система, установка приложений, а если это сервер баз данных, то у нас есть и некоторые файлы баз данных. Если мы допустили ошибку и вставили неправильную строку кода в нашу базу данных, мне, вероятно, не нужно восстанавливать всю виртуальную машину, я хочу быть детальным в том, что я восстанавливаю.\nСценарий резервного копирования Теперь я хочу начать строить скрипт защиты некоторых данных, в частности, я хочу защитить некоторые файлы на моей локальной машине (в данном случае Windows, но инструмент, который я собираюсь использовать, на самом деле не только бесплатный и с открытым исходным кодом, но и кроссплатформенный). Я хочу убедиться, что они защищены на устройстве NAS, которое у меня есть дома, а также в облачном хранилище Object Storage bucket.\nЯ хочу сделать резервную копию этих важных данных, так получилось, что это репозиторий для 90DaysOfDevOps, который, да, также отправляется на GitHub, где вы, вероятно, сейчас это читаете, но что, если моя машина умрет, а GitHub будет закрыт? Как бы кто-нибудь смог прочитать содержимое, а также как бы я мог восстановить эти данные на другом сервисе.\nСуществует множество инструментов, которые могут помочь нам достичь этого, но я собираюсь использовать инструмент под названием Kopia - это инструмент резервного копирования с открытым исходным кодом, который позволит нам шифровать, дедупировать и сжимать наши резервные копии, а также отправлять их во многие места.\nВы найдете релизы для загрузки здесь на момент написания статьи я буду использовать версию 0.10.6.\nУстановка Kopia Существует Kopia CLI и GUI, мы будем использовать GUI, но знайте, что вы можете иметь и CLI версию для тех Linux серверов, которые не дают вам GUI.\nЯ буду использовать KopiaUI-Setup-0.10.6.exe.\nДействительно быстрая установка, а затем, когда вы откроете приложение, вам предложат выбрать тип хранилища, которое вы хотите использовать в качестве хранилища резервных копий.\nНастройка хранилища Сначала мы хотим создать хранилище на локальном NAS-устройстве и собираемся сделать это с помощью SMB, но можно использовать и NFS.\nНа следующем экране мы собираемся определить пароль, этот пароль используется для шифрования содержимого хранилища.\nТеперь, когда хранилище настроено, мы можем запустить adhoc snapshot, чтобы начать запись данных в хранилище. [18:26, 16.06.2022] evgschegolkova: Прежде всего, нам нужно ввести путь к тому, что мы хотим сделать снимок, и в нашем случае мы хотим сделать копию папки 90DaysOfDevOps. Вскоре мы вернемся к аспекту планирования.\nМы можем определить хранение наших снимков.\nВозможно, есть файлы или типы файлов, которые мы хотим исключить.\nЕсли бы мы хотели определить расписание, мы могли бы сделать это на следующем экране, когда вы впервые создаете этот снимок, это начальная страница для определения.\nИ вы увидите ряд других настроек, которые могут быть обработаны здесь.\nВыберите snapshot now, и данные будут записаны в ваше хранилище.\nВнесетевое резервное копирование на S3 С помощью Kopia мы можем настроить только одно хранилище одновременно. Но через пользовательский интерфейс мы можем проявить творческий подход и, по сути, иметь несколько файлов конфигурации хранилища на выбор для достижения нашей цели - иметь локальную и внесетевую копию в Object Storage.\nХранилище Object Storage, в которое я решил отправить свои данные, будет Google Cloud Storage. Сначала я вошел в свой аккаунт Google Cloud Platform и создал себе ведро хранения. В моей системе уже был установлен Google Cloud SDK, но выполнение команды gcloud auth application-default login позволило мне аутентифицироваться в моей учетной записи.\nЗатем я использовал CLI Kopia, чтобы показать мне текущее состояние моего хранилища после того, как мы добавили наше SMB хранилище в предыдущих шагах. Я сделал это с помощью команды \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status.\nТеперь мы готовы заменить конфигурацию хранилища для целей демонстрации. Если бы мы хотели получить долгосрочное решение для обоих хранилищ, мы бы создали файл smb.config и файл object.config и могли бы запускать обе эти команды для отправки наших копий данных в каждое место. Для добавления нашего хранилища мы выполнили команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository create gcs --bucket 90daysofdevops.\nПриведенная выше команда учитывает, что ведро Google Cloud Storage, которое мы создали, называется 90daysofdevops.\nТеперь, когда мы создали наше новое хранилище, мы можем снова запустит [18:27, 16.06.2022] evgschegolkova: Прежде всего, нам нужно ввести путь к тому, что мы хотим сделать снимок, и в нашем случае мы хотим сделать копию папки 90DaysOfDevOps. Вскоре мы вернемся к аспекту планирования.\nМы можем определить хранение наших снимков.\nВозможно, есть файлы или типы файлов, которые мы хотим исключить.\nЕсли бы мы хотели определить расписание, мы могли бы сделать это на следующем экране, когда вы впервые создаете этот снимок, это начальная страница для определения.\nИ вы увидите ряд других настроек, которые могут быть обработаны здесь.\nВыберите snapshot now, и данные будут записаны в ваше хранилище.\nВнесетевое резервное копирование на S3 С помощью Kopia мы можем настроить только одно хранилище одновременно. Но через пользовательский интерфейс мы можем проявить творческий подход и, по сути, иметь несколько файлов конфигурации хранилища на выбор для достижения нашей цели - иметь локальную и внесетевую копию в Object Storage.\nХранилище Object Storage, в которое я решил отправить свои данные, будет Google Cloud Storage. Сначала я вошел в свой аккаунт Google Cloud Platform и создал себе ведро хранения. В моей системе уже был установлен Google Cloud SDK, но выполнение команды gcloud auth application-default login позволило мне аутентифицироваться в моей учетной записи.\nЗатем я использовал CLI Kopia, чтобы показать мне текущее состояние моего хранилища после того, как мы добавили наше SMB хранилище в предыдущих шагах. Я сделал это с помощью команды \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status.\nТеперь мы готовы заменить конфигурацию хранилища для целей демонстрации. Если бы мы хотели получить долгосрочное решение для обоих хранилищ, мы бы создали файл smb.config и файл object.config и могли бы запускать обе эти команды для отправки наших копий данных в каждое место. Для добавления нашего хранилища мы выполнили команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository create gcs --bucket 90daysofdevops.\nПриведенная выше команда учитывает, что ведро Google Cloud Storage, которое мы создали, называется 90daysofdevops.\nТеперь, когда мы создали наше новое хранилище, мы можем снова запустить команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config repository status, которая теперь покажет конфигурацию хранилища GCS.\nСледующее, что нам нужно сделать, это создать снимок и отправить его в наш только что созданный репозиторий. Используя команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config kopia snapshot create \"C:\\Users\\micha\\demo\\90DaysOfDevOps\" мы можем запустить этот процесс. В браузере ниже вы можете увидеть, что в нашем ведре Google Cloud Storage теперь есть файлы kopia, основанные на нашей резервной копии.\nС помощью вышеописанного процесса мы смогли решить нашу задачу по отправке важных данных в 2 разных места, одно из которых находится вне помещения в Google Cloud Storage, и, конечно же, у нас все еще есть наша производственная копия данных на другом типе носителя.\nВосстановление Восстановление - это еще один важный момент, Kopia дает нам возможность не только восстанавливать данные в существующее местоположение, но и в новое.\nЕсли мы выполним команду \"C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe\" --config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config snapshot list, это приведет к списку снимков, которые в настоящее время находятся в нашем настроенном хранилище (GCS).\nЗатем мы можем смонтировать эти снимки непосредственно из GCS, используя команду ``C:\\Program Files\\KopiaUI\\resources\\server\\kopia.exe’’ –config-file=C:\\Users\\micha\\AppData\\Roaming\\kopia\\repository.config mount all Z:`.\nМы также можем восстановить содержимое снимка с помощью команды kopia snapshot restore kdbd9dff738996cfe7bcf99b45314e193.\nОчевидно, что приведенные выше команды очень длинные, и это потому, что я использовал KopiaUI версию kopia.exe, как объяснялось в верхней части руководства, вы можете скачать kopia.exe и поместить в путь, чтобы вы могли просто использовать команду kopia.\nНа следующем занятии мы сосредоточимся на защите рабочих нагрузок в Kubernetes.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"86. Резервное копирование всех платформ","uri":"/ru/docs/90daysofdevops/day86/"},{"content":"Резервное копирование и восстановление своими руками На прошлом занятии мы рассмотрели Kopia - инструмент резервного копирования с открытым исходным кодом, который мы использовали для переноса важных данных на локальный NAS и в облачное хранилище объектов.\nВ этом разделе я хочу погрузиться в мир резервного копирования Kubernetes. Это платформа, которую мы рассматривали в The Big Picture: Kubernetes ранее в этой задаче.\nМы снова будем использовать наш кластер minikube, но на этот раз мы воспользуемся некоторыми из доступных аддонов.\nНастройка кластера Kubernetes Для настройки нашего кластера minikube мы выполним команду minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p 90daysofdevops --kubernetes-version=1.21.2. Вы заметите, что мы используем volumesnapshots и csi-hostpath-driver, поскольку мы будем использовать их для создания резервных копий.\nНа данном этапе я знаю, что мы еще не развернули Kasten K10, но мы хотим выполнить следующую команду, когда ваш кластер будет запущен, но мы хотим аннотировать класс volumesnapshotclass, чтобы Kasten K10 мог использовать его.\nkubectl annotate volumesnapshotclass csi-hostpath-snapclass \\\rk10.kasten.io/is-snapshot-class=true\rМы также собираемся изменить класс хранения по умолчанию со стандартного класса хранения по умолчанию на класс хранения csi-hostpath, используя следующее.\nkubectl patch storageclass csi-hostpath-sc -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"true\"}}}}''\rkubectl patch storageclass standard -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\": \"false\"}}}}''\rРазвертывание Kasten K10 Добавьте репозиторий Kasten Helm\nhelm repo add kasten https://charts.kasten.io/.\nМы могли бы использовать arkade kasten install k10 и здесь, но для целей демонстрации мы выполним следующие шаги. Подробнее\nСоздайте пространство имен и разверните K10, обратите внимание, что это займет около 5 минут\nhelm install k10 kasten/k10 --namespace=kasten-io --set auth.tokenAuth.enabled=true --set injectKanisterSidecar.enabled=true --set-string injectKanisterSidecar.namespaceSelector.matchLabels.k10/injectKanisterSidecar=true --create-namespace.\nВы можете наблюдать за появлением стручков, выполнив следующую команду.\nkubectl get pods -n kasten-io -w\nЧтобы получить доступ к приборной панели K10, откройте новый терминал и выполните следующую команду\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1)\rTOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode)\recho \"Значение токена: \"\recho $TOKEN\rТеперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nРазвертывание нашего stateful-приложения Используйте stateful-приложение, которое мы использовали в разделе Kubernetes.\nВы можете найти конфигурационный файл YAML для этого приложения здесьpacman-stateful-demo.yaml\nМы можем использовать kubectl get all -n pacman, чтобы проверить появление наших стручков.\nВ новом терминале мы можем перенаправить фронт-енд pacman. kubectl port-forward svc/pacman 9090:80 -n pacman.\nОткройте другую вкладку в браузере на http://localhost:9090/\nНайдите время, чтобы записать несколько высоких результатов в базе данных backend MongoDB.\nЗащитите наши высокие баллы Теперь у нас есть некоторые важные данные в нашей базе данных, и мы не хотим их потерять. Мы можем использовать Kasten K10 для защиты всего приложения.\nЕсли мы вернемся на вкладку приборной панели Kasten K10, вы увидите, что количество наших приложений увеличилось с 1 до 2 с добавлением нашего приложения pacman в наш кластер Kubernetes.\nЕсли вы нажмете на карточку Applications, вы увидите автоматически обнаруженные приложения в нашем кластере.\nВ Kasten K10 у нас есть возможность использовать моментальные снимки на основе хранилища, а также экспортировать наши копии в объектные хранилища.\nДля целей демонстрации мы создадим ручной снимок хранилища в нашем кластере, а затем добавим некоторые неавторизованные данные в наши высокие результаты, чтобы имитировать случайную ошибку или нет?\nДля начала мы можем воспользоваться приведенным ниже вариантом ручного снапшота.\nДля демонстрации я собираюсь оставить все по умолчанию\nВернувшись на приборную панель, вы получите отчет о состоянии задания в процессе его выполнения, а после завершения оно должно выглядеть так же успешно, как и здесь.\nСценарий неудачи Теперь мы можем внести фатальное изменение в наши критически важные данные, просто добавив предписывающее плохое изменение в наше приложение.\nКак вы можете видеть ниже, у нас есть два входа, которые мы, вероятно, не хотим видеть в нашей производственной критически важной базе данных.\nВосстановление данных Очевидно, что это простая демонстрация и в некотором роде нереалистичная, хотя вы видели, как легко можно сбросить базы данных?\nТеперь мы хотим, чтобы список высоких результатов выглядел немного чище и как он выглядел до того, как были допущены ошибки.\nВернемся в карточку приложений и на вкладку pacman, теперь у нас есть 1 точка восстановления, которую мы можем использовать для восстановления.\nПри выборе восстановления вы можете увидеть все связанные снимки и экспорты для этого приложения.\nВыберите восстановление и появится боковое окно, мы сохраним настройки по умолчанию и нажмем восстановить.\nПодтвердите, что вы действительно хотите, чтобы это произошло.\nЗатем вы можете вернуться на приборную панель и просмотреть ход восстановления. Вы должны увидеть что-то вроде этого.\nНо более важно то, как выглядит наш список High-Score в нашем критически важном приложении. Вам придется снова запустить проброс портов в pacman, как мы уже рассказывали ранее.\nЭто очень простая демонстрация, которая лишь слегка касается того, чего Kasten K10 может достичь в области резервного копирования. В будущем я буду создавать более подробные видеоматериалы по некоторым из этих областей. Мы также будем использовать Kasten K10 для освещения некоторых других важных областей управления данными, когда речь идет об аварийном восстановлении и мобильности ваших данных.\nДалее мы рассмотрим согласованность приложений.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"87. Резервное копирование и восстановление","uri":"/ru/docs/90daysofdevops/day87/"},{"content":"Резервное копирование, ориентированное на приложения В День 85 мы уже потратили некоторое время на обсуждение служб данных или приложений с интенсивным использованием данных, таких как базы данных. Для этих служб данных мы должны подумать о том, как управлять согласованностью, особенно когда речь идет о согласованности приложений.\nВ этой статье мы рассмотрим требования к защите данных приложения в последовательной манере.\nДля этого мы выберем инструмент Kanister\nПредставляем Kanister Kanister - это проект с открытым исходным кодом от Kasten, который позволяет нам управлять (резервное копирование и восстановление) данными приложений на Kubernetes. Вы можете развернуть Kanister как helm-приложение в своем кластере Kubernetes.\nKanister использует пользовательские ресурсы Kubernetes, основные пользовательские ресурсы, которые устанавливаются при развертывании Kanister, следующие\nProfile - целевое место для хранения резервных копий и восстановления. Чаще всего это объектное хранилище. Blueprint - шаги, которые необходимо предпринять для резервного копирования и восстановления базы данных, должны быть сохранены в Blueprint. ActionSet - действия по перемещению целевой резервной копии в наш профиль, а также действия по восстановлению. Описание выполнения Прежде чем приступить к работе, мы должны рассмотреть рабочий процесс, который использует Kanister для защиты данных приложения. Во-первых, наш контроллер развертывается с помощью helm в нашем кластере Kubernetes, Kanister живет в своем собственном пространстве имен. Мы берем наш Blueprint, для которого существует множество поддерживаемых сообществом Blueprint, мы рассмотрим это более подробно в ближайшее время. Затем у нас есть рабочая нагрузка базы данных.\nЗатем мы создаем наш ActionSet.\nActionSet позволяет нам запускать действия, определенные в чертеже, против конкретной службы данных.\nActionSet, в свою очередь, использует функции Kanister (KubeExec, KubeTask, Resource Lifecycle) и выталкивает нашу резервную копию в целевое хранилище (Profile).\nЕсли действие выполнено/не выполнено, соответствующий статус обновляется в наборе действий.\nРазвертывание Kanister И снова мы будем использовать кластер minikube для создания резервной копии приложения. Если у вас он все еще работает с предыдущей сессии, то мы можем продолжать использовать его.\nНа момент написания статьи мы имеем версию образа 0.75.0. С помощью следующей команды helm мы установим kanister в наш кластер Kubernetes.\nhelm install kanister --namespace kanister kanister/kanister-operator --set image.tag=0.75.0 --create-namespace.\nМы можем использовать kubectl get pods -n kanister, чтобы убедиться, что pod запущен и работает, а также проверить, что наши пользовательские определения ресурсов теперь доступны (Если вы только установили Kanister, то вы увидите выделенные 3) Развертывание базы данных Развертывание mysql через helm:\nAPP_NAME=my-production-app\rkubectl create ns ${APP_NAME}\rhelm repo add bitnami https://charts.bitnami.com/bitnami\rhelm install mysql-store bitnami/mysql --set primary.persistence.size=1Gi,volumePermissions.enabled=true --namespace=${APP_NAME}\rkubectl get pods -n ${APP_NAME} -w\rЗаполните базу данных mysql исходными данными, выполнив следующее:\nMYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace ${APP_NAME} mysql-store -o jsonpath=\"{.data.mysql-root-password}\" | base64 --decode)\rMYSQL_HOST=mysql-store.${APP_NAME}.svc.cluster.local\rMYSQL_EXEC=\"mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD} -DmyImportantData -t\"\recho MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\rСоздание MySQL CLIENT Мы запустим другой образ контейнера, который будет выступать в качестве нашего клиента\nAPP_NAME=my-production-app\rkubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash\rПримечание: если у вас уже запущен существующий mysql client pod, удалите его с помощью команды\rkubectl delete pod -n ${APP_NAME} mysql-client\rДобавление данных в MySQL echo \"create database myImportantData;\" | mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD}\rMYSQL_EXEC=\"mysql -h ${MYSQL_HOST} -u root --password=${MYSQL_ROOT_PASSWORD} -DmyImportantData -t\"\recho \"drop table Accounts\" | ${MYSQL_EXEC}\recho \"create table if not exists Accounts(name text, balance integer); insert into Accounts values('nick', 0);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('albert', 112);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('alfred', 358);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('beatrice', 1321);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('bartholomew', 34);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('edward', 5589);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('edwin', 144);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('edwina', 233);\" | ${MYSQL_EXEC}\recho \"insert into Accounts values('rastapopoulos', 377);\" | ${MYSQL_EXEC}\recho \"select * from Accounts;\" | ${MYSQL_EXEC}\rexit\rВы должны увидеть некоторые данные, как показано ниже.\nСоздание профиля Kanister Kanister предоставляет CLI, kanctl и другую утилиту kando, которая используется для взаимодействия с провайдером объектного хранилища из blueprint и обе эти утилиты.\nCLI Download\nЯ пошел и создал AWS S3 Bucket, который мы будем использовать в качестве цели профиля и места восстановления. Я буду использовать переменные окружения, чтобы иметь возможность показать вам команды, которые я выполняю с помощью kanctl для создания нашего профиля kanister.\nkanctl create profile s3compliant --access-key $ACCESS_KEY --secret-key $SECRET_KEY --bucket $BUCKET --region eu-west-2 --namespace my-production-app.\nВремя чертежа Не волнуйтесь, вам не нужно создавать свой собственный с нуля, если только ваш сервис данных не указан в Примерах Канистера, но, конечно, вклад сообщества - это то, как этот проект становится известным.\nМы будем использовать следующую схему.\napiVersion: cr.kanister.io/v1alpha1\rkind: Blueprint\rmetadata:\rname: mysql-blueprint\ractions:\rbackup:\routputArtifacts:\rmysqlCloudDump:\rkeyValue:\rs3path: \"{{ .Phases.dumpToObjectStore.Output.s3path }}\"\rphases:\r- func: KubeTask\rname: dumpToObjectStore\robjects:\rmysqlSecret:\rkind: Secret\rname: '{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}'\rnamespace: '{{ .StatefulSet.Namespace }}'\rargs:\rimage: ghcr.io/kanisterio/mysql-sidecar:0.75.0\rnamespace: \"{{ .StatefulSet.Namespace }}\"\rcommand:\r- bash\r- -o\r- errexit\r- -o\r- pipefail\r- -c\r- |\rs3_path=\"/mysql-backups/{{ .StatefulSet.Namespace }}/{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}/{{ toDate \"2006-01-02T15:04:05.999999999Z07:00\" .Time | date \"2006-01-02T15-04-05\" }}/dump.sql.gz\"\rroot_password=\"{{ index .Phases.dumpToObjectStore.Secrets.mysqlSecret.Data \"mysql-root-password\" | toString }}\"\rmysqldump --column-statistics=0 -u root --password=${root_password} -h {{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }} --single-transaction --all-databases | gzip - | kando location push --profile '{{ toJson .Profile }}' --path ${s3_path} -\rkando output s3path ${s3_path}\rrestore:\rinputArtifactNames:\r- mysqlCloudDump\rphases:\r- func: KubeTask\rname: restoreFromBlobStore\robjects:\rmysqlSecret:\rkind: Secret\rname: '{{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}'\rnamespace: '{{ .StatefulSet.Namespace }}'\rargs:\rimage: ghcr.io/kanisterio/mysql-sidecar:0.75.0\rnamespace: \"{{ .StatefulSet.Namespace }}\"\rcommand:\r- bash\r- -o\r- errexit\r- -o\r- pipefail\r- -c\r- |\rs3_path=\"{{ .ArtifactsIn.mysqlCloudDump.KeyValue.s3path }}\"\rroot_password=\"{{ index .Phases.restoreFromBlobStore.Secrets.mysqlSecret.Data \"mysql-root-password\" | toString }}\"\rkando location pull --profile '{{ toJson .Profile }}' --path ${s3_path} - | gunzip | mysql -u root --password=${root_password} -h {{ index .Object.metadata.labels \"app.kubernetes.io/instance\" }}\rdelete:\rinputArtifactNames:\r- mysqlCloudDump\rphases:\r- func: KubeTask\rname: deleteFromBlobStore\rargs:\rimage: ghcr.io/kanisterio/mysql-sidecar:0.75.0\rnamespace: \"{{ .Namespace.Name }}\"\rcommand:\r- bash\r- -o\r- errexit\r- -o\r- pipefail\r- -c\r- |\rs3_path=\"{{ .ArtifactsIn.mysqlCloudDump.KeyValue.s3path }}\"\rkando location delete --profile '{{ toJson .Profile }}' --path ${s3_path}\rЧтобы добавить его, мы воспользуемся командой kubectl create -f mysql-blueprint.yml -n kanister.\nСоздаем наш ActionSet и защищаем наше приложение Теперь мы создадим резервную копию данных MySQL с помощью ActionSet, определяющего резервное копирование для этого приложения. Создайте ActionSet в том же пространстве имен, что и контроллер.\nkubectl get profiles.cr.kanister.io -n my-production-app Эта команда покажет нам профиль, который мы ранее создали, здесь может быть настроено несколько профилей, поэтому мы можем захотеть использовать определенные профили для разных ActionSet’ов.\nЗатем мы создадим наш ActionSet следующей командой с помощью kanctl.\nkanctl create actionset --action backup --namespace kanister --blueprint mysql-blueprint --statefulset my-production-app/mysql-store --profile my-production-app/s3-profile-dc5zm --secrets mysql=my-production-app/mysql-store.\nИз приведенной выше команды видно, что мы определяем blueprint, который мы добавили в пространство имен, statefulset в нашем пространстве имен my-production-app, а также секреты для входа в приложение MySQL.\nПроверьте состояние ActionSet, взяв имя ActionSet и используя эту команду kubectl --namespace kanister describe actionset backup-qpnqv.\nНаконец, мы можем пойти и подтвердить, что теперь у нас есть данные в нашем ведре AWS S3.\nВосстановление Нам нужно нанести некоторый ущерб, прежде чем мы сможем что-либо восстановить, мы можем сделать это, уронив нашу таблицу, возможно, это был несчастный случай, а возможно и нет.\nПодключитесь к нашему MySQL pod.\nAPP_NAME=my-production-app\rkubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash\rВы можете увидеть, что наша база данных importantdata находится там с помощью echo \"SHOW DATABASES;\" | ${MYSQL_EXEC}.\nЗатем для удаления мы запустили echo \"DROP DATABASE myImportantData;\" | ${MYSQL_EXEC}.\nИ подтвердили, что все исчезло, сделав несколько попыток показать нашу базу данных.\nТеперь мы можем использовать Kanister, чтобы вернуть наши важные данные в рабочее состояние, используя команду kubectl get actionset -n kanister, чтобы узнать имя нашего ActionSet, который мы взяли ранее. Затем мы создадим ActionSet восстановления для восстановления наших данных, используя kanctl create actionset -n kanister --action restore --from \"backup-qpnqv\".\nМы можем подтвердить, что наши данные восстановлены, используя следующую команду для подключения к нашей базе данных.\nAPP_NAME=my-production-app\rkubectl run mysql-client --rm --env APP_NS=${APP_NAME} --env MYSQL_EXEC=\"${MYSQL_EXEC}\" --env MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} --env MYSQL_HOST=${MYSQL_HOST} --namespace ${APP_NAME} --tty -i --restart='Never' --image docker.io/bitnami/mysql:latest --command -- bash\rТеперь мы находимся внутри клиента MySQL, мы можем выполнить команду echo \"SHOW DATABASES;\" | ${MYSQL_EXEC} и мы увидим, что база данных восстановлена. Мы также можем выполнить команду echo \"select * from Accounts;\" | ${MYSQL_EXEC} для проверки содержимого базы данных, и наши важные данные будут восстановлены.\nВ следующем посте мы рассмотрим аварийное восстановление в Kubernetes.\nРесурсы Kanister Overview - An extensible open-source framework for app-lvl data management on Kubernetes Application Level Data Operations on Kubernetes Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"88. Резервное копирование, ориентированное на приложения","uri":"/ru/docs/90daysofdevops/day88/"},{"content":"Аварийное восстановление Мы уже упоминали о том, что различные скрипты сбоев требуют различных требований к восстановлению. Когда речь идет о скриптах пожара, наводнения и крови, мы можем рассматривать их как аварийные ситуации, в которых нам может потребоваться, чтобы наши рабочие нагрузки были запущены в совершенно другом месте как можно быстрее или, по крайней мере, с почти нулевым временем восстановления (RTO).\nЭтого можно достичь только в масштабе, если автоматизировать репликацию всего стека приложений в резервную среду.\nЭто позволяет быстро переходить от одного облачного региона к другому, облачным провайдерам или между локальной и облачной инфраструктурой.\nПродолжая тему, мы сосредоточимся на том, как этого можно достичь с помощью Kasten K10, используя наш кластер minikube, который мы развернули и настроили несколько занятий назад.\nЗатем мы создадим еще один кластер minikube с установленным Kasten K10 в качестве резервного кластера, который теоретически может находиться в любом месте.\nKasten K10 также имеет встроенную функциональность для обеспечения того, что если что-то случится с кластером Kubernetes, на котором он работает, данные каталога будут реплицированы и доступны на новом K10 Disaster Recovery.\nДобавление объектного хранилища в K10 Первое, что нам нужно сделать, это добавить ведро объектного хранилища в качестве целевого местоположения для наших резервных копий. Это не только выступает в качестве удаленного хранилища, но мы также можем использовать его в качестве исходных данных для аварийного восстановления.\nЯ очистил ведро S3, которое мы создали для демонстрации Kanister на прошлом занятии.\nЧтобы получить доступ к приборной панели K10, откройте новый терминал и выполните следующую команду:\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1)\rTOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode)\recho \"Token value: \"\recho $TOKEN\rТеперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nТеперь, когда мы вернулись в приборную панель Kasten K10, мы можем добавить наш профиль местоположения, выберите “Настройки” в верхней части страницы и “Новый профиль”.\nНа изображении ниже видно, что у нас есть выбор, где будет находиться этот профиль местоположения, мы выбираем Amazon S3, и добавляем наши учетные данные доступа, регион и имя ведра.\nЕсли мы прокрутим окно создания нового профиля вниз, то увидим, что у нас также есть возможность включить неизменяемое резервное копирование, которое использует API блокировки объектов S3. В данном демо мы не будем использовать эту возможность.\nНажмите “Сохранить профиль”, и теперь вы можете увидеть наш только что созданный или добавленный профиль местоположения, как показано ниже.\nСоздание политики для защиты приложения Pac-Man в объектном хранилище В предыдущем сеансе мы создали только специальный снимок нашего приложения Pac-Man, поэтому нам нужно создать политику резервного копирования, которая будет отправлять резервные копии нашего приложения в наше недавно созданное объектное хранилище.\nЕсли вы вернетесь на приборную панель и выберете карточку Policy, вы увидите окно, как показано ниже. Выберите “Создать новую политику”.\nВо-первых, мы можем дать нашей политике полезное имя и описание. Мы также можем определить частоту резервного копирования, для демонстрационных целей я использую “по требованию”.\nДалее мы хотим включить резервное копирование через Snapshot exports, что означает, что мы хотим отправлять наши данные в наш профиль местоположения. Если у вас их несколько, вы можете выбрать, в какой из них вы хотите отправлять резервные копии.\nДалее выбираем приложение по имени или по меткам, я собираюсь выбрать по имени и все ресурсы.\nВ разделе Advanced settings мы не будем использовать ничего из этого, но, основываясь на нашем вчерашнем walkthrough of Kanister, мы можем использовать Kanister как часть Kasten K10 для создания согласованных с приложением копий наших данных.\nНаконец, выберите “Создать политику”, и теперь вы увидите политику в нашем окне политики.\nВ нижней части созданной политики появится “Show import details”, нам нужна эта строка, чтобы иметь возможность импортировать в наш резервный кластер. Скопируйте ее в безопасное место.\nПрежде чем двигаться дальше, нам нужно выбрать “run once”, чтобы получить резервную копию, отправленную нашему ведру объектного хранилища.\nНиже, на скриншоте просто показано успешное резервное копирование и экспорт наших данных.\nСоздание нового кластера MiniKube и развертывание K10 Затем нам нужно развернуть второй кластер Kubernetes, и где это может быть любая поддерживаемая версия Kubernetes, включая OpenShift, в целях обучения мы будем использовать очень бесплатную версию MiniKube с другим названием.\nИспользуя minikube start --addons volumesnapshots,csi-hostpath-driver --apiserver-port=6443 --container-runtime=containerd -p standby --kubernetes-version=1.21.2 мы можем создать наш новый кластер.\nЗатем мы можем развернуть Kasten K10 в этом кластере, используя:\nhelm install k10 kasten/k10 --namespace=kasten-io --set auth.tokenAuth.enabled=true --set injectKanisterSidecar.enabled=true --set-string injectKanisterSidecar.namespaceSelector.matchLabels.k10/injectKanisterSidecar=true --create-namespace.\nЭто займет некоторое время, но тем временем мы можем использовать kubectl get pods -n kasten-io -w, чтобы наблюдать за прогрессом перехода наших pods в статус запущенных.\nСтоит отметить, что поскольку мы используем MiniKube, наше приложение будет запущено, когда мы запустим политику импорта, наш класс хранилища будет таким же на этом резервном кластере. Однако то, что мы рассмотрим на последнем занятии, касается мобильности и трансформации.\nКогда капсулы запущены, мы можем выполнить шаги, которые мы проделали в предыдущих шагах на другом кластере.\nПеренесите порт вперед для доступа к приборной панели K10, откройте новый терминал и выполните следующую команду\nkubectl --namespace kasten-io port-forward service/gateway 8080:8000.\nПриборная панель Kasten будет доступна по адресу: http://127.0.0.1:8080/k10/#/\nДля аутентификации на приборной панели нам теперь нужен токен, который мы можем получить с помощью следующих команд.\nTOKEN_NAME=$(kubectl get secret --namespace kasten-io|grep k10-k10-token | cut -d \" \" -f 1)\rTOKEN=$(kubectl get secret --namespace kasten-io $TOKEN_NAME -o jsonpath=\"{.data.token}\" | base64 --decode)\recho \"Token value: \"\recho $TOKEN\rТеперь мы берем этот токен и вводим его в браузер, после чего вам будет предложено ввести email и название компании.\nЗатем мы получаем доступ к приборной панели Kasten K10.\nИмпортируем Pac-Man в новый кластер MiniKube На данном этапе мы можем создать политику импорта в резервном кластере, подключиться к резервным копиям объектного хранилища и определить, что и как мы хотим, чтобы выглядело.\nВо-первых, мы добавляем наш профиль местоположения, который мы рассмотрели ранее на другом кластере, используя темный режим, чтобы показать разницу между нашей производственной системой и резервным местоположением DR.\nТеперь вернемся к приборной панели и перейдем на вкладку политик, чтобы создать новую политику.\nСоздайте политику импорта в соответствии с приведенным ниже изображением. После завершения мы можем создать политику. Здесь есть опция восстановления после импорта, и некоторые люди могут захотеть воспользоваться этой опцией, которая будет восстановлена в нашем резервном кластере по завершении. У нас также есть возможность изменить конфигурацию приложения при восстановлении, и это то, что я описал в Day 90.\nЯ выбрал импорт по требованию, но вы, очевидно, можете установить расписание, когда вы хотите, чтобы этот импорт происходил. В связи с этим я собираюсь выполнить один раз.\nНиже вы можете видеть успешное выполнение задания политики импорта.\nЕсли мы теперь вернемся на приборную панель и зайдем в карточку Applications, мы можем выбрать выпадающий список, где вы видите ниже “Removed”, здесь вы увидите наше приложение. Выберите “Восстановить\nЗдесь мы видим доступные нам точки восстановления; это было задание резервного копирования, которое мы выполнили на первичном кластере для нашего приложения Pac-Man.\nЯ не буду менять никаких настроек по умолчанию, так как хочу рассмотреть это более подробно на следующем занятии.\nКогда вы нажмете кнопку “Восстановить”, появится запрос на подтверждение.\nНиже мы видим, что мы находимся в резервном кластере, и если мы проверим наши pods, мы увидим, что у нас есть наше запущенное приложение.\nЗатем мы можем перенаправить порт (в реальной жизни/производственной среде вам не понадобится этот шаг для доступа к приложению, вы будете использовать ingress)\nДалее мы рассмотрим мобильность и трансформацию приложений.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility ","description":"","title":"89. Аварийное восстановление","uri":"/ru/docs/90daysofdevops/day89/"},{"content":"Python поставляется с большим количеством готового кода. Эти части кода известны как модули и пакеты. Модуль - это один импортируемый файл Python, а пакет состоит из двух или более модулей. Пакет может быть импортирован так же, как и модуль. Каждый раз, когда вы сохраняете собственный сценарий Python, вы создаете модуль. Это, конечно, может быть далеко не самым полезным модулем, но тем не менее. В этой главе мы узнаем, как импортировать модули, используя несколько различных методов. Давайте начнем!\nimport this Python предоставляет ключевое слово import для импорта модулей. Давайте попробуем:\nimport this Если вы запустите этот код в интерпретаторе, на выходе вы должны увидеть что-то вроде следующего:\nThe Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! Вы нашли “пасхальное яйцо” в Python, известное как “Zen of Python”. На самом деле это своего рода неофициальная лучшая практика для Python. Mодуль this на самом деле ничего не делает, но он предоставляет забавный способ показать, как импортировать что-то. Давайте действительно импортируем что-то, что мы можем использовать, например, модуль math:\n\u003e\u003e\u003e import math \u003e\u003e\u003e math.sqrt(4) 2.0 Здесь мы импортировали модуль math, а затем сделали кое-что новое. Мы вызвали одну из его функций, sqrt (т.е. квадратный корень). Чтобы вызвать метод импортированного модуля, мы должны использовать следующий синтаксис: имя_модуля.имя_метода(аргумент). В этом примере мы нашли квадратный корень из 4. Модуль math имеет множество других функций, которые мы можем использовать, например, cos (косинус), factorial, log (логарифм) и т. д. Вы можете вызывать эти функции точно так же, как и sqrt. Единственное, что вам нужно будет проверить, принимают ли они дополнительные аргументы или нет. Теперь давайте рассмотрим другой способ импорта.\nИспользование from для импорта Некоторым людям не нравится, что все, что они вводят, должно сопровождаться именем модуля. В Python есть решение для этого! Вы можете импортировать из модуля только те функции, которые вам нужны. Давайте представим, что мы хотим импортировать только функцию *sqrt:\n\u003e\u003e\u003e from math import sqrt \u003e\u003e\u003e sqrt(16) 4.0 Это работает практически так, как читается: из модуля math импортируйте функцию sqrt. Позвольте мне объяснить это по-другому. Мы используем ключевое слово Python from для импорта функции sqrt из модуля math. Вы также можете использовать этот метод для импорта нескольких функций из модуля math:\n\u003e\u003e\u003e from math import pi, sqrt В этом примере мы импортируем и pi, и sqrt. Если вы пытались получить доступ к pi, то, возможно, заметили, что на самом деле это значение, а не функция, которую можно вызвать. Она просто возвращает значение pi. Когда вы выполняете импорт, вы можете импортировать значение, функцию или даже другой модуль! Есть еще один способ импортировать материал, который мы должны рассмотреть. Давайте узнаем, как импортировать все!\nИмпорт всего! Python предоставляет возможность импортировать все функции и значения из модуля. На самом деле это плохая идея, так как это может привести к загрязнению вашего пространства имен. Пространство имен - это место, где находятся все ваши переменные в течение жизни программы. Допустим, у вас есть своя переменная с именем sqrt, например, так:\n\u003e\u003e\u003e from math import sqrt \u003e\u003e\u003e sqrt = 5 Теперь вы только что изменили функцию sqrt на переменную, которая хранит значение 5. Это называется затенением (shadowing). Это особенно хитрый способ упрощения своей жизни, когда вы выполняете импорт всего из модуля. Давайте взглянем:\n\u003e\u003e\u003e from math import * \u003e\u003e\u003e sqrt = 5 \u003e\u003e\u003e sqrt(16) Traceback (most recent call last): File \"\u003cstring\u003e\", line 1, in \u003cfragment\u003e TypeError: 'int' object is not callable Чтобы импортировать все, вместо указания списка элементов мы просто используем подстановочный знак “*”, который означает, что мы хотим импортировать все. Если мы не знаем, что находится в модуле math, мы не поймем, что только что провалили одну из импортированных функций. Когда мы пытаемся вызвать функцию sqrt после присвоения её целому числу, мы обнаружим, что она больше не работает.\nПоэтому в большинстве случаев рекомендуется импортировать элементы из модулей, используя один из предыдущих методов, упомянутых в этой главе. Из этого правила есть несколько исключений. Некоторые модули созданы для импорта с помощью метода “*”. Одним из ярких примеров является Tkinter, набор инструментов, входящий в состав Python, который позволяет создавать пользовательские интерфейсы для настольных компьютеров. Причина, по которой импортировать Tkinter таким образом якобы можно, заключается в том, что модули названы так, что вы вряд ли будете использовать их повторно.\nПодведение итогов Теперь вы знаете все об импорте в Python. В состав Python входят десятки модулей, которые вы можете использовать для придания дополнительной функциональности вашим программам. Вы можете использовать встроенные модули для опроса вашей ОС, получения информации из реестра Windows, настройки утилит протоколирования, разбора XML и многого, многого другого. Мы рассмотрим некоторые из этих модулей во второй части этой книги.\nВ следующей главе мы рассмотрим создание собственных функций. Я думаю, что следующая тема окажется для вас очень полезной.\n","description":"Python 101","title":"9. Импортирование","uri":"/ru/docs/python101/chapter9_imports/"},{"content":"Разберемся как работает hello-world Как работает Go Вчера мы прошли процедуру установки Go на ПК, а затем создали наше первое приложение Go.\nВ этом разделе мы собираемся глубже изучить код и понять еще несколько вещей о языке Go.\nЧто такое компиляция? Прежде чем мы перейдем к 6 строкам кода Hello World, которые написали вчера, нам нужно немного разобраться в компиляции.\nЯзыки программирования, которые мы обычно используем, такие как Python, Java, Go и C++, являются языками высокого уровня. Это означает, что они удобочитаемы для человека, но когда машина пытается выполнить программу, она должна быть в форме, понятной машине. Мы должны перевести наш человекочитаемый код в машинный код, что называется компиляцией.\nИз приведенного выше вы можете видеть, что мы сделали в День 8 - мы создали простой Hello World main.go, а затем использовали команду go build main.go для компиляции нашего исполняемого файла.\npackage main import \"fmt\" func main() { fmt.Println(\"Hello #90DaysOfDevOps\") } Что такое пакеты? Пакет — это набор исходных файлов в одном каталоге, которые скомпилированы вместе. Мы можем упростить это еще больше, пакет — это набор файлов .go в одном каталоге. Помните нашу папку Hello из Дня 8? Когда вы попадете в более сложные программы Go, вы можете обнаружить, что у вас есть папка1, папка2 и папка3, содержащие разные файлы .go, которые составляют вашу программу с несколькими пакетами.\nМы используем пакеты, чтобы мы могли повторно использовать код других людей, нам не нужно писать все с нуля. Возможно, нам нужен калькулятор как часть нашей программы, вы, вероятно, могли бы найти существующий пакет Go, содержащий математические функции, которые вы могли бы импортировать в свой код, что в конечном итоге сэкономит вам много времени и усилий.\nGo рекомендует организовывать код в пакеты, чтобы его было легко повторно использовать и поддерживать исходный код.\nHello #90DaysOfDevOps шаг за шагом Теперь давайте посмотрим на наш файл main.go Hello #90DaysOfDevOps и пройдемся по строкам. В первой строке у нас есть package main, что означает, что этот файл принадлежит пакету с именем main. Все файлы .go должны принадлежать пакету, они также должны иметь «package something» в открывающей строке.\nПакет можно назвать как угодно. Мы должны назвать этот main, так как это начальная точка программы, которая будет в этом пакете, это правило. Всякий раз, когда мы хотим скомпилировать и выполнить наш код, мы должны сообщить машине, где должно начаться выполнение. Мы делаем это, написав функцию с именем main. Машина будет искать функцию с именем main, чтобы найти точку входа в программу.\nФункция — это блок кода, который может выполнять определенную задачу и может использоваться во всей программе.\nВы можете объявить функцию с любым именем, используя func, но в этом случае нам нужно назвать ее main, так как именно здесь начинается код.\nДалее мы рассмотрим строку 3 нашего кода, импорт, это в основном означает, что вы хотите добавить другой пакет в свою основную программу. fmt — это стандартный пакет, используемый здесь, предоставленный Go, этот пакет содержит функцию Println(), и, поскольку мы импортировали ее, мы можем использовать ее в строке 6. Существует ряд стандартных пакетов, которые вы можете включить в свою программу и используйте или повторно используйте их в своем коде, избавляя вас от необходимости писать с нуля. Println(), который у нас есть, — это способ записи в стандартный вывод на терминал, где когда-либо исполняемый файл был успешно выполнен. Не стесняйтесь изменять сообщение между скобками (). TLDR Что такое TLDR\nСтрока 1 = Этот файл будет находиться в пакете с именем main, и его нужно назвать main, поскольку он включает точку входа программы. Строка 3 = Чтобы использовать Println(), мы должны импортировать пакет fmt, чтобы использовать его в строке 6. Строка 5 = фактическая начальная точка, это функция main. Строка 6 = Это позволит нам напечатать «Hello #90DaysOfDevOps» в нашей системе. Источники Стандартная библиотека Go Golang | Все Основы за 4 Часа Для Начинающих StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Увидимся на 10-й день\n","description":"Как работает hello-world на Golang","title":"9. Как работает hello-world на Golang","uri":"/ru/docs/90daysofdevops/day09/"},{"content":"Мобильность данных и приложений День 90 из #90DaysOfDevOps Challenge! В этой заключительной сессии я собираюсь рассказать о мобильности наших данных и приложений. Я сосредоточусь конкретно на Kubernetes, но потребность в мобильности между платформами и между платформами - это то, что является постоянно растущей потребностью и встречается на практике.\nСценарий использования таков: “Я хочу переместить рабочую нагрузку, приложение и данные из одного места в другое” по разным причинам, будь то стоимость, риск или предоставление бизнесу более качественных услуг.\nНа этом занятии мы возьмем нашу рабочую нагрузку и рассмотрим перемещение рабочей нагрузки Kubernetes с одного кластера на другой, но при этом мы изменим то, как наше приложение находится в целевом месте.\nФактически, здесь используются многие характеристики, которые мы рассмотрели в статье Аварийное восстановление\nТребование Наш текущий кластер Kubernetes не справляется со спросом, а наши затраты стремительно растут, поэтому мы хотим переместить наш производственный кластер Kubernetes в место аварийного восстановления, расположенное в другом публичном облаке, которое обеспечит возможность расширения, но при этом будет дешевле. Мы также сможем воспользоваться некоторыми собственными облачными сервисами, доступными в целевом облаке.\nНаше текущее критически важное приложение (Pac-Man) имеет базу данных (MongoDB) и работает на медленном хранилище, мы хотели бы перейти на новый более быстрый уровень хранения.\nТекущий фронтенд Pac-Man (NodeJS) не очень хорошо масштабируется, и мы хотели бы увеличить количество доступных стручков в новом месте.\nПриступаем к ИТ У нас есть бриф, и на самом деле мы уже импортировали наши импорты в кластер Disaster Recovery Kubernetes.\nПервое, что нам нужно сделать, это удалить операцию восстановления, которую мы выполнили в день 89 для тестирования Disaster Recovery.\nМы можем сделать это с помощью команды kubectl delete ns pacman на “резервном” кластере minikube.\nЧтобы начать работу, зайдите в Kasten K10 Dashboard, выберите карточку Applications. Из выпадающего списка выберите “Удаленные”\nЗатем мы получим список доступных точек восстановления. Мы выберем ту, которая доступна, так как она содержит важные данные. (В этом примере у нас только одна точка восстановления).\nКогда мы работали над процессом аварийного восстановления, мы оставили все по умолчанию. Однако эти дополнительные опции восстановления существуют, если у вас есть процесс Disaster Recovery, который требует преобразования вашего приложения. В данном случае нам требуется изменить хранилище и количество реплик. Выберите опцию “Применить преобразования к восстановленным ресурсам”.\nТак получилось, что два встроенных примера преобразования, которые мы хотим выполнить, соответствуют нашим требованиям.\nПервое требование заключается в том, что на нашем основном кластере мы использовали класс хранения под названием csi-hostpath-sc, а в нашем новом кластере мы хотим использовать standard, поэтому мы можем сделать это изменение здесь.\nВыглядит хорошо, нажимаем кнопку create transform внизу.\nСледующее требование заключается в том, что мы хотим масштабировать развертывание нашего фронтенда Pac-Man до “5”\nЕсли вы следите за развитием событий, вы должны увидеть оба наших преобразования, как показано ниже.\nТеперь вы можете видеть на изображении ниже, что мы собираемся восстановить все артефакты, перечисленные ниже, если бы мы захотели, мы могли бы также детализировать то, что мы хотим восстановить. Нажмите кнопку “Восстановить”\nСнова нам будет предложено подтвердить действия.\nИ последнее, что мы покажем, если мы вернемся в терминал и посмотрим на наш кластер, вы увидите, что у нас теперь 5 стручков для стручков pacman и наш класс хранения теперь установлен на стандартный, а не на csi-hostpath-sc\nСуществует множество различных вариантов, которые могут быть достигнуты с помощью трансформации. Это может охватывать не только миграцию, но и аварийное восстановление, скрипты типа тестирования и разработки и т.д.\nAPI и автоматизация Я не говорил о возможности использовать API и автоматизировать некоторые из этих задач, но эти опции присутствуют, и во всем пользовательском интерфейсе есть хлебные крошки, которые предоставляют наборы команд для использования API для задач автоматизации.\nВажно отметить, что при развертывании Kasten K10 развертывается внутри кластера Kubernetes и затем может быть вызван через API Kubernetes.\nНа этом мы завершаем раздел о хранении и защите данных.\nРесурсы Kubernetes Backup and Restore made easy! Kubernetes Backups, Upgrades, Migrations - with Velero 7 Database Paradigms Disaster Recovery vs. Backup: What’s the difference? Veeam Portability \u0026 Cloud Mobility Закрытие Заканчивая эту задачу, я хочу продолжить просить об обратной связи, чтобы убедиться, что информация всегда актуальна.\nЯ также ценю, что есть много тем, которые я не смог охватить или не смог глубже погрузиться в тему DevOps.\nЭто означает, что мы всегда можем предпринять еще одну попытку в следующем году и найти еще 90 дней контента и прохождений для работы.\nЧто дальше? Во-первых, немного отдохнем от писанины, я начал этот вызов 1 января 2022 года и закончил 31 марта 2022 года в 19:50 BST! Это был тяжелый труд. Но, как я говорю и говорил уже давно, если этот контент поможет одному человеку, то всегда стоит учиться публично! У меня есть несколько идей, куда двигаться дальше, и я надеюсь, что у него будет жизнь за пределами репозитория GitHub, и мы сможем рассмотреть возможность создания электронной книги и, возможно, даже физической книги.\nЯ также знаю, что нам нужно пересмотреть каждый пост и убедиться, что все грамматически правильно, прежде чем делать что-то подобное. Если кто-то знает о том, как использовать формат markdown для печати или создания электронной книги, я буду очень признателен за ответ.\nКак всегда, продолжайте обсуждать вопросы и PR.\nСпасибо!\n","description":"","title":"90. Мобильность данных и приложений","uri":"/ru/docs/90daysofdevops/day90/"},{"content":"Goal: Check if you are ready to pass Cloud exam\nGoal: Check if you are ready to pass the Cloud exam\nThe application calculates progress after each answered question. Ability to answer at least one question and get a comment at the same time. No need to pass all questions before. It is convenient to spend 20 min a day Works from web/tablet/mobile Link: https://www.cloud-exam-prepare.com\n","description":"Подготовка к сдаче экзамена AWS","title":"Cloud exam Quizz","uri":"/ru/apps/cloud-exam-quizz/"},{"content":"","description":"Отслеживает истечение срока действия access и id токенов Amazon Cognito. Обновляется по истечении срока действия.","title":"cognito-token-observer","uri":"/ru/apps/npm/cognito-token-observer/"},{"content":" Docs EN | RU Posts EN | RU ","description":"","title":"Docs","uri":"/ru/docs/archive/"},{"content":"Amazon EC2 Документация Amazon EC2 - 1 Документация Amazon EC2 - 2 Amazon Elastic Compute Cloud (EC2) - одна из самых популярных служб AWS. EC2 позволяет запускать различные типы облачных экземпляров и оплачивать их по модели “оплата за использование”. EC2 позволяет контролировать вычислительные ресурсы на уровне операционной системы, работая в вычислительной среде Amazon.\nЦены Актуальный прайс\nПрактика Создание EC2 инстанса Заходим на страницу EC2 -\u003e Launch Instance\nОбраз EC2 Выбираем нужный нам образ Создание ключей Создадим ключ, чтобы использовать его для подключения к инстансу извне Вводим любое имя. Остальные параметры оставляю по умолчанию После создания ключа начнется автоматическое скачивание. Ключ понадобится далее для подключения к EC2 с локального терминала\nСетевые настройки В разделе Network Settings оставляю включенным Allow SSH traffic from Создание Нажимаем Launch Instance\nИнстанс создан и доступен для подключения\nПодключение к EC2 с терминала Подключимся к EC2 с локального терминала\nПеренесем созданный и скачанный ранее ключ mykey в папку home текущего пользователя и дадим права на файл CHMOD 400\ncd ~ cd Downloads/ mv mykey.pem $HOME cd .. chmod 400 mykey.pem Для подключения нам необходим публичный iPv4 адрес. Находим на странице с инстансом\nПодключаемся с помощью команды ssh\nssh -i mykey.pem ec2-user@52.24.109.78 Вопросы Вопрос 1 A company is migrating a legacy application to Amazon EC2. The application uses a username and password stored in the source code to connect to a MySQL database. The database will be migrated to an Amazon RDS for MySQL DB instance. As part of the migration, the company wants to implement a secure way to store and automatically rotate the database credentials.\nWhich approach meets these requirements?\nA) Store the database credentials in environment variables in an Amazon Machine Image (AMI). Rotate the credentials by replacing the AMI. B) Store the database credentials in AWS Systems Manager Parameter Store. Configure Parameter Store to automatically rotate the credentials. C) Store the database credentials in environment variables on the EC2 instances. Rotate the credentials by relaunching the EC2 instances. D) Store the database credentials in AWS Secrets Manager. Configure Secrets Manager to automatically rotate the credentials Ответ Правильный ответ: D D – AWS Secrets Manager helps to protect the credentialsneeded to access databases, applications,services, and other IT resources. The service enables users to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to the Secrets Manager APIs, eliminating the need to hardcode sensitive information in plaintext. Secrets Manager offers secret rotation with built-in integration for Amazon RDS, Amazon Redshift, and Amazon DocumentDB.\n","description":"Пошаговое руководство по Amazon EC2","title":"EC2","uri":"/ru/docs/aws-certified-developer-associate/ec2/"},{"content":"AWS Elastic Beanstalk Документация AWS Elastic Beanstalk Документация AWS Elastic Beanstalk Цены Дополнительная плата за AWS Elastic Beanstalk не взимается. Оплате подлежат только ресурсы AWS, необходимые для хранения и работы приложений.\nПрактика Контролируемое развертывание с AWS Elastic Beanstalk Ссылка на лабораторную работу В этой лабораторной работе развернем несколько обновлений версий приложения в среде с балансировкой нагрузки и автоматическим масштабированием.\nПервое обновление развертывается с помощью простого развертывания. Второе обновление развертывается с помощью blue-green развертывания, когда создается отдельная среда для запуска новой версии приложения, а DNS свитчер переключает входящий трафик на новую среду.\nИтоговая архитектура развертывания будет выглядеть следующим образом Загрузка приложения В данном обзоре я использую код, который предоставил мне Cloudacademy, но у меня есть готовый скрипт для запуска, который вы можете загрузить в Elastic Beanstalk: скачать\nСоздание Заходим на страницу Elastic Beanstalk и нажимаем Create Application Название Указываем название нового приложения Выбор платформы В разделе Platform выбираем нужную платформу приложения. В нашем случае - Node.js Загрузка исходников В разделе Source code origin указываем версию приложения и загружаем архив с приложением. Пример\nКонфигурация приложения Изменяем предустановку Configuration на Custom configuration: Нажимаем Edit в разделе Rolling updates and deployments\nВ конфигурации по умолчанию обновления распространяются на все экземпляры одновременно. Это приводит к простою приложения, что неприемлемо для производственных сред.\nМы установим Rolling и Batch size 30% Сеть Вернувшись к основной форме приложения, нажмите Edit в конфигурации Network.\nНа форме Modify network настроим следующие значения, затем Save. VPC: Выберите VPC с блоком CIDR 10.0.0.0/16. Это не будет VPC по умолчанию. Load balancer settings: Load balancer subnets: Выберите подсети с блоками CIDR **10.0.100.0/24 **(us-west-2a)и 10.0.101.0/24 (us-west-2b). Это публичные подсети. Балансировщику нагрузки приложений требуется как минимум две подсети в разных зонах доступности Instance settings: Instance subnets: Выберите подсеть с блоком CIDR 10.0.1.0/24. Это частная подсеть. Подтверждение Нажимаем Create app\nПроцесс создания приложения занимает от 5 минут.\nДалее переходим в раздел Dasboard На этом этап загрузки приложения в Elastic Beanstalk закончен. Далее разберем как переключать загрузку новой версии приложения клиентам.\nЗагрузка 2-й версии приложения Загрузка версии 2.0 Нажимаем Upload and deploy и загружаем обновленный код. _Например, можно том же исходнике изменить текст для сравнения. Указываем новую версию и настройки публикации Сравнение версий Теперь можем сверить обе версии, пройдя по ссылкам. В моем случае приложения выглядят следующим образом Смена url у приложений Теперь поменяем приложения местами. Чтобы пользователь, который ранее заходил по одному адресу, теперь видел 2-ю версию приложения.\nВ разделе Actions нажимаем Swap environment URLs и далее выбираем приложение с которым происходит смена Удаление ресурсов Elastic Beanstalk Elastic Beanstalk для развертывания приложений запускает EC2 инстансы, а также прочие сервисы. Но удалить все сервисы можно из одного окна.\nИдем в раздел Applications Выбираем приложение Нажимаем Actions -\u003e Terminate environment Ресурсы https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/tutorials.html\n","description":"Пошаговое руководство по AWS Elastic Beanstalk. Разворачиваем приложение с AWS Elastic Beanstalk","title":"Elastic Beanstalk","uri":"/ru/docs/aws-certified-developer-associate/elasticbeanstalk/"},{"content":"","description":"Создает индекс страниц Hugo для поиска lunr.js","title":"hugo-lunr-ml","uri":"/ru/apps/npm/hugo-lunr-ml/"},{"content":"AWS Identity and Access Management Документация AWS IAM Документация AWS IAM AWS Identity and Access Management (IAM) позволяет безопасно контролировать доступ пользователей к службам и ресурсам AWS. Эта услуга предназначена для организаций с множеством пользователей или систем, использующих такие продукты AWS, как Amazon EC2, Amazon RDS и AWS Management Console. С помощью IAM вы можете централизованно управлять пользователями, учетными данными безопасности, такими как ключи доступа, и разрешениями, контролирующими доступ пользователей к ресурсам AWS.\nПрактика Переходим на страницу IAM\nСоздание групп IAM На странице User Groups нажимаем Create group\nУказываем имя группы. Мое: DevOps Добавляем разрешение на просмотр EC2: AmazonEC2ReadOnlyAccess Create Группа создана\nСоздание пользователей IAM На странице Users нажимаем Create user Вводим имя пользователя(логин) Permissions Добавляем пользователя в созданную группу Tags Пропускаем раздел или ставим tags. Полезно и популярно устанавливать теги ресурсам в компаниях, где много подключено ресурсов AWS\nЛогин/Пароль На последнем этапе скачиваем .csv файл с логином, ключами и паролем. Пароль понадобится далее, чтобы войти в систему под данным пользователем. На данной странице имеется ссылка для входа. Ею воспользуемся на следующем шаге Вход новым пользователем Проверка прав У данного пользователя есть доступ на просмотр EC2 инстансов. Проверим наличие/отсутствие доступа к S3 корзинам.\nПопробуем создать S3 корзину После попытки создать корзину получаем окно с указанием на отсутствие прав ","description":"Пошаговое руководство по настройке AWS Identity and Access Management (IAM)","title":"IAM","uri":"/ru/docs/aws-certified-developer-associate/iam/"},{"content":"Промежуточные метрики еще в процессе расчетов\nЗа 2020 год:\nЗатрачено времени на учебу/практику: ~5500 часов ","description":"Подтвержденные знания по IT за 2020 год","title":"IT курсы 2020","uri":"/ru/posts/diploma/"},{"content":"https://docs.aws.amazon.com/lambda/?id=docs_gateway\nhttps://aws.amazon.com/lambda/\nAWS Lambda – это сервис бессерверных вычислений, который запускает программный код в ответ на определенные события и отвечает за автоматическое выделение необходимых вычислительных ресурсов.\nAWS Lambda автоматически запускает программный код в ответ на различные события, такие как HTTP‑запросы через Amazon API Gateway, изменение объектов в корзинах Amazon Simple Storage Service (Amazon S3), обновление таблиц в Amazon DynamoDB или смена состояний в AWS Step Functions.\nПоддержка языков Java, Go, PowerShell, Node.js, C#, Python и Ruby\nЦены Актуальный прайс\nЦена x86\n0,0000166667 USD за каждую гигабайт-секунду 0,20 USD за 1 млн запросов Цена Arm\n0,0000133334 USD за каждую гигабайт-секунду 0,20 USD за 1 млн запросов Практика В строке поиска Консоли управления AWS введите Lambda и выбираем Lambda в разделе «Services»:\nhttps://us-west-2.console.aws.amazon.com/lambda/home?region=us-west-2#\nНа странице Functions нажимаем Create a function\nAuthor from scratch is selected and enter the following values in the bottom form:\nFunction name: MyCustomFunc Runtime: Node.js 16.X Я выбираю этот раздел, потому что использую аккаунт cloudacademy. Данная роль дает разрешение на создание функций\nPermissions: Change default execution role Execution Role: Select Use an existing role Existing role: Select the role beginning with cloudacademylabs-LambdaExecutionRole → Create function\nПишу функцию, чтобы просмотреть лог, добавлю печать в терминал. А также добавлю обработку получаемого сообщения (В следующем шаге в разделе тестирования)\nфункция принимает в качестве объекта event который содержит массив Records. На 1-й (0) позиции Объект Sns (название сервиса SNS Notifications).\nВ самом объекте будет 2 значения:\ncook_secs - время варки (микроволновки) req_secs - время приготовления console.log('Loading function'); exports.handler = function(event, context) { console.log(JSON.stringify(event, null, 2)); const message = JSON.parse(event.Records[0].Sns.Message); if (message.cook_secs \u003c message.req_secs) { if (message.pre) { context.succeed(\"User ended \" + message.pre + \" preset early\"); } else { context.succeed(\"User ended custom cook time early\"); } } context.succeed(); }; → Deploy\n→ Test\nДанная функциональность позволяет протестировать как функция реагирует на определенные события. Попробуем добавить событие от SNS Notifications.\nВыберем из списка\nПолучаем шаблон, в котором внесем правки, подправим поле Message - то самое, которое мы будем обрабатывать в нашей функции.\nПоле Message- строка, поэтому наш объект надо будет обернуть в кавычки\nЧтобы обработчик понимал, что мы ставим кавычки внутри кавычек, необходимо поставить специальный символ \\ перед кавычкой.\nВ итоге обновляем одну строку и сохраняем → Create\nТеперь нажимаем на кнопку Test\nТак как cook_secs в нашем евенте был меньше, чем req_secs, то функция распечатала первое условие, а ниже в разделе Function Logs видим сообщение, которые мы распечатываем при инициализации функции Loading function\n","description":"Пошаговое руководство по AWS Lambda","title":"Lambda","uri":"/ru/docs/aws-certified-developer-associate/lambda/"},{"content":"MacBook Pro Specification 13-inch Apple M1 Pro M1 2020 16 GB RAM 512 GB SSD QWERTY = English/Hebrew macOS Monterey (Update always) Homebrew Install Homebrew as package manager for macOS:\n## paste in terminal and follow the instructions /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Update everything in Homebrew to recent version:\nbrew update Add additional source for casks:\nbrew tap homebrew/cask-versions Install GUI applications (read more about these in GUI Applications):\nbrew install --cask \\ all-in-one-messenger \\ deepl \\ canva \\ dbeaver-community \\ deepl \\ discord \\ disk-inventory-x \\ docker \\ figma \\ firefox \\ google-chrome \\ google-drive \\ grammarly \\ iterm2 \\ kap \\ macx-youtube-downloader \\ mongodb-compass \\ notion \\ obs \\ postman \\ rectangle \\ reverso \\ spark-ar-studio spotify \\ sublime-text \\ syncthing \\ tor-browser \\ transmission \\ utm \\ viber \\ visual-studio-code \\ vlc \\ yandex-disk \\ zettlr \\ zoom Install terminal applications (read more about these in Terminal Applications):\nbrew install \\ git \\ ffmpeg \\ nvm \\ jupyterlab Additional GUI Applications Kotatogram Kotatogram - Experimental fork of Telegram Desktop. Folders with features\nGUI Applications Google Chrome Google Chrome (web development, web browsing)\nPreferences set default browser always show bookmarks import bookmarks from previous machine Chrome Developer Tools Network -\u003e only “Fetch/XHR” Search Shortcuts. Add Shortucts for different search engines. chrome://settings/searchEngines Yandex, search only in Russia. Shortcut: vv url: https://yandex.ru/{yandex:searchPath}?text=%s\u0026{yandex:referralID}\u0026lr=101443\u0026rstr=-225 Youtube Shortcut: yy url: https://www.youtube.com/results?search_query=%s\u0026page={startPage?}\u0026utm_source=opensearch Chrome Extensions Google Translate DeepL Translate - AI translator React Developer Tools Pocket Session Buddy (Manage Browser Tabs and Bokmarks) LanguageTool (multilingual grammar, style, and spell checker) RSS Feed Reader (Easy to subscribe/unsubscribe to blogs/no need email + iOS/Android) Inoreader (Easy to subscribe/unsubscribe to blogs/no need email + iOS/Android) 30 Seconds of Knowledge (random code snippet on a new tab) JSON Formatter picture-in-picture (yutube/video above other screens) Visual CSS Editor (Customize any website visually) Opus●Guide (Step-by-step for instructions) Disk Inventory X Disk Inventory X (disk usage utility for macOS)\nDocker Docker (Docker, see setup)\nused for running databases (e.g. PostgreSQL, MongoDB) in container without cluttering the Mac Preferences enable “Use Docker Compose” Firefox Firefox (web development)\nitsycal Itsycal is a tiny menu bar calendar.\nVisual Studio Code (VSCode) Visual Studio Code (web development IDE)\nSettings\nSublime Text Sublime Text (editor)\nKap Screen recorder / gif maker\nMaccy Maccy (clipboard manager)\nenable “Launch at Login” OBS OBS (for video recording and live streaming)\nfor Native Mac Screen recorder Base (Canvas) 2880x1800 (Ratio: 16:10) Output 1728x1080 Spotify Spotify\nSyncthing syncthing - Sync folders/files between devices. I use to backup all photos/video from mobile to PC\nTransmission Transmission (A torrent client that I use. Very minimal in its UI but very powerful and has all the features that I need)\nUTM UTM (Virtual machines UI using QEMU)\ndownload ubuntu for arm, doc On error with shared folder: Could not connect: Connection refused open in browser: http://127.0.0.1:9843/ For Debian install spice-webdavd for shared folder. https://packages.debian.org/search?keywords=spice-webdavd, https://github.com/utmapp/UTM/issues/1204 sudo apt install spice-vdagent spice-webdavd -y VLC VLC (video player)\nuse as default for video files Terminal Applications nvm nvm (node version manager)\njupyterlab jupyterlab (Jupyter - python development, fast code snippets)\njupyter notebook - to start jupyter notebook ffmpeg ffmpeg (Converting video and audio)\ncompress video: ffmpeg -i input.mp4 -c:v libx264 -crf 23 -preset slow -c:a aac -b:a 192k output.mp4 # or ffmpeg -i input.mp4 output.avi convert video to .gif: - ffmpeg \\ -i input.mp4 \\ -ss 00:00:00.000 \\ -pix_fmt rgb24 \\ -r 10 \\ -s 960x540 \\ -t 00:00:10.000 \\ output.gif NVM for Node/npm The node version manager (NVM) is used to install and manage multiple Node versions. After you have installed it via Homebrew in a previous step, type the following commands to complete the installation:\necho \"source $(brew --prefix nvm)/nvm.sh\" \u003e\u003e ~/.zshrc source ~/.zshrc ## or alias ## zshsource Now install the latest LTS version on the command line:\nnvm install \u003clatest LTS version from https://nodejs.org/en/\u003e Afterward, check whether the installation was successful and whether the node package manager (npm) got installed along the way:\nnode -v \u0026\u0026 npm -v Update npm to its latest version:\nnpm install -g npm@latest And set defaults for npm:\nnpm set init.author.name \"your name\" npm set init.author.email \"you@example.com\" npm set init.author.url \"example.com\" If you are a library author, log in to npm too:\nnpm adduser That’s it. If you want to list all your Node.js installation, type the following:\nnvm list If you want to install a newer Node.js version, then type:\nnvm install \u003cversion\u003e --reinstall-packages-from=$(nvm current) nvm use \u003cversion\u003e nvm alias default \u003cversion\u003e Optionally install yarn if you use it as alternative to npm:\nnpm install -g yarn yarn -v If you want to list all globally installed packages, run this command:\nnpm list -g --depth=0 That’s it. You have a running version of Node.js and its package manager.\nOH MY ZSH MacOS already comes with zsh as default shell. Install Oh My Zsh for an improved (plugins, themes, …) experience. Oh My Zsh is an open source, community-driven framework for managing your zsh configuration. It comes with a bunch of features out of the box and improves your terminal experience.\nInstall:\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" Update everything (e.g. plugins) in Oh My Zsh to recent version:\nomz update Install fonts for themes:\nbrew tap homebrew/cask-fonts brew install --cask font-hack-nerd-font iTerm2 Install theme Theme description brew install romkatv/powerlevel10k/powerlevel10k echo \"source $(brew --prefix)/opt/powerlevel10k/powerlevel10k.zsh-theme\" \u003e\u003e~/.zshrc Enable suggestions git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions echo \"plugins=(zsh-autosuggestions)\" \u003e\u003e~/.zshrc Open new tab(CMD+T)/restart iTerm to proceed with theme setup\nTerminal Script and Aliases Update .zprofile. Еhe changes will take effect after restarting the terminal\nvi ~/.zprofile Automatic software updates Add script to zprofile that updates everything:\nUpdate, upgrade all and cleanup softwareupdate - system software update tool We can execute this command on strartup, but i prefer handle it. When I kick of upd command in terminal, it will update everythin I need:\nalias upd='brew update; brew upgrade; brew cu -a --cleanup -y -v; brew cleanup; softwareupdate -i -a; i' Add aliases to latest versions pip \u0026 python\nalias pip=pip3 alias python=python3 Final view of .zprofile\n... alias pip=pip3 alias python=python3 alias upd='omz update; brew update; brew upgrade; brew cu -a --cleanup -y -v; brew cleanup; softwareupdate -i -a; i' Links https://www.robinwieruch.de/mac-setup-web-development/ https://sourabhbajaj.com/mac-setup/iTerm/ack.html https://www.engineeringwithutsav.com/blog/spice-up-your-macos-terminal ","description":"How I set up my M1 MacBook Pro software development...","title":"Mac Setup 2022","uri":"/ru/posts/mac-setup-development/"},{"content":" Docs EN | RU Posts EN | RU ","description":"","title":"Posts Archive","uri":"/ru/posts/archive/"},{"content":"PyScript PyScript - средство запуска Python в браузере, встроенное в HTML, был анонсирован на мероприятии PyCon в Солт-Лейк-Сити, США. Кнопка Instl здесь для шутки, так как установка не требуется\nPyScript зависит от существующего проекта Pyodide, который является скомпилированным в WebAssembly интерпретатором CPython 3.8, позволяющим запускать Python в браузере, а также скомпилированных научных пакетов Python.\nСвязывание с файлами библиотеки CSS и JavaScript PyScript позволяет разработчикам встраивать код Python с помощью тега \u003cpy-script\u003e, а также компонент \u003cpy-repl\u003e (Read, Evaluate, Print, Loop), который позволяет Python печатать и выполняться динамически.\nPyScript является открытым исходным кодом с использованием лицензии Apache 2.0.\nСогласно сайту проекта, цели включают в себя включение Python в браузере без настройки на стороне сервера, запуск популярных пакетов Python, двунаправленную связь между JavaScript и Python и визуальную разработку с использованием «легкодоступных контролируемых компонентов пользовательского интерфейса, таких как кнопки, контейнеры, текстовые поля и многое другое».\nУпрощение использования в браузере порадует не только ученых, разрабатывающих аналитические приложения, но и программистов любого профиля, ищущих альтернативу JavaScript — хотя разработчики проекта предупреждают, что это «чрезвычайно экспериментальный проект» и что он только проверен в веб-браузере Google Chrome.\nPlease be advised that PyScript is very alpha and under heavy development. There are many known issues, from usability to loading times, and you should expect things to change often. We encourage people to play and explore with PyScript, but at this time we do not recommend using it for production.\nТуториал PyScript Попробуем скачать, настроить и запустить приложение PyScript в браузере.\nРабочая среда Разработчики PyScript пишут, что для работы не требуется никакой среды разработки, кроме веб-браузера. Попробуем запустить в Chrome.\nУстановка Можно скачать весь пакет с сайта, но будем использовать скрипт, с сервера pyscript.net\nHello World Создаем файл hello.html\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print('Hello, World!') \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег \u003cpy-script\u003e расположен внутри HTML body. Внутри этого тега будем пиcать Python код.\nОткроем файл в браузере Работает!\nТег py-script Тег \u003cpy-script\u003e позволяет писать многострочный код\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print(\"Let's compute π:\") def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) s = f\"π is approximately {pi:.3f}\" print(s) \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Важно соблюдать отступы в самом блоке Python. Но Начальную строку кода можно начинать и с начала строки\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cpy-script\u003e print(\"Let's compute π:\") def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) s = f\"π is approximately {pi:.3f}\" print(s) \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Запись внутри HTML элементов В приведенном выше примере у нас был один тег \u003cpy-script\u003e, выводящий одну или несколько строк на страницу по порядку. Внутри \u003cpy-script\u003e есть доступ к модулю pyscript, который предоставляет метод .write() для отправки строк в помеченные элементы на странице.\nНапример, мы добавим некоторые элементы стиля и предоставим заполнители для тега \u003cpy-script\u003e для записи.\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003clink href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\" crossorigin=\"anonymous\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cb\u003e\u003cp\u003eToday is \u003cu\u003e\u003clabel id='today'\u003e\u003c/label\u003e\u003c/u\u003e\u003c/p\u003e\u003c/b\u003e \u003cbr\u003e \u003cdiv id=\"my-custom-pi\" class=\"alert alert-primary\"\u003e\u003c/div\u003e \u003cpy-script\u003e import datetime as dt pyscript.write('today', dt.date.today().strftime('%A %B %d, %Y')) def compute_pi(n): pi = 2 for i in range(1,n): pi *= 4 * i ** 2 / (4 * i ** 2 - 1) return pi pi = compute_pi(100000) pyscript.write('my-custom-pi', f'π is approximately {pi:.3f}') \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег py-env В дополнение к стандартной библиотеке Python и модулю pyscript, многие сторонние пакеты работают с PyScript. Чтобы их использовать, нужно объявить зависимости с помощью тега \u003cpy-env\u003e в заголовке HTML. Вы также можете ссылаться на файлы .whl прямо на диске\n\u003cpy-env\u003e - './static/wheels/travertino-0.1.3-py3-none-any.whl' - './static/wheels/my-other-package-0.0.1-py3-none-any.whl' \u003c/py-env\u003e \u003cpy-script\u003e #my python code ... \u003c/py-script\u003e Пример с NumPy\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003cpy-env\u003e - numpy - matplotlib \u003c/py-env\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eLet's plot random numbers\u003c/h1\u003e \u003cdiv id=\"plot\"\u003e\u003c/div\u003e \u003cpy-script output=\"plot\"\u003e import matplotlib.pyplot as plt import numpy as np x = np.random.randn(1000) y = np.random.randn(1000) fig, ax = plt.subplots() ax.scatter(x, y) fig \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Импорт локальный модулей Мы также можем использовать собсвтенные модули, которые импортируем внутри тега \u003cpy-script\u003e\nНапример, создадим файл `data.py’ и запишем в него собственную функцию\n# data.py import numpy as np def make_x_and_y(n): x = np.random.randn(n) y = np.random.randn(n) return x, y Внутри тега \u003cpy-env\u003e добавим стандартные модули и путь до нашего локального модуля\n\u003chtml\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /\u003e \u003cscript defer src=\"https://pyscript.net/latest/pyscript.js\"\u003e\u003c/script\u003e \u003cpy-env\u003e - numpy - matplotlib - paths: - /data.py \u003c/py-env\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eLet's plot random numbers\u003c/h1\u003e \u003cdiv id=\"plot\"\u003e\u003c/div\u003e \u003cpy-script output=\"plot\"\u003e import matplotlib.pyplot as plt from data import make_x_and_y x, y = make_x_and_y(n=1000) fig, ax = plt.subplots() ax.scatter(x, y) fig \u003c/py-script\u003e \u003c/body\u003e \u003c/html\u003e Тег py-repl Тег \u003cpy-repl\u003e создает компонент REPL(Read–eval–print loop), который отображается на странице как редактор кода, что позволяет писать исполняемый код в строке.\nТег py-config Тег \u003cpy-config\u003e используется для установки и настройки общих метаданных о вашем приложении PyScript в формате YAML.\n\u003cpy-config\u003e - autoclose_loader: false - runtimes: - src: \"https://cdn.jsdelivr.net/pyodide/v0.20.0/full/pyodide.js\" name: pyodide-0.20 lang: python \u003c/py-config\u003e Тег py-title Тег визуального отображения. Добавляет компонент заголовка статического текста, который стилизует текст внутри тега как заголовок страницы.\nТег py-box Создает объект-контейнер, который можно использовать для размещения одного или нескольких визуальных компонентов, определяющих, как элементы \u003cpy-box\u003e должны выравниваться и отображаться на странице.\nТег py-inputbox Позволяет вставить окно с текстовым полем\nТег py-button Добавляет кнопку, к которой авторы могут добавлять метки и обработчики событий для действий на кнопке, таких как on_focus или on_click.\nРесурсы Примеры использования PyScript Вопросы по PyScript ","description":"PyScript - Python, встроенный в HTML","title":"PyScript - Python, встроенный в HTML","uri":"/ru/posts/pyscript-python-embedded-in-html/"},{"content":" https://russiannlp.github.io/rugpt-demo/ Краткий экскурс в ruGPT-3. Инструкция и демонстрация ","description":"ruGPT-3","title":"ruGPT-3","uri":"/ru/posts/rugpt-3-notes/"},{"content":"Для работы большинства приложений WebRTC необходим сервер для ретрансляции трафика между узлами, поскольку прямой сокет часто невозможен между клиентами (если только они не находятся в одной локальной сети). Обычный способ решить эту проблему — использовать TURN-сервер (Traversal Using Relay NAT), который представляет собой протокол ретрансляции сетевого трафика.\nВ настоящее время существует несколько вариантов TURN-серверов, доступных в Интернете, как в виде самостоятельных приложений (например, проект COTURN с открытым исходным кодом), так и в виде облачных сервисов.\nЕсли у вас есть доступный онлайн TURN-сервер, то все, что вам нужно - это правильная RTCConfiguration для вашего клиентского приложения. Следующий фрагмент кода иллюстрирует пример конфигурации для RTCPeerConnection, где TURN-сервер hostname my-turn-server.mycompany.com работает на порту 19403.\nОбъект конфигурации также поддерживает свойства username и credentials для защиты доступа к серверу. Они необходимы при подключении к TURN-серверу.\nconst iceConfiguration = { iceServers: [ { urls: 'turn:my-turn-server.mycompany.com:19403', username: 'optional-username', credentials: 'auth-token' } ] } const peerConnection = new RTCPeerConnection(iceConfiguration); ","description":"Карманная книга по WebRTC","title":"TURN сервер","uri":"/ru/docs/webrtc/turn-server/"},{"content":"Добро пожаловать в Python 101! Я написал эту книгу, чтобы помочь вам изучить Python 3. Она не претендует на роль исчерпывающего справочника. Напротив, ее цель - познакомить вас со строительными блоками Python, чтобы вы могли сами написать что-нибудь полезное. Многие учебники по программированию учат только языку, но не идут дальше этого. Я постараюсь не только ознакомить вас с основами, но и показать, как создавать полезные программы. Теперь вы можете задаться вопросом, почему простого изучения основ недостаточно. По моему опыту, когда я заканчиваю читать вводный текст, мне хочется что-то создать, но я не знаю как! У меня есть знания, но нет клея, чтобы добраться из точки А в точку Б. Я считаю, что важно не только научить вас основам, но и охватить материал среднего уровня.\nТаким образом, эта книга будет состоять из пяти частей:\nВ первой части будут рассмотрены основы Python. Вторая часть будет посвящена небольшому подмножеству стандартной библиотеки Python Третья часть - материал среднего уровня Четвертая часть будет представлять собой серию небольших уроков Пятая часть будет посвящена упаковке и распространению Python. Позвольте мне потратить несколько минут на объяснение того, что предлагает каждая часть. В первой части мы рассмотрим следующее:\nТипы Python (строки, списки, массивы и т.д.) Условные операторы Циклы Понимание списков и словарей Обработка исключений Файловый ввод-вывод Функции и классы Во второй части мы поговорим о некоторых элементах стандартной библиотеки Python. Стандартная библиотека - это то, что поставляется в комплекте с Python. Она состоит из модулей, которые вы можете импортировать для получения дополнительной функциональности. Например, вы можете импортировать модуль math, чтобы получить некоторые математические функции высокого уровня. Я буду выбирать модули, которые чаще всего использую в повседневной работе, и объяснять, как они работают. Причина, по которой я считаю это хорошей идеей, заключается в том, что это обычные, повседневные модули, о которых, я думаю, вам будет полезно знать в начале вашего обучения Python. В этом разделе также будут рассмотрены различные способы установки модулей сторонних производителей. Наконец, я расскажу о том, как создавать собственные модули и пакеты и почему вы захотите сделать это в первую очередь. Вот некоторые модули, которые мы рассмотрим:\ncsv ConfigParser логирование os smtplib / email подпроцесс sys поток / очереди time / datetime В третьей части мы рассмотрим промежуточные вопросы. Это темы, которые полезно знать, но не обязательно уметь программировать на Python. Будут рассмотрены следующие темы:\nотладчик Python (pdb) декораторы лямбда-функция профилирование кода введение в тестирование Четвертая часть будет состоять из небольших уроков, которые помогут вам научиться использовать Python на практике. Таким образом, вы научитесь создавать программы на Python, которые действительно могут сделать что-то полезное! Знания, полученные из этих уроков, вы сможете использовать для создания собственных скриптов. В конце каждого урока будут приведены идеи по усовершенствованию этих мини-приложений, так что у вас будет то, что вы сможете опробовать самостоятельно. Вот несколько пакетов сторонних разработчиков, которые мы будем рассматривать:\npip и easy_install configobj lxml requests virtualenv pylint / pychecker SQLAlchemy В пятой части мы расскажем о том, как взять свой код и передать его своим друзьям, семье и всему миру! Вы узнаете следующее:\nКак превратить ваши многократно используемые скрипты в Python “eggs”, “wheels” и многое другое. Как загрузить свое творение в Python Package Index (PyPI) Как создавать двоичные исполняемые файлы, чтобы вы могли запускать свое приложение без Python Как создать программу установки для вашего приложения Главы и разделы могут быть не одинаковой длины. Хотя каждая тема будет хорошо освещена, не каждая тема требует одинакового количества страниц.\nКраткая история языка Python Я думаю, это поможет узнать предысторию языка программирования Python. Python был создан в конце 1980-х годов. Все согласны с тем, что его создателем является Гвидо ван Россум, он написал его как преемника языка программирования ABC, которым он пользовался. Гвидо назвал язык в честь одного из своих любимых комедийных артистов: Монти Пайтон. Язык был выпущен только в 1991 году, и за это время он сильно вырос в плане количества включенных модулей и пакетов. На момент написания этой статьи существует две основные версии Python: серия 2.x и 3.x (иногда известная как Python 3000) . Серия 3.x не имеет обратной совместимости с 2.x, поскольку при создании 3.x была идея избавиться от некоторых идиосинкразий оригинала. Текущими версиями являются 2.7.12 и 3.5.2. Большинство функций из 3.x были перенесены в 2.x; однако 3.x получает большую часть текущих разработок Python, так что это версия будущего.\nНекоторые люди думают, что Python предназначен только для написания небольших скриптов для склеивания “настоящего” кода, как C++ или Haskell. Однако вы найдете Python полезным практически в любой ситуации. Python используют многие известные компании, такие как Google, NASA, LinkedIn, Industrial Light \u0026 Magic и многие другие. Python используется не только в бэкенде, но и в фронтенде. Если вы новичок в области компьютерных наук, то бэкенд-программирование - это то, что находится за кулисами; такие вещи, как обработка баз данных, создание документов и т.д. Фронтенд-программирование - это красивые вещи, с которыми знакомо большинство пользователей, например, веб-страницы или пользовательские интерфейсы для настольных компьютеров. Например, есть несколько действительно хороших наборов инструментов графического интерфейса Python, таких как wxPython, PySide и Kivy. Есть также несколько веб-фреймворков, таких как Django, Pyramid и Flask. Вы возможно удивитесь, узнав, что Django используется для Instagram и Pinterest. Если вы пользовались этими или другими сайтами, то вы использовали что-то, работающее на Python, даже не подозревая об этом!\nОб авторе Возможно, вам интересно, кто я такой и почему я могу быть достаточно осведомлен о Python, чтобы писать о нем, поэтому я решил дать вам немного информации о себе. Я начал программировать на Python весной 2006 года по работе. Моим первым заданием было перенести сценарии входа в Windows с Kixtart на Python. Вторым моим проектом был перенос кода VBA (по сути, графического интерфейса поверх продуктов Microsoft Office) на Python, так я впервые познакомился с wxPython. С тех пор я использую Python, занимаясь различными видами бэкэнд-программирования и фронтэнд-интерфейсами для настольных компьютеров.\nЯ понял, что один из способов запомнить, как делать определенные вещи на Python, - это писать о них, и так появился мой блог о Python: http://www.blog.pythonlibrary.org/. По мере того как я писал, я получал отзывы от читателей, и в итоге я расширил блог, включив в него советы, учебники, новости Python и обзоры книг по Python. Я регулярно сотрудничаю с издательством Packt Publishing в качестве технического рецензента, что означает, что я стараюсь проверять книги на наличие ошибок до их публикации. Я также писал для сайтов Developer Zone (DZone) и i-programmer, а также для Python Software Foundation. В ноябре 2013 года DZone опубликовал книгу The Essential Core Python Cheat Sheet, которую я написал в соавторстве.\nУсловные обозначения Как и большинство технических книг, эта включает в себя несколько условностей, о которых вам необходимо знать. Новые темы и терминология будут выделены жирным шрифтом. Вы также увидите несколько примеров, которые выглядят следующим образом:\n\u003e\u003e\u003e myString = \"Welcome to Python!\" Символ »\u003e - это символ подсказки Python. Вы увидите его в интерпретаторе Python и в IDLE. Подробнее о каждом из них вы узнаете в первой главе. Другие примеры кода будут показаны аналогичным образом, но без символа »\u003e.\nТребования Вам потребуется рабочая установка Python 3. Большинство машин Linux и Mac поставляются с уже установленным Python. Однако если у вас нет Python, вы можете загрузить его копию с сайта http://python.org/download/. На сайте есть актуальные инструкции по установке, поэтому в этой книге я не буду приводить никаких инструкций по установке. Любые дополнительные требования будут объяснены позже в книге.\nОбратная связь с читателями Я приветствую отзывы о моих работах. Если вы хотите сообщить мне, что вы думаете о книге, вы можете отправить комментарии по следующему адресу:\ncomments@pythonlibrary.org\nОшибки Я изо всех сил стараюсь не публиковать свои работы с ошибками, но время от времени это случается. Если вы заметили ошибку в этой книге, не стесняйтесь сообщить мне об этом, написав по следующему адресу:\nerrata@pythonlibrary.org\n","description":"Python 101","title":"Введение","uri":"/ru/docs/python101/01-intro/"},{"content":"Вы создали приложение для потоковой передачи видео в реальном времени и обмена данными!\nЧто вы узнали\nВ этой codelab вы узнали, как:\nПолучать видео с вашей веб-камеры. стримить видео с помощью RTCPeerConnection. Стримить данные с помощью RTCDataChannel. Настраивать сигналинг-службу для обмена сообщениями. Комбинировать одноранговое соединение и сигналинг. Сделать снимок и поделиться им через канал передачи данных. Следующие шаги\nПосмотрите на код и архитектуру канонического приложения AppRTC для чата WebRTC – приложение (https://appr.tc/), код (https://github.com/webrtc/apprtc) Попробуйте реальные примеры (http://webrtc.github.io/samples) из github.com/webrtc/samples. Узнать больше\nРяд ресурсов для начала работы с WebRTC доступен на https://webrtc.org/ ","description":"Карманная книга по WebRTC","title":"Выводы","uri":"/ru/docs/webrtc/practice/practice-results/"},{"content":" Сгенерировать ","description":"Генерация краткого содержания текста","title":"Генерация аннотации","uri":"/ru/docs/disser/utils/text_2_short/"},{"content":"Загрузка кода Если вы знакомы с сайтом git, вы можете скачать код для данной codelab с GitHub, клонировав его: git clone https://github.com/googlecodelabs/webrtc-web\nМожно также нажать на ссылку ниже для загрузки zip-файла кода: https://github.com/googlecodelabs/webrtc-web/archive/master.zip\nОткройте загруженный zip-файл. Разархивируйте папку проекта (adaptive-web-media), в которой по одной папке на каждый шаг этой codelab, и есть все необходимые вам ресурсы. Вы будете выполнять все действия в папке work.\nПапки step-nn содержат финальную версию для каждого шага этой codelab. Они там для справки.\nУстановите и проверьте веб-сервер Несмотря на то, что вы можете использовать и свой собственный веб-сервер, эта codelab подразумевает работу с веб-сервером Chrome. Если у вас он еще не установлен, вы можете инсталлировать его из Chrome Web Store https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en\nПосле установки приложения Web Server для Chrome, нажмите на ярлык Chrome Apps на панели закладок, на странице новой вкладки или в панели запуска приложений:\nНажмите на значок Web Server\nДалее вы увидите это диалоговое окно, которое позволит настроить локальный веб-сервер:\nНажмите на кнопку «Choose Folder», и выберите папку work, которую вы только что создали. Это позволит вам просматривать текущую работу в Chrome по ссылке URL, подчеркнутой в диалоговом окне в разделе Web Server URL(s). Ниже, в Options, поставьте флажок в Automatically show index.html, как показано ниже:\nЗатем остановите и перезапустите сервер, сдвинув флажок с надписью «Web Server: STARTED» влево, а затем снова вправо.\nТеперь посетите свой рабочий сайт в браузере, кликнув на выделенный Web Server URL. Вы должны увидеть подобную страницу, которая соответствует пути work/index.html:\nОчевидно, что данное приложение пока еще не делает ничего интересного – пока это просто минимальный скелет, который нужен для того, чтоб убедиться, что веб-сервер работает, как надо. На следующих этапах мы добавим функциональности в этом приложение.\nС этого момента все тестирование и проверка должны выполняться с использованием этой настройки веб-сервера. Обычно достаточно просто обновить вкладку тестового браузера.\n","description":"Карманная книга по WebRTC","title":"Загрузка кода","uri":"/ru/docs/webrtc/practice/practice-get-code/"},{"content":"Захват мультимедиа и ограничения Мультимедиа-часть WebRTC показывает, как получить доступ к оборудованию, способному записывать видео и аудио (например, камеры и микрофоны), а также как работают медиа-потоки. И помимо этого – средства отображения, которые позволяют делать захват экрана.\nМультимедиа-устройства Все камеры и микрофоны, поддерживаемые браузером, доступны и управляются через объект navigator.mediaDevices. Приложения могут получать текущий список подсоединенных устройств и отслеживать изменения, т.к. многие камеры и микрофоны подсоединены через USB, и могут подключаться/отключаться в течение работы приложения. Поскольку статус мультимедиа-устройства может меняться в любой момент времени, рекомендуем, чтоб приложения регистрировали все изменения в статусе устройства для правильной обработки статусов изменений.\nОграничения При получении доступа к мультимедиа-устройствам, хорошо бы обеспечить настолько подробные ограничения, насколько это возможно. И хотя можно открыть камеру и микрофон по умолчанию с простым ограничением, это может привести к тому, что медиапоток будет далеко не самым оптимальным для приложения.\nКонкретные ограничения определяются в объекте MediaTrackConstraint (одно для аудио, одно для видео). Атрибуты в этом объекте типа ConstraintLong, ConstraintBoolean, ConstraintDouble или ConstraintDOMString. Данные могут быть как конкретным значением (например, число, Boolean или String), диапазоном (LongRange или DoubleRange с минимальным и максимальным значением) или объектом c ideal или exact определением. Для конкретных значений браузер будет пытаться выбрать что-то наиболее близкое. Для диапазонных будет использоваться лучшее значение из диапазона. Для exact – будет передаваться только тот медиа-поток, который точно соответствует заданным ограничениям.\nNEAR // Camera with a resolution as close to 640x480 as possible { \"video\": { \"width\": 640, \"height\": 480 } } RANGE // Camera with a resolution in the range 640x480 to 1024x768 { \"video\": { \"width\": { \"min\": 640, \"max\": 1024 }, \"height\": { \"min\": 480, \"max\": 768 } } } EXACT // Camera with the exact resolution of 1024x768 { \"video\": { \"width\": { \"exact\": 1024 }, \"height\": { \"exact\": 768 } } } Чтобы определить актуальную конфигурацию конкретной дорожки медиа-потока, мы можем воспользоваться запросом MediaStreamTrack.getSettings(), который возвращает набор настроек MediaTrackSettings, используемых в данные момент.\nТакже можно обновить ограничения дорожки с мультимедиа-устройства, которое открываем через applyConstraints(). Это позволяет приложению перенастроить устройство без прерывания текущего потока.\nЗахват экрана Приложение, которое потенциально может выполнять захват и запись экрана, должно использовать Display Media API. Функция getDisplayMedia() (которая является частью navigator.mediaDevices), аналогична getUserMedia() и используется, чтобы открыть содержимое дисплея (или его части, например, окна). Возвращенный MediaStream работает также, как при использовании getUserMedia().\nОграничения для getDisplayMedia() отличаются от ограничений, используемых для обычных входящих видео- и аудио-потоков.\n{ video: { cursor: ‘always’ | ‘motion’ | ‘never’, displaySurface: ‘application’ | ‘browser’ | ‘monitor’ | ‘window’ } } Фрагмент кода выше показывает, как работают специальные ограничения для записи экрана. Обратите внимание, что они могут не поддерживаться некоторыми браузерами, поддерживающими отображение мультимедиа.\nПотоки и дорожки MediaStream представляет собой поток медиаконтента, который состоит из аудио- и видео- дорожек (MediaStreamTrack). Можно достать все дорожки из MediaStream, вызвав команду MediaStream.getTracks(), которая возвращает массив объектов из MediaStreamTrack.\nMediaStreamTrack MediaStreamTrack обладает свойством kind (audio или video, указывающий тип мультимедиа, который он воспроизводит). Каждую дорожку можно выключить, переключив ее свойство enabled. У дорожки есть логическое свойство remote, которое показывает, является ли она источником RTCPeerConnection и идет ли она от удаленного узла.\n","description":"Карманная книга по WebRTC","title":"Захват мультимедиа и ограничения","uri":"/ru/docs/webrtc/media-capture-and-constraints/"},{"content":"Маршрут\n","description":"Израиль - Хайфа - Бахайские сады","title":"Израиль - Хайфа - Бахайские сады","uri":"/ru/posts/photos/22-07-02-israel-haifa-bahai-gardens/"},{"content":"Чему вы научитесь\nкак обмениваться данными между узлами WebRTC Полная версия этого шага находится в папке step-03.\nОбновите свой HTML\nНа этом шаге вы будете использовать WebRTC каналы данных для отправки текста между двумя textarea элементами на одной странице. Это опять не сильно применимо на практике, но зато демонстрирует, как WebRTC можно использовать для обмена данными, а также для потоковых видео.\nУдалите элементы video и button из index.html и замените их следующим HTML-кодом:\n\u003ctextarea id=\"dataChannelSend\" disabled placeholder=\"Press Start, enter some text, then press Send.\"\u003e\u003c/textarea\u003e \u003ctextarea id=\"dataChannelReceive\" disabled\u003e\u003c/textarea\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"sendButton\"\u003eSend\u003c/button\u003e \u003cbutton id=\"closeButton\"\u003eStop\u003c/button\u003e \u003c/div\u003e Одна текстовая область будет предназначена для ввода текста, другая будет отображать текст в потоковом режиме между узлами. Теперь index.html должен выглядеть так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003ctextarea id=\"dataChannelSend\" disabled placeholder=\"Press Start, enter some text, then press Send.\"\u003e\u003c/textarea\u003e \u003ctextarea id=\"dataChannelReceive\" disabled\u003e\u003c/textarea\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"sendButton\"\u003eSend\u003c/button\u003e \u003cbutton id=\"closeButton\"\u003eStop\u003c/button\u003e \u003c/div\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Обновите свой JavaScript\nЗамените main.js содержимым из step-03/js/main.js.\nКак и на предыдущем шаге, делать копи-паст на больших кусках кода – не идеальный вариант развития событий в codelab (как и с RTCPeerConnection). Но альтернатив у нас нет.\nПротестируйте потоковые данные между узлами: откройте index.html, нажмите Start для установки соединения между узлами, введите какой-то текст в textarea слева, затем нажмите на Send, чтобы передать текст через каналы данных WebRTC.\nКак это работает Этот код использует RTCPeerConnection и RTCDataChannel для обмена текстовыми сообщениями Большая часть кода на этом шаге такая же, как и в примере RTCPeerConnection. Функции sendData() и createConnection() содержат большую часть нового кода:\nfunction createConnection() { dataChannelSend.placeholder = ''; var servers = null; pcConstraint = null; dataConstraint = null; trace('Using SCTP based data channels'); // For SCTP, reliable and ordered delivery is true by default. // Add localConnection to global scope to make it visible // from the browser console. window.localConnection = localConnection = new RTCPeerConnection(servers, pcConstraint); trace('Created local peer connection object localConnection'); sendChannel = localConnection.createDataChannel('sendDataChannel', dataConstraint); trace('Created send data channel'); localConnection.onicecandidate = iceCallback1; sendChannel.onopen = onSendChannelStateChange; sendChannel.onclose = onSendChannelStateChange; // Add remoteConnection to global scope to make it visible // from the browser console. window.remoteConnection = remoteConnection = new RTCPeerConnection(servers, pcConstraint); trace('Created remote peer connection object remoteConnection'); remoteConnection.onicecandidate = iceCallback2; remoteConnection.ondatachannel = receiveChannelCallback; localConnection.createOffer().then( gotDescription1, onCreateSessionDescriptionError ); startButton.disabled = true; closeButton.disabled = false; } function sendData() { var data = dataChannelSend.value; sendChannel.send(data); trace('Sent Data: ' + data); } Синтаксис в RTCDataChannel намеренно похож на WebSocket, с методом send() событием message.\nОбратите внимание на использование dataConstraint. Каналы передачи данных могут быть настроены для обеспечения различных типов обмена данными — например, отправляемые данные могут быть в приоритете над над производительностью. Более подробную информацию о возможностях можно найти на https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/createDataChannel .\nТри типа ограничений Это сбивает с толку!\nРазличные типы параметров настройки вызовов WebRTC часто называются «ограничениями».\nУзнайте больше об ограничениях и возможностях:\nRTCPeerConnection https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/RTCPeerConnection RTCDataChannel https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/createDataChannel getUserMedia() https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia Бонусные задания\nс SCTP-протоколом, используемым каналами передачи данных WebRTC, надежная и упорядоченная доставка данных включена по умолчанию. Когда может понадобиться RTCDataChannel для обеспечения надежной доставки даных, а когда производительность может быть важнее – даже если это означает потерю каких-то данных? Используйте CSS для улучшения макета страницы и добавьте атрибут placeholder в текстовую область dataChannelReceive. Протестируйте страницу на мобильном устройстве. Что вы узнали? На этом шаге вы узнали, как\nустанавливать соединение между двумя узлами WebRTC обмениваться текстовыми данными между узлами Полная версия этого шага находится в папке step-03.\nУзнайте больше\nКаналы передачи данных WebRTC (написано пару лет назад, но все еще стоит прочитать) - http://www.html5rocks.com/en/tutorials/webrtc/datachannels/ Почему SCTP был выбран для канала передачи данных WebRTC? - https://bloggeek.me/sctp-data-channel/ Следующий шаг Вы узнали, как обмениваться данными между узлами на одной и той же странице, но как вы собираетесь это делать между разными устройствами? Сначала вам необходимо настроить сигналинг-канал для обмена сообщениями метаданных. Как – узнайте на следующем шаге!\n","description":"Карманная книга по WebRTC","title":"Использование RTCDataChannel для обмена данными","uri":"/ru/docs/webrtc/practice/practice-rtcdatachannel-exchange-data/"},{"content":"os.rename Если имеется весь путь до пути файла:\nold_source = '/Users/r/Desktop/old_source.txt' new_source = '/Users/r/Desktop/new_source.txt' os.rename(\"old_source\", \"new_source\") Если имеется только имя файла, воспользуемся os.path.splitext(), который возвращает кортеж из имени файла и расширения:\nimport os for file in os.listdir(): name, ext = os.path.splitext(file) # return ('путь до файла без расщирения', '.txt') new_name = f\"{name}_new{ext}\" os.rename(file, new_name) pathlib С помощью встроенного модуля pathlib\nPath.rename(new_name) from pathlib import Path for file in os.listdir(): f = Path(file) new_name = f\"{f.stem}_new{f.suffix}\" f.rename(new_name) shutil.move Модуль Shutil предлагает ряд высокоуровневых операций с файлами и коллекциями файлов. В частности, предусмотрены функции, поддерживающие копирование и удаление файлов.\nimport shutil old_source = '/Users/r/Desktop/old_source.txt' new_source = '/Users/r/Desktop/new_source.txt' newFileName = shutil.move(old_source, new_source) print(\"Новый файл:\", newFileName) # Новый файл: /Users/r/Desktop/new_source.txt ","description":"Различные способы переименовывания файлов в Python","title":"Как переименовать файлы в Python","uri":"/ru/posts/howto-rename-files-in-python/"},{"content":"Hugo предлагает подключение различных JS библиотек в проект. Такие изменения влекут за собой полное обновление проекта. Сегодня мы подключим компонент react без внесения больших изменений.\nReact - это библиотека. Чтобы она заработала на сайте, необходимо ее подклчюить, а далее воспользоваться внутренними функциями.\nПодключить можно двумя способоами. С помощью подгрузки скрипта с CDN или загрузки пакета в package.json, чтопозволит использовать .jsx\npackage.json План:\nИмпорт пакета в package.json Создание .jsx скрипта Загрузка/build пакета в Hugo Импорт В корне проекта запускаем команду\nnpm i react react-dom Создание jsx скрипта В папке с темой assets создадим файл my-react-script.jsx import React from 'react'; import * as ReactDOM from 'react-dom'; import { createRoot } from 'react-dom/client'; const App = () =\u003e { function sayHello () { alert('Hello, World!') } return ( \u003cbutton onClick={sayHello}\u003eClick me!\u003c/button\u003e ) } ReactDOM.render( React.createElement(App, null), document.getElementById('root') ) const container = document.getElementById('my_render_block'); const root = createRoot(container); root.render(\u003cApp /\u003e); Добавим блок div в место в шаблоне для отрисовки react приложения \u003cdiv id=\"my_render_block\"\u003e\u003c/div\u003e Подключение в HUGO В файле head.html или другом файте шаблона Hugo импортируем скрипт\n{{ with resources.Get \"my-react-script.jsx\" }} {{ $options := dict \"defines\" (dict \"process.env.NODE_ENV\" \"\\\"development\\\"\" \"process.env.BaseURL\" (printf `\"%s\"` $.Site.BaseURL)) }} {{ $script := . | js.Build $options }} \u003cscript src=\"{{ $script.RelPermalink }}\" defer\u003e\u003c/script\u003e {{ end }} CDN Второй способ\nПодключение библиотеки React В проекте Hugo в шаблонах обновим файл head.html. В моем проекте это шаблон, который содержит основные теги html и head. Открываем layouts/partials/head.html и добавляем скрипт в раздел \u003chead\u003e:\n\u003c!-- ... \u003chead\u003e ... --\u003e \u003c!-- Примечание: при деплое на продакшен замените «development.js» на «production.min.js» --\u003e \u003cscript src=\"https://unpkg.com/react@17/umd/react.development.js\" crossorigin\u003e\u003c/script\u003e \u003cscript src=\"https://unpkg.com/react-dom@17/umd/react-dom.development.js\" crossorigin\u003e\u003c/script\u003e \u003c!-- ... \u003c/head\u003e ... --\u003e Выбор места для отрисовки компонента Создадим div блок в любом шаблоне Hugo, где будем отрисоывать React компонент. Например файл layouts/partials/footer.html\n\u003cdiv id=\"my_react_app\"\u003e\u003c/div\u003e React будет искать данный блок и отрисует внутри него компонент\nСоздание компонента Вынесем создание компонента в отдельный js файл. В Hugo есть директория static в корне проекта. Если нету, то можно создать. Подробнее о static folder\nСоздадим файл static/js/my_react_component.js и запишем код:\nВажно: сркипт должен подключиться в проекте после блока \u003cdiv id=\"my_react_app\"\u003e\u003c/div\u003e\nconst e = React.createElement; const MyCountButton = () =\u003e { const [count, setCount] = React.useState(100); return e( 'button', { onClick: () =\u003e setCount(count + 1) }, count ); } // Выведем на экран компонент // ищем блок my_react_app и отрисовываем внутри него компонент ReactDOM.render(React.createElement(MyCountButton), document.getElementById(\"my_react_app\")); Подключение скрипта с React компонентами Так как скрипт будет искать div “my_react_app”, данный div блок должен быть загружен до исполнения скрипта. Поэтому в файле layouts/partials/footer.html добавляем скрипт в конец раздела \u003cbody\u003e:\nПример Нажми на счетчик: 100\n","description":"Подключение react компонентов в hugo проект","title":"Как подключить React .jsx в проект на Hugo","uri":"/ru/posts/integrate-hugo-react/"},{"content":"В JavaScript объекты копируются по ссылке. Это означает, что фактически две(или более) ссылок ссылается на один объект Для глубокого клонирования мы можем воспользоваться рекурсией\nВоспользуемся методом Object.assign() и возьмем пустой объект ({}), чтобы создать клон оригинального объекта. Используем Object.keys() и Array.prototype.forEach() для определения ключей-значений, которые нужно полностью клонировать (не ссылаться на них).\nconst deepClone = obj =\u003e { let clone = Object.assign({}, obj); Object.keys(clone).forEach( key =\u003e (clone[key] = typeof obj[key] === 'object' ? deepClone(obj[key]) : obj[key]) ); return Array.isArray(obj) \u0026\u0026 obj.length ? (clone.length = obj.length) \u0026\u0026 Array.from(clone) : Array.isArray(obj) ? Array.from(obj) : clone; }; const a = { foo: 'bar', obj: { a: 1, b: 2 } }; const b = deepClone(a); // a !== b, a.obj !== b.obj ","description":"Как сделать глубокое клонирование объекта в JavaScript","title":"Как сделать глубокое клонирование объекта в JavaScript","uri":"/ru/posts/howto-create-deepclone-js/"},{"content":"Пользователя можно перенаправлять с одной веб-страницы на любую другую несколькими способами.\nс помощью обновления мета-данных HTML. Перенаправления на стороне сервера. Например, используя файл .htaccess, PHP с помощью перенаправления на стороне клиента через JavaScript. Для перенаправления на другой URL с помощью JavaScript используем window.location.href или window.location.replace(). Передать второй аргумент, чтобы произвести клик по ссылке (true - по умолчанию) или перенаправление по HTTP (false).\nJavaScript функции Логика const newUrl = 'https://www.google.com/'; window.location.href = newUrl; // 1 window.location.replace(newUrl); // 2 window.location.assign(newUrl) // 3 Пример функции const redirect = (url, asLink = true) =\u003e asLink ? (window.location.href = url) : window.location.replace(url); JavaScript в html \u003chtml\u003e \u003chead\u003e \u003cscript\u003e const newUrl = 'https://www.google.com/'; window.location.href = newUrl; \u003c/script\u003e \u003c!--...--\u003e redirect('https://google.com'); метатег HTML \u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"refresh\" content=\"0; url=https://example.com/newlocation\" /\u003e \u003c/head\u003e \u003c/html\u003e После того как загрузится ткущая страница, браузер перенаправит на новую страницу, ожидая при этом 0 content=\"0 секунд.\nЧтобы выполнялась отложенная переадресация, укажите нужное количество секунд в атрибуте content:\n\u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"refresh\" content=\"10; url=https://example.com/newlocation\" /\u003e \u003c/head\u003e \u003c/html\u003e ","description":"Как сделать редирект на другой URL в JavaScript","title":"Как сделать редирект на другой URL в JavaScript","uri":"/ru/posts/howto-redirect-to-url/"},{"content":"Стандарт WebRTC также охватывает API для отправки произвольных данных через RTCPeerConnection. Это происходит через запрос createDataChannel() для объекта RTCPeerConnection, который возвращает объект RTCDataChannel.\nconst peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel();\nУдаленный узел может получать каналы данных через отслеживание события datachannel в объекте RTCPeerConnection. Полученное событие имеет тип RTCDataChannelEvent и содержит свойство channel, которое представляет RTCDataChannel между двумя узлами.\nconst peerConnection = new RTCPeerConnection(configuration); peerConnection.addEventListener('datachannel', event =\u003e { const dataChannel = event.channel; }); События Open и Close Прежде чем канал данных можно будет использовать для отправки данных, клиент должен дождаться его открытия. Это происходит через прослушивание события open. Точно так же существует событие close, когда одна из сторон закрывает канал.\nconst messageBox = document.querySelector('#messageBox'); const sendButton = document.querySelector('#sendButton'); const peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel(); // Enable textarea and button when opened dataChannel.addEventListener('open', event =\u003e { messageBox.disabled = false; messageBox.focus(); sendButton.disabled = false; }); // Disable input when closed dataChannel.addEventListener('close', event =\u003e { messageBox.disabled = false; sendButton.disabled = false; }); Сообщения Отправка сообщения в RTCDataChannel выполняется через вызов функции send() с данными, которые мы хотим отправить. Параметр data для этой функции может быть типа String, Blob, ArrayBuffer или ArrayBufferView.\nconst messageBox = document.querySelector('#messageBox'); const sendButton = document.querySelector('#sendButton'); // Send a simple text message when we click the button sendButton.addEventListener('click', event =\u003e { const message = messageBox.textContent; dataChannel.send(message); }) Удаленный узел будет получать сообщения, отправленные на RTCDataChannel, через отслеживание события message.\nconst incomingMessages = document.querySelector('#incomingMessages'); const peerConnection = new RTCPeerConnection(configuration); const dataChannel = peerConnection.createDataChannel(); // Append new messages to the box of incoming messages dataChannel.addEventListener('message', event =\u003e { const message = event.data; incomingMessages.textContent += message + '\\n'; }); ","description":"Карманная книга по WebRTC","title":"Каналы данных","uri":"/ru/docs/webrtc/data-channels/"},{"content":"Мультимедиа-устройства Начало работы с мультимедийными устройствами При web-разработке WebRTC-стандарт предоставляет API для доступа к камерам и микрофонам, подключенным к компьютеру или смартфону. Эти устройства обычно называются мультимедийными устройствами, и к ним можно получить доступ с помощью Java-скрипта через объект navigator.mediaDevices, который реализует интерфейс MediaDevices. С помощью этого объекта мы можем просмотреть все подключенные устройства, отслеживать изменения статуса устройства (когда устройство подключается или отключается) и открывать устройство для извлечения мультимедийного потока (см. ниже). Чаще всего для этого используют функцию getUserMedia(), которая возвращает промис, который будет преобразован в MediaStream для соответствующих мультимедийных устройств. Эта функция принимает один объект MediaStreamConstraints, который определяет имеющиеся требования. Например, чтобы просто открыть микрофон и камеру по умолчанию, мы должны сделать следующее:\nЧерез промисы:\nconst constraints = { 'video': true, 'audio': true } navigator.mediaDevices.getUserMedia(constraints) .then(stream =\u003e { console.log('Got MediaStream:', stream); }) .catch(error =\u003e { console.error('Error accessing media devices.', error); }); Через async/await\nconst openMediaDevices = async (constraints) =\u003e { return await navigator.mediaDevices.getUserMedia(constraints); } try { const stream = openMediaDevices({'video':true,'audio':true}); console.log('Got MediaStream:', stream); } catch(error) { console.error('Error accessing media devices.', error); } Обращение к getUserMedia() запускает запрос на разрешение. Если пользователь одобряет запрос, промис разрешает MediaStream, содержащий одну видео и одну аудио дорожку. Если запрос отклонен, появляется PermissionDeniedError. Если же нет подключенных устройств, появляется NotFoundError. Полный список API для интерфейса MediaDevices доступен по ссылке https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices\nОбращение к мультимедиа-устройствам В более сложных приложениях, мы скорее всего захотим проверить все подключенные камеры и микрофоны и дать соответствующий отчет пользователю. Это можно сделать через запрос функции enumerateDevices(). Она возвращает промис, который преобразуется в массив MediaDevicesInfo, описывающий каждое известное мультимедиа-устройство. Через него мы можем предоставить пользовательский интерфейс пользователю, который позволит выбрать те или иные устройства. Каждый список MediaDevicesInfo содержит свойства, которые называются kind с значениями audioinput, audiooutput или videoinput, отражая, какой это тип мультимедиа-устройства.\nЧерез промисы\nfunction getConnectedDevices(type, callback) { navigator.mediaDevices.enumerateDevices() .then(devices =\u003e { const filtered = devices.filter(device =\u003e device.kind === type); callback(filtered); }); } getConnectedDevices('videoinput', cameras =\u003e console.log('Cameras found', cameras)); через async/await\nasync function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } const videoCameras = getConnectedDevices('videoinput'); console.log('Cameras found:', videoCameras); Отслеживание изменений в статусах устройств Большинство компьютеров поддерживают подключение различных устройств прямо во время работы. Это может быть веб-камера, подключенная через USB, Bluetooth-гарнитура или внешние динамики. Чтобы должным образом поддерживать все это, веб-приложение должно отслеживать изменения в статусах мультимедиа-устройств. Это можно сделать, добавив «отслеживатель» в navigator.mediaDevices для события devicechange.\n// Updates the select element with the provided set of cameras function updateCameraList(cameras) { const listElement = document.querySelector(‘select#availableCameras’); listElement.innerHTML = ‘’; cameras.map(camera =\u003e { const cameraOption = document.createElement(‘option’); cameraOption.label = camera.label; cameraOption.value = camera.deviceId; }).forEach(cameraOption =\u003e listElement.add(cameraOption)); } // Fetch an array of devices of a certain type async function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } // Get the initial set of cameras connected const videoCameras = getConnectedDevices(‘videoinput’); updateCameraList(videoCameras); // Listen for changes to media devices and update the list accordingly navigator.mediaDevices.addEventListener(‘devicechange’, event =\u003e { const newCameraList = getConnectedDevices(‘video’); updateCameraList(newCameraList); }); Ограничения для мультимедиа Объект ограничений, осуществляющий интерфейс MediaStreamConstraints и который мы отправляем в качестве параметра в getUserMedia(), позволяет нам открывать мультимедиа-устройство, которое отвечает определенным требованиям. Эти требования могут быть как очень расплывчатыми (аудио и/или видео), так и очень специфичными (минимальное разрешение камеры или точный ID устройства). Рекомендуем, чтобы приложения, использующие getUserMedia() API, сначала проверяли существующие устройства, а затем определяли ограничения, которые соответствуют точному устройству через deviceID-ограничение. Устройства, по возможности, будут настроены в соответствии с ограничениями. Мы можем включить эхоподавление на микрофоне, установить определенную или минимальную ширину и высоту видео с камеры.\nasync function getConnectedDevices(type) { const devices = await navigator.mediaDevices.enumerateDevices(); return devices.filter(device =\u003e device.kind === type) } // Open camera with at least minWidth and minHeight capabilities async function openCamera(cameraId, minWidth, minHeight) { const constraints = { 'audio': {'echoCancellation': true}, 'video': { 'deviceId': cameraId, 'width': {'min': minWidth}, 'height': {'min': minHeight} } } return await navigator.mediaDevices.getUserMedia(constraints); } const cameras = getConnectedDevices('videoinput'); if (cameras \u0026\u0026 cameras.length \u003e 0) { // Open first available video camera with a resolution of 1280x720 pixels const stream = openCamera(cameras[0].deviceId, 1280, 720); } Полную документацию для интерфейса MediaStreamConstraints можно найти по ссылке: https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints\nЛокальное воспроизведение Как только мультимедиа-устройство открыто и есть доступный MediaStream, мы можем назначить его для его видео- или аудио-элемента локальное воспроизведение потока.\nasync function playVideoFromCamera() { try { const constraints = {'video': true, 'audio': true}; const stream = await navigator.mediaDevices.getUserMedia(constraints); const videoElement = document.querySelector('video#localVideo'); videoElement.srcObject = stream; } catch(error) { console.error('Error opening video camera.', error); } } Обычно код HTML, необходимый для типичного видео-элемента с getUserMedia(), имеет атрибуты autoplay и playsinline. Атрибут autoplay запускает воспроизведение новых потоков, связанных с элементом, автоматически. Атрибут playsinline позволяет проигрывать встроенное видео вместо видео на весь экран, в некоторых мобильных браузерах. Также рекомендуем использовать controls = “false” для прямых эфиров, если у пользователя нет необходимости ставить их на паузу.\n\u003chtml\u003e \u003chead\u003e\u003ctitle\u003eLocal video playback\u003c/video\u003e\u003c/head\u003e \u003cbody\u003e \u003cvideo id=\"localVideo\" autoplay playsinline controls=\"false\"/\u003e \u003c/body\u003e \u003c/html\u003e ","description":"Карманная книга по WebRTC","title":"Мультимедиа-устройства","uri":"/ru/docs/webrtc/media-devices/"},{"content":"В аннотацию прописывать предложения, которые могут быть запрошены как поисковый запрос в поисковиках. Анотации индексируются поисковиками яндекс, гугл.\nhttps://www.semanticscholar.org/ IMF Report: September 16, 2022: West Bank and Gaza: Report to the AD HOC Liaison Committee\n","description":"Заметки по написанию статей","title":"Написание статей","uri":"/ru/docs/disser/articles-notes/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nИспользовать npm для установки взаимосвязей, как указано в package.json Запускать сервер Node.js и использовать node-static для обслуживания статических файлов. Настраивать службу обмена сообщениями на Node.js через Socket.IO . Использовать это для создания ‘комнат\" и обмена сообщениями. Полная версия этого шага находится в папке step-04.\nКонцепции\nЧтобы установить и поддерживать вызов WebRTC, клиенты WebRTC (узлы) должны обмениваться метаданными:\nИнформация о кандидате (сети). сообщения offer и answer, содержащие информацию о медиа, например, о разрешении и кодеках. Другими словами, обмен метаданными требуется до P2P потоковой передачи аудио, видео или данных. Этот процесс называется сигналингом. На предыдущих этапах объекты RTCPeerConnection отправителя и получателя находились на одной странице, поэтому “сигналинг” - это просто вопрос передачи метаданных между объектами.\nВ реальном приложении отправитель и получатель RTCPeerConnections запущены на веб-страницах на разных устройствах, и вам нужен способ для обмена метаданными.\nДля этого используется signaling-server: сервер, который может передавать сообщения между клиентами WebRTC (узлами). Фактически сообщения представляют собой обычный текст: строковые объекты JavaScript.\nОбязательное условие: установить Node.js\nДля выполнения следующих шагов этой codelab (папки step-04 до step-06) вам необходимо запустить сервер на локальном хосте с помощью Node.js . Вы можете скачать и установить Node.js по этой ссылке (https://nodejs.org/en/download/) или через предпочтительный для вас менеджер пакетов (https://nodejs.org/en/download/package-manager/). После установки вы сможете импортировать зависимости, необходимые для следующих шагов (запуск npm install), а также запустить небольшой локальный сервер для выполнения codelab (запуск node index.js). Эти команды будут указаны позже, когда они потребуются.\nО приложении\nWebRTC использует клиентский JavaScript API, но для использования в реальных приложениях также требуется сигналинг-сервер (обмена сообщениями), а также серверы STUN и TURN. Вы можете узнать больше здесь - https://www.html5rocks.com/en/tutorials/webrtc/infrastructure/. На этом шаге вы создадите простой Node.js сигналинг-сервер, использующий Socket.IO Node js модуль и библиотеку JavaScript для обмена сообщениями. Опыт работы с Node.js и Socket.IO будет полезным, но не решающим; компоненты обмена сообщениями очень просты.\nВыбор правильного сигналинг-сервера В этой кодовой лаборатории используется Socket.IO для сигналинг-сервера. Дизайн Socket.IO упрощает создание службы для обмена сообщениями. и Socket.IO подходит для изучения сигналинга WebRTC благодаря встроенной концепции ‘комнат\". Однако для производственного сервиса есть альтернативы получше. Смотрите, как выбрать сигналинг-протокол для вашего следующего проекта WebRTC - https://bloggeek.me/siganling-protocol-webrtc/\nВ этом примере сервер (Node.js приложение) реализовано в index.js, и клиент, который работает на нем (веб-приложение), реализован в index.html. Node.js приложение на этом этапе имеет две задачи. Во-первых, он действует как ретранслятор сообщений:\nsocket.on('message', function (message) { log('Got message: ', message); socket.broadcast.emit('message', message); }); Во-вторых, он управляет «комнатами» видеочата WebRTC:\nif (numClients === 0) { socket.join(room); socket.emit('created', room, socket.id); } else if (numClients === 1) { socket.join(room); socket.emit('joined', room, socket.id); io.sockets.in(room).emit('ready'); } else { // max two clients socket.emit('full', room); } Наше простое приложение WebRTC позволит максимум двум узлам совместно использовать комнату.\nHTML и JavaScript\nОбновите index.html. Теперь страница должна выглядеть примерно так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e На этом шаге вы ничего не увидите на странице: все протоколирование выполняется в консоли браузера. (Чтобы просмотреть консоль в Chrome, нажмите Ctrl-Shift-J или Command-Option-J, если работаете на Mac.) Заменить js/main.js следующим файлом:\n'use strict'; var isInitiator; window.room = prompt(\"Enter room name:\"); var socket = io.connect(); if (room !== \"\") { console.log('Message from client: Asking to join room ' + room); socket.emit('create or join', room); } socket.on('created', function(room, clientId) { isInitiator = true; }); socket.on('full', function(room) { console.log('Message from client: Room ' + room + ' is full :^('); }); socket.on('ipaddr', function(ipaddr) { console.log('Message from client: Server IP address is ' + ipaddr); }); socket.on('joined', function(room, clientId) { isInitiator = false; }); socket.on('log', function(array) { console.log.apply(console, array); }); Настройте Socket.IO для запуска Node.js В HTML-файле вы, возможно, видели, что используете Socket.IO файл:\n\u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e На верхнем уровне вашей папки work создайте файл с именем package.json со следующим содержимым:\n{ \"name\": \"webrtc-codelab\", \"version\": \"0.0.1\", \"description\": \"WebRTC codelab\", \"dependencies\": { \"node-static\": \"^0.7.10\", \"socket.io\": \"^1.2.0\" } } Это манифест приложения, который сообщает диспетчеру пакетов узлов (npm), какие зависимости проекта следует установить.\nЧтобы установить зависимости (например, /socket.io/socket.io.js), выполните следующие действия из терминала командной строки в вашей папке work: npm install\nВы должны увидеть журнал установки, который заканчивается примерно так:\nКак вы видите, npm установил зависимости, определенные в package.json.\nСоздайте новый файл index.js на верхнем уровне вашей папки work (не в папке js) и добавьте следующий код:\n'use strict'; var os = require('os'); var nodeStatic = require('node-static'); var http = require('http'); var socketIO = require('socket.io'); var fileServer = new(nodeStatic.Server)(); var app = http.createServer(function(req, res) { fileServer.serve(req, res); }).listen(8080); var io = socketIO.listen(app); io.sockets.on('connection', function(socket) { // convenience function to log server messages on the client function log() { var array = ['Message from server:']; array.push.apply(array, arguments); socket.emit('log', array); } socket.on('message', function(message) { log('Client said: ', message); // for a real app, would be room-only (not broadcast) socket.broadcast.emit('message', message); }); socket.on('create or join', function(room) { log('Received request to create or join room ' + room); var clientsInRoom = io.sockets.adapter.rooms[room]; var numClients = clientsInRoom ? Object.keys(clientsInRoom.sockets).length : 0; log('Room ' + room + ' now has ' + numClients + ' client(s)'); if (numClients === 0) { socket.join(room); log('Client ID ' + socket.id + ' created room ' + room); socket.emit('created', room, socket.id); } else if (numClients === 1) { log('Client ID ' + socket.id + ' joined room ' + room); io.sockets.in(room).emit('join', room); socket.join(room); socket.emit('joined', room, socket.id); io.sockets.in(room).emit('ready'); } else { // max two clients socket.emit('full', room); } }); socket.on('ipaddr', function() { var ifaces = os.networkInterfaces(); for (var dev in ifaces) { ifaces[dev].forEach(function(details) { if (details.family === 'IPv4' \u0026\u0026 details.address !== '127.0.0.1') { socket.emit('ipaddr', details.address); } }); } }); }); Из терминала командной строки выполните следующую команду в папке work: node index.js\nВ браузере откройте localhost:8080.\nКаждый раз, когда вы открываете этот URL-адрес, вам будет предложено ввести название комнаты. Чтобы присоединиться к одной и той же комнате, каждый раз выбирайте одно и то же имя комнаты, например, «foo».\nОткройте новую вкладку и снова откройте localhost: 8080. Выберите то же самое название комнаты.\nОткройте localhost:8080 в третьей вкладке или окне. Выберите то же название комнаты еще раз.\nПроверьте консоль на каждой из вкладок: вы должны увидеть логи из JavaScript выше.\nБонусные задания\nКакие альтернативные механизмы обмена сообщениями могут быть возможны? С какими проблемами вы можете столкнуться при использовании «чистого» WebSocket? Какие проблемы могут быть связаны с масштабированием этого приложения? Можете ли вы разработать метод для тестирования тысяч или миллионов одновременных запросов на номер? Это приложение использует запрос JavaScript для получения названия комнаты. Разработайте способ получения названия комнаты из URL. Например, localhost:8080/foo будет указывать имя комнаты foo. Что вы узнали\nНа этом шаге вы узнали, как:\nИспользовать npm для установки зависимостей проекта, как указано в package.json Запускать Node.js сервер для обмена системных файлов. Настраивать службу обмена сообщениями на Node.js через socket.io . Использовать это для создания ‘комнат\" и обмена сообщениями. Полная версия этого шага находится в папке step-04. Узнайте больше\nПример socket.io chat - https://github.com/rauchg/chat-example WebRTC в реальном мире: STUN, TURN и сигналинг - http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/ Термин “signaling” в WebRTC - https://www.webrtc-experiment.com/docs/WebRTC-Signaling-Concepts.html Следующий шаг Узнайте, как исполь зовать сигналинг, чтобы позволить двум пользователям установить одноранговое соединение.\n","description":"Карманная книга по WebRTC","title":"Настройка службы сигналинга для обмена сообщениями","uri":"/ru/docs/webrtc/practice/practice-setup-signaling-service/"},{"content":"Создайте приложение для получения видео и снимков с веб-камеры, с возможностью делиться ими в P2P через WebRTC. В ходе codelab вы узнаете, как использовать основные API WebRTC и настроить сервер обмена сообщениями через Node.js.\nЧему вы научитесь\nполучать видео с вашей веб-камеры потоковое видео через RTCPeerConnection потоковая передача данных через RTCDataChannel настраивать сигналинг для обмена сообщениями комбинировать одноранговое соединение и сигналинг делать фото и передавать его через канал данных Что понадобится\nChrome версии 47 и выше веб-сервер для Chrome https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb , и ваш собственный веб-сервер по выбору пример кода текстовый редактор базовые знания HTML, CSS и Javaskript ","description":"Карманная книга по WebRTC","title":"Обзор","uri":"/ru/docs/webrtc/practice/practice-overview/"},{"content":"Начало работы с одноранговыми соединениями Одноранговые соединения – часть спецификации WebRTC, которая занимается связью двух приложений на различных компьютерах для коммуникации через P2P-протокол. Коммуникация между узлами может быть видео-, аудио- или произвольными двоичными данными (для клиентов, поддерживающих RTCDataChannel API). Чтобы выяснить, как два узла могут быть соединены, оба клиента должны предоставить конфигурацию ICE-Server. Это или STUN, или TURN-сервер, и их роль – обеспечить ICE-кандидатов для каждого клиента, который затем передается на удаленный узел. Эта «передача» ICE-кандидатов обычно называется «сигналинг».\nСигналинг Спецификации WebRTC включают API для коммуникации с ICE-сервером (ICE =Internet Connectivity Establishment, установление интерактивного подключения), но компонент сигналинга не является частью этого сервера. Сигналинг необходим, чтобы два узла могли использовать один и тот же способ подключения. Обычно это можно решить через обычный Web API на базе HTTP (то есть службу REST или другой механизм RPC), где веб-приложения могут передавать необходимую информацию до того, как будет установлено соединение. Следующий фрагмент кода показывает, как эту придуманную службу сигналинга можно использовать для отправки и получения асинхронных сообщений. Мы будем использовать по необходимости этот прием в оставшихся примерах в этом гайде.\n// Set up an asynchronous communication channel that will be // used during the peer connection setup const signalingChannel = new SignalingChannel(remoteClientId); signalingChannel.addEventListener('message', message =\u003e { // New message from remote client received }); // Send an asynchronous message to the remote client signalingChannel.send('Hello!'); Сигналинг может быть реализован разными способами, и спецификация WebRTC не отдает предпочтений какому-то определенному варианту.\nИнициирование одноранговых соединений Каждое одноранговое соединение управляется объектом RTCPeerConnection. Конструктор для этого класса берет в качестве параметра одиночный объект RTCConfiguration. Этот объект определяет, как одноранговое соединение устанавливается, и какую информацию должен содержать об используемых ICE-серверах.\nПосле того, как RTCPeerConnection установлено, мы должны задать SDP-запрос/ответ, в зависимости от того, являемся мы вызывающим или принимающим узлом. После того, как SDP-запрос/ответ создан, он должен быть отправлен на удаленный узел через другой канал. Передача SDP-объектов на удаленные узлы называется сигналингом и не рассматривается в WebRTC спецификации.\nДля установки однорангового соединения с вызывающей стороны, мы создаем объект RTCPeerConnection, и затем вызываем createOffer() для создания объекта RTCSessionDescription. Описание этого сеанса устанавливается как локальное описание с использованием setLocalDescription(), и затем отправляется через наш сигналинг-канал получающей стороне. Мы также устанавливаем «прослушиватель» для нашего сигналинг-канала, чтобы знать, когда получающей стороной будет получен ответ на описание нашего запрошенного сеанса.\nasync function makeCall() { const configuration = {'iceServers': [{'urls': 'stun:stun.l.google.com:19302'}]} const peerConnection = new RTCPeerConnection(configuration); signalingChannel.addEventListener('message', async message =\u003e { if (message.answer) { const remoteDesc = new RTCSessionDescription(message.answer); await peerConnection.setRemoteDescription(remoteDesc); } }); const offer = await peerConnection.createOffer(); await peerConnection.setLocalDescription(offer); signalingChannel.send({'offer': offer}); } На получающей стороне мы ждем входящий запрос до того, как мы создали пример RTCPeerConnection. После этого мы устанавливаем полученный запрос, используя setRemoteDescription().\nДалее, мы делаем запрос createAnswer() для создания ответа на полученный запрос. Этот ответ устанавливается как локальное описание через использование setLocalDescription() и затем отправляется набирающей стороне через наш сигналинг-сервер.\nconst peerConnection = new RTCPeerConnection(configuration); signalingChannel.addEventListener('message', async message =\u003e { if (message.offer) { peerConnection.setRemoteDescription(new RTCSessionDescription(message.offer)); const answer = await peerConnection.createAnswer(); await peerConnection.setLocalDescription(answer); signalingChannel.send({'answer': answer}); } }); Как только два узла установили описания и локального, и удаленного сеансов, становятся доступны возможности удаленного узла. Это еще не означает, что соединение между узлами готово. Для работы необходимо собрать ICE-кандидатов на каждом узле и передать (по сигналинг-каналу) другому узлу.\nICE-кандидаты До того, как два узла смогут коммуницировать через WebRTC, им необходимо обменяться информацией о подключении. Так как условия сети могут отличаться в зависимости от ряда факторов, для обнаружения возможных кандидатов на соединение с узлом обычно используется внешний сервис. Этот сервис называется ICE и использует серверы STUN или TURN. STUN – это аббревиатура от Session Traversal for NAT, и обычно косвенно используется в большинстве WebRTC приложениях.\nTURN (Traversal Using Relay NAT) более продвинутое решение, которое включает в себя протоколы STUN, и большинство коммерческих служб WebRTC используют TURN сервер для установки соединения между узлами.\nAPI WebRTC напрямую поддерживает как STUN, так и TURN, и объединяется под более полным термином ICE (Internet Connectivity Establishment - «Установление подключения к Интернету»). При установке WebRTC-соединения мы обычно предоставляем один или несколько ICE-серверов в конфигурации для объекта RTCPeerConnection.\nTrickle ICE После создания объекта RTCPeerConnection, исходный фреймворк использует предоставленные ICE-серверы для сбора кандидатов на установление соединения (кандидатов ICE).\nСобытие icegatheringstatechange на RTCPeerConnection передает информацию о том, в каком состоянии находится ICE-сбор (new, gathering или complete). Несмотря на то, что для узла возможно просто дождаться, пока ICE-сбор будет завершен, обычно гораздо эффективнее использовать метод «trickle ice» и передавать каждого вновь обнаруженного ICE-кандидата удаленному узлу. Это значительно сократит время настройки однорангового соединения и позволит начать видео-звонок с меньшими задержками.\nДля сбора ICE-кандидатов, просто добавьте «прослушиватель» в событие icecandidate. Объект RTCPeerConnectionIceEvent, созданный этим «прослушивателем», будет содержать свойство candidate, представляющее нового кандидата, которого нужно отправить удаленному узлу (см. Сигналинг)\n// Listen for local ICE candidates on the local RTCPeerConnection peerConnection.addEventListener(‘icecandidate’, event =\u003e { if (event.candidate) { signalingChannel.send({‘new-ice-candidate’: event.candidate}); } }); // Listen for remote ICE candidates and add them to the local RTCPeerConnection signalingChannel.addEventListener(‘message’, async message =\u003e { if (message.iceCandidate) { try { await peerConnection.addIceCandidate(message.iceCandidate); } catch € { console.error(‘Error adding received ice candidate’, e); } } }); Соединение установлено После того, как ICE-кандидаты получены, нужно дождаться, пока состояние нашего однорангового соединения изменится на подключенное состояние. Чтобы отследить это, добавим «прослушиватель» в наш RTCPeerConnection, где можно просматривать изменения события connectionstatechange.\n","description":"Карманная книга по WebRTC","title":"Одноранговые соединения","uri":"/ru/docs/webrtc/peer-connections/"},{"content":"Задача Есть таблица google. Необходимо конвертировать ее в JSON и не делать каждый раз ручной экспорт.\nУсловия таблица закрыта для общего просмотра json отображение читать по ссылке План Использовать webapps от google. Парсить google таблицу и выдавать готовый url с json.\nПодготовка Открываем Таблицу Google Extensions → Apps Script Создаем скрипт Как работает endpoint. Документация\nКогда пользователь посещает приложение или программа отправляет приложению HTTP-запрос GET, Apps Script запускает функцию doGet(e).\nКогда отправляется приложению HTTP-запрос POST, вместо этого Apps Script запускает doPost(e).\nВ обоих случаях аргумент e представляет собой параметр события, который может содержать информацию о любых параметрах запроса.\nДополнительные условия в запрос сейчас посылать не буду.\nИтого функция с получением массива и функция с выдачей результата:\nconst sheetName = 's1' // название листа const sheetRange = 'A:J' // диапазон const sheet = SpreadsheetApp.getActive().getSheetByName(sheetName) function getData(){ const result = [] const values = sheet.getRange(sheetRange).getValues() const lastRow = parseInt(sheet.getLastRow()) for (let i = 1; i \u003c lastRow; i++) { result.push(values[i]) } return result } function doGet() { const data = getData() return ContentService.createTextOutput( JSON.stringify( {'result': data} ) ).setMimeType(ContentService.MimeType.JSON) } Публикуем приложение Результат ","description":"Экспорт google sheet в JSON, с моментальным обновлением данных","title":"Отображение таблицы Google Sheets в JSON","uri":"/ru/posts/google-sheets-2-json/"},{"content":" https://scholar.google.com/citations?user=R5xmgOgAAAAJ\u0026authuser=1\nПечатные журналы / сборники статья даша / статья катя икт экспорт / elibrary\n«Ключевые подходы к разработке доступного, интуитивно понятного интерфейса статистического пакета», // Научный журнал // к.т.н., профессор Суханова Е. И., канд. физ.-мат., доцент Ширяева Л. К., Курновский Р. М. // 2014 г. //\n«Мобильность платформы 1С на базе приложения 1С:Монитор ERP» // Известия Института Систем Управления Самарского государственного экономического университета. // Курновский Р. М., Нечаев А. Н. // 2013 г. // Номер: 2 (8) // Страницы: 243-247 //\n«Современные инструменты моделирования архитектуры предприятия» // Известия Института Систем Управления Самарского государственного экономического университета. // 2012 г. // Номер: 3 (6) // Страницы: 256-260 //\n«Стволовая клетка — миф или реальность» // Тезисы 36-й Самарской областной студенческой научной конференции. // 2010 г. //\n«Права человека — миф или реальность» // Тезисы 4-й Международной научной конференции молодых ученых, аспирантов и студентов. // 2010 г. //\n«Хулиганство в Самаре 1920-1930-х гг.» // Тезисы 4-й Международной научной конференции молодых ученых, аспирантов и студентов. // 2010 г. //\n«Обеспечение прав человека — миф или реальность» // Сборник тезисов конкурсных работ, опубликованных Государственной Думой Федерального Собрания Российской Федерации во всероссийском конкурсе молодежи, образовательных учреждений и научных организаций на лучшую работу «Моя законотворческая инициатива». // 2008 г. //\n«Хулиганство в России в 20-30-е годы 20-го века на примере Самарской области» // Сборник тезисов 37-й городской научно-практической конференции. // 2008 г. //\n«Генетический паспорт гражданина Российской Федерации» // Сборник тезисов конкурсных работ, опубликованных Государственной Думой Федерального Собрания Российской Федерации во всероссийском конкурсе молодежи, образовательных учреждений и научных организаций на лучшую работу «Моя законотворческая инициатива». // 2007 г. //\nПлощадки How to unmount disk on Linux\n","description":"Печатные журналы / сборники","title":"Печатные публикации","uri":"/ru/p/publications/"},{"content":"Список приложений: ФСФР - Базовый экзамен\nНастоящая Политика конфиденциальности персональных данных (далее – Политика конфиденциальности) действует в отношении всей информации, которую приложения из раздела: “Список приложений” могут получить о Пользователе во время использования.\nОбщие положения 1.1. Целью Политики конфиденциальности является реализация требований законодательства в области обработки и защиты персональных данных. 1.2. Настоящий Регламент разработан на основании Конституции Российской Федерации, Трудового кодекса Российской Федерации, Гражданского кодекса Российской Федерации, Уголовного кодекса Российской Федерации, Кодекса об административных правонарушениях Российской Федерации, Федерального закона Российской Федерации «О персональных данных» № 152-ФЗ от 27 июля 2006 года.\nОсновные понятия На основании законодательства Российской Федерации в целях настоящего Политики конфиденциальности используются следующие понятия 2.1. Администратор Приложений (далее – Администратор) – уполномоченные сотрудник, который организуют и (или) осуществляет обработку персональных данных, а также определяет цели обработки персональных данных, состав персональных данных, подлежащих обработке, действия (операции), совершаемые с персональными данными.\n2.2. Пользователь – лицо, являющееся субъектом персональных данных и сообщающее свои персональные данные посредством Приложений.\n2.3. «Персональные данные» - любая информация, относящаяся к прямо или косвенно к определяемому физическому лицу (субъекту персональных данных).\n2.4. «Обработка персональных данных» - любое действие (операция) или совокупность действий (операций), совершаемых с использованием средств автоматизации или без использования таких средств с персональными данными, включая сбор, запись, систематизацию, накопление, хранение, уточнение (обновление, изменение), извлечение, использование, передачу (распространение, предоставление, доступ), обезличивание, блокирование, удаление, уничтожение персональных данных.\nОбщие положения 3.1. Использование Пользователем Приложений означает согласие с настоящей Политикой конфиденциальности и условиями обработки персональных данных Пользователя. 3.2. В случае несогласия с условиями Политики конфиденциальности Пользователь должен прекратить использование Приложений.\n3.3. Настоящая Политика конфиденциальности применяется только к Приложениям.\nПредмет политики конфиденциальности 4.1. Настоящая Политика конфиденциальности устанавливает обязательства по неразглашению и обеспечению режима защиты конфиденциальности персональных данных, которые Пользователь. 4.2. Персональные данные, разрешённые к обработке в рамках настоящей Политики конфиденциальности, предоставляются Пользователем путём заполнения и включают в себя следующую информацию:\nфамилию, имя, отчество;\nконтактный телефон Пользователя;\ne-mail\n4.3. Любая иная персональная информация неоговоренная выше подлежит надежному хранению и нераспространению.\n4.4. Обработка персональных данных осуществляется с использованием интернет-сервисов сторонних организаций, в том числе с использованием интернет-сервиса Google Analitics. С порядком обработки данных с помощью интернет-сервиса Google Analitics можно ознакомиться, перейдя по ссылке https://www.google.ru/policies/privacy/partners/\nЦели сбора персональных данных 5.1. Запрещено обрабатывать персональные данные Пользователя о его политических, религиозных и иных убеждениях и частной жизни. 5.2. При передаче персональных данных Пользователя, Администратор предупреждает лиц, получающих персональные данные Пользователя, о том, что эти данные могут быть использованы лишь в целях, для которых они сообщены. Данная норма не распространяется на обмен персональными данными Пользователей в порядке, установленном федеральными законами.\n5.3. Защита персональных данных Пользователя от неправомерного их использования или утраты обеспечивается в порядке, установленном законодательством Российской Федерации.\n5.4. Пользователь вправе в любое время по своему усмотрению отозвать свое согласие на обработку своих персональных данных путем отправки сообщения об удалении персональных данных по следующему e-mail: r.kurnovskii@gmail.com.\nСпособы и сроки обработки персональных данных 6.1. Обработка персональных данных Пользователя осуществляется без ограничения срока, любым законным способом, в том числе в информационных системах персональных данных с использованием средств автоматизации или без использования таких средств. 6.2. При утрате или разглашении персональных данных Администрация сайта информирует Пользователя об утрате или разглашении персональных данных.\nОбязательства сторон 7.1. Администратор обязан: 7.1.1. Использовать полученную информацию исключительно для целей, указанных в п. 5 настоящей Политики конфиденциальности.\n7.1.2. Обеспечить хранение конфиденциальной информации в тайне.\n7.1.3. Принимать меры предосторожности для защиты конфиденциальности персональных данных Пользователя согласно порядку, обычно используемого для защиты такого рода информации в существующем деловом обороте.\n7.1.4. Осуществить блокирование, удаление персональных данных, относящихся к соответствующему Пользователю, с момента обращения или запроса Пользователя или его законного представителя либо уполномоченного органа по защите прав субъектов персональных данных на период проверки, в случае выявления недостоверных персональных данных или неправомерных действий\n7.2. Администратор не несет ответственности за возможное нецелевое использование персональных данных Пользователей, произошедшее из-за:\n7.2.1. технических неполадок в программном обеспечении, серверах или компьютерных сетях, находящихся вне контроля Администратора;\nДополнительные условия 8.1. Администратор вправе вносить изменения в настоящую Политику конфиденциальности без согласия Пользователя. 8.2. Новая Политика конфиденциальности вступает в силу с момента ее размещения на Сайте https://romankurnovskii.github.io/p/privacy_ru/, если иное не предусмотрено новой редакцией Политики конфиденциальности.\n","description":"","title":"Политика конфиденциальности","uri":"/ru/p/privacy_ru/"},{"content":"Web Создание заявки в IB Заходим на сайт https://www.interactivebrokers.co.uk/portal/#/ Нажимаем Deposit Нажимаем Use a new deposit method если ранее шаблон не был создан Bank Wire -\u003e Get instructions Account Number: Номер банковского счета.\nПолучаем инструкции с реквизитами для пополнения Bank Wire Instructions Эти данные Вам нужны для оплаты в Discount Bank\nОтправить деньги из Discount Bank Заходим в личный кабинет банка start.telebank.co.il Нажимаем: ביצוע העברה\nЗаполняем форму\nНажимаем המשך и жмем далее. Приходит смс с подверждением, вводим и жмем далее ","description":"Пополнение Interactive Brokers с Израильского счета банка Дисконт","title":"Пополнение Interactive Brokers с Израильского счета","uri":"/ru/posts/interactivebrokers-deposit/"},{"content":"Full in english\nТоп 10 комманд Docker docker ps — смотрим список запущенных контейнеров docker pull — загрузка образа docker build — собирает образ docker logs — смотрим логи docker run — запускаем контейнер docker stop — останавливает контейнер docker kill — «убивает» контейнер docker rm — удаляет контейнер docker rmi — удаляет образ docker volume ls — список томов docker build Документация Построить образ из Dockerfile.\ndocker build [DOCKERFILE PATH] Флаги --file -f Путь, где находится Dockerfile --force-rm Всегда удалять временные контейнеры. --no-cache Не использовать кэш при построении образа. --rm Удалить временные контейнеры после успешного построения. --tag -t Название и возможный тег в формате name:tag или просто тег my_tag (опционально) Примеры Построить образ с меткой my-org/my-image, используя Dockerfile в /tmp/Dockerfile.\ndocker build -t my-org:my-image -f /tmp/Dockerfile docker run Документация\nСоздает и запускает контейнер за один операционный шаг\nПримеры docker run -it ubuntu:latest /bin/bash Данная команда запустит контейнер ubuntu и при старте сразу запустит /bin/bash. Если образ ubuntu не был загружен ранее, он загрузится перед запуском.\nФлаги -it This will not make the container you started shut down immediately, as it will create a pseudo-TTY session (-t) and keep STDIN open (-i) --rm Automatically remove the container when it exit. Otherwise it will be stored and visible running docker ps -a. --detach -d Run container in background and print container ID --volume -v Bind mount a volume. Useful for accessing folders on your local disk inside your docker container, like configuration files or storage that should be persisted (database, logs etc.). docker exec Документация Выполнить команду внутри запущенного контейнера.\ndocker exec [CONTAINER ID] Флаги --detach -d Detached mode: запуск в фоновом режиме -it запуск в интерактивном режиме. запуск псевдотерминала pseudo-TTY (-t) и перенаправление ввода-вывода (STDIN) (-i). Даёт доступ к выполнению команд в терминале контейнера. Примеры docker exec [CONTAINER ID] touch /tmp/exec_works docker images Документация Вывести список всех загруженных/созданных образов\ndocker images Флаги -q показать только ID образов docker inspect Документация\nПоказать всю информацию о контейнере.\ndocker inspect [CONTAINER ID] docker logs Документация\nВывести логи контейнера.\ndocker logs [CONTAINER ID] Флаги --details Показывает дополнительную информацию в логе. --follow -f Следить за выводом журнала --timestamps -t Показать журналы с меткой времени docker ps Документация\nПоказывает информацию о всех запущенных контейнерах.\ndocker ps Флаги --all -a Show all containers (default shows just running) --filter -f Filter output based on conditions provided, docker ps -f=\"name=\"example\" --quiet -q Only display numeric IDs docker rmi Документация\nУдалить один или несколько образов.\ndocker rmi [IMAGE ID] Флаги --force -f Force removal of the image Советы и рекомендации по докеру Сборник полезных советов по Docker.\nУдалить все контейнеры NOTE: Удалить ВСЕ контенеры.\ndocker container prune или\ndocker rm $(docker ps -a -q) Удалить все непомеченные контейнеры docker image prune Вывести сколько памяти занимает Docker docker system df Получить IP-адрес работающего контейнера docker inspect [CONTAINER ID] | grep -wm1 IPAddress | cut -d '\"' -f 4 Сгенерировать образ на основе файла Dockerfile и добавить этому образу имя и версию docker build -t new_image_name:v1 . . означает текущую директорию, где расположен файл Dockerfile.\nСгенерировать из запущенного контейнера новый образ docker commit [CONTAINER ID] [NEW IMAGE NAME] “Убить” все запущенные контейнеры docker kill $(docker ps -q) Ссылки docs.docker.com docker-cheat-sheet https://sourabhbajaj.com/mac-setup/Docker/ ","description":"Основные команды Docker, которыми пользуюсь в процессе разработки.","title":"Популярные команды Docker","uri":"/ru/posts/docker-commands/"},{"content":"Чему вы научитесь:\nНа этом шаге вы узнаете, как\nполучить видеопоток с вашей веб-камеры управлять воспроизведением потока использовать CSS и SVG для обработки видео Полная версия этого шага находится в папке step-01. Немного HTML\nДобавьте элемент video и элемент script в index.html в папку work.\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cvideo autoplay playsinline\u003e\u003c/video\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e И немного JavaScript\nДобавьте следующее в main.js в вашей папке js:\n'use strict'; // On this codelab, you will be streaming only video (video: true). const mediaStreamConstraints = { video: true, }; // Video element where stream will be placed. const localVideo = document.querySelector('video'); // Local stream that will be reproduced on the video. let localStream; // Handles success by adding the MediaStream to the video element. function gotLocalMediaStream(mediaStream) { localStream = mediaStream; localVideo.srcObject = mediaStream; } // Handles error by logging a message to the console with the error message. function handleLocalMediaStreamError(error) { console.log('navigator.getUserMedia error: ', error); } // Initializes media stream. navigator.mediaDevices.getUserMedia(mediaStreamConstraints) .then(gotLocalMediaStream).catch(handleLocalMediaStreamError); Все приведенные здесь примеры JavaScript используют ‘use strict’, для избежания частых ошибок в кодировании. Узнайте больше, что это означает в http://ejohn.org/blog/ecmascript-5-strict-mode-json-and-more/\nПопробуйте\nОткройте index.html в вашем браузере и вы должны увидеть что-то подобное (с видом из вашей камеры, конечно!):\nКак это работает\nСледуя запросу getUserMedia(), браузер запрашивает у пользователя разрешение на доступ к своей камере (если это впервые, когда запрашивается доступ к камере для текущего источника). В случае успеха возвращается MediaStream, который может быть использован элементов мультимедиа через атрибут srcObject:\nnavigator.mediaDevices.getUserMedia(mediaStreamConstraints) .then(gotLocalMediaStream).catch(handleLocalMediaStreamError); function gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; } Аргумент constraints позволяет указать, какой тип мультимедиа получать. В этом примере используется только видео, т.к. звук по умолчанию отключен:\nconst mediaStreamConstraints = { video: true, }; Вы можете использовать ограничения для дополнительных требований, таких как разрешение видео:\nconst hdConstraints = { video: { width: { min: 1280 }, height: { min: 720 } } } Спецификация MediaTrackConstraints перечисляет все возможные типы ограничений, хотя не все параметры поддерживаются во всех браузерах. Если запрошенное разрешение не поддерживается выбранной в данный момент камерой, getUserMedia() будет отклонен с ошибкой OverconstrainedError и пользователю даже не предложат предоставить разрешение на доступ к своей камере.\nДемо-версию, демонстрирующую, как использовать ограничения для запроса различных разрешений, можно посмотреть по ссылке https://simpl.info/getusermedia/constraints/, а демо-версию с использованием ограничений для выбора камеры и микрофона – по этой ссылке https://simpl.info/getusermedia/sources/.\nЕсли getUserMedia() сработал успешно, в качестве источника элемента video устанавливается видеопоток с веб-камеры:\nfunction gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; } Бонусные задания\nПереданный getUserMedia() объект localStream находится в глобальной области видимости, поэтому вы можете проверить его через консоль браузера: откройте консоль в Chrome, введите stream и нажмите Return (для просмотра консоли в Chrome, нажмите Ctrl+Shift+J, или command+Option+J, если вы работаете на Mac). что возвращает localStream.getVideoTracks()? попробуйте сделать запрос localStream.getVideoTracks()[0].stop() Посмотрите на объект constraints: что произойдет, когда вы меняете его на {audio: true, video: true)? Какой размер у элемента video? Как можно получить естественный размер из JavaScript, в отличие от размера экрана? Используйте Chrome Dev Tools для проверки Попробуйте добавить CSS фильтры в элемент video. Например: video { filter: blur(4px) invert(1) opacity(0.5); } Попробуйте добавить SVG-фильтры. Например: video { filter: hue-rotate(180deg) saturate(200%); } Что вы узнали\nНа этом шаге вы узнали, как\nполучать видео с вашей веб-камеры устанавливать ограничения для мультимедиа как навести хаос в элементе video Полная версия этого шага находится в папке step-01.\nСоветы\nне забывайте про атрибут autoplay в элемент video. Без него вы будете видеть только один кадр! есть гораздо больше ограничений для getUserMedia(). Посмотрите их по ссылке https://webrtc.github.io/samples/src/content/peerconnection/constraints/. Как видите, есть много интересных примеров c WebRTC на сайте. Лучшая практика\nубедитесь, что ваш элемент video не переполняет его контейнер. Мы добавили width и max-width для установки соответствующего размера и максимального размера видео. Браузер будет рассчитывать высоту автоматически. video { max-width: 100%; width: 320px; } Следующий шаг\nВы получили видео, но как его транслировать? Узнайте на следующем шаге!\n","description":"Карманная книга по WebRTC","title":"Потоковое видео с веб-камеры","uri":"/ru/docs/webrtc/practice/practice-stream-to-cam/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nАбстрагироваться от различий браузера с помощью оболочки WebRTC, adapter.js. Использовать RTCPeerConnection API для потоковой передачи видео. Управлять захватом и потоковой передачей мультимедиа. Полная версия этого шага находится в папке step-2.\nЧто такое RTCPeerConnection?\nRTCPeerConnection - это API для выполнения WebRTC-запросов для потоковой передачи видео и аудио и обмена данными.\nВ этом примере устанавливается соединение между двумя объектами RTCPeerConnection (известными как узлы) на одной и той же странице.\nНе очень практично, но зато полезно для понимания того, как работает RTCPeerConnection.\nДобавление элементов video и кнопок управления\nВ index.html замените один видеоэлемент двумя видеоэлементами и тремя кнопками:\n\u003cvideo id=\"localVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cdiv\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"callButton\"\u003eCall\u003c/button\u003e \u003cbutton id=\"hangupButton\"\u003eHang Up\u003c/button\u003e \u003c/div\u003e Один видеоэлемент будет отображать поток из getUserMedia(), а другой будет показывать это же видео, но передаваемое через RTCPeerConnection (в реальном приложении один видеоэлемент будет отображать локальный поток, а другой – удаленный поток).\nДобавьте adapter.js Добавьте ссылку на текущую версию adapter.js выше ссылки на main.js:\n\u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e adapter.js - это оболочка для изоляции приложений от изменений спецификаций и различий в префиксах. (Хотя на самом деле стандарты и протоколы, используемые для реализации WebRTC, очень стабильны, и существует всего несколько имен с префиксами.)\nНа этом этапе мы используем самую последнюю версию adapter.js, что хорошо для codelab, но не всегда хорошо для приложений. Здесь https://github.com/webrtc/adapter мы объясняем, как сделать так, чтоб у вашего приложения всегда был доступ к самой последней версии.\nДля получения полной информации о взаимодействии сWebRTC, переходи по ссылке https://webrtc.github.io/webrtc-org/web-apis/interop/\nТеперь index.html должен выглядеть так:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cvideo id=\"localVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay playsinline\u003e\u003c/video\u003e \u003cdiv\u003e \u003cbutton id=\"startButton\"\u003eStart\u003c/button\u003e \u003cbutton id=\"callButton\"\u003eCall\u003c/button\u003e \u003cbutton id=\"hangupButton\"\u003eHang Up\u003c/button\u003e \u003c/div\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Установите код RTCPeerConnection\nЗамените main.js в папке step-02.\nДелать копи-паст в больших кусках кода в codelab – это так себе вариант, конечно. Но чтобы получить и запустить RTCPeerConnection, у нас нет других альтернатив, как провести вас через весь этот путь. Вам нужно научиться, как код работает в каждый момент.\nСделайте звонок Откройте index.html, нажмите кнопку Start, чтоб получить видео с вашей веб-камеры, и затем нажмите Call, чтобы установить одноранговое соединение. Вы должны увидеть одно и то же видео (с вашей веб-камеры) в обоих видео-элементах. Посмотрите консоль браузера, чтоб увидеть логи WebRTC.\nКак это работает\nВ этом шаге будет много всего…\nЕсли вы хотите пропустить объяснение ниже - ок. Вы все еще можете продолжить работу с codelab!\nWebRTC использует API RTCPeerConnection для настройки соединения для потоковой передачи видео между клиентами WebRTC, известными как узлы. В этом примере два объекта RTCPeerConnection находятся на одной странице: pc1 и pc2. Это мало используется на практике, но зато хорошо демонстрирует, как работают API. Настройка вызова между WebRTC-узлами включает в себя три задачи:\nСоздать RTCPeerConnection для каждого конца вызова и на каждом конце добавить локальный поток из getUserMedia(). Получать и делиться сетевой информацией: потенциальные конечные точки подключения известны как ICE-кандидаты. Получать и делиться локальными и удаленными описаниями: метаданные о локальными мультимедиа в формате SDP. Представьте, что Алиса и Боб хотят использовать RTCPeerConnection для настройки видеочата. Сначала Алиса и Боб обмениваются информацией о сети. Выражение “finding candidates” относится к процессу поиска сетевых интерфейсов и портов с использованием ICE-фреймворк.\nАлиса создает объект RTCPeerConnection с обработчиком onicecandidate (addEventListener(‘icecandidate’)). Это соответствует следующему коду из main.js let localPeerConnection; localPeerConnection = new RTCPeerConnection(servers); localPeerConnection.addEventListener('icecandidate', handleConnection); localPeerConnection.addEventListener( 'iceconnectionstatechange', handleConnectionChange); Аргумент servers для RTCPeerConnection в этом примере не используется. Здесь вы можете указать STUN и TURN серверы. WebRTC разработан для работы с P2P, поэтому пользователи могут подключаться по самому прямому возможному маршруту. Однако WebRTC создан для работы в реальных сетях: клиентским приложениям необходимо проходить через шлюзы NAT (http://en.wikipedia.org/wiki/NAT_traversal) и брандмауэры, а P2P сеть нуждается в резервном варианте на случай сбоя прямого соединения. В рамках этого процесса, API WebRTC используют STUN-серверы для получения IP-адреса вашего компьютера и TURN-серверы для ретрансляции в случае сбоя P2P связи. Подробнее об этом - http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/\nАлиса вызывает getUserMedia() и добавляет переданные поток: navigator.mediaDevices.getUserMedia(mediaStreamConstraints). then(gotLocalMediaStream). catch(handleLocalMediaStreamError); function gotLocalMediaStream(mediaStream) { localVideo.srcObject = mediaStream; localStream = mediaStream; trace('Received local stream.'); callButton.disabled = false; // Enable call button. } localPeerConnection.addStream(localStream); trace('Added local stream to localPeerConnection.'); Обработчик onicecandidate из шага 1 вызывается, когда становятся доступными сетевые кандидаты. Алиса отправляет Бобу данные кандидата. В реальном приложении этот процесс (известный как сигналинг) осуществляется через службу обмена сообщениями – вы узнаете, как это сделать, позднее. Конечно, на этом этапе два объекта RTCPeerConnection находятся на одной странице и могут взаимодействовать напрямую без необходимости во внешних сообщениях. Когда Боб получает сообщение о кандидате от Алисы, он вызывает addIceCandidate(), чтобы добавить кандидата в описание удаленного узла: function handleConnection(event) { const peerConnection = event.target; const iceCandidate = event.candidate; if (iceCandidate) { const newIceCandidate = new RTCIceCandidate(iceCandidate); const otherPeer = getOtherPeer(peerConnection); otherPeer.addIceCandidate(newIceCandidate) .then(() =\u003e { handleConnectionSuccess(peerConnection); }).catch((error) =\u003e { handleConnectionFailure(peerConnection, error); }); trace(`${getPeerName(peerConnection)} ICE candidate:\\n` + `${event.candidate.candidate}.`); } } Узлам WebRTC также необходимо узнавать и обмениваться информацией о локальных и удаленных аудио- и видеоматериалах, такими как разрешение и возможности кодеков, и обмениваться ими. Сигналинг для обмена информацией о конфигурации мультимедиа осуществляется путем обмена большими двоичными объектами метаданных, известными как offer и answer, с использованием формата Session Description Protocol, известного как SDP (http://en.wikipedia.org/wiki/Session_Description_Protocol):\nАлиса запускает метод RTCPeerConnectioncreateOffer(). Возвращенный промис обеспечивает RTCSessionDescription: Alice’s local session description: trace('localPeerConnection createOffer start.'); localPeerConnection.createOffer(offerOptions) .then(createdOffer).catch(setSessionDescriptionError); В случае успеха Алиса устанавливает локальное описание, используя setLocalDescription(), а затем отправляет это описание сеанса Бобу через сигналинг-канал. Боб принимает описание, отправленное ему Алисой, в качестве удаленного описания, используя setRemoteDescription(). Боб запускает метод RTCPeerConnection createAnswer(), передавая ему удаленное описание, которое он получил от Алисы, чтобы можно было создать локальный сеанс, совместимый с ее сеансом. Промис createAnswer() передает описание RTCSessionDescription: Боб устанавливает это как локальное описание и отправляет его Алисе. Когда Алиса получает описание сеанса Боба, она устанавливает его в качестве удаленного описания с помощью setRemoteDescription(). // Logs offer creation and sets peer connection session descriptions. function createdOffer(description) { trace(`Offer from localPeerConnection:\\n${description.sdp}`); trace('localPeerConnection setLocalDescription start.'); localPeerConnection.setLocalDescription(description) .then(() =\u003e { setLocalDescriptionSuccess(localPeerConnection); }).catch(setSessionDescriptionError); trace('remotePeerConnection setRemoteDescription start.'); remotePeerConnection.setRemoteDescription(description) .then(() =\u003e { setRemoteDescriptionSuccess(remotePeerConnection); }).catch(setSessionDescriptionError); trace('remotePeerConnection createAnswer start.'); remotePeerConnection.createAnswer() .then(createdAnswer) .catch(setSessionDescriptionError); } // Logs answer to offer creation and sets peer connection session descriptions. function createdAnswer(description) { trace(`Answer from remotePeerConnection:\\n${description.sdp}.`); trace('remotePeerConnection setLocalDescription start.'); remotePeerConnection.setLocalDescription(description) .then(() =\u003e { setLocalDescriptionSuccess(remotePeerConnection); }).catch(setSessionDescriptionError); trace('localPeerConnection setRemoteDescription start.'); localPeerConnection.setRemoteDescription(description) .then(() =\u003e { setRemoteDescriptionSuccess(localPeerConnection); }).catch(setSessionDescriptionError); } Пинг! Бонусные задания\nПосмотрите chrome://webrtc-internals. Там отражены статы WebRTC и отлаженные данные (Полный список ссылок в Chrome – chrome://about). Сделайте разметку страницы через CSS: Расположите видео друг за другом Сделайте кнопки такой же ширины, но с большим размером текста Убедитесь, что макет работает на мобильных устройствах В консоли Chrome Dev Tools посмотрите localStream, localPeerConnection и remotePeerConnection. Из консоли, посмотрите на localPeerConnecionpc1.localDescription. Как выглядит формат SDP? Что вы узнали?\nНа этом шаге вы узнали, как\nуйти от различий в браузерах через WebRTC оболочку adapter.js использовать RTCPeerConncetion API для потоковой передачи видео контролировать захват медиа и потоковую передачу данных делиться мультимедиа и сетевой информацией между узлами, чтоб разрешить вызов WebRTC. Полная версия этого шага находится в папке step-2. Советы\nна этом шаге вам нужно столько всего освоить! Чтобы найти другие ресурсы, объясняющие более детально RTCPeerConnection, загляните на webrtc.org. Эта страница включает решения для JavaScript фреймворков – если вы хотите использовать WebRTC, но не хотите конфликтовать с API. Узнайте больше про оболочку adapter.js из https://github.com/webrtc/adapter Хотите посмотреть, как выглядит лучшее в мире приложение для видеочата? Посмотрите на AppRTC, каноническое приложение для звонков WebRTC: приложение (https://appr.tc/) и код (https://github.com/webrtc/apprtc) . Время настройки вызова составляет менее 500 мс! Лучшая практика\nДля обеспечения надежности вашего кода в будущем используйте новые API-интерфейсы на основе промисов и включите совместимость с браузерами, которые их не поддерживают, используя adapter.js Следующий шаг\nЭтот шаг показывает, как использовать WebRTC для передачи видео между узлами – но эта codelab в том числе и о данных! В следующем шаге выясним, как передавать произвольные данные с помощью RTCDataChannel.\n","description":"Карманная книга по WebRTC","title":"Потоковое видео с помощью RTCPeerConnection","uri":"/ru/docs/webrtc/practice/practice-stream-with-rtcpeerconnection/"},{"content":"Подготовка коммит все предыдущего состояния на случай вынужденного отката\nДля того чтобы Actions имели доступ к репозиторию нужно подключить ключи шифрования\nНастройка репозитория Создаю ключи\nssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" Создалось 2 файла с ключами:\ngh-pages - приватный gh-pages.pub - публичный в Репозитории (не профиле)\nhttps://github.com/romankurnovskii/notion-project/settings/keys\nSettings → Deploy keys →Add new\nиз файла gh-pages.pub вставляю текст публичного ключа\nSettings → Secrets\nИмя: ACTIONS_DEPLOY_KEY\nВставляю приватный ключ из приватного файла gh-pages\nhttps://github.com/romankurnovskii/notion-project/settings/secrets/actions/new\nУдаляю ключи файлы чтобы случайно не закоммитить\nна гитхабе создаю экшн\nhttps://github.com/romankurnovskii/notion-project/new/main?filename=.github%2Fworkflows%2Fmain.yml\u0026workflow_template=blank\nActions → Create\nСоздание Actions Выбираю стандартный action (Deploy…)\nРедактирую нижнюю часть кода\n- name: Build run: | npm i npm run build npm run export - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./out npm run export - для создания статических файлов (добавлю позже)\nACTIONS_DEPLOY_KEY - название ключа, что создал ранее\npeaceiris/actions-gh-pages@v3 - action из другого популярного репозитория. Ссылаюсь на него.\nИтого код:\nname: Deploy to Github Pages on: push: branches: - main workflow_dispatch: jobs: deployment: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup Node uses: actions/setup-node@v3 with: node-version: \"lts/*\" cache: \"npm\" - name: Build run: | npm i npm run build npm run export - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./out открыть package.json\nнайти поле scripts, если нет создать:\n{ ..., \"scripts\": { \"dev\": \"next dev\", \"build\": \"next build\", \"start\": \"next start\", \"deploy\": \"vercel --prod\", \"export\": \"next export\" }, ... } Если npm run build \u0026\u0026 npm run export отработала, то хорошо\nОтладка Не отработала, ошибка:\ninfo - Copying \"static build\" directory info - No \"exportPathMap\" found in \"next.config.js\". Generating map from \"./pages\" Error: Image Optimization using Next.js' default loader is not compatible with `next export`. Possible solutions: - Use `next start` to run a server, which includes the Image Optimization API. - Use any provider which supports Image Optimization (like Vercel). - Configure a third-party loader in `next.config.js`. - Use the `loader` prop for `next/image`. Read more: https://nextjs.org/docs/messages/export-image-api https://nextjs.org/docs/api-reference/next.config.js/exportPathMap\nпример кода из документации\nmodule.exports = { exportPathMap: async function ( defaultPathMap, { dev, dir, outDir, distDir, buildId } ) { return { \"/\": { page: \"/\" }, \"/about\": { page: \"/about\" }, \"/p/hello-nextjs\": { page: \"/post\", query: { title: \"hello-nextjs\" } }, \"/p/learn-nextjs\": { page: \"/post\", query: { title: \"learn-nextjs\" } }, \"/p/deploy-nextjs\": { page: \"/post\", query: { title: \"deploy-nextjs\" } }, }; }, }; мой:\nmodule.exports = withBundleAnalyzer({ images: { domains: [\"pbs.twimg.com\"], }, }); Редактирую **next.config.js**\nДобавляю:\nconst repoName = '/notion-project' module.exports = { basePath: repoName, assetPrefix: repoName, ... https://github.com/romankurnovskii/notion-project/blob/main/next.config.js\nПроблема с установкой зависимости вовремя использованя npm установщика. Буду использовать yarn потому что он пропускает минорные уведомления для меня кажется более стабильным.\nПока разбирался с проблемы запуска экшенов и настройками нашёл новые экшены и без использования ключа. Обновлю код\nПосле того как я редактирую данные нужен они не меняются на сайте. Не меняются потому что гитхаб создаёт статические файлы, то есть нужно заново сделать новый билд. Для меня моментальные изменения не критичны поэтому я поставлю задачу билда повторяться каждый день в 7:00 утра\nДобавляю код в yaml файл\non: push: branches: [main] schedule: - cron: \"0 7 * * *\" ## every day 7 am Итоговый результат\nhttps://github.com/romankurnovskii/notion-project/blob/main/.github/workflows/main.yml\nlines (32 sloc) 867 Bytes name: Deploy to GitHub Pages on: push: branches: [main] schedule: - cron: \"0 7 * * *\" ## every day 7 am jobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x] steps: - name: Get files uses: actions/checkout@v2 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v2 with: node-version: ${{ matrix.node-version }} - name: Install packages run: yarn install - name: Build project run: yarn run build - name: Export static files run: yarn run export - name: Add .nojekyll file run: touch ./out/.nojekyll - name: Deploy uses: JamesIves/github-pages-deploy-action@4.1.1 #third party github actions / ok to use with: branch: gh-pages folder: out После тестового комитета и билда получаю 2 проблемы:\nСтилей нет, картинки не подгружены Ссылки не работают Next.js ожидает адрес вида https://username.github.io/\nА у меня в конце ещё добавляется репозиторий. Т.е. добавился ещё один уровень в пути\n- name: Deploy uses: JamesIves/github-pages-deploy-action@4.1.1 #third party github actions / ok to use with: branch: gh-pages folder: out - name: Add .nojekyll file run: touch ./out/.nojekyll Источники https://wallis.dev/blog/deploying-a-next-js-app-to-github-pages https://gregrickaby.blog/article/nextjs-github-pages https://medium.com/@anotherplanet/git-tips-next-js-github-pages-2dbc9a819cb8 https://www.linkedin.com/pulse/deploy-nextjs-app-github-pages-federico-antu%C3%B1a ","description":"Сайт на next.js использует данные из Notion. Сделать публикацию на github pages с помощью github actions","title":"Публикация next.js приложения на github pages","uri":"/ru/posts/nextjs-to-github-pages-ations/"},{"content":"Эта статья предлагает пример базового синтаксиса Markdown, который можно использовать в файлах содержимого Hugo, а также показывает, украшаются ли основные элементы HTML с помощью CSS в теме Hugo.\nРекомендации по оформления статьи\nЗаголовки Заголовки первого и второго уровней, выполненные с помощью подчеркивания, выглядят следующим образом:\nЗаголовок первого уровня ======================== Заголовок второго уровня ------------------------- Заголовок первого уровня Заголовок второго уровня Заголовки всех шести уровней можно обозначать и с помощью символа («#»)\n# H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 H1 H2 H3 H4 H5 H6 Параграфы Для оформления абзацев в html используются теги \u003cp\u003e\u003c/p\u003e, но в Markdown блок текста автоматически преобразуется в параграф.\nДля вставки пустой строки необходимо два раза поставить символ переноса строки (нажать на Enter)\nLorem ipsum dolor sit amet, consectetur adipisicing elit. Consequuntur eius in labore quidem, sequi suscipit! Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aliquam aut commodi debitis ipsam nobis perspiciatis sequi, sint unde vitae. Цитаты Элемент blockquote представляет содержимое, которое цитируется из другого источника, по желанию с цитатой, которая должна находиться в элементе footer или cite, и по желанию с изменениями в строке, такими как аннотации и сокращения.\nБлок-цитата без указания авторства Tiam, ad mint andaepu dandae nostion secatur sequo quae. Обратите внимание, что вы можете использовать синтаксис Markdown внутри блочной цитаты.\nБлок-цитата с указанием авторства Don’t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n\u003eЭто пример цитаты, \u003eв которой перед каждой строкой \u003eставится угловая скобка. \u003eЭто пример цитаты, в которой угловая скобка ставится только перед началом нового параграфа. \u003eВторой параграф. Это пример цитаты, в которой перед каждой строкой ставится угловая скобка.\nЭто пример цитаты, в которой угловая скобка ставится только перед началом нового параграфа. Второй параграф.\n\u003e Первый уровень цитирования \u003e\u003e Второй уровень цитирования \u003e\u003e\u003e Третий уровень цитирования \u003e \u003eПервый уровень цитирования Первый уровень цитирования\nВторой уровень цитирования\nТретий уровень цитирования\nПервый уровень цитирования\nТаблицы Таблицы не являются частью основной спецификации Markdown, но Hugo поддерживает их из коробки.\n| Name | Age | | ----- | --- | | Bob | 27 | | Alice | 23 | Name Age Bob 27 Alice 23 В ячейках разделительной строки используются только символы - и :. Символ : ставится в начале, в конце или с обеих сторон содержимого ячейки разделительной строки, чтобы обозначить выравнивание текста в соответствующем столбце по левой стороне, по правой стороне или по центру.\nКолонка по левому краю | Колонка по правому краю | Колонка по центру :--- | ---: | :---: Текст | Текст | Текст Колонка по левому краю Колонка по правому краю Колонка по центру Текст Текст Текст Markdown внутри таблицы | Italics | Bold | Code | | --------- | -------- | ------ | | *italics* | **bold** | `code` | Italics Bold Code italics bold code Блоки кода Блок кода с обратными кавычками \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Блок кода с отступом в четыре пробела \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Блок кода с внутренним шорткодом подсветки Hugo \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Списки Оформляйте заголовки единообразно. В конце заголовка точку не ставьте.\nПравильно Неправильно Получение сертификата Создание кластера Получить сертификат Создание кластера Получить сертификат Создать кластер Если требуется описать последовательность действий, используйте нумерованный список. В конце строк ставьте точку.\nЕсли порядок пунктов неважен, используйте маркированный список. Оформляйте его одним из способов:\nЕсли элементы списка — отдельные предложения, начинайте их с заглавной буквы и ставьте точку в конце. Если вводная фраза и список составляют одно предложение, то элементы списка должны начинаться со строчной буквы и завершаться точкой с запятой. Последний элемент списка завершается точкой. Если список состоит из названий или значений параметров (без пояснений), знаки в конце строк не ставьте. Упорядоченный список First item Second item Third item Чтобы оформить упорядоченный нумерованный список, используйте цифры с символом . или ). Рекомендованный формат разметки: цифра 1 и символ ..\n1. Первый пункт 1. Второй пункт 1. Третий пункт будет отображаться как:\nПервый пункт Второй пункт Третий пункт Чтобы оформить вложенный упорядоченный список, добавьте отступ для элементов дочернего списка. Допустимый размер отступа — от двух до пяти пробелов. Рекомендуемый размер отступа — четыре пробела.\nНапример, разметка:\n1. Первый пункт 1. Вложенный пункт 1. Вложенный пункт 1. Второй пункт будет отображаться как:\nПервый пункт Вложенный пункт Вложенный пункт Второй пункт Неупорядоченный список List item Another item And another item Вложенный список Fruit Apple Orange Banana Dairy Milk Cheese Другие элементы - abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n💡 Структура данных — это контейнер, который хранит данные в определённом формате. Этот контейнер решает, каким образом внешний мир может эти данные считать или изменить.\nПриведенная выше цитата взята из книги Роба Пайка talk during Gopherfest, November 18, 2015. ↩︎\n","description":"Руководство по оформлению Markdown файлов","title":"Руководство по оформлению Markdown файлов","uri":"/ru/posts/markdown-syntax/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nДелать снимок и получать из него данные, используя элемент canvas. Обмениваться изображениями с удаленным пользователем. Полная версия этого шага находится в папке step-06.\nКак это работает\nРанее вы узнали, как обмениваться текстовыми сообщениями с помощью RTCDataChannel.\nЭтот шаг позволяет обмениваться целыми файлами: в этом примере - фотографиями, снятыми с помощью getUserMedia().\nОсновные части этого шага заключаются в следующем:\nУстановите канал передачи данных. Обратите внимание, что на этом шаге вы не добавляете никаких медиапотоков к одноранговому соединению. Захватите видеопоток пользователя с веб-камеры с помощью getUserMedia(): var video = document.getElementById('video'); function grabWebCamVideo() { console.log('Getting user media (video) ...'); navigator.mediaDevices.getUserMedia({ video: true }) .then(gotStream) .catch(function(e) { alert('getUserMedia() error: ' + e.name); }); } Когда пользователь нажимает кнопку Snap, получает снимок (видеокадр) из видеопотока и отображает его в элементе canvas: var photo = document.getElementById('photo'); var photoContext = photo.getContext('2d'); function snapPhoto() { photoContext.drawImage(video, 0, 0, photo.width, photo.height); show(photo, sendBtn); } Когда пользователь нажимает кнопку Send, преобразуйте изображение в байты и отправьте их по каналу передачи данных: function sendPhoto() { // Split data channel message in chunks of this byte length. var CHUNK_LEN = 64000; var img = photoContext.getImageData(0, 0, photoContextW, photoContextH), len = img.data.byteLength, n = len / CHUNK_LEN | 0; console.log('Sending a total of ' + len + ' byte(s)'); dataChannel.send(len); // split the photo and send in chunks of about 64KB for (var i = 0; i \u003c n; i++) { var start = i * CHUNK_LEN, end = (i + 1) * CHUNK_LEN; console.log(start + ' - ' + (end - 1)); dataChannel.send(img.data.subarray(start, end)); } // send the reminder, if any if (len % CHUNK_LEN) { console.log('last ' + len % CHUNK_LEN + ' byte(s)'); dataChannel.send(img.data.subarray(n * CHUNK_LEN)); } } Принимающая сторона преобразует байты сообщений канала передачи данных обратно в изображение и отображает изображение пользователю: function receiveDataChromeFactory() { var buf, count; return function onmessage(event) { if (typeof event.data === 'string') { buf = window.buf = new Uint8ClampedArray(parseInt(event.data)); count = 0; console.log('Expecting a total of ' + buf.byteLength + ' bytes'); return; } var data = new Uint8ClampedArray(event.data); buf.set(data, count); count += data.byteLength; console.log('count: ' + count); if (count === buf.byteLength) { // we're done: all data chunks have been received console.log('Done. Rendering photo.'); renderPhoto(buf); } }; } function renderPhoto(data) { var canvas = document.createElement('canvas'); canvas.width = photoContextW; canvas.height = photoContextH; canvas.classList.add('incomingPhoto'); // trail is the element holding the incoming images trail.insertBefore(canvas, trail.firstChild); var context = canvas.getContext('2d'); var img = context.createImageData(photoContextW, photoContextH); img.data.set(data); context.putImageData(img, 0, 0); } Получите код\nЗамените содержимое вашей папки work содержимым из step-06. Ваш файл index.html в папке work теперь должен выглядеть следующим образом :\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003ch2\u003e \u003cspan\u003eRoom URL: \u003c/span\u003e\u003cspan id=\"url\"\u003e...\u003c/span\u003e \u003c/h2\u003e \u003cdiv id=\"videoCanvas\"\u003e \u003cvideo id=\"camera\" autoplay\u003e\u003c/video\u003e \u003ccanvas id=\"photo\"\u003e\u003c/canvas\u003e \u003c/div\u003e \u003cdiv id=\"buttons\"\u003e \u003cbutton id=\"snap\"\u003eSnap\u003c/button\u003e\u003cspan\u003e then \u003c/span\u003e\u003cbutton id=\"send\"\u003eSend\u003c/button\u003e \u003cspan\u003e or \u003c/span\u003e \u003cbutton id=\"snapAndSend\"\u003eSnap \u0026amp; Send\u003c/button\u003e \u003c/div\u003e \u003cdiv id=\"incoming\"\u003e \u003ch2\u003eIncoming photos\u003c/h2\u003e \u003cdiv id=\"trail\"\u003e\u003c/div\u003e \u003c/div\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Если вы не отслеживаете эту codelab из своей папки work, вам может потребоваться установить зависимости для папки step-06 или вашей текущей рабочей папки. Просто запустите следующую команду из своей рабочей папки:\nnpm install После установки, если ваш Node.js сервер не запущен, запустите его, вызвав следующую команду из вашей папки work: node index.js\nУбедитесь, что вы используете версию index.js, который реализует Socket.IO, и не забудьте перезапустить ваш сервер Node.js, если вы собираетесь что-то менять. Для большей информации на Node и Socket.IO, загляните в раздел «Set up a signaling service to exchange messages».\nПри необходимости нажмите на кнопку Allow, чтобы разрешить приложению использовать вашу веб-камеру.\nПриложение создаст случайный ID комнаты, и добавьте этот ID в URL. Откройте URL из адресной стройки в новой вкладке или окне браузера.\nНажмите кнопку Snap\u0026Send и затем посмотрите входящую область в другой вкладке внизу страницы. Приложение переносит фотографии между вкладками.\nВы должны увидеть что-то типа этого:\nБонусные задания:\nКак вы можете изменить код, чтобы сделать возможным совместное использование файлов любого типа? Узнайте больше\nThe MediaStream Image Capture API (https://www.chromestatus.com/features/4843864737185792): API для фотосъемки и управления камерами — скоро появится в браузере! API MediaRecorder для записи аудио и видео: демо-примеры (https://webrtc.github.io/samples/src/content/getusermedia/record/) и документация (https://www.chromestatus.com/features/5929649028726784) Что вы узнали\nКак делать фото и получать из нее данные с помощью элемента canvas. Как обмениваться этими данными с удаленным пользователем. Полная версия этого шага находится в папке step-06.\n","description":"Карманная книга по WebRTC","title":"Сделайте фото и отправьте его через канал данных","uri":"/ru/docs/webrtc/practice/practice-take-photo/"},{"content":"Дата Текущая import datetime x = datetime.datetime.now() # 2022-08-04 21:41:24.871910 Формат YYYY-MM-DD import datetime x = datetime.datetime.now().strftime(\"%Y-%m-%d\") # 2022-08-04 Создать папку import os if not os.path.exists(name): os.makedirs(name) Поиск наиболее часто встречаемого значения в списке import collections x = [1, 2, 7, 4, 5, 6, 7, 10] print(collections.Counter(x).most_common(1)[0][0]) # 7 def most_freq(list): return max(set(list), key=list.count) test = [10, 10, 20, 20, 10, 30, 30, 30, 20, 10] print(most_freq(test)) # 10 Случайное целое число import random x = random.randint(1, 10) # 9 Одновременная проверка нескольких флагов в Python x, y, z = 0, 1, 0 if x == 1 or y == 1 or z == 1: print('passed') if 1 in (x, y, z): print('passed') # These only test for truthiness: if x or y or z: print('passed') if any((x, y, z)): print('passed') Pdf -\u003e Audio import PyPDF2, pyttsx3 # PDF file path = open('clcoding.pdf', 'rb') # creating a PdfFileReader object pdfReader = PyPDF2.PdfFileReader(path) # Get an engine instance for the speech synthesis speak = pyttsx3.init() for pages in range(pdfReader.numPages): text = pdfReader.getPage(pages).extractText() speak.say(text) speak.runAndWait() speak.stop() Полный обзор # Однострочные комментарии начинаются с символа решётки. \"\"\" Многострочный текст может быть записан, используя 3 знака \" и обычно используется в качестве встроенной документации \"\"\" #################################################### ## 1. Примитивные типы данных и операторы #################################################### # У вас есть числа 3 # =\u003e 3 # Математика работает вполне ожидаемо 1 + 1 # =\u003e 2 8 - 1 # =\u003e 7 10 * 2 # =\u003e 20 35 / 5 # =\u003e 7.0 # Результат целочисленного деления округляется в меньшую сторону # как для положительных, так и для отрицательных чисел. 5 // 3 # =\u003e 1 -5 // 3 # =\u003e -2 5.0 // 3.0 # =\u003e 1.0 # работает и для чисел с плавающей запятой -5.0 // 3.0 # =\u003e -2.0 # # Результат деления возвращает число с плавающей запятой 10.0 / 3 # =\u003e 3.3333333333333335 # Остаток от деления 7 % 3 # =\u003e 1 # Возведение в степень 2**3 # =\u003e 8 # Приоритет операций указывается скобками 1 + 3 * 2 # =\u003e 7 (1 + 3) * 2 # =\u003e 8 # Булевы значения - примитивы (Обратите внимание на заглавную букву) True # =\u003e True False # =\u003e False # Для отрицания используется ключевое слово not not True # =\u003e False not False # =\u003e True # Булевы операторы # Обратите внимание: ключевые слова \"and\" и \"or\" чувствительны к регистру букв True and False # =\u003e False False or True # =\u003e True # True и False на самом деле 1 и 0, но с разными ключевыми словами True + True # =\u003e 2 True * 8 # =\u003e 8 False - 5 # =\u003e -5 # Операторы сравнения обращают внимание на числовое значение True и False 0 == False # =\u003e True 1 == True # =\u003e True 2 == True # =\u003e False -5 != False # =\u003e True # Использование булевых логических операторов на типах int превращает их в булевы значения, но возвращаются оригинальные значения # Не путайте с bool(ints) и bitwise and/or (\u0026,|) bool(0) # =\u003e False bool(4) # =\u003e True bool(-6) # =\u003e True 0 and 2 # =\u003e 0 -5 or 0 # =\u003e -5 # Равенство — это == 1 == 1 # =\u003e True 2 == 1 # =\u003e False # Неравенство — это != 1 != 1 # =\u003e False 2 != 1 # =\u003e True # Ещё немного сравнений 1 \u003c 10 # =\u003e True 1 \u003e 10 # =\u003e False 2 \u003c= 2 # =\u003e True 2 \u003e= 2 # =\u003e True # Проверка, находится ли значение в диапазоне 1 \u003c 2 and 2 \u003c 3 # =\u003e True 2 \u003c 3 and 3 \u003c 2 # =\u003e False # Сравнения могут быть записаны цепочкой 1 \u003c 2 \u003c 3 # =\u003e True 2 \u003c 3 \u003c 2 # =\u003e False # (is vs. ==) ключевое слово is проверяет, относятся ли две переменные к одному и тому же объекту, но == проверяет если указанные объекты имеют одинаковые значения. a = [1, 2, 3, 4] # a указывает на новый список, [1, 2, 3, 4] b = a # b указывает на то, что указывает a b is a # =\u003e True, a и b относятся к одному и тому же объекту b == a # =\u003e True, Объекты a и b равны b = [1, 2, 3, 4] # b указывает на новый список, [1, 2, 3, 4] b is a # =\u003e False, a и b не относятся к одному и тому же объекту b == a # =\u003e True, Объекты a и b равны # Строки определяются символом \" или ' \"Это строка.\" 'Это тоже строка.' # И строки тоже могут складываться! Хотя лучше не злоупотребляйте этим. \"Привет \" + \"мир!\" # =\u003e \"Привет мир!\" # Строки (но не переменные) могут быть объединены без использования '+' \"Привет \" \"мир!\" # =\u003e \"Привет мир!\" # Со строкой можно работать, как со списком символов \"Привет мир!\"[0] # =\u003e 'П' # Вы можете найти длину строки len(\"Это строка\") # =\u003e 10 # Вы также можете форматировать, используя f-строки (в Python 3.6+) name = \"Рейко\" f\"Она сказала, что ее зовут {name}.\" # =\u003e \"Она сказала, что ее зовут Рейко\" # Вы можете поместить любой оператор Python в фигурные скобки, и он будет выведен в строке. f\"{name} состоит из {len(name)} символов.\" # =\u003e \"Рэйко состоит из 5 символов.\" # None является объектом None # =\u003e None # Не используйте оператор равенства \"==\" для сравнения # объектов с None. Используйте для этого \"is\" \"etc\" is None # =\u003e False None is None # =\u003e True # None, 0 и пустые строки/списки/словари/кортежи приводятся к False. # Все остальные значения равны True bool(0) # =\u003e False bool(\"\") # =\u003e False bool([]) # =\u003e False bool({}) # =\u003e False bool(()) # =\u003e False #################################################### ## 2. Переменные и Коллекции #################################################### # В Python есть функция Print print(\"Я Python. Приятно познакомиться!\") # =\u003e Я Python. Приятно познакомиться! # По умолчанию функция, print() также выводит новую строку в конце. # Используйте необязательный аргумент end, чтобы изменить последнюю строку. print(\"Привет мир\", end=\"!\") # =\u003e Привет мир! # Простой способ получить входные данные из консоли input_string_var = input(\"Введите данные: \") # Возвращает данные в виде строки # Примечание: в более ранних версиях Python метод input() назывался raw_input() # Объявлять переменные перед инициализацией не нужно. # По соглашению используется нижний_регистр_с_подчёркиваниями some_var = 5 some_var # =\u003e 5 # При попытке доступа к неинициализированной переменной выбрасывается исключение. # Об исключениях см. раздел \"Поток управления и итерируемые объекты\". some_unknown_var # Выбрасывает ошибку NameError # if можно использовать как выражение # Эквивалент тернарного оператора '?:' в C \"да!\" if 0 \u003e 1 else \"нет!\" # =\u003e \"нет!\" # Списки хранят последовательности li = [] # Можно сразу начать с заполненного списка other_li = [4, 5, 6] # Объекты добавляются в конец списка методом append() li.append(1) # [1] li.append(2) # [1, 2] li.append(4) # [1, 2, 4] li.append(3) # [1, 2, 4, 3] # И удаляются с конца методом pop() li.pop() # =\u003e возвращает 3 и li становится равен [1, 2, 4] # Положим элемент обратно li.append(3) # [1, 2, 4, 3]. # Обращайтесь со списком, как с обычным массивом li[0] # =\u003e 1 # Обратимся к последнему элементу li[-1] # =\u003e 3 # Попытка выйти за границы массива приведёт к ошибке индекса li[4] # Выбрасывает ошибку IndexError # Можно обращаться к диапазону, используя так называемые срезы # (Для тех, кто любит математику, это называется замкнуто-открытый интервал). li[1:3] # Вернуть список из индекса с 1 по 3 =\u003e [2, 4] li[2:] # Вернуть список, начиная с индекса 2 =\u003e [4, 3] li[:3] # Вернуть список с начала до индекса 3 =\u003e [1, 2, 4] li[::2] # Вернуть список, выбирая каждую вторую запись =\u003e [1, 4] li[::-1] # Вернуть список в обратном порядке =\u003e [3, 4, 2, 1] # Используйте сочетания всего вышеназванного для выделения более сложных срезов # li[начало:конец:шаг] # Сделать однослойную глубокую копию, используя срезы li2 = li[:] # =\u003e li2 = [1, 2, 4, 3], но (li2 is li) вернет False. # Удаляем произвольные элементы из списка оператором del del li[2] # [1, 2, 3] # Удалить первое вхождение значения li.remove(2) # [1, 3] li.remove(2) # Выбрасывает ошибку ValueError поскольку 2 нет в списке # Вставить элемент по определенному индексу li.insert(1, 2) # [1, 2, 3] # Получить индекс первого найденного элемента, соответствующего аргументу li.index(2) # =\u003e 1 li.index(4) # Выбрасывает ошибку ValueError поскольку 4 нет в списке # Вы можете складывать, или, как ещё говорят, конкатенировать списки # Обратите внимание: значения li и other_li при этом не изменились. li + other_li # =\u003e [1, 2, 3, 4, 5, 6] # Объединять списки можно методом extend() li.extend(other_li) # Теперь li содержит [1, 2, 3, 4, 5, 6] # Проверить элемент на наличие в списке можно оператором in 1 in li # =\u003e True # Длина списка вычисляется функцией len len(li) # =\u003e 6 # Кортежи похожи на списки, только неизменяемые tup = (1, 2, 3) tup[0] # =\u003e 1 tup[0] = 3 # Выбрасывает ошибку TypeError # Обратите внимание, что кортеж длины 1 должен иметь запятую после последнего элемента, но кортежи другой длины, даже 0, не должны. type((1)) # =\u003e \u003cclass 'int'\u003e type((1,)) # =\u003e \u003cclass 'tuple'\u003e type(()) # =\u003e \u003cclass 'tuple'\u003e # Всё то же самое можно делать и с кортежами len(tup) # =\u003e 3 tup + (4, 5, 6) # =\u003e (1, 2, 3, 4, 5, 6) tup[:2] # =\u003e (1, 2) 2 in tup # =\u003e True # Вы можете распаковывать кортежи (или списки) в переменные a, b, c = (1, 2, 3) # a == 1, b == 2 и c == 3 # Вы также можете сделать расширенную распаковку a, *b, c = (1, 2, 3, 4) # a теперь 1, b теперь [2, 3] и c теперь 4 # Кортежи создаются по умолчанию, если опущены скобки d, e, f = 4, 5, 6 # кортеж 4, 5, 6 распаковывается в переменные d, e и f # соответственно, d = 4, e = 5 и f = 6 # Обратите внимание, как легко поменять местами значения двух переменных e, d = d, e # теперь d == 5, а e == 4 # Словари содержат ассоциативные массивы empty_dict = {} # Вот так описывается предзаполненный словарь filled_dict = {\"one\": 1, \"two\": 2, \"three\": 3} # Обратите внимание, что ключи для словарей должны быть неизменяемыми типами. Это # сделано для того, чтобы ключ может быть преобразован в хеш для быстрого поиска. # Неизменяемые типы включают целые числа, числа с плавающей запятой, строки, кортежи. invalid_dict = {[1,2,3]: \"123\"} # =\u003e Выбрасывает ошибку TypeError: unhashable type: 'list' valid_dict = {(1,2,3):[1,2,3]} # Однако значения могут быть любого типа. # Поиск значений с помощью [] filled_dict[\"one\"] # =\u003e 1 # Все ключи в виде списка получаются с помощью метода keys(). # Его вызов нужно обернуть в list(), так как обратно мы получаем # итерируемый объект, о которых поговорим позднее. Примечание - для Python # версии \u003c3.7, порядок словарных ключей не гарантируется. Ваши результаты могут # не точно соответствовать приведенному ниже примеру. Однако, начиная с Python 3.7 # элементы в словаре сохраняют порядок, в котором они вставляются в словарь. list(filled_dict.keys()) # =\u003e [\"three\", \"two\", \"one\"] в Python \u003c3.7 list(filled_dict.keys()) # =\u003e [\"one\", \"two\", \"three\"] в Python 3.7+ # Все значения в виде списка можно получить с помощью values(). # И снова нам нужно обернуть вызов в list(), чтобы превратить # итерируемый объект в список. # То же самое замечание насчёт порядка ключей справедливо и здесь list(filled_dict.values()) # =\u003e [3, 2, 1] в Python \u003c3.7 list(filled_dict.values()) # =\u003e [1, 2, 3] в Python 3.7+ # При помощи ключевого слова in можно проверять наличие ключей в словаре \"one\" in filled_dict # =\u003e True 1 in filled_dict # =\u003e False # Попытка получить значение по несуществующему ключу выбросит ошибку KeyError filled_dict[\"four\"] # Выбрасывает ошибку KeyError # Чтобы избежать этого, используйте метод get() filled_dict.get(\"one\") # =\u003e 1 filled_dict.get(\"four\") # =\u003e None # Метод get поддерживает аргумент по умолчанию, когда значение отсутствует filled_dict.get(\"one\", 4) # =\u003e 1 filled_dict.get(\"four\", 4) # =\u003e 4 # Метод setdefault() вставляет пару ключ-значение, только если такого ключа нет filled_dict.setdefault(\"five\", 5) # filled_dict[\"five\"] возвращает 5 filled_dict.setdefault(\"five\", 6) # filled_dict[\"five\"] по-прежнему возвращает 5 # Добавление элементов в словарь filled_dict.update({\"four\":4}) # =\u003e {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4} filled_dict[\"four\"] = 4 # Другой способ добавления элементов # Удаляйте ключи из словаря с помощью ключевого слова del del filled_dict[\"one\"] # Удаляет ключ \"one\" из словаря # После Python 3.5 вы также можете использовать дополнительные параметры распаковки {'a': 1, **{'b': 2}} # =\u003e {'a': 1, 'b': 2} {'a': 1, **{'a': 2}} # =\u003e {'a': 2} # Множества содержат... ну, в общем, множества empty_set = set() # Инициализация множества набором значений. # Да, оно выглядит примерно как словарь. Ну извините, так уж вышло. filled_set = {1, 2, 2, 3, 4} # =\u003e {1, 2, 3, 4} # Similar to keys of a dictionary, elements of a set have to be immutable. # Как и ключи словаря, элементы множества должны быть неизменяемыми. invalid_set = {[1], 1} # =\u003e Выбрасывает ошибку TypeError: unhashable type: 'list' valid_set = {(1,), 1} # Множеству можно назначать новую переменную filled_set = some_set filled_set.add(5) # {1, 2, 3, 4, 5} # В множествах нет повторяющихся элементов filled_set.add(5) # {1, 2, 3, 4, 5} # Пересечение множеств: \u0026 other_set = {3, 4, 5, 6} filled_set \u0026 other_set # =\u003e {3, 4, 5} # Объединение множеств: | filled_set | other_set # =\u003e {1, 2, 3, 4, 5, 6} # Разность множеств: - {1, 2, 3, 4} - {2, 3, 5} # =\u003e {1, 4} # Симметричная разница: ^ {1, 2, 3, 4} ^ {2, 3, 5} # =\u003e {1, 4, 5} # Проверить, является ли множество слева надмножеством множества справа {1, 2} \u003e= {1, 2, 3} # =\u003e False # Проверить, является ли множество слева подмножеством множества справа {1, 2} \u003c= {1, 2, 3} # =\u003e True # Проверка на наличие в множестве: in 2 in filled_set # =\u003e True 10 in filled_set # =\u003e False # Сделать однослойную глубокую копию filled_set = some_set.copy() # {1, 2, 3, 4, 5} filled_set is some_set # =\u003e False #################################################### ## 3. Поток управления и итерируемые объекты #################################################### # Для начала создадим переменную some_var = 5 # Так выглядит выражение if. Отступы в python очень важны! # Конвенция заключается в использовании четырех пробелов, а не табуляции. # Pезультат: \"some_var меньше, чем 10\" if some_var \u003e 10: print(\"some_var точно больше, чем 10.\") elif some_var \u003c 10: # Выражение elif необязательно. print(\"some_var меньше, чем 10.\") else: # Это тоже необязательно. print(\"some_var равно 10.\") \"\"\" Циклы For проходят по спискам. Выводит: собака — это млекопитающее кошка — это млекопитающее мышь — это млекопитающее \"\"\" for animal in [\"собака\", \"кошка\", \"мышь\"]: # Можете использовать format() для интерполяции форматированных строк print(\"{} — это млекопитающее\".format(animal)) \"\"\" \"range(число)\" возвращает список чисел от нуля до заданного числа Выводит: 0 1 2 3 \"\"\" for i in range(4): print(i) \"\"\" \"range(нижнее, верхнее)\" возвращает список чисел от нижнего числа к верхнему Выводит: 4 5 6 7 \"\"\" for i in range(4, 8): print(i) \"\"\" \"range(нижнее, верхнее, шаг)\" возвращает список чисел от нижнего числа к верхнему, от нижнего числа к верхнему, увеличивая шаг за шагом. Если шаг не указан, значение по умолчанию - 1. Выводит: 4 6 \"\"\" for i in range(4, 8, 2): print(i) \"\"\" Чтобы перебрать список и получить индекс и значение каждого элемента в списке Выводит: 0 собака 1 кошка 2 мышь \"\"\" animals = [\"собака\", \"кошка\", \"мышь\"] for i, value in enumerate(animals): print(i, value) \"\"\" Циклы while продолжаются до тех пор, пока указанное условие не станет ложным. Выводит: 0 1 2 3 \"\"\" x = 0 while x \u003c 4: print(x) x += 1 # Краткая запись для x = x + 1 # Обрабатывайте исключения блоками try/except try: # Чтобы выбросить ошибку, используется raise raise IndexError(\"Это ошибка индекса\") except IndexError as e: pass # pass — это просто отсутствие оператора. Обычно здесь происходит восстановление после ошибки. except (TypeError, NameError): pass # Несколько исключений можно обработать вместе, если нужно. else: # Необязательное выражение. Должно следовать за последним блоком except print(\"Всё хорошо!\") # Выполнится, только если не было никаких исключений finally: # Выполнить при любых обстоятельствах print(\"Мы можем очистить ресурсы здесь\") # Вместо try/finally чтобы очистить ресурсы, можно использовать оператор with with open(\"myfile.txt\") as f: for line in f: print(line) # Запись в файл contents = {\"aa\": 12, \"bb\": 21} with open(\"myfile1.txt\", \"w+\") as file: file.write(str(contents)) # Записывает строку в файл with open(\"myfile2.txt\", \"w+\") as file: file.write(json.dumps(contents)) # Записывает объект в файл # Чтение из файла with open('myfile1.txt', \"r+\") as file: contents = file.read() # Читает строку из файла print(contents) # print: {\"aa\": 12, \"bb\": 21} with open('myfile2.txt', \"r+\") as file: contents = json.load(file) # Читает объект json из файла print(contents) # print: {\"aa\": 12, \"bb\": 21} # Python предоставляет фундаментальную абстракцию, # которая называется итерируемым объектом (Iterable). # Итерируемый объект — это объект, который воспринимается как последовательность. # Объект, который возвратила функция range(), итерируемый. filled_dict = {\"one\": 1, \"two\": 2, \"three\": 3} our_iterable = filled_dict.keys() print(our_iterable) # =\u003e dict_keys(['one', 'two', 'three']). Это объект, реализующий интерфейс Iterable # Мы можем проходить по нему циклом. for i in our_iterable: print(i) # Выводит one, two, three # Но мы не можем обращаться к элементу по индексу. our_iterable[1] # Выбрасывает ошибку TypeError # Итерируемый объект знает, как создавать итератор. our_iterator = iter(our_iterable) # Итератор может запоминать состояние при проходе по объекту. # Мы получаем следующий объект, вызывая функцию next(). next(our_iterator) # =\u003e \"one\" # Он сохраняет состояние при вызове next(). next(our_iterator) # =\u003e \"two\" next(our_iterator) # =\u003e \"three\" # Возвратив все данные, итератор выбрасывает исключение StopIterator next(our_iterator) # Выбрасывает исключение StopIteration # Мы можем проходить по нему циклом. our_iterator = iter(our_iterable) for i in our_iterator: print(i) # Выводит one, two, three # Вы можете получить сразу все элементы итератора, вызвав на нём функцию list(). list(our_iterable) # =\u003e Возвращает [\"one\", \"two\", \"three\"] list(our_iterator) # =\u003e Возвращает [] потому что состояние сохраняется #################################################### ## 4. Функции #################################################### # Используйте def для создания новых функций def add(x, y): print(\"x равен %s, а y равен %s\" % (x, y)) return x + y # Возвращайте результат с помощью ключевого слова return # Вызов функции с аргументами add(5, 6) # =\u003e Выводит \"x равен 5, а y равен 6\" и возвращает 11 # Другой способ вызова функции — вызов с именованными аргументами add(y=6, x=5) # Именованные аргументы можно указывать в любом порядке. # Вы можете определить функцию, принимающую переменное число аргументов def varargs(*args): return args varargs(1, 2, 3) # =\u003e (1,2,3) # А также можете определить функцию, принимающую переменное число # именованных аргументов def keyword_args(**kwargs): return kwargs # Вызовем эту функцию и посмотрим, что из этого получится keyword_args(big=\"foot\", loch=\"ness\") # =\u003e {\"big\": \"foot\", \"loch\": \"ness\"} # Если хотите, можете использовать оба способа одновременно def all_the_args(*args, **kwargs): print(args) print(kwargs) \"\"\" all_the_args(1, 2, a=3, b=4) выводит: (1, 2) {\"a\": 3, \"b\": 4} \"\"\" # Вызывая функции, можете сделать наоборот! # Используйте символ * для распаковки кортежей и ** для распаковки словарей args = (1, 2, 3, 4) kwargs = {\"a\": 3, \"b\": 4} all_the_args(*args) # эквивалентно all_the_args(1, 2, 3, 4) all_the_args(**kwargs) # эквивалентно all_the_args(a=3, b=4) all_the_args(*args, **kwargs) # эквивалентно all_the_args(1, 2, 3, 4, a=3, b=4) # Возврат нескольких значений (с назначением кортежей) def swap(x, y): return y, x # Возвращает несколько значений в виде кортежа без скобок. # (Примечание: скобки исключены, но могут быть включены) x = 1 y = 2 x, y = swap(x, y) # =\u003e x = 2, y = 1 # (x, y) = swap(x,y) # Снова, скобки были исключены, но могут быть включены. # Область определения функций x = 5 def set_x(num): # Локальная переменная x — это не то же самое, что глобальная переменная x x = num # =\u003e 43 print(x) # =\u003e 43 def set_global_x(num): global x print(x) # =\u003e 5 x = num # Глобальная переменная x теперь равна 6 print(x) # =\u003e 6 set_x(43) set_global_x(6) # Python имеет функции первого класса def create_adder(x): def adder(y): return x + y return adder add_10 = create_adder(10) add_10(3) # =\u003e 13 # Также есть и анонимные функции (lambda x: x \u003e 2)(3) # =\u003e True (lambda x, y: x ** 2 + y ** 2)(2, 1) # =\u003e 5 # Есть встроенные функции высшего порядка list(map(add_10, [1, 2, 3])) # =\u003e [11, 12, 13] list(map(max, [1, 2, 3], [4, 2, 1])) # =\u003e [4, 2, 3] list(filter(lambda x: x \u003e 5, [3, 4, 5, 6, 7])) # =\u003e [6, 7] # Для удобного отображения и фильтрации можно использовать списочные интерпретации # Интерпретация списка сохраняет вывод в виде списка, который сам может быть вложенным списком [add_10(i) for i in [1, 2, 3]] # =\u003e [11, 12, 13] [x for x in [3, 4, 5, 6, 7] if x \u003e 5] # =\u003e [6, 7] # Вы также можете создавать интерпретации множеств и словарей. {x for x in 'abcddeef' if x not in 'abc'} # =\u003e {'d', 'e', 'f'} {x: x**2 for x in range(5)} # =\u003e {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} #################################################### ## 5. Модули #################################################### # Вы можете импортировать модули import math print(math.sqrt(16)) # =\u003e 4.0 # Вы можете получить определенные функции из модуля from math import ceil, floor print(ceil(3.7)) # =\u003e 4.0 print(floor(3.7)) # =\u003e 3.0 # Вы можете импортировать все функции из модуля. # Предупреждение: это не рекомендуется from math import * # Вы можете сократить имена модулей import math as m math.sqrt(16) == m.sqrt(16) # =\u003e True # Модули Python - это обычные файлы Python. Вы # можете писать свои собственные и импортировать их. Имя # модуля совпадает с именем файла. # Вы можете узнать, какие функции и атрибуты # определены в модуле. import math dir(math) # Если у вас есть скрипт Python с именем math.py в той же папке, # что и ваш текущий скрипт, файл math.py будет # будет загружен вместо встроенного модуля Python. # Это происходит потому, что локальная папка имеет приоритет # над встроенными библиотеками Python. #################################################### ## 6. Классы #################################################### # Мы используем оператор class для создания класса class Human: # Атрибут класса. Он используется всеми экземплярами этого класса species = \"Гомосапиенс\" # Обычный конструктор, вызывается при инициализации экземпляра класса # Обратите внимание, что двойное подчёркивание в начале и в конце имени # означает объекты и атрибуты, которые используются Python, но находятся # в пространствах имён, управляемых пользователем. # Методы (или объекты или атрибуты), например: # __init__, __str__, __repr__ и т. д. называются специальными методами. # Не придумывайте им имена самостоятельно. def __init__(self, name): # Присваивание значения аргумента атрибуту self.name = name # Инициализация свойства self._age = 0 # Метод экземпляра. Все методы принимают self в качестве первого аргумента def say(self, msg): return \"{name}: {message}\".format(name=self.name, message=msg) # Другой метод экземпляра def sing(self): return 'йо... йо... проверка микрофона... раз, два... раз, два...' # Метод класса разделяется между всеми экземплярами # Они вызываются с указыванием вызывающего класса в качестве первого аргумента @classmethod def get_species(cls): return cls.species # Статический метод вызывается без ссылки на класс или экземпляр @staticmethod def grunt(): return \"*grunt*\" # property похоже на геттер. # Оно превращает метод age() в одноименный атрибут только для чтения. # Однако нет необходимости писать тривиальные геттеры и сеттеры в Python. @property def age(self): return self._age # Это позволяет установить свойство @age.setter def age(self, age): self._age = age # Это позволяет удалить свойство @age.deleter def age(self): del self._age # Когда интерпретатор Python читает исходный файл, он выполняет весь его код. # Проверка __name__ гарантирует, что этот блок кода выполняется только тогда, когда # этот модуль - это основная программа. if __name__ == '__main__': # Инициализация экземпляра класса i = Human(name=\"Иван\") i.say(\"привет\") # Выводит: \"Иван: привет\" j = Human(\"Пётр\") j.say(\"привет\") # Выводит: \"Пётр: привет\" # i и j являются экземплярами типа Human, или другими словами: они являются объектами Human # Вызов метода класса i.say(i.get_species()) # \"Иван: Гомосапиенс\" # Изменение разделяемого атрибута Human.species = \"Неандертальец\" i.say(i.get_species()) # =\u003e \"Иван: Неандертальец\" j.say(j.get_species()) # =\u003e \"Пётр: Неандертальец\" # Вызов статического метода print(Human.grunt()) # =\u003e \"*grunt*\" # Невозможно вызвать статический метод с экземпляром объекта # потому что i.grunt() автоматически поместит \"self\" (объект i) в качестве аргумента print(i.grunt()) # =\u003e TypeError: grunt() takes 0 positional arguments but 1 was given # Обновить свойство для этого экземпляра i.age = 42 # Получить свойство i.say(i.age) # =\u003e \"Иван: 42\" j.say(j.age) # =\u003e \"Пётр: 0\" # Удалить свойство del i.age # i.age # =\u003e это выбрасило бы ошибку AttributeError #################################################### ## 6.1 Наследование #################################################### # Наследование позволяет определять новые дочерние классы, которые наследуют методы и # переменные от своего родительского класса. # Используя класс Human, определенный выше как базовый или родительский класс, мы можем # определить дочерний класс Superhero, который наследует переменные класса, такие как # \"species\", \"name\" и \"age\", а также методы, такие как \"sing\" и \"grunt\" из класса Human, # но также может иметь свои уникальные свойства. # Чтобы воспользоваться преимуществами модульности по файлам, вы можете поместить # вышеперечисленные классы в их собственные файлы, например, human.py # Чтобы импортировать функции из других файлов, используйте следующий формат # from \"имя-файла-без-расширения\" import \"функция-или-класс\" from human import Human # Укажите родительский класс(ы) как параметры определения класса class Superhero(Human): # Если дочерний класс должен наследовать все определения родителя без каких-либо # изменений, вы можете просто использовать ключевое слово pass (и ничего больше), # но в этом случае оно закомментировано, чтобы разрешить уникальный дочерний класс: # pass # Дочерние классы могут переопределять атрибуты своих родителей species = 'Сверхчеловек' # Дочерние классы автоматически наследуют конструктор родительского класса, включая # его аргументы, но также могут определять дополнительные аргументы или определения # и переопределять его методы, такие как конструктор класса. # Этот конструктор наследует аргумент \"name\" от класса \"Human\" # и добавляет аргументы \"superpower\" и \"movie\": def __init__(self, name, movie=False, superpowers=[\"сверхсила\", \"пуленепробиваемость\"]): # добавить дополнительные атрибуты класса: self.fictional = True self.movie = movie # помните об изменяемых значениях по умолчанию, # поскольку значения по умолчанию являются общими self.superpowers = superpowers # Функция \"super\" позволяет вам получить доступ к методам родительского класса, # которые переопределяются дочерним, в данном случае, методом __init__. # Это вызывает конструктор родительского класса: super().__init__(name) # переопределить метод sing def sing(self): return 'Бам, бам, БАМ!' # добавить дополнительный метод экземпляра def boast(self): for power in self.superpowers: print(\"Я обладаю силой '{pow}'!\".format(pow=power)) if __name__ == '__main__': sup = Superhero(name=\"Тик\") # Проверка типа экземпляра if isinstance(sup, Human): print('Я человек') if type(sup) is Superhero: print('Я супергерой') # Получить порядок поиска разрешения метода (MRO), # используемый как getattr(), так и super() # Этот атрибут является динамическим и может быть обновлен print(Superhero.__mro__) # =\u003e (\u003cclass '__main__.Superhero'\u003e, # =\u003e \u003cclass 'human.Human'\u003e, \u003cclass 'object'\u003e) # Вызывает родительский метод, но использует свой собственный атрибут класса print(sup.get_species()) # =\u003e Сверхчеловек # Вызов переопределенного метода print(sup.sing()) # =\u003e Бам, бам, БАМ! # Вызывает метод из Human sup.say('Ложка') # =\u003e Тик: Ложка # Метод вызова, существующий только в Superhero sup.boast() # =\u003e Я обладаю силой 'сверхсила'! # =\u003e Я обладаю силой 'пуленепробиваемость'! # Атрибут унаследованного класса sup.age = 31 print(sup.age) # =\u003e 31 # Атрибут, который существует только в Superhero print('Достоин ли я Оскара? ' + str(sup.movie)) #################################################### ## 6.2 Множественное наследование #################################################### # Eще одно определение класса # bat.py class Bat: species = 'Летучая мышь' def __init__(self, can_fly=True): self.fly = can_fly # В этом классе также есть метод say def say(self, msg): msg = '... ... ...' return msg # И свой метод тоже def sonar(self): return '))) ... (((' if __name__ == '__main__': b = Bat() print(b.say('привет')) print(b.fly) # И еще одно определение класса, унаследованное от Superhero и Bat # superhero.py from superhero import Superhero from bat import Bat # Определите Batman как дочерний класс, унаследованный от Superhero и Bat class Batman(Superhero, Bat): def __init__(self, *args, **kwargs): # Обычно для наследования атрибутов необходимо вызывать super: # super(Batman, self).__init__(*args, **kwargs) # Однако здесь мы имеем дело с множественным наследованием, а super() # работает только со следующим базовым классом в списке MRO. # Поэтому вместо этого мы вызываем __init__ для всех родителей. # Использование *args и **kwargs обеспечивает чистый способ передачи # аргументов, когда каждый родитель \"очищает слой луковицы\". Superhero.__init__(self, 'анонимный', movie=True, superpowers=['Богатый'], *args, **kwargs) Bat.__init__(self, *args, can_fly=False, **kwargs) # переопределить значение атрибута name self.name = 'Грустный Бен Аффлек' def sing(self): return 'на на на на на бэтмен!' if __name__ == '__main__': sup = Batman() # Получить порядок поиска разрешения метода (MRO), # используемый как getattr(), так и super() # Этот атрибут является динамическим и может быть обновлен print(Batman.__mro__) # =\u003e (\u003cclass '__main__.Batman'\u003e, # =\u003e \u003cclass 'superhero.Superhero'\u003e, # =\u003e \u003cclass 'human.Human'\u003e, # =\u003e \u003cclass 'bat.Bat'\u003e, \u003cclass 'object'\u003e) # Вызывает родительский метод, но использует свой собственный атрибут класса print(sup.get_species()) # =\u003e Сверхчеловек # Вызов переопределенного метода print(sup.sing()) # =\u003e на на на на на бэтмен! # Вызывает метод из Human, потому что порядок наследования имеет значение sup.say('Я согласен') # =\u003e Грустный Бен Аффлек: Я согласен # Вызов метода, существующий только во втором родителе print(sup.sonar()) # =\u003e ))) ... ((( # Атрибут унаследованного класса sup.age = 100 print(sup.age) # =\u003e 100 # Унаследованный атрибут от второго родителя, # значение по умолчанию которого было переопределено. print('Могу ли я летать? ' + str(sup.fly)) # =\u003e Могу ли я летать? False #################################################### ## 7. Дополнительно #################################################### # Генераторы помогут выполнить ленивые вычисления def double_numbers(iterable): for i in iterable: yield i + i # Генераторы эффективны с точки зрения памяти, потому что они загружают только данные, # необходимые для обработки следующего значения в итерации. # Это позволяет им выполнять операции с недопустимо большими диапазонами значений. # ПРИМЕЧАНИЕ: \"range\" заменяет \"xrange\" в Python 3. for i in double_numbers(range(1, 900000000)): # \"range\" - генератор. print(i) if i \u003e= 30: break # Так же, как вы можете создать интерпретации списков, вы можете создать и # интерпретации генераторов. values = (-x for x in [1,2,3,4,5]) for x in values: print(x) # Выводит -1 -2 -3 -4 -5 # Вы также можете преобразовать интерпретацию генератора непосредственно в список. values = (-x for x in [1,2,3,4,5]) gen_to_list = list(values) print(gen_to_list) # =\u003e [-1, -2, -3, -4, -5] # Декораторы # В этом примере \"beg\" оборачивает \"say\". # Если say_please равно True, он изменит возвращаемое сообщение. from functools import wraps def beg(target_function): @wraps(target_function) def wrapper(*args, **kwargs): msg, say_please = target_function(*args, **kwargs) if say_please: return \"{} {}\".format(msg, \"Пожалуйста! Спасибо :)\") return msg return wrapper @beg def say(say_please=False): msg = \"Вы не купите мне сока?\" return msg, say_please print(say()) # Вы не купите мне сока? print(say(say_please=True)) # Вы не купите мне сока? Пожалуйста! Спасибо :) ","description":"Сниппеты Python","title":"Сниппеты Python","uri":"/ru/posts/python-snippets/"},{"content":"Чему вы научитесь\nНа этом шаге вы узнаете, как:\nЗапускать службу сигнализации WebRTC с помощью Socket.IO на Node.js Использовать эту службу для обмена метаданными WebRTC между узлами. Полная версия этого шага находится в папке step-05. Поменяйте HTML и JavaScript\nЗамените содержимое index.html следующим:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eRealtime communication with WebRTC\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/css/main.css\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eRealtime communication with WebRTC\u003c/h1\u003e \u003cdiv id=\"videos\"\u003e \u003cvideo id=\"localVideo\" autoplay muted\u003e\u003c/video\u003e \u003cvideo id=\"remoteVideo\" autoplay\u003e\u003c/video\u003e \u003c/div\u003e \u003cscript src=\"/socket.io/socket.io.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://webrtc.github.io/adapter/adapter-latest.js\"\u003e\u003c/script\u003e \u003cscript src=\"js/main.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e Замените js/main.js содержимым из step-05/js/main.js.\nЗапустите Node.js сервер\nЕсли вы не отслеживаете эту codelab из своей папки work, вам может потребоваться установить зависимости для папки step-05 или вашей текущей рабочей папки. Выполните следующую команду из своей рабочей папки: npm install\nПосле установки, если ваш Node.js сервер не запущен, запустите его, вызвав следующую команду в папке work: node index.js\nУбедитесь, что вы используете версию index.js из предыдущего шага, который реализует Socket.IO. Для получения дополнительной информации о Node и Socket.IO, посмотрите раздел “Set up a signaling service to exchange messages”. В вашем браузере откройте localhost:8080.\nСнова откройте localhost: 8080 в новой вкладке или окне. Один видеоэлемент будет отображать локальный поток из getUserMedia(), а другой будет показывать “удаленное” видео, передаваемое через RTCPeerConnection.\nВам необходимо перезапускать Node.js сервер каждый раз, когда вы закрываете клиентскую вкладку или окно. Посмотрите логи в консоли браузера.\nБонусные задания\nЭто приложение поддерживает только видеочат один на один. Как вы можете изменить дизайн, чтобы несколько человек могли посещать одну и ту же комнату видеочата? В примере строго задано имя комнаты foo. Каков наилучший способ включить другие имена комнат? Как пользователям обмениваться названием комнаты? Попробуйте создать альтернативу для обмена именами комнат. Как вы могли бы изменить приложение Что вы узнали\nНа этом шаге вы узнали, как:\nЗапускать сигналинг-службу WebRTC с помощью Socket.IO через Node.js . Использовать эту службу для обмена метаданными WebRTC между узлами. Полная версия этого шага находится в папке step-05. Советы\nСтатистика WebRTC и данные отладки доступны в chrome:// webrtc-internals. test.webrtc.org может использоваться для проверки ваших локальных настроек и тестирования камеры и микрофона. Если у вас возникли странные проблемы с кэшированием, попробуйте следующее: Выполните принудительную перезагрузку обновление, удерживая нажатой клавишу ctrl и нажав кнопку Reload Перезапустите браузер Запустите npm cache clean из командной строки. Далее\nУзнайте, как делать снимки, получать изображения и делиться ими между удаленными узлами.\n","description":"Карманная книга по WebRTC","title":"Соединение однорангового соединения и сигналинга","uri":"/ru/docs/webrtc/practice/practice-peer-signaling-combine/"},{"content":"При написании автоматических тестов для приложений WebRTC, существуют полезные конфигурации, которые можно включить для браузеров, и которые упростят разработку и тестирование.\nChrome При запуске автоматических тестов в Chrome полезны следующие функции:\n–allow-file-access-from-files — дает API-доступ для file://URLs –disable-translate — отключает всплывающие окна –use-fake-ui-for-media-stream — Представляет поддельные медиапотоки. Полезно при работе на CI-серверах. –use-file-for-fake-audio-capture= — дает возможность использовать файл при захвате звука. –use-file-for-fake-video-capture= — дает возможность использовать файл при захвате видео. –headless - Запустить в автономном режиме. Полезно при работе на CI-серверах. –mute-audio - Отключить аудио. Firefox При запуске автоматических тестов в Firefox, необходимо указать набор ключей предпочтений, которые будут использоваться в запущенном соединении. Ниже приведена конфигурация, используемая для автоматических тестов образцов WebRTC:\n\"prefs\": { \"browser.cache.disk.enable\": false, \"browser.cache.disk.capacity\": 0, \"browser.cache.disk.smart_size.enabled\": false, \"browser.cache.disk.smart_size.first_run\": false, \"browser.sessionstore.resume_from_crash\": false, \"browser.startup.page\": 0, \"media.navigator.streams.fake\": true, \"media.navigator.permission.disabled\": true, \"device.storage.enabled\": false, \"media.gstreamer.enabled\": false, \"browser.startup.homepage\": \"about:blank\", \"browser.startup.firstrunSkipsHomepage\": false, \"extensions.update.enabled\": false, \"app.update.enabled\": false, \"network.http.use-cache\": false, \"browser.shell.checkDefaultBrowser\": false } ","description":"Карманная книга по WebRTC","title":"Тестирование приложений WebRTC","uri":"/ru/docs/webrtc/testing/"},{"content":"Необходимые документы:\nЗаявление на имя заведующего кафедрой. В з-и указать название и шифр специальности Монография на иностранном языке. Реферат на русском языке (объем 21-8 стр) по прочитанной лит-ре объемом 300 стр. Реферат, подписанный автором, должен иметь заключения, а также библиографию (список использованной литературы). Глосарий (словарь специальных терминов) - ен менее 300 единиц. Отзыв от научного руководителя или специалиста по данной дисциплине. Содержание экзамена:\nВышеуказанные документы сдаются н а кафедру иностраных яызков за 10 дней до экзамена. Чтение, перевод со (словарем) на руский язык оп специальности оригинального текста. Объем 2500 печ знаков. Время на подготовку 45 мин. Форма проверки - чтение части текста вслух, выборочная проверка подготовленного перевода (Если не выполнен минимум 2тыс знаков - экзамен не продолжается). Чтение (просмотровое без словаря) оригинального газетного публицистического текста по специальности. Объем 2500 печ знаков. Время на подготовку - 5 мин. Форма проверки - передача содержания текста на русском языке (реферирование). Чтение оригинального газетно-публицистического текста без словаря. Объем - 2500 печатных знаков. Время н а подготовку - 15-20 мин. Форма проверки - передача содержания текста на иностранном языке и беседа на иностранном языке по прочитанному тексту. Беседа на иностранном по вопросам, связынным со специальностью и научной работой аспиранта (защита реферата по теме исследования; требования к реферату см. выше) Примечание: вышеуказанные документы иностранных языков за 14 дней до экзамена тексту.\n","description":"Основные требования к кандидатскому экзамену по иностранным языкам","title":"Требования по иностранным языкам","uri":"/ru/docs/disser/canditate-minimum/languages-requirements/"},{"content":"Введение В Hugo по умолчанию используется парсинг markdown файлов. Т.е. мы получаем html код в том виде, как он написан в markdown.\nДля того, чтобы нам понимать какие именно изображения мы можем увеличивать, добавим к этим изображениям отдельный тег/ключ/id\nИнструменты Для реализации функционала нам необходимо:\nнаписать/подключить скрипт/обработчик, который будет выполнять эффект zoomin к нужным нам изображениям Добавить необходимые метаданные к изображениям, чтобы скрипт их смог найти Скрипт zoomin Для добавления возможности увеличивать картинку при нажатии воспользуемся пакетом medium-zoom.\nДанный покет реализовывает данную функциональность в ненагруженном удобном стиле.\nДемо сайт\nЛогика скрипта Скрипт находит изображения с id и так понимает, что нужно применить свойство zoomin к этим изображениям\nВозможные id:\nzoom-default zoom-margin zoom-background zoom-scrollOffset zoom-trigger zoom-detach zoom-center Подключение скриптов Для работы скрипта, нам необходимо подключить логику, а также обработчик.\nВ Hugo в корне проекта есть папка static, которую можно использовать для хранения статических файлов (стиле, скриптов) и использовать для подключения на сайте. Если такой папки нет, то можно создать.\nВ папке static создадим папку zoom-image и добавим в нее 2 скрипта\nstatic/js/zoom-image/index.js const zoomDefault = mediumZoom('#zoom-default') const zoomMargin = mediumZoom('#zoom-margin', { margin: 48 }) const zoomBackground = mediumZoom('#zoom-background', { background: '#212530' }) const zoomScrollOffset = mediumZoom('#zoom-scrollOffset', { scrollOffset: 0, background: 'rgba(25, 18, 25, .9)', }) // Trigger the zoom when the button is clicked const zoomToTrigger = mediumZoom('#zoom-trigger') const button = document.querySelector('#button-trigger') button.addEventListener('click', () =\u003e zoomToTrigger.open()) // Detach the zoom after having been zoomed once const zoomToDetach = mediumZoom('#zoom-detach') zoomToDetach.on('closed', () =\u003e zoomToDetach.detach()) // Observe zooms to write the history const observedZooms = [ zoomDefault, zoomMargin, zoomBackground, zoomScrollOffset, zoomToTrigger, zoomToDetach, ] // Log all interactions in the history const history = document.querySelector('#history') observedZooms.forEach(zoom =\u003e { zoom.on('open', event =\u003e { const time = new Date().toLocaleTimeString() history.innerHTML += `\u003cli\u003eImage \"\u003cem\u003e${event.target.alt }\u003c/em\u003e\" was zoomed at ${time}\u003c/li\u003e` }) zoom.on('detach', event =\u003e { const time = new Date().toLocaleTimeString() history.innerHTML += `\u003cli\u003eImage \u003cem\u003e\"${event.target.alt }\"\u003c/em\u003e was detached at ${time}\u003c/li\u003e` }) }) static/js/zoom-image/placeholders.js // Show placeholders for paragraphs const paragraphs = [].slice.call(document.querySelectorAll('p.placeholder')) paragraphs.forEach(paragraph =\u003e { // eslint-disable-next-line no-param-reassign paragraph.innerHTML = paragraph.textContent .split(' ') .filter(text =\u003e text.length \u003e 4) .map(text =\u003e `\u003cspan class=\"placeholder__word\"\u003e${text}\u003c/span\u003e`) .join(' ') }) CDN скрипт Скрипт можно скачать, а можно подгружать\nСсылка на скрипт\nДобавление в шаблон Для того, чтобы данные скрипты работали в шаблоне сайта, их необходимо подключить.\nЯ использую для этого шаблон baseof.html. Просто добавляю ссылки на скрипта в body шаблона.\n# baseof.html ... \u003c/footer\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js\" defer\u003e\u003c/script\u003e \u003cscript src=\"/js/zoom-image/placeholders.js\" defer\u003e\u003c/script\u003e \u003cscript src=\"/js/zoom-image/index.js\" defer\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ID изображения Hugo позволяет изменить поведение при парсинге markdown файлов с помощью хуков. Подробнее о рендер-хуках можно прочитать на сайте.\nВ папке *layouts\nДобавим файл render-image.html по следующему пути layouts -\u003e _default -\u003e _markup код файла:\n\u003cp class=\"md__image\"\u003e \u003cimg src=\"{{ .Destination | safeURL }}\" id=\"zoom-default\" alt=\"{{ .Text }}\" {{ with .Title}} title=\"{{ . }}\" {{ end }} /\u003e \u003c/p\u003e Мы добавили только id=\"zoom-default\" в код по умолчанию\nИтоги Your browser does not support the video tag. Процесс ","description":"Добавляем скрипт, который будет увеличивать картинку в статье при нажатии","title":"Увеличение картинки по нажатию в Hugo","uri":"/ru/posts/hugo-add-image-zoomin/"},{"content":"Начало работы с удаленными потоками Как только RTCPeerConnection подключился к удаленному узлу, между ними можно передавать аудио- и видео-потоки. Это точка, в которой мы подключаем поток, полученный от getUserMedia(), к RTCPeerConnection. Медиаопоток состоит как минимум из одной дорожки мультимедиа, и они по отдельности добавляются в RTCPeerConnection, когда мы хотим передать данные удаленному узлу.\nconst localStream = await getUserMedia({vide: true, audio: true}); const peerConnection = new RTCPeerConnection(iceConfig); localStream.getTracks().forEach(track =\u003e { peerConnection.addTrack(track, localStream); }); Дорожки можно добавлять в RTCPeerConnection до подключения к удаленному узлу, поэтому имеет смысл выполнить эту настройку как можно раньше, а не ждать завершения соединения.\nДобавление удаленных дорожек Для получения удаленных дорожек, которые были добавлены другим узлом, мы регистрируем «прослушиватель» на локальном RTCPeerConnection, отслеживая изменения в событии track. RTCTrackEvent содержит массив объектов MediaStream, которые имеют те же значения MediaStream.id, что и соответствующие локальные потоки узла. В нашем примере каждая дорожка связана только с одним потоком.\nОбратите внимание, что, хотя ID из MediaStream совпадают на обеих сторонах однорангового соединения, в общем случае это не работает для ID MediaStreamTrack.\nconst remoteVideo = document.querySelector('#remoteVideo'); peerConnection.addEventListener('track', async (event) =\u003e { const [remoteStream] = event.streams; remoteVideo.srcObject = remoteStream; }); ","description":"Карманная книга по WebRTC","title":"Удаленные потоки","uri":"/ru/docs/webrtc/remote-streams/"},{"content":"Red Hat Enterprise Linux 9 (RHEL 9) под кодовым названием Plow стал общедоступным (GA). Компания Red Hat объявила об этом 18 мая 2022 года. Она сменила бета-версию, которая существовала с 3 ноября 2021 года.\nRHEL 9 - это несколько первых релизов в семействе Red Hat. Это первый крупный релиз после приобретения Red Hat компанией IBM в июле 2019 года, а также первая крупная версия после отказа от проекта CentOS в пользу CentOS Stream, который теперь является предшественником RHEL.\nRHEL 9 является последней основной версией RHEL и поставляется с ядром 5.14, множеством новых пакетов программного обеспечения и массой усовершенствований. В ней особое внимание уделяется безопасности, стабильности, гибкости и надежности.\nОписание RHEL 9 поставляется с новыми версиями программного обеспечения, включая Python 3.9. Node.JS 16, GCC 11, Perl 5.32, Ruby 3.0, PHP 8.0 и многие другие.\nПодготовка к установке Регистрация на портале Red Hat Подписка Red Hat Developer Subscription - это бесплатное предложение программы Red Hat Developer, предназначенное для индивидуальных разработчиков, которые хотят воспользоваться всеми преимуществами Red Hat Enterprise Linux.\nОна дает разработчикам доступ ко всем версиям Red Hat Enterprise Linux, а также к другим продуктам Red Hat, таким как дополнения, обновления программного обеспечения и ошибки безопасности.\nПрежде всего, убедитесь, что у вас есть активная учетная запись Red Hat. Если у вас еще нет учетной записи, перейдите на портал Red Hat Customer Portal, нажмите на кнопку “Регистрация” и заполните свои данные для создания учетной записи Red Hat. Загрузка установочного образа После создания учетной записи Red Hat вы можете приступать к загрузке RHEL 9. Чтобы загрузить Red Hat Enterprise Linux 9 абсолютно бесплатно, зайдите на Red Hat Developer Portal и войдите в систему, используя учетные данные своей учетной записи. Затем перейдите на страницу загрузки RHEL 9 и нажмите на кнопку загрузки, показанную ниже.\nЯ использую MacBook M1, поэтому скачиваю образ RHEL 9 для M1 процессора aarch64 Виртуальная машина В качестве вирутальной машины для установки RHEL 9 использую бесплатную виртуальную машину UTM. Установить можно с помощью Homebrew, выполнив команду brew install --cask utm.\nУстановка Red Hat Enterprise Linux 9 Настройка виртуальной машины UTM В UTM нажимаем Create a New Virtual Machine -\u003e Virtualize Выбираем скачанный образ RHEL 9 и нажимаем Continue Главное меню Помеченные поля необходимо заполнить\nСоздаем Root Password User Creation. Создаем пользователя, под которым будет осуществляться вход в систему. Connect to Red Hat. Здесь используем учетную запись, созданную выше.\nВводим данные аккаунта, нажимаем Register Нажимаем Done\nВ разделе Installation Destination выбираем диск по умолчанию\nТеперь можем продолижть установку. На главном экране появилась кнопка Begin installation\nПосле завершения установки перезагружаем систему. Иногда после перезагрузки запускается загрузка с установочного образа опять. Неоьбходимо либо отключить диск в настройка вирутальной машины либо перезагрузить UTM.\nЗапуск Red Hat Enterprise Linux 9 Вводим пароль и видим рабочий стол RHEL 9 Для доступа к приложениям нажимаем кнопку Activities в верхнем левом углу\nНастройка Red Hat Enterprise Linux 9 Проверка пользователя ROOT В системе Linux пользователи относятся к разным группам, у которых есть определенные права. Если в процессе установки мы не поставили галку сделать пользователя администратором, то по умолчанию он не сможет устанавливать некоторые системные программы.\nВыходим из системы и заходим в систему под пользователем root (тем самым, которого создавали ранее на главном экране). Нажимаем Log out Теперь входим под root. Пользователя может не быть в списке. Жмем Not listed и вводим данные аккаунта. Открываем терминал и проверяем Настройка параметров системы Кнопки сворачивания приложения Первое, что кажется непривычным при использовании GUI, отсутствие кнопок сворачивания окон Устанавливаем необходимый пакет\nyum install gnome-tweaks -y После установки появится приложение Tweaks. Найдем его через поиск. В приложении множество и других настроек. Мы отобразим кнопки сворачивания приложений.\nИдем в раздел Windows titlebars и включаем параметры Maximize, Minimize Доступ пользователю на установку приложений Чтобы постоянно не переключаться на root пользователя для устновки приложений, мы можем предоставить обычному пользвоателю доступ к установке приложений. Действия продолжаем делать под пользователем root. Открываем файл /etc/sudoers и добавляем пользователя\nsudo vi /etc/sudoers Добавляем в конец файла данные пользователя. Имя моего пользователя: rhel-user\nrhel-user ALL= NOPASSWD: /usr/sbin/synaptic, /usr/bin/software-center, /usr/bin/apt-get, /usr/bin/dnf Установим Visual Studio Code под обычным пользователем Установка состоит из следующих шагов:\nдобавление нужного репозитория. Права на добавление репозитория (изменение файлов в директории по прежнему только у root пользователя) загрузка и Установка Первый шаг делаем под пользователем root Идем на сайт https://code.visualstudio.com/docs/setup/linux\nКопируем код и запускаем в терминале\nsudo rpm --import https://packages.microsoft.com/keys/microsoft.asc sudo sh -c 'echo -e \"[code]\\nname=Visual Studio Code\\nbaseurl=https://packages.microsoft.com/yumrepos/vscode\\nenabled=1\\ngpgcheck=1\\ngpgkey=https://packages.microsoft.com/keys/microsoft.asc\" \u003e /etc/yum.repos.d/vscode.repo' Переключаемся на пользователя rhel-user. Это можно сделать и в терминале. Обновим репозитории Установим VSCode su rhel-user dnf check-update sudo dnf install code Ссылки https://developers.redhat.com/products/rhel/getting-started https://www.redhat.com/sysadmin/install-linux-rhel-9 ","description":"Скачать и установить Linux RHEL 9 бесплатно","title":"Установка Linux RHEL 9","uri":"/ru/posts/howto-install-rhel-9-free/"},{"content":"Ubuntu - одна из популярных Linux систем и достаточно много обзоров по установке Ubuntu. В этой статье мы будем устанавливать образ Ubuntu для ARM процессора на виртуальную машину UTM. Вся установка будет проходить на Mac OS.\nЗагрузка установочного образа На сайте Ubuntu доступен для скачивания только образ Ubuntu Server ARM версии 22.04 - без графического интерфейса. Но можно скачать обновленный релиз Ubuntu Desktop для ARM - Daily Build по ссылке.\nНаходим 64-bit ARM (ARMv8/AArch64) desktop image и скачиваем Виртуальная машина В качестве виртуальной машины для установки RHEL 9 использую бесплатную виртуальную машину UTM. Установить можно с помощью Homebrew, выполнив команду brew install --cask utm.\nУстановка Ubuntu Desktop Настройка виртуальной машины UTM В UTM нажимаем Create a New Virtual Machine -\u003e Virtualize Выбираем скачанный образ и нажимаем Continue, далее оставляем опции по умолчанию Запуск Live версии Выбираем Try or Install Ubuntu. Запустится live образ ubuntu. Такой образ не сохраняет свое состояние после перезагрузки. Входим под пользователем ubuntu\nВидим рабочий стол и можем пользоваться.\nУстановка Внизу справа есть ярлык для стандартной установки Ubuntu. Нажимаем и запускаем обычную установку на диск. Выбираем нужный язык Я выбираю минимальную установку, т.к. мне не нужны будут предустановленные игры и прочие приложения. Графический интерфейс, браузер, терминал остается со всеми базовыми настройками. Оставляем по умолчанию стирание виртуального диска перед установкой Создаем пользователя, под которым будем входить в систему Как только установка закончится, нажимаем Restart. У меня после перезагрузки черный экран. Поэтому я просто закрываю и снова запускаю вирутальную машину.\nВход в систему После запуска системы выбираем *Boot from next volume. Первым по умолчанию будет запуск с вирутального образа, но у нас уже есть система на диске, поэтому выбираем запуск со следующего по очереди диска. Входим под своим пользователем Система предлагает скачать обновления для системы. Нажимаю установить. Теперь можно пользоваться системой и все данные будут сохраняться после перезагрузки. Ссылки Kinetic Kudu Release Schedule ","description":"Быстрая базовая установка Ubuntu Desktop 22.10 на виртуальную машину UTM с процессором ARM M1","title":"Установка Ubuntu Desktop 22.10 (Kinetic Kudu) на ARM CPU","uri":"/ru/posts/howto-install-ubuntu-desktop-on-arm/"},{"content":"Google планирует перевести реализацию WebRTC в Chrome с текущего SDP-формата (называемого «Plan B») на формат соответствующих стандартов («Unified Plan», draft-ietf-rtcweb-jsep) в течение следующих нескольких кварталов. План включает 5 этапов и одну временную функцию API.\nКто будет затронут? Людям, которые используют несколько аудиодорожек или несколько видеодорожек в одном PeerConnection, придется протестировать свой продукт в рамках Унифицированного Плана и, соответственно, адаптироваться. В случае, когда вызов инициируется с конечной точки не из Chrome, и на него отвечают в Chrome, форма запросов может измениться.\nЛюдям, выполняющим детальный анализ SDP и заботящимся о msid атрибутах, придется убедиться, что их код синтаксического анализа поддерживает новый формат (a=msid). Подробная информация о том, потребуются ли изменения и как должны измениться приложения, будет зависеть от приложения. Мы думаем, что почти все приложения, которые используют только одну аудио- и одну видеодорожку для каждого RTCPeerConnection, - их эти изменения не коснутся.\nФункция API Мы добавляем новую функцию в RTCConfiguration RTCPeerConnection:\nenum SdpSemantics { \"plan-b\", \"unified-plan\" }; partial dictionary RTCConfiguration { SdpSemantics sdpSemantics; } RTCConfiguration может быть передана конструктору из RTCPeerConnection, и все запросы и ответы будут в формате Унифицированного Плана. Запросы в setLocalDescription и setRemoteDescription также будут ожидать, что SDP будет в формате Унифицированного Плана; если он в устаревшем формате Chrome, то все, кроме первой звуковой дорожки и первой видеодорожки, будут игнорироваться.\nТакже есть флаг командной строки (–enable-features=RTCUnifiedPlanByDefault в версии Chrome M71 и выше, –enable-blink-features=RTCUnifiedPlanByDefault в более ранних версиях), который позволяет установить для этого флага значение по умолчанию в «Unified-plan».\nЭтапы Этап 1. Внедрение Унифицированного Плана На этом этапе Унифицированный План разрабатывался под флагом экспериментов, доступным с версии M65. До этапа 2 разумнее всего было тестировать Chrome Canary, используя «–enable-blink-features=RTCUnifiedPlan».\nЭтап 2. Сделать функцию API общедоступной Представлено в версии M69 (бета-август 2018 г., стабильная версия в сентябре 2018 г.)\nНа этом этапе значением по умолчанию флага sdpSemantics было «plan-b». На этапе 2 люди, у которых были реализации, зависящие от формата SDP, должны были протестировать, работают ли их приложения при использовании Унифицированного Плана. Для приложений, поддерживающих Firefox, это очень простое упражнение: просто делайте то же, что делали до этого в Firefox. Значение по умолчанию флага sdpSemantics можно изменить в «chrome://flags»; найдите функцию «WebRTC: Use Unified Plan SDP Semantics by default».\nЭтап 3 Переключите значение по умолчанию Датой перехода была версия M72 (бета-декабрь 2018 г., стабильная версия — январь 2019 г.). На этом этапе было изменено значение флага sdpSemantics по умолчанию на «unified plan». Приложения, которые обнаружили, что стали работать медленнее, переустановили флаг sdpSemantics в «plan-b», чтобы вернуться к предыдущему поведению.\nЭтап 4: бросьте «План Б» На этом этапе установка флага sdpSemantics в значение «plan-b» приводит к возникновению исключения. Это было сделано при переходе от версии Canary к M93. Что касается M96, исключение работает как в Canary, так и на Beta. План состоит в том, чтобы добавить его и в стабильную версию. Мы следим за использованием Plan B. На этом этапе доступна пробная версия, которая позволяет использовать план Б без создания исключений. Эта пробная версия перестала работать 29 декабря 2021 г.\nЭтап 5: Уберите «План Б» После окончания пробного периода Plan B будет удален из Chrome. На этом этапе флаг sdpSemantics будет удален. Попытка установить его на «plan-b» не вызовет исключение, и перестанет работать.\n","description":"Карманная книга по WebRTC","title":"Формат SDP унифицированного плана – план перехода","uri":"/ru/docs/webrtc/unified-plan-transition-guide/"},{"content":"В первой части мы изучим основы языка программирования Python. Этот раздел книги должен подготовить вас к использованию всех строительных блоков Python, чтобы вы были готовы уверенно взяться за следующие разделы.\nДавайте рассмотрим, что мы будем изучать:\nIDLE Строки Списки, словари и кортежи Условные операторы Циклы Генераторы Обработка исключений Файловый ввод-вывод Импорт модулей и пакетов Функции Классы В первой главе этого раздела вы познакомитесь со встроенной средой разработки Python, которая называется IDLE. В следующих двух главах мы рассмотрим некоторые типы Python, такие как строки, списки и словари. После этого мы рассмотрим условные операторы в Python и такие циклы Python как for и while.\nВо второй половине этого раздела мы рассмотрим генераторы, такие как генераторы списков и словарей. Затем мы рассмотрим возможности Python по обработке исключений и работу Python с файлами. Далее мы узнаем, как импортировать готовые модули и пакеты. Последние две главы посвящены функциям и классам Python.\n","description":"Python 101","title":"Часть I - Основы","uri":"/ru/docs/python101/01-part_i/"},{"content":"Во второй части вы получите сокращенное описание некоторых разделов стандартной библиотеки Python. Причина такого сокращения в том, что стандартная библиотека Python огромна! Поэтому этот раздел предназначен для того, чтобы вы познакомились с использованием модулей, поставляемых вместе с Python. Я расскажу о модулях, которые я чаще всего использую в своей повседневной работе, а также о тех, которые используют мои коллеги. Я думаю, что этот мини-тур подготовит вас к самостоятельной работе.\nЧто мы будем изучать:\ncsv ConfigParser logging os smtplib / email subprocess sys thread / queues time / datetime Далее мы научимся использовать ConfigParser, небольшой модуль, позволяющий читать и записывать файлы конфигурации. После этого мы рассмотрим logging. Модуль os может делать много интересных вещей, но мы постараемся сосредоточиться на тех, которые, как мне кажется, будут наиболее полезными. subprocess позволяет открывать другие процессы.\nМодуль sys позволяет завершить программу, получить путь к Python, получить информацию о версии, перенаправить stdout и многое другое. Модуль thread позволяет создавать потоки в вашей программе. Мы не будем слишком углубляться в эту тему, так как она может быстро запутаться.\nМодули time и datetime позволяют манипулировать датами и временем в Python, что имеет множество применений при разработке программ.\n","description":"Python 101","title":"Часть II - Стандартные модули","uri":"/ru/docs/python101/02-part_ii/"},{"content":"В третьей части вы узнаете о некоторых внутренних компонентах Python, которые многие относят к владению Python среднего уровня. Вы перешли от молока и готовы к мясу! В этой части мы рассмотрим следующие темы:\nОтладка Декораторы Оператор лямбда Профилирование кода Тестирование В первой главе этого раздела вы познакомитесь с модулем отладки Python, pdb, и узнаете, как использовать его для отладки кода. Следующая глава посвящена декораторам. Вы узнаете о том, как их создавать, и о некоторых декораторах, встроенных в Python. В третьей главе мы рассмотрим оператор лямбда, который, по сути, создает однострочную анонимную функцию. Это немного странно, но весело! В четвертой главе речь пойдет о том, как профилировать свой код. Эта дисциплина дает вам возможность найти возможные узкие места в вашем коде, чтобы вы знали, на чем сосредоточиться для оптимизации кода. Последняя глава этого раздела посвящена тестированию кода. В ней вы узнаете, как тестировать свой код с помощью нескольких встроенных модулей Python.\nЯ думаю, что вы найдете этот раздел очень полезным для продолжения вашего обучения Python.\n","description":"Python 101","title":"Часть III - Промежуточные вопросы и ответы","uri":"/ru/docs/python101/03-part_iii/"},{"content":"В части IV вы узнаете, как устанавливать пакеты сторонних разработчиков из Python Package Index (PyPI). Вы узнаете немного о easy_install, pip и setup.py* и о том, как использовать эти инструменты для установки пакетов. Однако это только первая глава. Вот список пакетов, о которых вы узнаете:\nconfigobj - работа с файлами Config более “питоническим” способом. lxml - пакет для работы с XML pylint / pyflakes - анализаторы кода Python requests - версия urllib для работы с Python SQLAlchemy - объектно-реляционный маппер для Python virtualenv - узнайте о виртуальных средах в Python Мы будем рассматривать configobj, потому что я считаю, что он работает лучше, чем ConfigParser, модуль, поставляемый вместе с Python. Пакет configobj имеет более интуитивный и мощный интерфейс, чем ConfigParser. В следующей главе мы рассмотрим модуль lxml и узнаем несколько новых способов чтения, разбора и создания XML. В четвертой главе мы рассмотрим pylint и pyflakes, которые отлично подходят для анализа кода. Они могут посмотреть на ваш модуль и проверить его на наличие ошибок. pylint также можно использовать для приведения вашего кода в соответствие с PEP8, руководством по стилю Python.\nПакет requests - отличная замена модулю urllib. Его интерфейс проще, а документация довольно хорошая. SQLAlchemy - это лучший объектно-реляционный маппер для Python. Он позволяет писать SQL-запросы, таблицы и т.д. в коде Python. Одна из его лучших особенностей заключается в том, что если вам понадобится сменить бэкенд базы данных, вам не придется сильно менять свой код, чтобы продолжать работать с этой базой данных. В последней главе мы рассмотрим virtualenv - удобный модуль, позволяющий создавать мини-виртуальные среды, в которых вы можете писать свой код. Эти виртуальные среды особенно удобны для тестирования новых модулей или просто новых выпусков модулей, прежде чем вы примените их к своей основной установке Python.\n","description":"Python 101","title":"Часть IV - Советы, приемы и учебные пособия","uri":"/ru/docs/python101/04-part_iv/"},{"content":"В части V вы узнаете об упаковке Python и различных методах распространения вашего кода. Вы узнаете о следующем:\nКак создать модуль и пакет Публикация пакетов в Python Packaging Index (PyPI) Python eggs Python wheels py2exe bb_freeze cx_Freeze PyInstaller GUI2Exe Как создать инсталлятор с помощью InnoSetup В первой главе этого раздела описано, как создать модуль или пакет. Затем, в следующей главе, мы рассмотрим публикацию нашего пакета в PyPI. Далее мы узнаем, как создать и установить Python egg и Python wheel.\nВ следующих четырех главах мы рассмотрим, как создавать двоичные файлы с помощью следующих пакетов сторонних разработчиков: py2exe, bb_freeze, cx_Freeze и PyInstaller. Единственный пакет в этом списке, который действительно совместим с Python 3 - это cx_Freeze.\nВ предпоследней главе мы покажем вам, как использовать GUI2Exe, небольшой аккуратный пользовательский интерфейс, который был создан для работы поверх py2exe, bb_freeze и др. GUI2Exe делает создание двоичных файлов еще проще!\nВ последней главе этого раздела будет показано, как создать программу установки с помощью InnoSetup. Давайте приступим!\n","description":"Python 101","title":"Часть V - Упаковка и распространение","uri":"/ru/docs/python101/05-part_v/"},{"content":"Инфа СОХНУТ - Еврейское агентство для Израиля, — международная сионистская организация с центром в государстве Израиль, которая занимается репатриацией в Израиль и помощью репатриантам.\nhttps://www.jewishagency.org/ru/\nМинистерства алии и интеграции тел. *2994 или 03-9733333\nСсылки Чаты, где спрашивать:\nhttps://t.me/OlimHadashim https://t.me/olehadash_com_chat https://t.me/forum_israel Няни, частные учителя, частные школы и садики в Израиле. https://www.facebook.com/groups/Nyani.Uchitelya.Shkoli.Israel\nASD в Израиле. Все о детях в спектре и их родителях https://www.facebook.com/groups/asdisraelrus\nМамочки Израиля https://www.facebook.com/groups/1524467887858435\nРепатрианты в Израиле: здесь помогают и делятся опытом https://www.facebook.com/groups/1511311149184796\nОТДАМ ДАРОМ В ИЗРАИЛЕ https://www.facebook.com/groups/1601685156757272\nДругие инструкции\nhttps://olehadash.com/\nВторичка:\nhttps://t.me/BROOTTO\nРассчет налога по зарплате\nПервая неделя Сначала получить симкарту, все уведомления на нее. Брать любую, тариф в среднем около 30-40 шек мес\nБанк\nоткрыть счет (леуми или дисконт)\nсразу запросить чеки (нужны для аренды квартиры и мало ли на что еще, стоят около 10шек)\nсамую дешевую карту, без всяких плат попросить.\nБольничаная касса\nвзял маккаби, вроде все примерно одинаковые но у маккаби больше покрытия, может чуть подороже она\nПодработки Форма для добавления в базу резюме или на поиск работы: https://forms.gle/NFB2JXs1fHrCJn5Q7\nРасчет налога на зарплату: https://investomatica.com/income-tax-calculator/israel\nЧто спрашивают и какие документы нужны, и как с оплатой\nhttps://t.me/joinchat/DlAMLxN_S-XCXgJ8MQxslg https://t.me/Rus_Work_Israel https://t.me/izrail_rabota https://t.me/sidejobisrael https://t.me/rabotadlyadruzei https://t.me/rabotaisraeli ","description":"репатриация в Израиль","title":"Чеклист репатриация в Израиль","uri":"/ru/p/%D1%80%D0%B5%D0%BF%D0%B0%D1%82%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D1%8F/"},{"content":"Кратко Создать:\ntar cf archive.tar directory Распаковать:\ntar xf archive.tar Создание mkdir my_dir # Создаем папку tar cf dir_archive.tar my_dir # Создаем архив с папкой ll # Проверяем содержимое текущего каталога # -rw-r--r-- 1 r staff 1.5K Jun 4 14:42 dir_archive.tar # drwxr-xr-x 2 r staff 64B Jun 4 14:42 my_dir Распаковка tar xf dir_archive.tar Сжатие tar czf dir_archive.tar.gz dir_archive.tar Распаковка сжатого файла tar xzf dir_archive.tar.gz Сжатие с помощью bzip2 tar cjf dir_archive.tar.bz2 my_dir Распаковка с помощью bzip2 tar xjf dir_archive.tar.bz2 Просмотр содержимого архива tar -tvf dir_archive.tar ","description":"Необходимые команды для работы с архиватором tar","title":"Шпаргалка tar архиватор","uri":"/ru/posts/cheat-sheet-command-tar/"}]